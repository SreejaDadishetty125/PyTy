[
  {
    "project": "PyTorchLightning/metrics",
    "commit": "2c528bdc1d0e5c292c769227e127aad559b3dd21",
    "filename": "torchmetrics/classification/accuracy.py",
    "min_patch_found": false,
    "full_warning_msg": "torchmetrics/classification/accuracy.py:247:16 Incompatible parameter type [6]: Expected `str` for 4th parameter `mdmc_reduce` to call `_accuracy_update` but got `Optional[str]`.",
    "exception": "PatchSet should only have 1 Patch, but it has 0",
    "dd_fail": true
  },
  {
    "project": "PyTorchLightning/metrics",
    "commit": "2c528bdc1d0e5c292c769227e127aad559b3dd21",
    "filename": "torchmetrics/classification/accuracy.py",
    "min_patch_found": false,
    "full_warning_msg": "torchmetrics/classification/accuracy.py:275:63 Incompatible parameter type [6]: Expected `str` for 6th positional only parameter to call `_accuracy_compute` but got `Optional[str]`.",
    "exception": "PatchSet should only have 1 Patch, but it has 0",
    "dd_fail": true
  },
  {
    "project": "PyTorchLightning/metrics",
    "commit": "2c528bdc1d0e5c292c769227e127aad559b3dd21",
    "filename": "torchmetrics/classification/average_precision.py",
    "min_patch_found": false,
    "full_warning_msg": "torchmetrics/classification/average_precision.py:128:75 Incompatible parameter type [6]: Expected `int` for 4th positional only parameter to call `_average_precision_compute` but got `Optional[int]`.",
    "exception": "PatchSet should only have 1 Patch, but it has 0",
    "dd_fail": true
  },
  {
    "project": "PyTorchLightning/metrics",
    "commit": "2c528bdc1d0e5c292c769227e127aad559b3dd21",
    "filename": "torchmetrics/classification/precision_recall_curve.py",
    "min_patch_found": false,
    "full_warning_msg": "torchmetrics/classification/precision_recall_curve.py:148:80 Incompatible parameter type [6]: Expected `int` for 4th positional only parameter to call `_precision_recall_curve_compute` but got `Optional[int]`.",
    "exception": "PatchSet should only have 1 Patch, but it has 0",
    "dd_fail": true
  },
  {
    "project": "PyTorchLightning/metrics",
    "commit": "2c528bdc1d0e5c292c769227e127aad559b3dd21",
    "filename": "torchmetrics/classification/roc.py",
    "min_patch_found": false,
    "full_warning_msg": "torchmetrics/classification/roc.py:168:61 Incompatible parameter type [6]: Expected `int` for 4th positional only parameter to call `_roc_compute` but got `Optional[int]`.",
    "exception": "PatchSet should only have 1 Patch, but it has 0",
    "dd_fail": true
  },
  {
    "project": "PyTorchLightning/metrics",
    "commit": "2c528bdc1d0e5c292c769227e127aad559b3dd21",
    "filename": "torchmetrics/functional/classification/accuracy.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/PyTorchLightning-metrics/torchmetrics/functional/classification/accuracy.py",
    "file_hunks_size": 3,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "torchmetrics/functional/classification/accuracy.py:294:31 Incompatible parameter type [6]: Expected `str` for 4th positional only parameter to call `_accuracy_update` but got `Optional[str]`.",
    "message": " Expected `str` for 4th positional only parameter to call `_accuracy_update` but got `Optional[str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 294,
    "warning_line": "        preds, target, reduce, mdmc_average, threshold, num_classes, top_k, multiclass, ignore_index, mode"
  },
  {
    "project": "PyTorchLightning/metrics",
    "commit": "2c528bdc1d0e5c292c769227e127aad559b3dd21",
    "filename": "torchmetrics/functional/classification/accuracy.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/PyTorchLightning-metrics/torchmetrics/functional/classification/accuracy.py",
    "file_hunks_size": 3,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "torchmetrics/functional/classification/accuracy.py:296:54 Incompatible parameter type [6]: Expected `str` for 6th positional only parameter to call `_accuracy_compute` but got `Optional[str]`.",
    "message": " Expected `str` for 6th positional only parameter to call `_accuracy_compute` but got `Optional[str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 296,
    "warning_line": "    return _accuracy_compute(tp, fp, tn, fn, average, mdmc_average, mode)"
  },
  {
    "project": "PyTorchLightning/metrics",
    "commit": "2c528bdc1d0e5c292c769227e127aad559b3dd21",
    "filename": "torchmetrics/functional/classification/auroc.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/PyTorchLightning-metrics/torchmetrics/functional/classification/auroc.py",
    "file_hunks_size": 5,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "torchmetrics/functional/classification/auroc.py:83:31 Incompatible parameter type [6]: Expected `typing_extensions.SupportsIndex` for 1st positional only parameter to call `range.__init__` but got `Optional[int]`.",
    "message": " Expected `typing_extensions.SupportsIndex` for 1st positional only parameter to call `range.__init__` but got `Optional[int]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 83,
    "warning_line": "                for i in range(num_classes)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "            fpr, tpr, _ = roc(preds.flatten(), target.flatten(), 1, pos_label, sample_weights)\n        else:\n            # for multilabel we iteratively evaluate roc in a binary fashion\n",
        "source_code_len": 186,
        "target_code": "            fpr, tpr, _ = roc(preds.flatten(), target.flatten(), 1, pos_label, sample_weights)\n        elif num_classes:\n            # for multilabel we iteratively evaluate roc in a binary fashion\n",
        "target_code_len": 198,
        "diff_format": "@@ -78,3 +78,3 @@\n             fpr, tpr, _ = roc(preds.flatten(), target.flatten(), 1, pos_label, sample_weights)\n-        else:\n+        elif num_classes:\n             # for multilabel we iteratively evaluate roc in a binary fashion\n",
        "source_code_with_indent": "            <IND>fpr, tpr, _ = roc(preds.flatten(), target.flatten(), 1, pos_label, sample_weights)\n        <DED>else:\n            # for multilabel we iteratively evaluate roc in a binary fashion\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "            <IND>fpr, tpr, _ = roc(preds.flatten(), target.flatten(), 1, pos_label, sample_weights)\n        <DED>elif num_classes:\n            # for multilabel we iteratively evaluate roc in a binary fashion\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "            tpr = [o[1] for o in output]\n    else:\n        if mode != 'binary' and num_classes is None:\n            raise ValueError('Detected input to ``multiclass`` but you did not provide ``num_classes`` argument')\n        fpr, tpr, _ = roc(preds, target, num_classes, pos_label, sample_weights)\n",
        "source_code_len": 299,
        "target_code": "            tpr = [o[1] for o in output]\n        else:\n            raise ValueError('Detected input to be `multilabel` but you did not provide `num_classes` argument')\n    else:\n        if mode != 'binary' and num_classes is None:\n            raise ValueError('Detected input to `multiclass` but you did not provide `num_classes` argument')\n        fpr, tpr, _ = roc(preds, target, num_classes, pos_label, sample_weights)\n",
        "target_code_len": 422,
        "diff_format": "@@ -86,5 +86,7 @@\n             tpr = [o[1] for o in output]\n+        else:\n+            raise ValueError('Detected input to be `multilabel` but you did not provide `num_classes` argument')\n     else:\n         if mode != 'binary' and num_classes is None:\n-            raise ValueError('Detected input to ``multiclass`` but you did not provide ``num_classes`` argument')\n+            raise ValueError('Detected input to `multiclass` but you did not provide `num_classes` argument')\n         fpr, tpr, _ = roc(preds, target, num_classes, pos_label, sample_weights)\n",
        "source_code_with_indent": "            tpr = [o[1] for o in output]\n    <DED><DED>else:\n        <IND>if mode != 'binary' and num_classes is None:\n            <IND>raise ValueError('Detected input to ``multiclass`` but you did not provide ``num_classes`` argument')\n        <DED>fpr, tpr, _ = roc(preds, target, num_classes, pos_label, sample_weights)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "            tpr = [o[1] for o in output]\n        <DED>else:\n            <IND>raise ValueError('Detected input to be `multilabel` but you did not provide `num_classes` argument')\n    <DED><DED>else:\n        <IND>if mode != 'binary' and num_classes is None:\n            <IND>raise ValueError('Detected input to `multiclass` but you did not provide `num_classes` argument')\n        <DED>fpr, tpr, _ = roc(preds, target, num_classes, pos_label, sample_weights)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "PyTorchLightning/metrics",
    "commit": "2c528bdc1d0e5c292c769227e127aad559b3dd21",
    "filename": "torchmetrics/functional/classification/dice.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/PyTorchLightning-metrics/torchmetrics/functional/classification/dice.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "torchmetrics/functional/classification/dice.py:101:4 Incompatible variable type [9]: bg is declared to have type `bool` but is used as type `int`.",
    "message": " bg is declared to have type `bool` but is used as type `int`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 101,
    "warning_line": "    bg = (1 - int(bool(bg)))",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    num_classes = preds.shape[1]\n    bg = (1 - int(bool(bg)))\n    scores = torch.zeros(num_classes - bg, device=preds.device, dtype=torch.float32)\n    for i in range(bg, num_classes):\n        if not (target == i).any():\n            # no foreground class\n            scores[i - bg] += no_fg_score\n            continue\n",
        "source_code_len": 317,
        "target_code": "    num_classes = preds.shape[1]\n    bg_inv = (1 - int(bg))\n    scores = torch.zeros(num_classes - bg_inv, device=preds.device, dtype=torch.float32)\n    for i in range(bg_inv, num_classes):\n        if not (target == i).any():\n            # no foreground class\n            scores[i - bg_inv] += no_fg_score\n            continue\n",
        "target_code_len": 327,
        "diff_format": "@@ -100,8 +100,8 @@\n     num_classes = preds.shape[1]\n-    bg = (1 - int(bool(bg)))\n-    scores = torch.zeros(num_classes - bg, device=preds.device, dtype=torch.float32)\n-    for i in range(bg, num_classes):\n+    bg_inv = (1 - int(bg))\n+    scores = torch.zeros(num_classes - bg_inv, device=preds.device, dtype=torch.float32)\n+    for i in range(bg_inv, num_classes):\n         if not (target == i).any():\n             # no foreground class\n-            scores[i - bg] += no_fg_score\n+            scores[i - bg_inv] += no_fg_score\n             continue\n",
        "source_code_with_indent": "    num_classes = preds.shape[1]\n    bg = (1 - int(bool(bg)))\n    scores = torch.zeros(num_classes - bg, device=preds.device, dtype=torch.float32)\n    for i in range(bg, num_classes):\n        <IND>if not (target == i).any():\n            # no foreground class\n            <IND>scores[i - bg] += no_fg_score\n            continue\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    num_classes = preds.shape[1]\n    bg_inv = (1 - int(bg))\n    scores = torch.zeros(num_classes - bg_inv, device=preds.device, dtype=torch.float32)\n    for i in range(bg_inv, num_classes):\n        <IND>if not (target == i).any():\n            # no foreground class\n            <IND>scores[i - bg_inv] += no_fg_score\n            continue\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "PyTorchLightning/metrics",
    "commit": "2c528bdc1d0e5c292c769227e127aad559b3dd21",
    "filename": "torchmetrics/functional/classification/precision_recall_curve.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/PyTorchLightning-metrics/torchmetrics/functional/classification/precision_recall_curve.py",
    "file_hunks_size": 7,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": true,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "torchmetrics/functional/classification/precision_recall_curve.py:27:4 Incompatible variable type [9]: pos_label is declared to have type `int` but is used as type `float`.",
    "message": " pos_label is declared to have type `int` but is used as type `float`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 27,
    "warning_line": "    pos_label: int = 1.,",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    sample_weights: Optional[Sequence] = None,\n    pos_label: int = 1.,\n) -> Tuple[Tensor, Tensor, Tensor]:\n",
        "source_code_len": 108,
        "target_code": "    sample_weights: Optional[Sequence] = None,\n    pos_label: int = 1,\n) -> Tuple[Tensor, Tensor, Tensor]:\n",
        "target_code_len": 107,
        "diff_format": "@@ -26,3 +26,3 @@\n     sample_weights: Optional[Sequence] = None,\n-    pos_label: int = 1.,\n+    pos_label: int = 1,\n ) -> Tuple[Tensor, Tensor, Tensor]:\n",
        "source_code_with_indent": "    sample_weights: Optional[Sequence] = None,\n    pos_label: int = 1.,\n) -> Tuple[Tensor, Tensor, Tensor]:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    sample_weights: Optional[Sequence] = None,\n    pos_label: int = 1,\n) -> Tuple[Tensor, Tensor, Tensor]:\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "PyTorchLightning/metrics",
    "commit": "2c528bdc1d0e5c292c769227e127aad559b3dd21",
    "filename": "torchmetrics/functional/regression/ssim.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/PyTorchLightning-metrics/torchmetrics/functional/regression/ssim.py",
    "file_hunks_size": 3,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "torchmetrics/functional/regression/ssim.py:33:50 Incompatible parameter type [6]: Expected `int` for 2nd positional only parameter to call `_gaussian` but got `float`.",
    "message": " Expected `int` for 2nd positional only parameter to call `_gaussian` but got `float`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 33,
    "warning_line": "    gaussian_kernel_x = _gaussian(kernel_size[0], sigma[0], dtype, device)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef _gaussian(kernel_size: int, sigma: int, dtype: torch.dtype, device: torch.device):\n    dist = torch.arange(start=(1 - kernel_size) / 2, end=(1 + kernel_size) / 2, step=1, dtype=dtype, device=device)\n",
        "source_code_len": 204,
        "target_code": "\ndef _gaussian(kernel_size: int, sigma: float, dtype: torch.dtype, device: torch.device) -> Tensor:\n    dist = torch.arange(start=(1 - kernel_size) / 2, end=(1 + kernel_size) / 2, step=1, dtype=dtype, device=device)\n",
        "target_code_len": 216,
        "diff_format": "@@ -23,3 +23,3 @@\n \n-def _gaussian(kernel_size: int, sigma: int, dtype: torch.dtype, device: torch.device):\n+def _gaussian(kernel_size: int, sigma: float, dtype: torch.dtype, device: torch.device) -> Tensor:\n     dist = torch.arange(start=(1 - kernel_size) / 2, end=(1 + kernel_size) / 2, step=1, dtype=dtype, device=device)\n",
        "source_code_with_indent": "\ndef _gaussian(kernel_size: int, sigma: int, dtype: torch.dtype, device: torch.device):\n    <IND>dist = torch.arange(start=(1 - kernel_size) / 2, end=(1 + kernel_size) / 2, step=1, dtype=dtype, device=device)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\ndef _gaussian(kernel_size: int, sigma: float, dtype: torch.dtype, device: torch.device) -> Tensor:\n    <IND>dist = torch.arange(start=(1 - kernel_size) / 2, end=(1 + kernel_size) / 2, step=1, dtype=dtype, device=device)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "PyTorchLightning/metrics",
    "commit": "2c528bdc1d0e5c292c769227e127aad559b3dd21",
    "filename": "torchmetrics/functional/regression/ssim.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/PyTorchLightning-metrics/torchmetrics/functional/regression/ssim.py",
    "file_hunks_size": 3,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "torchmetrics/functional/regression/ssim.py:34:50 Incompatible parameter type [6]: Expected `int` for 2nd positional only parameter to call `_gaussian` but got `float`.",
    "message": " Expected `int` for 2nd positional only parameter to call `_gaussian` but got `float`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 34,
    "warning_line": "    gaussian_kernel_y = _gaussian(kernel_size[1], sigma[1], dtype, device)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef _gaussian(kernel_size: int, sigma: int, dtype: torch.dtype, device: torch.device):\n    dist = torch.arange(start=(1 - kernel_size) / 2, end=(1 + kernel_size) / 2, step=1, dtype=dtype, device=device)\n",
        "source_code_len": 204,
        "target_code": "\ndef _gaussian(kernel_size: int, sigma: float, dtype: torch.dtype, device: torch.device) -> Tensor:\n    dist = torch.arange(start=(1 - kernel_size) / 2, end=(1 + kernel_size) / 2, step=1, dtype=dtype, device=device)\n",
        "target_code_len": 216,
        "diff_format": "@@ -23,3 +23,3 @@\n \n-def _gaussian(kernel_size: int, sigma: int, dtype: torch.dtype, device: torch.device):\n+def _gaussian(kernel_size: int, sigma: float, dtype: torch.dtype, device: torch.device) -> Tensor:\n     dist = torch.arange(start=(1 - kernel_size) / 2, end=(1 + kernel_size) / 2, step=1, dtype=dtype, device=device)\n",
        "source_code_with_indent": "\ndef _gaussian(kernel_size: int, sigma: int, dtype: torch.dtype, device: torch.device):\n    <IND>dist = torch.arange(start=(1 - kernel_size) / 2, end=(1 + kernel_size) / 2, step=1, dtype=dtype, device=device)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\ndef _gaussian(kernel_size: int, sigma: float, dtype: torch.dtype, device: torch.device) -> Tensor:\n    <IND>dist = torch.arange(start=(1 - kernel_size) / 2, end=(1 + kernel_size) / 2, step=1, dtype=dtype, device=device)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  }
]