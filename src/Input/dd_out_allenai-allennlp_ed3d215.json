[
  {
    "project": "allenai/allennlp",
    "commit": "ed3d215b49e9114c272416e70fbc51fbd1ee7cd1",
    "filename": "allennlp/data/fields/label_field.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/fields/label_field.py",
    "file_hunks_size": 3,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "allennlp/data/fields/label_field.py:60:43 Incompatible parameter type [6]: Expected `str` for 1st positional only parameter to call `dict.__getitem__` but got `Union[int, str]`.",
    "message": " Expected `str` for 1st positional only parameter to call `dict.__getitem__` but got `Union[int, str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 60,
    "warning_line": "            counter[self._label_namespace][self._label] += 1",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "        if self._label_id is None:\n            counter[self._label_namespace][self._label] += 1\n\n",
        "source_code_len": 97,
        "target_code": "        if self._label_id is None:\n            counter[self._label_namespace][self._label] += 1  # type: ignore\n\n",
        "target_code_len": 113,
        "diff_format": "@@ -59,3 +59,3 @@\n         if self._label_id is None:\n-            counter[self._label_namespace][self._label] += 1\n+            counter[self._label_namespace][self._label] += 1  # type: ignore\n \n",
        "source_code_with_indent": "        <IND>if self._label_id is None:\n            <IND>counter[self._label_namespace][self._label] += 1\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        <IND>if self._label_id is None:\n            <IND>counter[self._label_namespace][self._label] += 1  # type: ignore\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "ed3d215b49e9114c272416e70fbc51fbd1ee7cd1",
    "filename": "allennlp/data/fields/label_field.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/fields/label_field.py",
    "file_hunks_size": 3,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "allennlp/data/fields/label_field.py:60:43 Incompatible parameter type [6]: Expected `str` for 1st positional only parameter to call `dict.__setitem__` but got `Union[int, str]`.",
    "message": " Expected `str` for 1st positional only parameter to call `dict.__setitem__` but got `Union[int, str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 60,
    "warning_line": "            counter[self._label_namespace][self._label] += 1",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "        if self._label_id is None:\n            counter[self._label_namespace][self._label] += 1\n\n",
        "source_code_len": 97,
        "target_code": "        if self._label_id is None:\n            counter[self._label_namespace][self._label] += 1  # type: ignore\n\n",
        "target_code_len": 113,
        "diff_format": "@@ -59,3 +59,3 @@\n         if self._label_id is None:\n-            counter[self._label_namespace][self._label] += 1\n+            counter[self._label_namespace][self._label] += 1  # type: ignore\n \n",
        "source_code_with_indent": "        <IND>if self._label_id is None:\n            <IND>counter[self._label_namespace][self._label] += 1\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        <IND>if self._label_id is None:\n            <IND>counter[self._label_namespace][self._label] += 1  # type: ignore\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "ed3d215b49e9114c272416e70fbc51fbd1ee7cd1",
    "filename": "allennlp/data/fields/label_field.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/fields/label_field.py",
    "file_hunks_size": 3,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "allennlp/data/fields/label_field.py:65:51 Incompatible parameter type [6]: Expected `str` for 1st positional only parameter to call `Vocabulary.get_token_index` but got `Union[int, str]`.",
    "message": " Expected `str` for 1st positional only parameter to call `Vocabulary.get_token_index` but got `Union[int, str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 65,
    "warning_line": "            self._label_id = vocab.get_token_index(self._label, self._label_namespace)",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "        if self._label_id is None:\n            self._label_id = vocab.get_token_index(self._label, self._label_namespace)\n            self._num_labels = vocab.get_vocab_size(self._label_namespace)\n",
        "source_code_len": 197,
        "target_code": "        if self._label_id is None:\n            self._label_id = vocab.get_token_index(self._label, self._label_namespace)  # type: ignore\n            self._num_labels = vocab.get_vocab_size(self._label_namespace)\n",
        "target_code_len": 213,
        "diff_format": "@@ -64,3 +64,3 @@\n         if self._label_id is None:\n-            self._label_id = vocab.get_token_index(self._label, self._label_namespace)\n+            self._label_id = vocab.get_token_index(self._label, self._label_namespace)  # type: ignore\n             self._num_labels = vocab.get_vocab_size(self._label_namespace)\n",
        "source_code_with_indent": "        <IND>if self._label_id is None:\n            <IND>self._label_id = vocab.get_token_index(self._label, self._label_namespace)\n            self._num_labels = vocab.get_vocab_size(self._label_namespace)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        <IND>if self._label_id is None:\n            <IND>self._label_id = vocab.get_token_index(self._label, self._label_namespace)  # type: ignore\n            self._num_labels = vocab.get_vocab_size(self._label_namespace)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "ed3d215b49e9114c272416e70fbc51fbd1ee7cd1",
    "filename": "allennlp/data/iterators/adaptive_iterator.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/iterators/adaptive_iterator.py",
    "file_hunks_size": 3,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/iterators/adaptive_iterator.py:102:52 Incompatible parameter type [6]: Expected `allennlp.data.dataset.Dataset` for 1st positional only parameter to call `AdaptiveIterator._adaptive_grouping` but got `typing.Union[List[allennlp.data.instance.Instance], allennlp.data.dataset.Dataset]`.",
    "message": " Expected `allennlp.data.dataset.Dataset` for 1st positional only parameter to call `AdaptiveIterator._adaptive_grouping` but got `typing.Union[List[allennlp.data.instance.Instance], allennlp.data.dataset.Dataset]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 102,
    "warning_line": "        grouped_instances = self._adaptive_grouping(instances)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        if self._sorting_keys:\n            instances = self._sort_dataset_by_padding(dataset,\n                                                      self._sorting_keys,\n                                                      self._padding_noise)\n        else:\n            instances = dataset.instances\n        # Group the instances into different sized batches, depending on how padded they are.\n        grouped_instances = self._adaptive_grouping(instances)\n        if shuffle:\n",
        "source_code_len": 476,
        "target_code": "        if self._sorting_keys:\n            dataset = self._sort_dataset_by_padding(dataset,\n                                                    self._sorting_keys,\n                                                    self._padding_noise)\n        # Group the instances into different sized batches, depending on how padded they are.\n        grouped_instances = self._adaptive_grouping(dataset)\n        if shuffle:\n",
        "target_code_len": 412,
        "diff_format": "@@ -95,9 +95,7 @@\n         if self._sorting_keys:\n-            instances = self._sort_dataset_by_padding(dataset,\n-                                                      self._sorting_keys,\n-                                                      self._padding_noise)\n-        else:\n-            instances = dataset.instances\n+            dataset = self._sort_dataset_by_padding(dataset,\n+                                                    self._sorting_keys,\n+                                                    self._padding_noise)\n         # Group the instances into different sized batches, depending on how padded they are.\n-        grouped_instances = self._adaptive_grouping(instances)\n+        grouped_instances = self._adaptive_grouping(dataset)\n         if shuffle:\n",
        "source_code_with_indent": "        <DED>if self._sorting_keys:\n            <IND>instances = self._sort_dataset_by_padding(dataset,\n                                                      self._sorting_keys,\n                                                      self._padding_noise)\n        <DED>else:\n            <IND>instances = dataset.instances\n        # Group the instances into different sized batches, depending on how padded they are.\n        <DED>grouped_instances = self._adaptive_grouping(instances)\n        if shuffle:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        <DED>if self._sorting_keys:\n            <IND>dataset = self._sort_dataset_by_padding(dataset,\n                                                    self._sorting_keys,\n                                                    self._padding_noise)\n        # Group the instances into different sized batches, depending on how padded they are.\n        <DED>grouped_instances = self._adaptive_grouping(dataset)\n        if shuffle:\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "ed3d215b49e9114c272416e70fbc51fbd1ee7cd1",
    "filename": "allennlp/data/iterators/bucket_iterator.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/iterators/bucket_iterator.py",
    "file_hunks_size": 4,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/iterators/bucket_iterator.py:97:73 Incompatible parameter type [6]: Expected `typing.Dict[typing.Any, float]` for 1st positional only parameter to call `add_noise_to_dict_values` but got `typing.Dict[str, int]`.",
    "message": " Expected `typing.Dict[typing.Any, float]` for 1st positional only parameter to call `add_noise_to_dict_values` but got `typing.Dict[str, int]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 97,
    "warning_line": "                    noisy_lengths[field_name] = add_noise_to_dict_values(field_lengths, padding_noise)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from typing import List, Tuple\nimport random\n",
        "source_code_len": 45,
        "target_code": "from typing import List, Tuple, Dict, cast\nimport random\n",
        "target_code_len": 57,
        "diff_format": "@@ -1,2 +1,2 @@\n-from typing import List, Tuple\n+from typing import List, Tuple, Dict, cast\n import random\n",
        "source_code_with_indent": "from typing import List, Tuple\nimport random\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from typing import List, Tuple, Dict, cast\nimport random\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        for instance in dataset.instances:\n            padding_lengths = instance.get_padding_lengths()\n            print(\"Instance:\", instance)\n",
        "source_code_len": 145,
        "target_code": "        for instance in dataset.instances:\n            padding_lengths = cast(Dict[str, Dict[str, float]], instance.get_padding_lengths())\n            print(\"Instance:\", instance)\n",
        "target_code_len": 180,
        "diff_format": "@@ -90,3 +90,3 @@\n         for instance in dataset.instances:\n-            padding_lengths = instance.get_padding_lengths()\n+            padding_lengths = cast(Dict[str, Dict[str, float]], instance.get_padding_lengths())\n             print(\"Instance:\", instance)\n",
        "source_code_with_indent": "        for instance in dataset.instances:\n            <IND>padding_lengths = instance.get_padding_lengths()\n            print(\"Instance:\", instance)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        for instance in dataset.instances:\n            <IND>padding_lengths = cast(Dict[str, Dict[str, float]], instance.get_padding_lengths())\n            print(\"Instance:\", instance)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "ed3d215b49e9114c272416e70fbc51fbd1ee7cd1",
    "filename": "allennlp/data/token_indexers/token_characters_indexer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/token_indexers/token_characters_indexer.py",
    "file_hunks_size": 4,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/token_indexers/token_characters_indexer.py:48:44 Incompatible parameter type [6]: Expected `typing.Sized` for 1st positional only parameter to call `len` but got `typing.Union[List[int], int]`.",
    "message": " Expected `typing.Sized` for 1st positional only parameter to call `len` but got `typing.Union[List[int], int]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 48,
    "warning_line": "        return {'num_token_characters': len(token)}",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from typing import Dict, List\nimport itertools\n",
        "source_code_len": 47,
        "target_code": "from typing import Dict, List, cast\nimport itertools\n",
        "target_code_len": 53,
        "diff_format": "@@ -1,2 +1,2 @@\n-from typing import Dict, List\n+from typing import Dict, List, cast\n import itertools\n",
        "source_code_with_indent": "from typing import Dict, List\nimport itertools\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from typing import Dict, List, cast\nimport itertools\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    def get_padding_lengths(self, token: TokenType) -> Dict[str, int]:\n        return {'num_token_characters': len(token)}\n\n",
        "source_code_len": 124,
        "target_code": "    def get_padding_lengths(self, token: TokenType) -> Dict[str, int]:\n        list_token = cast(List[int], token)\n        return {'num_token_characters': len(list_token)}\n\n",
        "target_code_len": 173,
        "diff_format": "@@ -47,3 +47,4 @@\n     def get_padding_lengths(self, token: TokenType) -> Dict[str, int]:\n-        return {'num_token_characters': len(token)}\n+        list_token = cast(List[int], token)\n+        return {'num_token_characters': len(list_token)}\n \n",
        "source_code_with_indent": "    def get_padding_lengths(self, token: TokenType) -> Dict[str, int]:\n        <IND>return {'num_token_characters': len(token)}\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    def get_padding_lengths(self, token: TokenType) -> Dict[str, int]:\n        <IND>list_token = cast(List[int], token)\n        return {'num_token_characters': len(list_token)}\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "ed3d215b49e9114c272416e70fbc51fbd1ee7cd1",
    "filename": "allennlp/data/tokenizers/character_tokenizer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/tokenizers/character_tokenizer.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "allennlp/data/tokenizers/character_tokenizer.py:37:12 Incompatible variable type [9]: text is declared to have type `str` but is used as type `bytes`.",
    "message": " text is declared to have type `str` but is used as type `bytes`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 37,
    "warning_line": "            text = text.encode(self.byte_encoding)",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "        if self.byte_encoding is not None:\n            text = text.encode(self.byte_encoding)\n        return list(text)\n",
        "source_code_len": 120,
        "target_code": "        if self.byte_encoding is not None:\n            text = text.encode(self.byte_encoding)  # type: ignore\n        return list(text)\n",
        "target_code_len": 136,
        "diff_format": "@@ -36,3 +36,3 @@\n         if self.byte_encoding is not None:\n-            text = text.encode(self.byte_encoding)\n+            text = text.encode(self.byte_encoding)  # type: ignore\n         return list(text)\n",
        "source_code_with_indent": "        <DED>if self.byte_encoding is not None:\n            <IND>text = text.encode(self.byte_encoding)\n        <DED>return list(text)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        <DED>if self.byte_encoding is not None:\n            <IND>text = text.encode(self.byte_encoding)  # type: ignore\n        <DED>return list(text)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  }
]