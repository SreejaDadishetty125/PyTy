[
  {
    "project": "readthedocs/sphinx-autoapi",
    "commit": "f607d5e1db766867564643fe110eb9a909ae566f",
    "filename": "tests/pyexample/example/example.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/readthedocs-sphinx-autoapi/tests/pyexample/example/example.py",
    "file_hunks_size": 1,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "tests/pyexample/example/example.py:147:4 Inconsistent override [15]: `_fields` overrides attribute defined in `Definition` inconsistently. Type `typing.Tuple[str, str, str, str, str, str, str, str, str, str]` is not a subtype of the overridden attribute `typing.Tuple[str, str, str, str, str, str, str, str]`.",
    "message": " `_fields` overrides attribute defined in `Definition` inconsistently. Type `typing.Tuple[str, str, str, str, str, str, str, str, str, str]` is not a subtype of the overridden attribute `typing.Tuple[str, str, str, str, str, str, str, str]`.",
    "rule_id": "Inconsistent override [15]",
    "warning_line_no": 147,
    "warning_line": "    _fields = ('name', '_source', 'start', 'end', 'decorators', 'docstring',",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "#! /usr/bin/env python\n\"\"\"Static analysis tool for checking docstring conventions and style.\n\nThe repository is located at:\nhttp://github.com/PyCQA/pydocstyle\n\n\"\"\"\nfrom __future__ import with_statement\n\nimport os\nimport string\nimport sys\nimport ast\nimport copy\nimport logging\nimport tokenize as tk\nfrom itertools import takewhile, dropwhile, chain\nfrom re import compile as re\nimport itertools\nfrom collections import defaultdict, namedtuple, Set\n\ntry:  # Python 3.x\n    from ConfigParser import RawConfigParser\nexcept ImportError:  # Python 2.x\n    from configparser import RawConfigParser\n\nlog = logging.getLogger(__name__)\n\n\ntry:\n    from StringIO import StringIO\nexcept ImportError:  # Python 3.0 and later\n    from io import StringIO\n\n\ntry:\n    next\nexcept NameError:  # Python 2.5 and earlier\n    nothing = object()\n\n    def next(obj, default=nothing):\n        if default == nothing:\n            return obj.next()\n        else:\n            try:\n                return obj.next()\n            except StopIteration:\n                return default\n\n\n# If possible (python >= 3.2) use tokenize.open to open files, so PEP 263\n# encoding markers are interpreted.\ntry:\n    tokenize_open = tk.open\nexcept AttributeError:\n    tokenize_open = open\n\n\n__version__ = '1.0.1-rc1'\n__all__ = ('check',)\n\n\nclass ReturnCode(object):\n    no_violations_found = 0\n    violations_found = 1\n    invalid_options = 2\n\n\nVARIADIC_MAGIC_METHODS = ('__init__', '__call__', '__new__')\n\n\ndef humanize(string):\n    return re(r'(.)([A-Z]+)').sub(r'\\1 \\2', string).lower()\n\n\ndef is_magic(name):\n    return (name.startswith('__') and\n            name.endswith('__') and\n            name not in VARIADIC_MAGIC_METHODS)\n\n\ndef is_ascii(string):\n    return all(ord(char) < 128 for char in string)\n\n\ndef is_blank(string):\n    return not string.strip()\n\n\ndef leading_space(string):\n    return re('\\s*').match(string).group()\n\n\nclass Value(object):\n\n    def __init__(self, *args):\n        vars(self).update(zip(self._fields, args))\n\n    def __hash__(self):\n        return hash(repr(self))\n\n    def __eq__(self, other):\n        return other and vars(self) == vars(other)\n\n    def __repr__(self):\n        kwargs = ', '.join('{0}={1!r}'.format(field, getattr(self, field))\n                           for field in self._fields)\n        return '{0}({1})'.format(self.__class__.__name__, kwargs)\n\n\nclass Definition(Value):\n\n    _fields = ('name', '_source', 'start', 'end', 'decorators', 'docstring',\n               'children', 'parent')\n\n    _human = property(lambda self: humanize(type(self).__name__))\n    kind = property(lambda self: self._human.split()[-1])\n    module = property(lambda self: self.parent.module)\n    all = property(lambda self: self.module.all)\n    _slice = property(lambda self: slice(self.start - 1, self.end))\n    is_class = False\n\n    def __iter__(self):\n        return chain([self], *self.children)\n\n    @property\n    def _publicity(self):\n        return {True: 'public', False: 'private'}[self.is_public]\n\n    @property\n    def source(self):\n        \"\"\"Return the source code for the definition.\"\"\"\n        full_src = self._source[self._slice]\n\n        def is_empty_or_comment(line):\n            return line.strip() == '' or line.strip().startswith('#')\n\n        filtered_src = dropwhile(is_empty_or_comment, reversed(full_src))\n        return ''.join(reversed(list(filtered_src)))\n\n    def __str__(self):\n        return 'in %s %s `%s`' % (self._publicity, self._human, self.name)\n\n\nclass Module(Definition):\n\n    _fields = ('name', '_source', 'start', 'end', 'decorators', 'docstring',\n               'children', 'parent', '_all', 'future_imports')\n    is_public = True\n    _nest = staticmethod(lambda s: {'def': Function, 'class': Class}[s])\n    module = property(lambda self: self)\n    all = property(lambda self: self._all)\n\n    def __str__(self):\n        return 'at module level'\n\n\nclass Package(Module):\n    \"\"\"A package is a __init__.py module.\"\"\"\n\n\nclass Function(Definition):\n\n    _nest = staticmethod(lambda s: {'def': NestedFunction,\n                                    'class': NestedClass}[s])\n\n    @property\n    def is_public(self):\n        if self.all is not None:\n            return self.name in self.all\n        else:\n            return not self.name.startswith('_')\n\n    @property \n    def args(self):\n        sig = self.source.split('\\n')[0]\n        sig = sig.split('(')[1]\n        sig = sig.split(')')[0]\n        return sig.split(',')\n\n\nclass NestedFunction(Function):\n\n    is_public = False\n\n\nclass Method(Function):\n\n    @property\n    def is_public(self):\n        # Check if we are a setter/deleter method, and mark as private if so.\n        for decorator in self.decorators:\n            # Given 'foo', match 'foo.bar' but not 'foobar' or 'sfoo'\n            if re(r\"^{0}\\.\".format(self.name)).match(decorator.name):\n                return False\n        name_is_public = (not self.name.startswith('_') or\n                          self.name in VARIADIC_MAGIC_METHODS or\n                          is_magic(self.name))\n        return self.parent.is_public and name_is_public\n\n\nclass Class(Definition):\n\n    _nest = staticmethod(lambda s: {'def': Method, 'class': NestedClass}[s])\n    is_public = Function.is_public\n    is_class = True\n\n\nclass NestedClass(Class):\n\n    @property\n    def is_public(self):\n        return (not self.name.startswith('_') and\n                self.parent.is_class and\n                self.parent.is_public)\n\n\nclass Decorator(Value):\n    \"\"\"A decorator for function, method or class.\"\"\"\n\n    _fields = 'name arguments'.split()\n\n\nclass TokenKind(int):\n    def __repr__(self):\n        return \"tk.{0}\".format(tk.tok_name[self])\n\n\nclass Token(Value):\n\n    _fields = 'kind value start end source'.split()\n\n    def __init__(self, *args):\n        super(Token, self).__init__(*args)\n        self.kind = TokenKind(self.kind)\n\n\nclass TokenStream(object):\n\n    def __init__(self, filelike):\n        self._generator = tk.generate_tokens(filelike.readline)\n        self.current = Token(*next(self._generator, None))\n        self.line = self.current.start[0]\n\n    def move(self):\n        previous = self.current\n        current = next(self._generator, None)\n        self.current = None if current is None else Token(*current)\n        self.line = self.current.start[0] if self.current else self.line\n        return previous\n\n    def __iter__(self):\n        while True:\n            if self.current is not None:\n                yield self.current\n            else:\n                return\n            self.move()\n\n\nclass AllError(Exception):\n\n    def __init__(self, message):\n        Exception.__init__(\n            self, message +\n            'That means pydocstyle cannot decide which definitions are public.'\n            ' Variable __all__ should be present at most once in each file, '\n            \"in form `__all__ = ('a_public_function', 'APublicClass', ...)`. \"\n            'More info on __all__: http://stackoverflow.com/q/44834/. ')\n\n\nclass Parser(object):\n\n    def __call__(self, filelike, filename):\n        self.source = filelike.readlines()\n        src = ''.join(self.source)\n        self.stream = TokenStream(StringIO(src))\n        self.filename = filename\n        self.all = None\n        self.future_imports = defaultdict(lambda: False)\n        self._accumulated_decorators = []\n        return self.parse_module()\n\n    current = property(lambda self: self.stream.current)\n    line = property(lambda self: self.stream.line)\n\n    def consume(self, kind):\n        \"\"\"Consume one token and verify it is of the expected kind.\"\"\"\n        next_token = self.stream.move()\n        assert next_token.kind == kind\n\n    def leapfrog(self, kind, value=None):\n        \"\"\"Skip tokens in the stream until a certain token kind is reached.\n\n        If `value` is specified, tokens whose values are different will also\n        be skipped.\n        \"\"\"\n        while self.current is not None:\n            if (self.current.kind == kind and\n               (value is None or self.current.value == value)):\n                self.consume(kind)\n                return\n            self.stream.move()\n\n    def parse_docstring(self):\n        \"\"\"Parse a single docstring and return its value.\"\"\"\n        log.debug(\"parsing docstring, token is %r (%s)\",\n                  self.current.kind, self.current.value)\n        while self.current.kind in (tk.COMMENT, tk.NEWLINE, tk.NL):\n            self.stream.move()\n            log.debug(\"parsing docstring, token is %r (%s)\",\n                      self.current.kind, self.current.value)\n        if self.current.kind == tk.STRING:\n            docstring = self.current.value\n            self.stream.move()\n            return docstring\n        return None\n\n    def parse_decorators(self):\n        \"\"\"Called after first @ is found.\n\n        Parse decorators into self._accumulated_decorators.\n        Continue to do so until encountering the 'def' or 'class' start token.\n        \"\"\"\n        name = []\n        arguments = []\n        at_arguments = False\n\n        while self.current is not None:\n            if (self.current.kind == tk.NAME and\n                    self.current.value in ['def', 'class']):\n                # Done with decorators - found function or class proper\n                break\n            elif self.current.kind == tk.OP and self.current.value == '@':\n                # New decorator found. Store the decorator accumulated so far:\n                self._accumulated_decorators.append(\n                    Decorator(''.join(name), ''.join(arguments)))\n                # Now reset to begin accumulating the new decorator:\n                name = []\n                arguments = []\n                at_arguments = False\n            elif self.current.kind == tk.OP and self.current.value == '(':\n                at_arguments = True\n            elif self.current.kind == tk.OP and self.current.value == ')':\n                # Ignore close parenthesis\n                pass\n            elif self.current.kind == tk.NEWLINE or self.current.kind == tk.NL:\n                # Ignore newlines\n                pass\n            else:\n                # Keep accumulating current decorator's name or argument.\n                if not at_arguments:\n                    name.append(self.current.value)\n                else:\n                    arguments.append(self.current.value)\n            self.stream.move()\n\n        # Add decorator accumulated so far\n        self._accumulated_decorators.append(\n            Decorator(''.join(name), ''.join(arguments)))\n\n    def parse_definitions(self, class_, all=False):\n        \"\"\"Parse multiple definitions and yield them.\"\"\"\n        while self.current is not None:\n            log.debug(\"parsing definition list, current token is %r (%s)\",\n                      self.current.kind, self.current.value)\n            if all and self.current.value == '__all__':\n                self.parse_all()\n            elif self.current.kind == tk.OP and self.current.value == '@':\n                self.consume(tk.OP)\n                self.parse_decorators()\n            elif self.current.value in ['def', 'class']:\n                yield self.parse_definition(class_._nest(self.current.value))\n            elif self.current.kind == tk.INDENT:\n                self.consume(tk.INDENT)\n                for definition in self.parse_definitions(class_):\n                    yield definition\n            elif self.current.kind == tk.DEDENT:\n                self.consume(tk.DEDENT)\n                return\n            elif self.current.value == 'from':\n                self.parse_from_import_statement()\n            else:\n                self.stream.move()\n\n    def parse_all(self):\n        \"\"\"Parse the __all__ definition in a module.\"\"\"\n        assert self.current.value == '__all__'\n        self.consume(tk.NAME)\n        if self.current.value != '=':\n            raise AllError('Could not evaluate contents of __all__. ')\n        self.consume(tk.OP)\n        if self.current.value not in '([':\n            raise AllError('Could not evaluate contents of __all__. ')\n        if self.current.value == '[':\n            msg = (\"%s WARNING: __all__ is defined as a list, this means \"\n                   \"pydocstyle cannot reliably detect contents of the __all__ \"\n                   \"variable, because it can be mutated. Change __all__ to be \"\n                   \"an (immutable) tuple, to remove this warning. Note, \"\n                   \"pydocstyle uses __all__ to detect which definitions are \"\n                   \"public, to warn if public definitions are missing \"\n                   \"docstrings. If __all__ is a (mutable) list, pydocstyle \"\n                   \"cannot reliably assume its contents. pydocstyle will \"\n                   \"proceed assuming __all__ is not mutated.\\n\"\n                   % self.filename)\n            sys.stderr.write(msg)\n        self.consume(tk.OP)\n\n        self.all = []\n        all_content = \"(\"\n        while self.current.kind != tk.OP or self.current.value not in \")]\":\n            if self.current.kind in (tk.NL, tk.COMMENT):\n                pass\n            elif (self.current.kind == tk.STRING or\n                  self.current.value == ','):\n                all_content += self.current.value\n            else:\n                raise AllError('Unexpected token kind in  __all__: %r. ' %\n                               self.current.kind)\n            self.stream.move()\n        self.consume(tk.OP)\n        all_content += \")\"\n        try:\n            self.all = eval(all_content, {})\n        except BaseException as e:\n            raise AllError('Could not evaluate contents of __all__.'\n                           '\\bThe value was %s. The exception was:\\n%s'\n                           % (all_content, e))\n\n    def parse_module(self):\n        \"\"\"Parse a module (and its children) and return a Module object.\"\"\"\n        log.debug(\"parsing module.\")\n        start = self.line\n        docstring = self.parse_docstring()\n        children = list(self.parse_definitions(Module, all=True))\n        assert self.current is None, self.current\n        end = self.line\n        cls = Module\n        if self.filename.endswith('__init__.py'):\n            cls = Package\n        module = cls(self.filename, self.source, start, end,\n                     [], docstring, children, None, self.all)\n        for child in module.children:\n            child.parent = module\n        module.future_imports = self.future_imports\n        log.debug(\"finished parsing module.\")\n        return module\n\n    def parse_definition(self, class_):\n        \"\"\"Parse a definition and return its value in a `class_` object.\"\"\"\n        start = self.line\n        self.consume(tk.NAME)\n        name = self.current.value\n        log.debug(\"parsing %s '%s'\", class_.__name__, name)\n        self.stream.move()\n        if self.current.kind == tk.OP and self.current.value == '(':\n            parenthesis_level = 0\n            while True:\n                if self.current.kind == tk.OP:\n                    if self.current.value == '(':\n                        parenthesis_level += 1\n                    elif self.current.value == ')':\n                        parenthesis_level -= 1\n                        if parenthesis_level == 0:\n                            break\n                self.stream.move()\n        if self.current.kind != tk.OP or self.current.value != ':':\n            self.leapfrog(tk.OP, value=\":\")\n        else:\n            self.consume(tk.OP)\n        if self.current.kind in (tk.NEWLINE, tk.COMMENT):\n            self.leapfrog(tk.INDENT)\n            assert self.current.kind != tk.INDENT\n            docstring = self.parse_docstring()\n            decorators = self._accumulated_decorators\n            self._accumulated_decorators = []\n            log.debug(\"parsing nested definitions.\")\n            children = list(self.parse_definitions(class_))\n            log.debug(\"finished parsing nested definitions for '%s'\", name)\n            end = self.line - 1\n        else:  # one-liner definition\n            docstring = self.parse_docstring()\n            decorators = []  # TODO\n            children = []\n            end = self.line\n            self.leapfrog(tk.NEWLINE)\n        definition = class_(name, self.source, start, end,\n                            decorators, docstring, children, None)\n        for child in definition.children:\n            child.parent = definition\n        log.debug(\"finished parsing %s '%s'. Next token is %r (%s)\",\n                  class_.__name__, name, self.current.kind,\n                  self.current.value)\n        return definition\n\n    def parse_from_import_statement(self):\n        \"\"\"Parse a 'from x import y' statement.\n\n        The purpose is to find __future__ statements.\n\n        \"\"\"\n        log.debug('parsing from/import statement.')\n        assert self.current.value == 'from', self.current.value\n        self.stream.move()\n        if self.current.value != '__future__':\n            return\n        self.stream.move()\n        assert self.current.value == 'import', self.current.value\n        self.stream.move()\n        if self.current.value == '(':\n            self.consume(tk.OP)\n            expected_end_kind = tk.OP\n        else:\n            expected_end_kind = tk.NEWLINE\n        while self.current.kind != expected_end_kind and not(\n                self.current.kind == tk.OP and self.current.value == ';'):\n            if self.current.kind != tk.NAME:\n                self.stream.move()\n                continue\n            log.debug(\"parsing import, token is %r (%s)\",\n                      self.current.kind, self.current.value)\n            log.debug('found future import: %s', self.current.value)\n            self.future_imports[self.current.value] = True\n            self.consume(tk.NAME)\n            log.debug(\"parsing import, token is %r (%s)\",\n                      self.current.kind, self.current.value)\n            if self.current.kind == tk.NAME and self.current.value == 'as':\n                self.consume(tk.NAME)  # as\n                if self.current.kind == tk.NAME:\n                    self.consume(tk.NAME)  # new name, irrelevant\n            if self.current.value == ',':\n                self.consume(tk.OP)\n            log.debug(\"parsing import, token is %r (%s)\",\n                      self.current.kind, self.current.value)\n\n\nclass Error(object):\n    \"\"\"Error in docstring style.\"\"\"\n\n    # should be overridden by inheriting classes\n    code = None\n    short_desc = None\n    context = None\n\n    # Options that define how errors are printed:\n    explain = False\n    source = False\n\n    def __init__(self, *parameters):\n        self.parameters = parameters\n        self.definition = None\n        self.explanation = None\n\n    def set_context(self, definition, explanation):\n        self.definition = definition\n        self.explanation = explanation\n\n    filename = property(lambda self: self.definition.module.name)\n    line = property(lambda self: self.definition.start)\n\n    @property\n    def message(self):\n        ret = '%s: %s' % (self.code, self.short_desc)\n        if self.context is not None:\n            ret += ' (' + self.context % self.parameters + ')'\n        return ret\n\n    @property\n    def lines(self):\n        source = ''\n        lines = self.definition._source[self.definition._slice]\n        offset = self.definition.start\n        lines_stripped = list(reversed(list(dropwhile(is_blank,\n                                                      reversed(lines)))))\n        numbers_width = 0\n        for n, line in enumerate(lines_stripped):\n            numbers_width = max(numbers_width, n + offset)\n        numbers_width = len(str(numbers_width))\n        numbers_width = 6\n        for n, line in enumerate(lines_stripped):\n            source += '%*d: %s' % (numbers_width, n + offset, line)\n            if n > 5:\n                source += '        ...\\n'\n                break\n        return source\n\n    def __str__(self):\n        self.explanation = '\\n'.join(l for l in self.explanation.split('\\n')\n                                     if not is_blank(l))\n        template = '%(filename)s:%(line)s %(definition)s:\\n        %(message)s'\n        if self.source and self.explain:\n            template += '\\n\\n%(explanation)s\\n\\n%(lines)s\\n'\n        elif self.source and not self.explain:\n            template += '\\n\\n%(lines)s\\n'\n        elif self.explain and not self.source:\n            template += '\\n\\n%(explanation)s\\n\\n'\n        return template % dict((name, getattr(self, name)) for name in\n                               ['filename', 'line', 'definition', 'message',\n                                'explanation', 'lines'])\n\n    __repr__ = __str__\n\n    def __lt__(self, other):\n        return (self.filename, self.line) < (other.filename, other.line)\n\n\nclass ErrorRegistry(object):\n    groups = []\n\n    class ErrorGroup(object):\n\n        def __init__(self, prefix, name):\n            self.prefix = prefix\n            self.name = name\n            self.errors = []\n\n        def create_error(self, error_code, error_desc, error_context=None):\n            # TODO: check prefix\n\n            class _Error(Error):\n                code = error_code\n                short_desc = error_desc\n                context = error_context\n\n            self.errors.append(_Error)\n            return _Error\n\n    @classmethod\n    def create_group(cls, prefix, name):\n        group = cls.ErrorGroup(prefix, name)\n        cls.groups.append(group)\n        return group\n\n    @classmethod\n    def get_error_codes(cls):\n        for group in cls.groups:\n            for error in group.errors:\n                yield error.code\n\n    @classmethod\n    def to_rst(cls):\n        sep_line = '+' + 6 * '-' + '+' + '-' * 71 + '+\\n'\n        blank_line = '|' + 78 * ' ' + '|\\n'\n        table = ''\n        for group in cls.groups:\n            table += sep_line\n            table += blank_line\n            table += '|' + ('**%s**' % group.name).center(78) + '|\\n'\n            table += blank_line\n            for error in group.errors:\n                table += sep_line\n                table += ('|' + error.code.center(6) + '| ' +\n                          error.short_desc.ljust(70) + '|\\n')\n        table += sep_line\n        return table\n\n\nD1xx = ErrorRegistry.create_group('D1', 'Missing Docstrings')\nD100 = D1xx.create_error('D100', 'Missing docstring in public module')\nD101 = D1xx.create_error('D101', 'Missing docstring in public class')\nD102 = D1xx.create_error('D102', 'Missing docstring in public method')\nD103 = D1xx.create_error('D103', 'Missing docstring in public function')\nD104 = D1xx.create_error('D104', 'Missing docstring in public package')\nD105 = D1xx.create_error('D105', 'Missing docstring in magic method')\n\nD2xx = ErrorRegistry.create_group('D2', 'Whitespace Issues')\nD200 = D2xx.create_error('D200', 'One-line docstring should fit on one line '\n                                 'with quotes', 'found %s')\nD201 = D2xx.create_error('D201', 'No blank lines allowed before function '\n                                 'docstring', 'found %s')\nD202 = D2xx.create_error('D202', 'No blank lines allowed after function '\n                                 'docstring', 'found %s')\nD203 = D2xx.create_error('D203', '1 blank line required before class '\n                                 'docstring', 'found %s')\nD204 = D2xx.create_error('D204', '1 blank line required after class '\n                                 'docstring', 'found %s')\nD205 = D2xx.create_error('D205', '1 blank line required between summary line '\n                                 'and description', 'found %s')\nD206 = D2xx.create_error('D206', 'Docstring should be indented with spaces, '\n                                 'not tabs')\nD207 = D2xx.create_error('D207', 'Docstring is under-indented')\nD208 = D2xx.create_error('D208', 'Docstring is over-indented')\nD209 = D2xx.create_error('D209', 'Multi-line docstring closing quotes should '\n                                 'be on a separate line')\nD210 = D2xx.create_error('D210', 'No whitespaces allowed surrounding '\n                                 'docstring text')\nD211 = D2xx.create_error('D211', 'No blank lines allowed before class '\n                                 'docstring', 'found %s')\nD212 = D2xx.create_error('D212', 'Multi-line docstring summary should start '\n                                 'at the first line')\nD213 = D2xx.create_error('D213', 'Multi-line docstring summary should start '\n                                 'at the second line')\n\nD3xx = ErrorRegistry.create_group('D3', 'Quotes Issues')\nD300 = D3xx.create_error('D300', 'Use \"\"\"triple double quotes\"\"\"',\n                         'found %s-quotes')\nD301 = D3xx.create_error('D301', 'Use r\"\"\" if any backslashes in a docstring')\nD302 = D3xx.create_error('D302', 'Use u\"\"\" for Unicode docstrings')\n\nD4xx = ErrorRegistry.create_group('D4', 'Docstring Content Issues')\nD400 = D4xx.create_error('D400', 'First line should end with a period',\n                         'not %r')\nD401 = D4xx.create_error('D401', 'First line should be in imperative mood',\n                         '%r, not %r')\nD402 = D4xx.create_error('D402', 'First line should not be the function\\'s '\n                                 '\"signature\"')\nD403 = D4xx.create_error('D403', 'First word of the first line should be '\n                                 'properly capitalized', '%r, not %r')\nD404 = D4xx.create_error('D404', 'First word of the docstring should not '\n                                 'be `This`')\n\n\nclass AttrDict(dict):\n    def __getattr__(self, item):\n        return self[item]\n\n\nconventions = AttrDict({\n    'pep257': set(ErrorRegistry.get_error_codes()) - set(['D203',\n                                                          'D212',\n                                                          'D213',\n                                                          'D404'])\n})\n\n\n# General configurations for pydocstyle run.\nRunConfiguration = namedtuple('RunConfiguration',\n                              ('explain', 'source', 'debug',\n                               'verbose', 'count'))\n\n\nclass IllegalConfiguration(Exception):\n    \"\"\"An exception for illegal configurations.\"\"\"\n\n    pass\n\n\n# Check configuration - used by the ConfigurationParser class.\nCheckConfiguration = namedtuple('CheckConfiguration',\n                                ('checked_codes', 'match', 'match_dir'))\n\n\ndef check_initialized(method):\n    \"\"\"Check that the configuration object was initialized.\"\"\"\n    def _decorator(self, *args, **kwargs):\n        if self._arguments is None or self._options is None:\n            raise RuntimeError('using an uninitialized configuration')\n        return method(self, *args, **kwargs)\n    return _decorator\n\n\nclass ConfigurationParser(object):\n    \"\"\"Responsible for parsing configuration from files and CLI.\n\n    There are 2 types of configurations: Run configurations and Check\n    configurations.\n\n    Run Configurations:\n    -------------------\n\n    Responsible for deciding things that are related to the user interface,\n    e.g. verbosity, debug options, etc.\n    All run configurations default to `False` and are decided only by CLI.\n\n    Check Configurations:\n    ---------------------\n\n    Configurations that are related to which files and errors will be checked.\n    These are configurable in 2 ways: using the CLI, and using configuration\n    files.\n\n    Configuration files are nested within the file system, meaning that the\n    closer a configuration file is to a checked file, the more relevant it will\n    be. For instance, imagine this directory structure:\n\n    A\n    +-- tox.ini: sets `select=D100`\n    +-- B\n        +-- foo.py\n        +-- tox.ini: sets `add-ignore=D100`\n\n    Then `foo.py` will not be checked for `D100`.\n    The configuration build algorithm is described in `self._get_config`.\n\n    Note: If any of `BASE_ERROR_SELECTION_OPTIONS` was selected in the CLI, all\n    configuration files will be ignored and each file will be checked for\n    the error codes supplied in the CLI.\n\n    \"\"\"\n\n    CONFIG_FILE_OPTIONS = ('convention', 'select', 'ignore', 'add-select',\n                           'add-ignore', 'match', 'match-dir')\n    BASE_ERROR_SELECTION_OPTIONS = ('ignore', 'select', 'convention')\n\n    DEFAULT_MATCH_RE = '(?!test_).*\\.py'\n    DEFAULT_MATCH_DIR_RE = '[^\\.].*'\n    DEFAULT_CONVENTION = conventions.pep257\n\n    PROJECT_CONFIG_FILES = (\n        'setup.cfg',\n        'tox.ini',\n        '.pydocstyle',\n        '.pydocstylerc',\n        # The following is deprecated, but remains for backwards compatibility.\n        '.pep257',\n    )\n\n    POSSIBLE_SECTION_NAMES = ('pydocstyle', 'pep257')\n\n    def __init__(self):\n        \"\"\"Create a configuration parser.\"\"\"\n        self._cache = {}\n        self._override_by_cli = None\n        self._options = self._arguments = self._run_conf = None\n        self._parser = self._create_option_parser()\n\n    # ---------------------------- Public Methods -----------------------------\n\n    def get_default_run_configuration(self):\n        \"\"\"Return a `RunConfiguration` object set with default values.\"\"\"\n        options, _ = self._parse_args([])\n        return self._create_run_config(options)\n\n    def parse(self):\n        \"\"\"Parse the configuration.\n\n        If one of `BASE_ERROR_SELECTION_OPTIONS` was selected, overrides all\n        error codes to check and disregards any error code related\n        configurations from the configuration files.\n\n        \"\"\"\n        self._options, self._arguments = self._parse_args()\n        self._arguments = self._arguments or ['.']\n\n        if not self._validate_options(self._options):\n            raise IllegalConfiguration()\n\n        self._run_conf = self._create_run_config(self._options)\n\n        config = self._create_check_config(self._options, use_dafaults=False)\n        self._override_by_cli = config\n\n    @check_initialized\n    def get_user_run_configuration(self):\n        \"\"\"Return the run configuration for the script.\"\"\"\n        return self._run_conf\n\n    @check_initialized\n    def get_files_to_check(self):\n        \"\"\"Generate files and error codes to check on each one.\n\n        Walk dir trees under `self._arguments` and generate yield filnames\n        that `match` under each directory that `match_dir`.\n        The method locates the configuration for each file name and yields a\n        tuple of (filename, [error_codes]).\n\n        With every discovery of a new configuration file `IllegalConfiguration`\n        might be raised.\n\n        \"\"\"\n        def _get_matches(config):\n            \"\"\"Return the `match` and `match_dir` functions for `config`.\"\"\"\n            match_func = re(config.match + '$').match\n            match_dir_func = re(config.match_dir + '$').match\n            return match_func, match_dir_func\n\n        for name in self._arguments:\n            if os.path.isdir(name):\n                for root, dirs, filenames in os.walk(name):\n                    config = self._get_config(root)\n                    match, match_dir = _get_matches(config)\n\n                    # Skip any dirs that do not match match_dir\n                    dirs[:] = [dir for dir in dirs if match_dir(dir)]\n\n                    for filename in filenames:\n                        if match(filename):\n                            full_path = os.path.join(root, filename)\n                            yield full_path, list(config.checked_codes)\n            else:\n                config = self._get_config(name)\n                match, _ = _get_matches(config)\n                if match(name):\n                    yield name, list(config.checked_codes)\n\n    # --------------------------- Private Methods -----------------------------\n\n    def _get_config(self, node):\n        \"\"\"Get and cache the run configuration for `node`.\n\n        If no configuration exists (not local and not for the parend node),\n        returns and caches a default configuration.\n\n        The algorithm:\n        -------------\n        * If the current directory's configuration exists in\n           `self._cache` - return it.\n        * If a configuration file does not exist in this directory:\n          * If the directory is not a root directory:\n            * Cache its configuration as this directory's and return it.\n          * Else:\n            * Cache a default configuration and return it.\n        * Else:\n          * Read the configuration file.\n          * If a parent directory exists AND the configuration file\n            allows inheritance:\n            * Read the parent configuration by calling this function with the\n              parent directory as `node`.\n            * Merge the parent configuration with the current one and\n              cache it.\n        * If the user has specified one of `BASE_ERROR_SELECTION_OPTIONS` in\n          the CLI - return the CLI configuration with the configuration match\n          clauses\n        * Set the `--add-select` and `--add-ignore` CLI configurations.\n\n        \"\"\"\n        path = os.path.abspath(node)\n        path = path if os.path.isdir(path) else os.path.dirname(path)\n\n        if path in self._cache:\n            return self._cache[path]\n\n        config_file = self._get_config_file_in_folder(path)\n\n        if config_file is None:\n            parent_dir, tail = os.path.split(path)\n            if tail:\n                # No configuration file, simply take the parent's.\n                config = self._get_config(parent_dir)\n            else:\n                # There's no configuration file and no parent directory.\n                # Use the default configuration or the one given in the CLI.\n                config = self._create_check_config(self._options)\n        else:\n            # There's a config file! Read it and merge if necessary.\n            options, inherit = self._read_configuration_file(config_file)\n\n            parent_dir, tail = os.path.split(path)\n            if tail and inherit:\n                # There is a parent dir and we should try to merge.\n                parent_config = self._get_config(parent_dir)\n                config = self._merge_configuration(parent_config, options)\n            else:\n                # No need to merge or parent dir does not exist.\n                config = self._create_check_config(options)\n\n        # Make the CLI always win\n        final_config = {}\n        for attr in CheckConfiguration._fields:\n            cli_val = getattr(self._override_by_cli, attr)\n            conf_val = getattr(config, attr)\n            final_config[attr] = cli_val if cli_val is not None else conf_val\n\n        config = CheckConfiguration(**final_config)\n\n        self._set_add_options(config.checked_codes, self._options)\n        self._cache[path] = config\n        return self._cache[path]\n\n    def _read_configuration_file(self, path):\n        \"\"\"Try to read and parse `path` as a configuration file.\n\n        If the configurations were illegal (checked with\n        `self._validate_options`), raises `IllegalConfiguration`.\n\n        Returns (options, should_inherit).\n\n        \"\"\"\n        parser = RawConfigParser()\n        options = None\n        should_inherit = True\n\n        if parser.read(path) and self._get_section_name(parser):\n            option_list = dict([(o.dest, o.type or o.action)\n                                for o in self._parser.option_list])\n\n            # First, read the default values\n            new_options, _ = self._parse_args([])\n\n            # Second, parse the configuration\n            section_name = self._get_section_name(parser)\n            for opt in parser.options(section_name):\n                if opt == 'inherit':\n                    should_inherit = parser.getboolean(section_name, opt)\n                    continue\n\n                if opt.replace('_', '-') not in self.CONFIG_FILE_OPTIONS:\n                    log.warning(\"Unknown option '{0}' ignored\".format(opt))\n                    continue\n\n                normalized_opt = opt.replace('-', '_')\n                opt_type = option_list[normalized_opt]\n                if opt_type in ('int', 'count'):\n                    value = parser.getint(section_name, opt)\n                elif opt_type == 'string':\n                    value = parser.get(section_name, opt)\n                else:\n                    assert opt_type in ('store_true', 'store_false')\n                    value = parser.getboolean(section_name, opt)\n                setattr(new_options, normalized_opt, value)\n\n            # Third, fix the set-options\n            options = self._fix_set_options(new_options)\n\n        if options is not None:\n            if not self._validate_options(options):\n                raise IllegalConfiguration('in file: {0}'.format(path))\n\n        return options, should_inherit\n\n    def _merge_configuration(self, parent_config, child_options):\n        \"\"\"Merge parent config into the child options.\n\n        The migration process requires an `options` object for the child in\n        order to distinguish between mutually exclusive codes, add-select and\n        add-ignore error codes.\n\n        \"\"\"\n        # Copy the parent error codes so we won't override them\n        error_codes = copy.deepcopy(parent_config.checked_codes)\n        if self._has_exclusive_option(child_options):\n            error_codes = self._get_exclusive_error_codes(child_options)\n\n        self._set_add_options(error_codes, child_options)\n\n        match = child_options.match \\\n            if child_options.match is not None else parent_config.match\n        match_dir = child_options.match_dir \\\n            if child_options.match_dir is not None else parent_config.match_dir\n\n        return CheckConfiguration(checked_codes=error_codes,\n                                  match=match,\n                                  match_dir=match_dir)\n\n    def _parse_args(self, args=None, values=None):\n        \"\"\"Parse the options using `self._parser` and reformat the options.\"\"\"\n        options, arguments = self._parser.parse_args(args, values)\n        return self._fix_set_options(options), arguments\n\n    @staticmethod\n    def _create_run_config(options):\n        \"\"\"Create a `RunConfiguration` object from `options`.\"\"\"\n        values = dict([(opt, getattr(options, opt)) for opt in\n                       RunConfiguration._fields])\n        return RunConfiguration(**values)\n\n    @classmethod\n    def _create_check_config(cls, options, use_dafaults=True):\n        \"\"\"Create a `CheckConfiguration` object from `options`.\n\n        If `use_dafaults`, any of the match options that are `None` will\n        be replaced with their default value and the default convention will be\n        set for the checked codes.\n\n        \"\"\"\n        match = cls.DEFAULT_MATCH_RE \\\n            if options.match is None and use_dafaults \\\n            else options.match\n\n        match_dir = cls.DEFAULT_MATCH_DIR_RE \\\n            if options.match_dir is None and use_dafaults \\\n            else options.match_dir\n\n        checked_codes = None\n\n        if cls._has_exclusive_option(options) or use_dafaults:\n            checked_codes = cls._get_checked_errors(options)\n\n        return CheckConfiguration(checked_codes=checked_codes,\n                                  match=match, match_dir=match_dir)\n\n    @classmethod\n    def _get_section_name(cls, parser):\n        \"\"\"Parse options from relevant section.\"\"\"\n        for section_name in cls.POSSIBLE_SECTION_NAMES:\n            if parser.has_section(section_name):\n                return section_name\n\n        return None\n\n    @classmethod\n    def _get_config_file_in_folder(cls, path):\n        \"\"\"Look for a configuration file in `path`.\n\n        If exists return it's full path, otherwise None.\n\n        \"\"\"\n        if os.path.isfile(path):\n            path = os.path.dirname(path)\n\n        for fn in cls.PROJECT_CONFIG_FILES:\n            config = RawConfigParser()\n            full_path = os.path.join(path, fn)\n            if config.read(full_path) and cls._get_section_name(config):\n                return full_path\n\n    @staticmethod\n    def _get_exclusive_error_codes(options):\n        \"\"\"Extract the error codes from the selected exclusive option.\"\"\"\n        codes = set(ErrorRegistry.get_error_codes())\n        checked_codes = None\n\n        if options.ignore is not None:\n            checked_codes = codes - options.ignore\n        elif options.select is not None:\n            checked_codes = options.select\n        elif options.convention is not None:\n            checked_codes = getattr(conventions, options.convention)\n\n        # To not override the conventions nor the options - copy them.\n        return copy.deepcopy(checked_codes)\n\n    @staticmethod\n    def _set_add_options(checked_codes, options):\n        \"\"\"Set `checked_codes` by the `add_ignore` or `add_select` options.\"\"\"\n        checked_codes |= options.add_select\n        checked_codes -= options.add_ignore\n\n    @classmethod\n    def _get_checked_errors(cls, options):\n        \"\"\"Extract the codes needed to be checked from `options`.\"\"\"\n        checked_codes = cls._get_exclusive_error_codes(options)\n        if checked_codes is None:\n            checked_codes = cls.DEFAULT_CONVENTION\n\n        cls._set_add_options(checked_codes, options)\n\n        return checked_codes\n\n    @classmethod\n    def _validate_options(cls, options):\n        \"\"\"Validate the mutually exclusive options.\n\n        Return `True` iff only zero or one of `BASE_ERROR_SELECTION_OPTIONS`\n        was selected.\n\n        \"\"\"\n        for opt1, opt2 in \\\n                itertools.permutations(cls.BASE_ERROR_SELECTION_OPTIONS, 2):\n            if getattr(options, opt1) and getattr(options, opt2):\n                log.error('Cannot pass both {0} and {1}. They are '\n                          'mutually exclusive.'.format(opt1, opt2))\n                return False\n\n        if options.convention and options.convention not in conventions:\n            log.error(\"Illegal convention '{0}'. Possible conventions: {1}\"\n                      .format(options.convention,\n                              ', '.join(conventions.keys())))\n            return False\n        return True\n\n    @classmethod\n    def _has_exclusive_option(cls, options):\n        \"\"\"Return `True` iff one or more exclusive options were selected.\"\"\"\n        return any([getattr(options, opt) is not None for opt in\n                    cls.BASE_ERROR_SELECTION_OPTIONS])\n\n    @staticmethod\n    def _fix_set_options(options):\n        \"\"\"Alter the set options from None/strings to sets in place.\"\"\"\n        optional_set_options = ('ignore', 'select')\n        mandatory_set_options = ('add_ignore', 'add_select')\n\n        def _get_set(value_str):\n            \"\"\"Split `value_str` by the delimiter `,` and return a set.\n\n            Removes any occurrences of '' in the set.\n\n            \"\"\"\n            return set(value_str.split(',')) - set([''])\n\n        for opt in optional_set_options:\n            value = getattr(options, opt)\n            if value is not None:\n                setattr(options, opt, _get_set(value))\n\n        for opt in mandatory_set_options:\n            value = getattr(options, opt)\n            if value is None:\n                value = ''\n\n            if not isinstance(value, Set):\n                value = _get_set(value)\n\n            setattr(options, opt, value)\n\n        return options\n\n    @classmethod\n    def _create_option_parser(cls):\n        \"\"\"Return an option parser to parse the command line arguments.\"\"\"\n        from optparse import OptionParser\n\n        parser = OptionParser(\n            version=__version__,\n            usage='Usage: pydocstyle [options] [<file|dir>...]')\n\n        option = parser.add_option\n\n        # Run configuration options\n        option('-e', '--explain', action='store_true', default=False,\n               help='show explanation of each error')\n        option('-s', '--source', action='store_true', default=False,\n               help='show source for each error')\n        option('-d', '--debug', action='store_true', default=False,\n               help='print debug information')\n        option('-v', '--verbose', action='store_true', default=False,\n               help='print status information')\n        option('--count', action='store_true', default=False,\n               help='print total number of errors to stdout')\n\n        # Error check options\n        option('--select', metavar='<codes>', default=None,\n               help='choose the basic list of checked errors by '\n                    'specifying which errors to check for (with a list of '\n                    'comma-separated error codes). '\n                    'for example: --select=D101,D202')\n        option('--ignore', metavar='<codes>', default=None,\n               help='choose the basic list of checked errors by '\n                    'specifying which errors to ignore (with a list of '\n                    'comma-separated error codes). '\n                    'for example: --ignore=D101,D202')\n        option('--convention', metavar='<name>', default=None,\n               help='choose the basic list of checked errors by specifying an '\n                    'existing convention. Possible conventions: {0}'\n                    .format(', '.join(conventions)))\n        option('--add-select', metavar='<codes>', default=None,\n               help='amend the list of errors to check for by specifying '\n                    'more error codes to check.')\n        option('--add-ignore', metavar='<codes>', default=None,\n               help='amend the list of errors to check for by specifying '\n                    'more error codes to ignore.')\n\n        # Match clauses\n        option('--match', metavar='<pattern>', default=None,\n               help=(\"check only files that exactly match <pattern> regular \"\n                     \"expression; default is --match='{0}' which matches \"\n                     \"files that don't start with 'test_' but end with \"\n                     \"'.py'\").format(cls.DEFAULT_MATCH_RE))\n        option('--match-dir', metavar='<pattern>', default=None,\n               help=(\"search only dirs that exactly match <pattern> regular \"\n                     \"expression; default is --match-dir='{0}', which \"\n                     \"matches all dirs that don't start with \"\n                     \"a dot\").format(cls.DEFAULT_MATCH_DIR_RE))\n\n        return parser\n\n\ndef check(filenames, select=None, ignore=None):\n    \"\"\"Generate PEP 257 errors that exist in `filenames` iterable.\n\n    Only returns errors with error-codes defined in `checked_codes` iterable.\n\n    Example\n    -------\n    >>> check([ppydocstyle.py.py], checked_codes=['D100'])\n    <generator object check at 0x...>\n\n    \"\"\"\n    if select is not None and ignore is not None:\n        raise IllegalConfiguration('Cannot pass both select and ignore. '\n                                   'They are mutually exclusive.')\n    elif select is not None:\n        checked_codes = select\n    elif ignore is not None:\n        checked_codes = list(set(ErrorRegistry.get_error_codes()) -\n                             set(ignore))\n    else:\n        checked_codes = conventions.pep257\n\n    for filename in filenames:\n        log.info('Checking file %s.', filename)\n        try:\n            with tokenize_open(filename) as file:\n                source = file.read()\n            for error in PEP257Checker().check_source(source, filename):\n                code = getattr(error, 'code', None)\n                if code in checked_codes:\n                    yield error\n        except (EnvironmentError, AllError):\n            yield sys.exc_info()[1]\n        except tk.TokenError:\n            yield SyntaxError('invalid syntax in file %s' % filename)\n\n\ndef setup_stream_handlers(conf):\n    \"\"\"Setup logging stream handlers according to the options.\"\"\"\n    class StdoutFilter(logging.Filter):\n        def filter(self, record):\n            return record.levelno in (logging.DEBUG, logging.INFO)\n\n    log.handlers = []\n\n    stdout_handler = logging.StreamHandler(sys.stdout)\n    stdout_handler.setLevel(logging.WARNING)\n    stdout_handler.addFilter(StdoutFilter())\n    if conf.debug:\n        stdout_handler.setLevel(logging.DEBUG)\n    elif conf.verbose:\n        stdout_handler.setLevel(logging.INFO)\n    else:\n        stdout_handler.setLevel(logging.WARNING)\n    log.addHandler(stdout_handler)\n\n    stderr_handler = logging.StreamHandler(sys.stderr)\n    stderr_handler.setLevel(logging.WARNING)\n    log.addHandler(stderr_handler)\n\n\ndef run_pydocstyle(use_pep257=False):\n    log.setLevel(logging.DEBUG)\n    conf = ConfigurationParser()\n    setup_stream_handlers(conf.get_default_run_configuration())\n\n    try:\n        conf.parse()\n    except IllegalConfiguration:\n        return ReturnCode.invalid_options\n\n    run_conf = conf.get_user_run_configuration()\n\n    # Reset the logger according to the command line arguments\n    setup_stream_handlers(run_conf)\n\n    if use_pep257:\n        log.warning(\"Deprecation Warning:\\n\"\n                    \"pep257 has been renamed to pydocstyle and the use of the \"\n                    \"pep257 executable is deprecated and will be removed in \"\n                    \"the next major version. Please use `pydocstyle` instead.\")\n\n    log.debug(\"starting in debug mode.\")\n\n    Error.explain = run_conf.explain\n    Error.source = run_conf.source\n\n    errors = []\n    try:\n        for filename, checked_codes in conf.get_files_to_check():\n            errors.extend(check((filename,), select=checked_codes))\n    except IllegalConfiguration:\n        # An illegal configuration file was found during file generation.\n        return ReturnCode.invalid_options\n\n    code = ReturnCode.no_violations_found\n    count = 0\n    for error in errors:\n        sys.stderr.write('%s\\n' % error)\n        code = ReturnCode.violations_found\n        count += 1\n    if run_conf.count:\n        print(count)\n    return code\n\n\nparse = Parser()\n\n\ndef check_for(kind, terminal=False):\n    def decorator(f):\n        f._check_for = kind\n        f._terminal = terminal\n        return f\n    return decorator\n\n\nclass PEP257Checker(object):\n    \"\"\"Checker for PEP 257.\n\n    D10x: Missing docstrings\n    D20x: Whitespace issues\n    D30x: Docstring formatting\n    D40x: Docstring content issues\n\n    \"\"\"\n\n    def check_source(self, source, filename):\n        module = parse(StringIO(source), filename)\n        for definition in module:\n            for check in self.checks:\n                terminate = False\n                if isinstance(definition, check._check_for):\n                    error = check(None, definition, definition.docstring)\n                    errors = error if hasattr(error, '__iter__') else [error]\n                    for error in errors:\n                        if error is not None:\n                            partition = check.__doc__.partition('.\\n')\n                            message, _, explanation = partition\n                            error.set_context(explanation=explanation,\n                                              definition=definition)\n                            yield error\n                            if check._terminal:\n                                terminate = True\n                                break\n                if terminate:\n                    break\n\n    @property\n    def checks(self):\n        all = [check for check in vars(type(self)).values()\n               if hasattr(check, '_check_for')]\n        return sorted(all, key=lambda check: not check._terminal)\n\n    @check_for(Definition, terminal=True)\n    def check_docstring_missing(self, definition, docstring):\n        \"\"\"D10{0,1,2,3}: Public definitions should have docstrings.\n\n        All modules should normally have docstrings.  [...] all functions and\n        classes exported by a module should also have docstrings. Public\n        methods (including the __init__ constructor) should also have\n        docstrings.\n\n        Note: Public (exported) definitions are either those with names listed\n              in __all__ variable (if present), or those that do not start\n              with a single underscore.\n\n        \"\"\"\n        if (not docstring and definition.is_public or\n                docstring and is_blank(ast.literal_eval(docstring))):\n            codes = {Module: D100, Class: D101, NestedClass: D101,\n                     Method: (lambda: D105() if is_magic(definition.name)\n                              else D102()),\n                     Function: D103, NestedFunction: D103, Package: D104}\n            return codes[type(definition)]()\n\n    @check_for(Definition)\n    def check_one_liners(self, definition, docstring):\n        \"\"\"D200: One-liner docstrings should fit on one line with quotes.\n\n        The closing quotes are on the same line as the opening quotes.\n        This looks better for one-liners.\n\n        \"\"\"\n        if docstring:\n            lines = ast.literal_eval(docstring).split('\\n')\n            if len(lines) > 1:\n                non_empty_lines = sum(1 for l in lines if not is_blank(l))\n                if non_empty_lines == 1:\n                    return D200(len(lines))\n\n    @check_for(Function)\n    def check_no_blank_before(self, function, docstring):  # def\n        \"\"\"D20{1,2}: No blank lines allowed around function/method docstring.\n\n        There's no blank line either before or after the docstring.\n\n        \"\"\"\n        if docstring:\n            before, _, after = function.source.partition(docstring)\n            blanks_before = list(map(is_blank, before.split('\\n')[:-1]))\n            blanks_after = list(map(is_blank, after.split('\\n')[1:]))\n            blanks_before_count = sum(takewhile(bool, reversed(blanks_before)))\n            blanks_after_count = sum(takewhile(bool, blanks_after))\n            if blanks_before_count != 0:\n                yield D201(blanks_before_count)\n            if not all(blanks_after) and blanks_after_count != 0:\n                yield D202(blanks_after_count)\n\n    @check_for(Class)\n    def check_blank_before_after_class(self, class_, docstring):\n        \"\"\"D20{3,4}: Class docstring should have 1 blank line around them.\n\n        Insert a blank line before and after all docstrings (one-line or\n        multi-line) that document a class -- generally speaking, the class's\n        methods are separated from each other by a single blank line, and the\n        docstring needs to be offset from the first method by a blank line;\n        for symmetry, put a blank line between the class header and the\n        docstring.\n\n        \"\"\"\n        # NOTE: this gives false-positive in this case\n        # class Foo:\n        #\n        #     \"\"\"Docstring.\"\"\"\n        #\n        #\n        # # comment here\n        # def foo(): pass\n        if docstring:\n            before, _, after = class_.source.partition(docstring)\n            blanks_before = list(map(is_blank, before.split('\\n')[:-1]))\n            blanks_after = list(map(is_blank, after.split('\\n')[1:]))\n            blanks_before_count = sum(takewhile(bool, reversed(blanks_before)))\n            blanks_after_count = sum(takewhile(bool, blanks_after))\n            if blanks_before_count != 0:\n                yield D211(blanks_before_count)\n            if blanks_before_count != 1:\n                yield D203(blanks_before_count)\n            if not all(blanks_after) and blanks_after_count != 1:\n                yield D204(blanks_after_count)\n\n    @check_for(Definition)\n    def check_blank_after_summary(self, definition, docstring):\n        \"\"\"D205: Put one blank line between summary line and description.\n\n        Multi-line docstrings consist of a summary line just like a one-line\n        docstring, followed by a blank line, followed by a more elaborate\n        description. The summary line may be used by automatic indexing tools;\n        it is important that it fits on one line and is separated from the\n        rest of the docstring by a blank line.\n\n        \"\"\"\n        if docstring:\n            lines = ast.literal_eval(docstring).strip().split('\\n')\n            if len(lines) > 1:\n                post_summary_blanks = list(map(is_blank, lines[1:]))\n                blanks_count = sum(takewhile(bool, post_summary_blanks))\n                if blanks_count != 1:\n                    return D205(blanks_count)\n\n    @check_for(Definition)\n    def check_indent(self, definition, docstring):\n        \"\"\"D20{6,7,8}: The entire docstring should be indented same as code.\n\n        The entire docstring is indented the same as the quotes at its\n        first line.\n\n        \"\"\"\n        if docstring:\n            before_docstring, _, _ = definition.source.partition(docstring)\n            _, _, indent = before_docstring.rpartition('\\n')\n            lines = docstring.split('\\n')\n            if len(lines) > 1:\n                lines = lines[1:]  # First line does not need indent.\n                indents = [leading_space(l) for l in lines if not is_blank(l)]\n                if set(' \\t') == set(''.join(indents) + indent):\n                    yield D206()\n                if (len(indents) > 1 and min(indents[:-1]) > indent or\n                        indents[-1] > indent):\n                    yield D208()\n                if min(indents) < indent:\n                    yield D207()\n\n    @check_for(Definition)\n    def check_newline_after_last_paragraph(self, definition, docstring):\n        \"\"\"D209: Put multi-line docstring closing quotes on separate line.\n\n        Unless the entire docstring fits on a line, place the closing\n        quotes on a line by themselves.\n\n        \"\"\"\n        if docstring:\n            lines = [l for l in ast.literal_eval(docstring).split('\\n')\n                     if not is_blank(l)]\n            if len(lines) > 1:\n                if docstring.split(\"\\n\")[-1].strip() not in ['\"\"\"', \"'''\"]:\n                    return D209()\n\n    @check_for(Definition)\n    def check_surrounding_whitespaces(self, definition, docstring):\n        \"\"\"D210: No whitespaces allowed surrounding docstring text.\"\"\"\n        if docstring:\n            lines = ast.literal_eval(docstring).split('\\n')\n            if lines[0].startswith(' ') or \\\n                    len(lines) == 1 and lines[0].endswith(' '):\n                return D210()\n\n    @check_for(Definition)\n    def check_multi_line_summary_start(self, definition, docstring):\n        \"\"\"D21{2,3}: Multi-line docstring summary style check.\n\n        A multi-line docstring summary should start either at the first,\n        or separately at the second line of a docstring.\n\n        \"\"\"\n        if docstring:\n            start_triple = [\n                '\"\"\"', \"'''\",\n                'u\"\"\"', \"u'''\",\n                'r\"\"\"', \"r'''\",\n                'ur\"\"\"', \"ur'''\"\n            ]\n\n            lines = ast.literal_eval(docstring).split('\\n')\n            if len(lines) > 1:\n                first = docstring.split(\"\\n\")[0].strip().lower()\n                if first in start_triple:\n                    return D212()\n                else:\n                    return D213()\n\n    @check_for(Definition)\n    def check_triple_double_quotes(self, definition, docstring):\n        r'''D300: Use \"\"\"triple double quotes\"\"\".\n\n        For consistency, always use \"\"\"triple double quotes\"\"\" around\n        docstrings. Use r\"\"\"raw triple double quotes\"\"\" if you use any\n        backslashes in your docstrings. For Unicode docstrings, use\n        u\"\"\"Unicode triple-quoted strings\"\"\".\n\n        Note: Exception to this is made if the docstring contains\n              \"\"\" quotes in its body.\n\n        '''\n        if docstring:\n            opening = docstring[:5].lower()\n            if '\"\"\"' in ast.literal_eval(docstring) and opening.startswith(\n                    (\"'''\", \"r'''\", \"u'''\", \"ur'''\")):\n                # Allow ''' quotes if docstring contains \"\"\", because\n                # otherwise \"\"\" quotes could not be expressed inside\n                # docstring. Not in PEP 257.\n                return\n            if not opening.startswith(('\"\"\"', 'r\"\"\"', 'u\"\"\"', 'ur\"\"\"')):\n                quotes = \"'''\" if \"'''\" in opening else \"'\"\n                return D300(quotes)\n\n    @check_for(Definition)\n    def check_backslashes(self, definition, docstring):\n        r'''D301: Use r\"\"\" if any backslashes in a docstring.\n\n        Use r\"\"\"raw triple double quotes\"\"\" if you use any backslashes\n        (\\) in your docstrings.\n\n        '''\n        # Just check that docstring is raw, check_triple_double_quotes\n        # ensures the correct quotes.\n        if docstring and '\\\\' in docstring and not docstring.startswith(\n                ('r', 'ur')):\n            return D301()\n\n    @check_for(Definition)\n    def check_unicode_docstring(self, definition, docstring):\n        r'''D302: Use u\"\"\" for docstrings with Unicode.\n\n        For Unicode docstrings, use u\"\"\"Unicode triple-quoted strings\"\"\".\n\n        '''\n        if definition.module.future_imports['unicode_literals']:\n            return\n\n        # Just check that docstring is unicode, check_triple_double_quotes\n        # ensures the correct quotes.\n        if docstring and sys.version_info[0] <= 2:\n            if not is_ascii(docstring) and not docstring.startswith(\n                    ('u', 'ur')):\n                return D302()\n\n    @check_for(Definition)\n    def check_ends_with_period(self, definition, docstring):\n        \"\"\"D400: First line should end with a period.\n\n        The [first line of a] docstring is a phrase ending in a period.\n\n        \"\"\"\n        if docstring:\n            summary_line = ast.literal_eval(docstring).strip().split('\\n')[0]\n            if not summary_line.endswith('.'):\n                return D400(summary_line[-1])\n\n    @check_for(Function)\n    def check_imperative_mood(self, function, docstring):  # def context\n        \"\"\"D401: First line should be in imperative mood: 'Do', not 'Does'.\n\n        [Docstring] prescribes the function or method's effect as a command:\n        (\"Do this\", \"Return that\"), not as a description; e.g. don't write\n        \"Returns the pathname ...\".\n\n        \"\"\"\n        if docstring:\n            stripped = ast.literal_eval(docstring).strip()\n            if stripped:\n                first_word = stripped.split()[0]\n                if first_word.endswith('s') and not first_word.endswith('ss'):\n                    return D401(first_word[:-1], first_word)\n\n    @check_for(Function)\n    def check_no_signature(self, function, docstring):  # def context\n        \"\"\"D402: First line should not be function's or method's \"signature\".\n\n        The one-line docstring should NOT be a \"signature\" reiterating the\n        function/method parameters (which can be obtained by introspection).\n\n        \"\"\"\n        if docstring:\n            first_line = ast.literal_eval(docstring).strip().split('\\n')[0]\n            if function.name + '(' in first_line.replace(' ', ''):\n                return D402()\n\n    @check_for(Function)\n    def check_capitalized(self, function, docstring):\n        \"\"\"D403: First word of the first line should be properly capitalized.\n\n        The [first line of a] docstring is a phrase ending in a period.\n\n        \"\"\"\n        if docstring:\n            first_word = ast.literal_eval(docstring).split()[0]\n            if first_word == first_word.upper():\n                return\n            for char in first_word:\n                if char not in string.ascii_letters and char != \"'\":\n                    return\n            if first_word != first_word.capitalize():\n                return D403(first_word.capitalize(), first_word)\n\n    @check_for(Definition)\n    def check_starts_with_this(self, function, docstring):\n        \"\"\"D404: First word of the docstring should not be `This`.\n\n        Docstrings should use short, simple language. They should not begin\n        with \"This class is [..]\" or \"This module contains [..]\".\n\n        \"\"\"\n        if docstring:\n            first_word = ast.literal_eval(docstring).split()[0]\n            if first_word.lower() == 'this':\n                return D404()\n\n    # Somewhat hard to determine if return value is mentioned.\n    # @check(Function)\n    def SKIP_check_return_type(self, function, docstring):\n        \"\"\"D40x: Return value type should be mentioned.\n\n        [T]he nature of the return value cannot be determined by\n        introspection, so it should be mentioned.\n\n        \"\"\"\n        if docstring and function.returns_value:\n            if 'return' not in docstring.lower():\n                return Error()\n\n\ndef main(use_pep257=False):\n    try:\n        sys.exit(run_pydocstyle(use_pep257))\n    except KeyboardInterrupt:\n        pass\n\n\ndef main_pep257():\n    main(use_pep257=True)\n\n\nif __name__ == '__main__':\n    main()\n",
        "source_code_len": 64318,
        "target_code": "\"\"\"Example module\n\nThis is a description\n\"\"\"\n\n\nclass Foo(object):\n\n    class_var = 42  #: Class var docstring\n\n    another_class_var = 42\n    \"\"\"Another class var docstring\"\"\"\n\n    class Meta(object):\n        \"\"\"A nested class just to test things out\"\"\"\n\n        @classmethod\n        def foo():\n            \"\"\"The foo class method\"\"\"\n            return True\n\n    def method_okay(self, foo=None, bar=None):\n        \"\"\"This method should parse okay\"\"\"\n        return True\n\n    def method_multiline(self, foo=None, bar=None,\n                         baz=None):\n        \"\"\"This is on multiple lines, but should parse okay too\n\n        pydocstyle gives us lines of source. Test if this means that multiline\n        definitions are covered in the way we're anticipating here\n        \"\"\"\n        return True\n\n    def method_tricky(self, foo=None, bar=dict(foo=1, bar=2)):\n        \"\"\"This will likely fail our argument testing\n\n        We parse naively on commas, so the nested dictionary will throw this off\n        \"\"\"\n        return True\n",
        "target_code_len": 1033,
        "diff_format": "@@ -1,1734 +1,40 @@\n-#! /usr/bin/env python\n-\"\"\"Static analysis tool for checking docstring conventions and style.\n+\"\"\"Example module\n \n-The repository is located at:\n-http://github.com/PyCQA/pydocstyle\n-\n+This is a description\n \"\"\"\n-from __future__ import with_statement\n-\n-import os\n-import string\n-import sys\n-import ast\n-import copy\n-import logging\n-import tokenize as tk\n-from itertools import takewhile, dropwhile, chain\n-from re import compile as re\n-import itertools\n-from collections import defaultdict, namedtuple, Set\n-\n-try:  # Python 3.x\n-    from ConfigParser import RawConfigParser\n-except ImportError:  # Python 2.x\n-    from configparser import RawConfigParser\n-\n-log = logging.getLogger(__name__)\n \n \n-try:\n-    from StringIO import StringIO\n-except ImportError:  # Python 3.0 and later\n-    from io import StringIO\n+class Foo(object):\n \n+    class_var = 42  #: Class var docstring\n \n-try:\n-    next\n-except NameError:  # Python 2.5 and earlier\n-    nothing = object()\n+    another_class_var = 42\n+    \"\"\"Another class var docstring\"\"\"\n \n-    def next(obj, default=nothing):\n-        if default == nothing:\n-            return obj.next()\n-        else:\n-            try:\n-                return obj.next()\n-            except StopIteration:\n-                return default\n+    class Meta(object):\n+        \"\"\"A nested class just to test things out\"\"\"\n \n+        @classmethod\n+        def foo():\n+            \"\"\"The foo class method\"\"\"\n+            return True\n \n-# If possible (python >= 3.2) use tokenize.open to open files, so PEP 263\n-# encoding markers are interpreted.\n-try:\n-    tokenize_open = tk.open\n-except AttributeError:\n-    tokenize_open = open\n-\n-\n-__version__ = '1.0.1-rc1'\n-__all__ = ('check',)\n-\n-\n-class ReturnCode(object):\n-    no_violations_found = 0\n-    violations_found = 1\n-    invalid_options = 2\n-\n-\n-VARIADIC_MAGIC_METHODS = ('__init__', '__call__', '__new__')\n-\n-\n-def humanize(string):\n-    return re(r'(.)([A-Z]+)').sub(r'\\1 \\2', string).lower()\n-\n-\n-def is_magic(name):\n-    return (name.startswith('__') and\n-            name.endswith('__') and\n-            name not in VARIADIC_MAGIC_METHODS)\n-\n-\n-def is_ascii(string):\n-    return all(ord(char) < 128 for char in string)\n-\n-\n-def is_blank(string):\n-    return not string.strip()\n-\n-\n-def leading_space(string):\n-    return re('\\s*').match(string).group()\n-\n-\n-class Value(object):\n-\n-    def __init__(self, *args):\n-        vars(self).update(zip(self._fields, args))\n-\n-    def __hash__(self):\n-        return hash(repr(self))\n-\n-    def __eq__(self, other):\n-        return other and vars(self) == vars(other)\n-\n-    def __repr__(self):\n-        kwargs = ', '.join('{0}={1!r}'.format(field, getattr(self, field))\n-                           for field in self._fields)\n-        return '{0}({1})'.format(self.__class__.__name__, kwargs)\n-\n-\n-class Definition(Value):\n-\n-    _fields = ('name', '_source', 'start', 'end', 'decorators', 'docstring',\n-               'children', 'parent')\n-\n-    _human = property(lambda self: humanize(type(self).__name__))\n-    kind = property(lambda self: self._human.split()[-1])\n-    module = property(lambda self: self.parent.module)\n-    all = property(lambda self: self.module.all)\n-    _slice = property(lambda self: slice(self.start - 1, self.end))\n-    is_class = False\n-\n-    def __iter__(self):\n-        return chain([self], *self.children)\n-\n-    @property\n-    def _publicity(self):\n-        return {True: 'public', False: 'private'}[self.is_public]\n-\n-    @property\n-    def source(self):\n-        \"\"\"Return the source code for the definition.\"\"\"\n-        full_src = self._source[self._slice]\n-\n-        def is_empty_or_comment(line):\n-            return line.strip() == '' or line.strip().startswith('#')\n-\n-        filtered_src = dropwhile(is_empty_or_comment, reversed(full_src))\n-        return ''.join(reversed(list(filtered_src)))\n-\n-    def __str__(self):\n-        return 'in %s %s `%s`' % (self._publicity, self._human, self.name)\n-\n-\n-class Module(Definition):\n-\n-    _fields = ('name', '_source', 'start', 'end', 'decorators', 'docstring',\n-               'children', 'parent', '_all', 'future_imports')\n-    is_public = True\n-    _nest = staticmethod(lambda s: {'def': Function, 'class': Class}[s])\n-    module = property(lambda self: self)\n-    all = property(lambda self: self._all)\n-\n-    def __str__(self):\n-        return 'at module level'\n-\n-\n-class Package(Module):\n-    \"\"\"A package is a __init__.py module.\"\"\"\n-\n-\n-class Function(Definition):\n-\n-    _nest = staticmethod(lambda s: {'def': NestedFunction,\n-                                    'class': NestedClass}[s])\n-\n-    @property\n-    def is_public(self):\n-        if self.all is not None:\n-            return self.name in self.all\n-        else:\n-            return not self.name.startswith('_')\n-\n-    @property \n-    def args(self):\n-        sig = self.source.split('\\n')[0]\n-        sig = sig.split('(')[1]\n-        sig = sig.split(')')[0]\n-        return sig.split(',')\n-\n-\n-class NestedFunction(Function):\n-\n-    is_public = False\n-\n-\n-class Method(Function):\n-\n-    @property\n-    def is_public(self):\n-        # Check if we are a setter/deleter method, and mark as private if so.\n-        for decorator in self.decorators:\n-            # Given 'foo', match 'foo.bar' but not 'foobar' or 'sfoo'\n-            if re(r\"^{0}\\.\".format(self.name)).match(decorator.name):\n-                return False\n-        name_is_public = (not self.name.startswith('_') or\n-                          self.name in VARIADIC_MAGIC_METHODS or\n-                          is_magic(self.name))\n-        return self.parent.is_public and name_is_public\n-\n-\n-class Class(Definition):\n-\n-    _nest = staticmethod(lambda s: {'def': Method, 'class': NestedClass}[s])\n-    is_public = Function.is_public\n-    is_class = True\n-\n-\n-class NestedClass(Class):\n-\n-    @property\n-    def is_public(self):\n-        return (not self.name.startswith('_') and\n-                self.parent.is_class and\n-                self.parent.is_public)\n-\n-\n-class Decorator(Value):\n-    \"\"\"A decorator for function, method or class.\"\"\"\n-\n-    _fields = 'name arguments'.split()\n-\n-\n-class TokenKind(int):\n-    def __repr__(self):\n-        return \"tk.{0}\".format(tk.tok_name[self])\n-\n-\n-class Token(Value):\n-\n-    _fields = 'kind value start end source'.split()\n-\n-    def __init__(self, *args):\n-        super(Token, self).__init__(*args)\n-        self.kind = TokenKind(self.kind)\n-\n-\n-class TokenStream(object):\n-\n-    def __init__(self, filelike):\n-        self._generator = tk.generate_tokens(filelike.readline)\n-        self.current = Token(*next(self._generator, None))\n-        self.line = self.current.start[0]\n-\n-    def move(self):\n-        previous = self.current\n-        current = next(self._generator, None)\n-        self.current = None if current is None else Token(*current)\n-        self.line = self.current.start[0] if self.current else self.line\n-        return previous\n-\n-    def __iter__(self):\n-        while True:\n-            if self.current is not None:\n-                yield self.current\n-            else:\n-                return\n-            self.move()\n-\n-\n-class AllError(Exception):\n-\n-    def __init__(self, message):\n-        Exception.__init__(\n-            self, message +\n-            'That means pydocstyle cannot decide which definitions are public.'\n-            ' Variable __all__ should be present at most once in each file, '\n-            \"in form `__all__ = ('a_public_function', 'APublicClass', ...)`. \"\n-            'More info on __all__: http://stackoverflow.com/q/44834/. ')\n-\n-\n-class Parser(object):\n-\n-    def __call__(self, filelike, filename):\n-        self.source = filelike.readlines()\n-        src = ''.join(self.source)\n-        self.stream = TokenStream(StringIO(src))\n-        self.filename = filename\n-        self.all = None\n-        self.future_imports = defaultdict(lambda: False)\n-        self._accumulated_decorators = []\n-        return self.parse_module()\n-\n-    current = property(lambda self: self.stream.current)\n-    line = property(lambda self: self.stream.line)\n-\n-    def consume(self, kind):\n-        \"\"\"Consume one token and verify it is of the expected kind.\"\"\"\n-        next_token = self.stream.move()\n-        assert next_token.kind == kind\n-\n-    def leapfrog(self, kind, value=None):\n-        \"\"\"Skip tokens in the stream until a certain token kind is reached.\n-\n-        If `value` is specified, tokens whose values are different will also\n-        be skipped.\n-        \"\"\"\n-        while self.current is not None:\n-            if (self.current.kind == kind and\n-               (value is None or self.current.value == value)):\n-                self.consume(kind)\n-                return\n-            self.stream.move()\n-\n-    def parse_docstring(self):\n-        \"\"\"Parse a single docstring and return its value.\"\"\"\n-        log.debug(\"parsing docstring, token is %r (%s)\",\n-                  self.current.kind, self.current.value)\n-        while self.current.kind in (tk.COMMENT, tk.NEWLINE, tk.NL):\n-            self.stream.move()\n-            log.debug(\"parsing docstring, token is %r (%s)\",\n-                      self.current.kind, self.current.value)\n-        if self.current.kind == tk.STRING:\n-            docstring = self.current.value\n-            self.stream.move()\n-            return docstring\n-        return None\n-\n-    def parse_decorators(self):\n-        \"\"\"Called after first @ is found.\n-\n-        Parse decorators into self._accumulated_decorators.\n-        Continue to do so until encountering the 'def' or 'class' start token.\n-        \"\"\"\n-        name = []\n-        arguments = []\n-        at_arguments = False\n-\n-        while self.current is not None:\n-            if (self.current.kind == tk.NAME and\n-                    self.current.value in ['def', 'class']):\n-                # Done with decorators - found function or class proper\n-                break\n-            elif self.current.kind == tk.OP and self.current.value == '@':\n-                # New decorator found. Store the decorator accumulated so far:\n-                self._accumulated_decorators.append(\n-                    Decorator(''.join(name), ''.join(arguments)))\n-                # Now reset to begin accumulating the new decorator:\n-                name = []\n-                arguments = []\n-                at_arguments = False\n-            elif self.current.kind == tk.OP and self.current.value == '(':\n-                at_arguments = True\n-            elif self.current.kind == tk.OP and self.current.value == ')':\n-                # Ignore close parenthesis\n-                pass\n-            elif self.current.kind == tk.NEWLINE or self.current.kind == tk.NL:\n-                # Ignore newlines\n-                pass\n-            else:\n-                # Keep accumulating current decorator's name or argument.\n-                if not at_arguments:\n-                    name.append(self.current.value)\n-                else:\n-                    arguments.append(self.current.value)\n-            self.stream.move()\n-\n-        # Add decorator accumulated so far\n-        self._accumulated_decorators.append(\n-            Decorator(''.join(name), ''.join(arguments)))\n-\n-    def parse_definitions(self, class_, all=False):\n-        \"\"\"Parse multiple definitions and yield them.\"\"\"\n-        while self.current is not None:\n-            log.debug(\"parsing definition list, current token is %r (%s)\",\n-                      self.current.kind, self.current.value)\n-            if all and self.current.value == '__all__':\n-                self.parse_all()\n-            elif self.current.kind == tk.OP and self.current.value == '@':\n-                self.consume(tk.OP)\n-                self.parse_decorators()\n-            elif self.current.value in ['def', 'class']:\n-                yield self.parse_definition(class_._nest(self.current.value))\n-            elif self.current.kind == tk.INDENT:\n-                self.consume(tk.INDENT)\n-                for definition in self.parse_definitions(class_):\n-                    yield definition\n-            elif self.current.kind == tk.DEDENT:\n-                self.consume(tk.DEDENT)\n-                return\n-            elif self.current.value == 'from':\n-                self.parse_from_import_statement()\n-            else:\n-                self.stream.move()\n-\n-    def parse_all(self):\n-        \"\"\"Parse the __all__ definition in a module.\"\"\"\n-        assert self.current.value == '__all__'\n-        self.consume(tk.NAME)\n-        if self.current.value != '=':\n-            raise AllError('Could not evaluate contents of __all__. ')\n-        self.consume(tk.OP)\n-        if self.current.value not in '([':\n-            raise AllError('Could not evaluate contents of __all__. ')\n-        if self.current.value == '[':\n-            msg = (\"%s WARNING: __all__ is defined as a list, this means \"\n-                   \"pydocstyle cannot reliably detect contents of the __all__ \"\n-                   \"variable, because it can be mutated. Change __all__ to be \"\n-                   \"an (immutable) tuple, to remove this warning. Note, \"\n-                   \"pydocstyle uses __all__ to detect which definitions are \"\n-                   \"public, to warn if public definitions are missing \"\n-                   \"docstrings. If __all__ is a (mutable) list, pydocstyle \"\n-                   \"cannot reliably assume its contents. pydocstyle will \"\n-                   \"proceed assuming __all__ is not mutated.\\n\"\n-                   % self.filename)\n-            sys.stderr.write(msg)\n-        self.consume(tk.OP)\n-\n-        self.all = []\n-        all_content = \"(\"\n-        while self.current.kind != tk.OP or self.current.value not in \")]\":\n-            if self.current.kind in (tk.NL, tk.COMMENT):\n-                pass\n-            elif (self.current.kind == tk.STRING or\n-                  self.current.value == ','):\n-                all_content += self.current.value\n-            else:\n-                raise AllError('Unexpected token kind in  __all__: %r. ' %\n-                               self.current.kind)\n-            self.stream.move()\n-        self.consume(tk.OP)\n-        all_content += \")\"\n-        try:\n-            self.all = eval(all_content, {})\n-        except BaseException as e:\n-            raise AllError('Could not evaluate contents of __all__.'\n-                           '\\bThe value was %s. The exception was:\\n%s'\n-                           % (all_content, e))\n-\n-    def parse_module(self):\n-        \"\"\"Parse a module (and its children) and return a Module object.\"\"\"\n-        log.debug(\"parsing module.\")\n-        start = self.line\n-        docstring = self.parse_docstring()\n-        children = list(self.parse_definitions(Module, all=True))\n-        assert self.current is None, self.current\n-        end = self.line\n-        cls = Module\n-        if self.filename.endswith('__init__.py'):\n-            cls = Package\n-        module = cls(self.filename, self.source, start, end,\n-                     [], docstring, children, None, self.all)\n-        for child in module.children:\n-            child.parent = module\n-        module.future_imports = self.future_imports\n-        log.debug(\"finished parsing module.\")\n-        return module\n-\n-    def parse_definition(self, class_):\n-        \"\"\"Parse a definition and return its value in a `class_` object.\"\"\"\n-        start = self.line\n-        self.consume(tk.NAME)\n-        name = self.current.value\n-        log.debug(\"parsing %s '%s'\", class_.__name__, name)\n-        self.stream.move()\n-        if self.current.kind == tk.OP and self.current.value == '(':\n-            parenthesis_level = 0\n-            while True:\n-                if self.current.kind == tk.OP:\n-                    if self.current.value == '(':\n-                        parenthesis_level += 1\n-                    elif self.current.value == ')':\n-                        parenthesis_level -= 1\n-                        if parenthesis_level == 0:\n-                            break\n-                self.stream.move()\n-        if self.current.kind != tk.OP or self.current.value != ':':\n-            self.leapfrog(tk.OP, value=\":\")\n-        else:\n-            self.consume(tk.OP)\n-        if self.current.kind in (tk.NEWLINE, tk.COMMENT):\n-            self.leapfrog(tk.INDENT)\n-            assert self.current.kind != tk.INDENT\n-            docstring = self.parse_docstring()\n-            decorators = self._accumulated_decorators\n-            self._accumulated_decorators = []\n-            log.debug(\"parsing nested definitions.\")\n-            children = list(self.parse_definitions(class_))\n-            log.debug(\"finished parsing nested definitions for '%s'\", name)\n-            end = self.line - 1\n-        else:  # one-liner definition\n-            docstring = self.parse_docstring()\n-            decorators = []  # TODO\n-            children = []\n-            end = self.line\n-            self.leapfrog(tk.NEWLINE)\n-        definition = class_(name, self.source, start, end,\n-                            decorators, docstring, children, None)\n-        for child in definition.children:\n-            child.parent = definition\n-        log.debug(\"finished parsing %s '%s'. Next token is %r (%s)\",\n-                  class_.__name__, name, self.current.kind,\n-                  self.current.value)\n-        return definition\n-\n-    def parse_from_import_statement(self):\n-        \"\"\"Parse a 'from x import y' statement.\n-\n-        The purpose is to find __future__ statements.\n-\n-        \"\"\"\n-        log.debug('parsing from/import statement.')\n-        assert self.current.value == 'from', self.current.value\n-        self.stream.move()\n-        if self.current.value != '__future__':\n-            return\n-        self.stream.move()\n-        assert self.current.value == 'import', self.current.value\n-        self.stream.move()\n-        if self.current.value == '(':\n-            self.consume(tk.OP)\n-            expected_end_kind = tk.OP\n-        else:\n-            expected_end_kind = tk.NEWLINE\n-        while self.current.kind != expected_end_kind and not(\n-                self.current.kind == tk.OP and self.current.value == ';'):\n-            if self.current.kind != tk.NAME:\n-                self.stream.move()\n-                continue\n-            log.debug(\"parsing import, token is %r (%s)\",\n-                      self.current.kind, self.current.value)\n-            log.debug('found future import: %s', self.current.value)\n-            self.future_imports[self.current.value] = True\n-            self.consume(tk.NAME)\n-            log.debug(\"parsing import, token is %r (%s)\",\n-                      self.current.kind, self.current.value)\n-            if self.current.kind == tk.NAME and self.current.value == 'as':\n-                self.consume(tk.NAME)  # as\n-                if self.current.kind == tk.NAME:\n-                    self.consume(tk.NAME)  # new name, irrelevant\n-            if self.current.value == ',':\n-                self.consume(tk.OP)\n-            log.debug(\"parsing import, token is %r (%s)\",\n-                      self.current.kind, self.current.value)\n-\n-\n-class Error(object):\n-    \"\"\"Error in docstring style.\"\"\"\n-\n-    # should be overridden by inheriting classes\n-    code = None\n-    short_desc = None\n-    context = None\n-\n-    # Options that define how errors are printed:\n-    explain = False\n-    source = False\n-\n-    def __init__(self, *parameters):\n-        self.parameters = parameters\n-        self.definition = None\n-        self.explanation = None\n-\n-    def set_context(self, definition, explanation):\n-        self.definition = definition\n-        self.explanation = explanation\n-\n-    filename = property(lambda self: self.definition.module.name)\n-    line = property(lambda self: self.definition.start)\n-\n-    @property\n-    def message(self):\n-        ret = '%s: %s' % (self.code, self.short_desc)\n-        if self.context is not None:\n-            ret += ' (' + self.context % self.parameters + ')'\n-        return ret\n-\n-    @property\n-    def lines(self):\n-        source = ''\n-        lines = self.definition._source[self.definition._slice]\n-        offset = self.definition.start\n-        lines_stripped = list(reversed(list(dropwhile(is_blank,\n-                                                      reversed(lines)))))\n-        numbers_width = 0\n-        for n, line in enumerate(lines_stripped):\n-            numbers_width = max(numbers_width, n + offset)\n-        numbers_width = len(str(numbers_width))\n-        numbers_width = 6\n-        for n, line in enumerate(lines_stripped):\n-            source += '%*d: %s' % (numbers_width, n + offset, line)\n-            if n > 5:\n-                source += '        ...\\n'\n-                break\n-        return source\n-\n-    def __str__(self):\n-        self.explanation = '\\n'.join(l for l in self.explanation.split('\\n')\n-                                     if not is_blank(l))\n-        template = '%(filename)s:%(line)s %(definition)s:\\n        %(message)s'\n-        if self.source and self.explain:\n-            template += '\\n\\n%(explanation)s\\n\\n%(lines)s\\n'\n-        elif self.source and not self.explain:\n-            template += '\\n\\n%(lines)s\\n'\n-        elif self.explain and not self.source:\n-            template += '\\n\\n%(explanation)s\\n\\n'\n-        return template % dict((name, getattr(self, name)) for name in\n-                               ['filename', 'line', 'definition', 'message',\n-                                'explanation', 'lines'])\n-\n-    __repr__ = __str__\n-\n-    def __lt__(self, other):\n-        return (self.filename, self.line) < (other.filename, other.line)\n-\n-\n-class ErrorRegistry(object):\n-    groups = []\n-\n-    class ErrorGroup(object):\n-\n-        def __init__(self, prefix, name):\n-            self.prefix = prefix\n-            self.name = name\n-            self.errors = []\n-\n-        def create_error(self, error_code, error_desc, error_context=None):\n-            # TODO: check prefix\n-\n-            class _Error(Error):\n-                code = error_code\n-                short_desc = error_desc\n-                context = error_context\n-\n-            self.errors.append(_Error)\n-            return _Error\n-\n-    @classmethod\n-    def create_group(cls, prefix, name):\n-        group = cls.ErrorGroup(prefix, name)\n-        cls.groups.append(group)\n-        return group\n-\n-    @classmethod\n-    def get_error_codes(cls):\n-        for group in cls.groups:\n-            for error in group.errors:\n-                yield error.code\n-\n-    @classmethod\n-    def to_rst(cls):\n-        sep_line = '+' + 6 * '-' + '+' + '-' * 71 + '+\\n'\n-        blank_line = '|' + 78 * ' ' + '|\\n'\n-        table = ''\n-        for group in cls.groups:\n-            table += sep_line\n-            table += blank_line\n-            table += '|' + ('**%s**' % group.name).center(78) + '|\\n'\n-            table += blank_line\n-            for error in group.errors:\n-                table += sep_line\n-                table += ('|' + error.code.center(6) + '| ' +\n-                          error.short_desc.ljust(70) + '|\\n')\n-        table += sep_line\n-        return table\n-\n-\n-D1xx = ErrorRegistry.create_group('D1', 'Missing Docstrings')\n-D100 = D1xx.create_error('D100', 'Missing docstring in public module')\n-D101 = D1xx.create_error('D101', 'Missing docstring in public class')\n-D102 = D1xx.create_error('D102', 'Missing docstring in public method')\n-D103 = D1xx.create_error('D103', 'Missing docstring in public function')\n-D104 = D1xx.create_error('D104', 'Missing docstring in public package')\n-D105 = D1xx.create_error('D105', 'Missing docstring in magic method')\n-\n-D2xx = ErrorRegistry.create_group('D2', 'Whitespace Issues')\n-D200 = D2xx.create_error('D200', 'One-line docstring should fit on one line '\n-                                 'with quotes', 'found %s')\n-D201 = D2xx.create_error('D201', 'No blank lines allowed before function '\n-                                 'docstring', 'found %s')\n-D202 = D2xx.create_error('D202', 'No blank lines allowed after function '\n-                                 'docstring', 'found %s')\n-D203 = D2xx.create_error('D203', '1 blank line required before class '\n-                                 'docstring', 'found %s')\n-D204 = D2xx.create_error('D204', '1 blank line required after class '\n-                                 'docstring', 'found %s')\n-D205 = D2xx.create_error('D205', '1 blank line required between summary line '\n-                                 'and description', 'found %s')\n-D206 = D2xx.create_error('D206', 'Docstring should be indented with spaces, '\n-                                 'not tabs')\n-D207 = D2xx.create_error('D207', 'Docstring is under-indented')\n-D208 = D2xx.create_error('D208', 'Docstring is over-indented')\n-D209 = D2xx.create_error('D209', 'Multi-line docstring closing quotes should '\n-                                 'be on a separate line')\n-D210 = D2xx.create_error('D210', 'No whitespaces allowed surrounding '\n-                                 'docstring text')\n-D211 = D2xx.create_error('D211', 'No blank lines allowed before class '\n-                                 'docstring', 'found %s')\n-D212 = D2xx.create_error('D212', 'Multi-line docstring summary should start '\n-                                 'at the first line')\n-D213 = D2xx.create_error('D213', 'Multi-line docstring summary should start '\n-                                 'at the second line')\n-\n-D3xx = ErrorRegistry.create_group('D3', 'Quotes Issues')\n-D300 = D3xx.create_error('D300', 'Use \"\"\"triple double quotes\"\"\"',\n-                         'found %s-quotes')\n-D301 = D3xx.create_error('D301', 'Use r\"\"\" if any backslashes in a docstring')\n-D302 = D3xx.create_error('D302', 'Use u\"\"\" for Unicode docstrings')\n-\n-D4xx = ErrorRegistry.create_group('D4', 'Docstring Content Issues')\n-D400 = D4xx.create_error('D400', 'First line should end with a period',\n-                         'not %r')\n-D401 = D4xx.create_error('D401', 'First line should be in imperative mood',\n-                         '%r, not %r')\n-D402 = D4xx.create_error('D402', 'First line should not be the function\\'s '\n-                                 '\"signature\"')\n-D403 = D4xx.create_error('D403', 'First word of the first line should be '\n-                                 'properly capitalized', '%r, not %r')\n-D404 = D4xx.create_error('D404', 'First word of the docstring should not '\n-                                 'be `This`')\n-\n-\n-class AttrDict(dict):\n-    def __getattr__(self, item):\n-        return self[item]\n-\n-\n-conventions = AttrDict({\n-    'pep257': set(ErrorRegistry.get_error_codes()) - set(['D203',\n-                                                          'D212',\n-                                                          'D213',\n-                                                          'D404'])\n-})\n-\n-\n-# General configurations for pydocstyle run.\n-RunConfiguration = namedtuple('RunConfiguration',\n-                              ('explain', 'source', 'debug',\n-                               'verbose', 'count'))\n-\n-\n-class IllegalConfiguration(Exception):\n-    \"\"\"An exception for illegal configurations.\"\"\"\n-\n-    pass\n-\n-\n-# Check configuration - used by the ConfigurationParser class.\n-CheckConfiguration = namedtuple('CheckConfiguration',\n-                                ('checked_codes', 'match', 'match_dir'))\n-\n-\n-def check_initialized(method):\n-    \"\"\"Check that the configuration object was initialized.\"\"\"\n-    def _decorator(self, *args, **kwargs):\n-        if self._arguments is None or self._options is None:\n-            raise RuntimeError('using an uninitialized configuration')\n-        return method(self, *args, **kwargs)\n-    return _decorator\n-\n-\n-class ConfigurationParser(object):\n-    \"\"\"Responsible for parsing configuration from files and CLI.\n-\n-    There are 2 types of configurations: Run configurations and Check\n-    configurations.\n-\n-    Run Configurations:\n-    -------------------\n-\n-    Responsible for deciding things that are related to the user interface,\n-    e.g. verbosity, debug options, etc.\n-    All run configurations default to `False` and are decided only by CLI.\n-\n-    Check Configurations:\n-    ---------------------\n-\n-    Configurations that are related to which files and errors will be checked.\n-    These are configurable in 2 ways: using the CLI, and using configuration\n-    files.\n-\n-    Configuration files are nested within the file system, meaning that the\n-    closer a configuration file is to a checked file, the more relevant it will\n-    be. For instance, imagine this directory structure:\n-\n-    A\n-    +-- tox.ini: sets `select=D100`\n-    +-- B\n-        +-- foo.py\n-        +-- tox.ini: sets `add-ignore=D100`\n-\n-    Then `foo.py` will not be checked for `D100`.\n-    The configuration build algorithm is described in `self._get_config`.\n-\n-    Note: If any of `BASE_ERROR_SELECTION_OPTIONS` was selected in the CLI, all\n-    configuration files will be ignored and each file will be checked for\n-    the error codes supplied in the CLI.\n-\n-    \"\"\"\n-\n-    CONFIG_FILE_OPTIONS = ('convention', 'select', 'ignore', 'add-select',\n-                           'add-ignore', 'match', 'match-dir')\n-    BASE_ERROR_SELECTION_OPTIONS = ('ignore', 'select', 'convention')\n-\n-    DEFAULT_MATCH_RE = '(?!test_).*\\.py'\n-    DEFAULT_MATCH_DIR_RE = '[^\\.].*'\n-    DEFAULT_CONVENTION = conventions.pep257\n-\n-    PROJECT_CONFIG_FILES = (\n-        'setup.cfg',\n-        'tox.ini',\n-        '.pydocstyle',\n-        '.pydocstylerc',\n-        # The following is deprecated, but remains for backwards compatibility.\n-        '.pep257',\n-    )\n-\n-    POSSIBLE_SECTION_NAMES = ('pydocstyle', 'pep257')\n-\n-    def __init__(self):\n-        \"\"\"Create a configuration parser.\"\"\"\n-        self._cache = {}\n-        self._override_by_cli = None\n-        self._options = self._arguments = self._run_conf = None\n-        self._parser = self._create_option_parser()\n-\n-    # ---------------------------- Public Methods -----------------------------\n-\n-    def get_default_run_configuration(self):\n-        \"\"\"Return a `RunConfiguration` object set with default values.\"\"\"\n-        options, _ = self._parse_args([])\n-        return self._create_run_config(options)\n-\n-    def parse(self):\n-        \"\"\"Parse the configuration.\n-\n-        If one of `BASE_ERROR_SELECTION_OPTIONS` was selected, overrides all\n-        error codes to check and disregards any error code related\n-        configurations from the configuration files.\n-\n-        \"\"\"\n-        self._options, self._arguments = self._parse_args()\n-        self._arguments = self._arguments or ['.']\n-\n-        if not self._validate_options(self._options):\n-            raise IllegalConfiguration()\n-\n-        self._run_conf = self._create_run_config(self._options)\n-\n-        config = self._create_check_config(self._options, use_dafaults=False)\n-        self._override_by_cli = config\n-\n-    @check_initialized\n-    def get_user_run_configuration(self):\n-        \"\"\"Return the run configuration for the script.\"\"\"\n-        return self._run_conf\n-\n-    @check_initialized\n-    def get_files_to_check(self):\n-        \"\"\"Generate files and error codes to check on each one.\n-\n-        Walk dir trees under `self._arguments` and generate yield filnames\n-        that `match` under each directory that `match_dir`.\n-        The method locates the configuration for each file name and yields a\n-        tuple of (filename, [error_codes]).\n-\n-        With every discovery of a new configuration file `IllegalConfiguration`\n-        might be raised.\n-\n-        \"\"\"\n-        def _get_matches(config):\n-            \"\"\"Return the `match` and `match_dir` functions for `config`.\"\"\"\n-            match_func = re(config.match + '$').match\n-            match_dir_func = re(config.match_dir + '$').match\n-            return match_func, match_dir_func\n-\n-        for name in self._arguments:\n-            if os.path.isdir(name):\n-                for root, dirs, filenames in os.walk(name):\n-                    config = self._get_config(root)\n-                    match, match_dir = _get_matches(config)\n-\n-                    # Skip any dirs that do not match match_dir\n-                    dirs[:] = [dir for dir in dirs if match_dir(dir)]\n-\n-                    for filename in filenames:\n-                        if match(filename):\n-                            full_path = os.path.join(root, filename)\n-                            yield full_path, list(config.checked_codes)\n-            else:\n-                config = self._get_config(name)\n-                match, _ = _get_matches(config)\n-                if match(name):\n-                    yield name, list(config.checked_codes)\n-\n-    # --------------------------- Private Methods -----------------------------\n-\n-    def _get_config(self, node):\n-        \"\"\"Get and cache the run configuration for `node`.\n-\n-        If no configuration exists (not local and not for the parend node),\n-        returns and caches a default configuration.\n-\n-        The algorithm:\n-        -------------\n-        * If the current directory's configuration exists in\n-           `self._cache` - return it.\n-        * If a configuration file does not exist in this directory:\n-          * If the directory is not a root directory:\n-            * Cache its configuration as this directory's and return it.\n-          * Else:\n-            * Cache a default configuration and return it.\n-        * Else:\n-          * Read the configuration file.\n-          * If a parent directory exists AND the configuration file\n-            allows inheritance:\n-            * Read the parent configuration by calling this function with the\n-              parent directory as `node`.\n-            * Merge the parent configuration with the current one and\n-              cache it.\n-        * If the user has specified one of `BASE_ERROR_SELECTION_OPTIONS` in\n-          the CLI - return the CLI configuration with the configuration match\n-          clauses\n-        * Set the `--add-select` and `--add-ignore` CLI configurations.\n-\n-        \"\"\"\n-        path = os.path.abspath(node)\n-        path = path if os.path.isdir(path) else os.path.dirname(path)\n-\n-        if path in self._cache:\n-            return self._cache[path]\n-\n-        config_file = self._get_config_file_in_folder(path)\n-\n-        if config_file is None:\n-            parent_dir, tail = os.path.split(path)\n-            if tail:\n-                # No configuration file, simply take the parent's.\n-                config = self._get_config(parent_dir)\n-            else:\n-                # There's no configuration file and no parent directory.\n-                # Use the default configuration or the one given in the CLI.\n-                config = self._create_check_config(self._options)\n-        else:\n-            # There's a config file! Read it and merge if necessary.\n-            options, inherit = self._read_configuration_file(config_file)\n-\n-            parent_dir, tail = os.path.split(path)\n-            if tail and inherit:\n-                # There is a parent dir and we should try to merge.\n-                parent_config = self._get_config(parent_dir)\n-                config = self._merge_configuration(parent_config, options)\n-            else:\n-                # No need to merge or parent dir does not exist.\n-                config = self._create_check_config(options)\n-\n-        # Make the CLI always win\n-        final_config = {}\n-        for attr in CheckConfiguration._fields:\n-            cli_val = getattr(self._override_by_cli, attr)\n-            conf_val = getattr(config, attr)\n-            final_config[attr] = cli_val if cli_val is not None else conf_val\n-\n-        config = CheckConfiguration(**final_config)\n-\n-        self._set_add_options(config.checked_codes, self._options)\n-        self._cache[path] = config\n-        return self._cache[path]\n-\n-    def _read_configuration_file(self, path):\n-        \"\"\"Try to read and parse `path` as a configuration file.\n-\n-        If the configurations were illegal (checked with\n-        `self._validate_options`), raises `IllegalConfiguration`.\n-\n-        Returns (options, should_inherit).\n-\n-        \"\"\"\n-        parser = RawConfigParser()\n-        options = None\n-        should_inherit = True\n-\n-        if parser.read(path) and self._get_section_name(parser):\n-            option_list = dict([(o.dest, o.type or o.action)\n-                                for o in self._parser.option_list])\n-\n-            # First, read the default values\n-            new_options, _ = self._parse_args([])\n-\n-            # Second, parse the configuration\n-            section_name = self._get_section_name(parser)\n-            for opt in parser.options(section_name):\n-                if opt == 'inherit':\n-                    should_inherit = parser.getboolean(section_name, opt)\n-                    continue\n-\n-                if opt.replace('_', '-') not in self.CONFIG_FILE_OPTIONS:\n-                    log.warning(\"Unknown option '{0}' ignored\".format(opt))\n-                    continue\n-\n-                normalized_opt = opt.replace('-', '_')\n-                opt_type = option_list[normalized_opt]\n-                if opt_type in ('int', 'count'):\n-                    value = parser.getint(section_name, opt)\n-                elif opt_type == 'string':\n-                    value = parser.get(section_name, opt)\n-                else:\n-                    assert opt_type in ('store_true', 'store_false')\n-                    value = parser.getboolean(section_name, opt)\n-                setattr(new_options, normalized_opt, value)\n-\n-            # Third, fix the set-options\n-            options = self._fix_set_options(new_options)\n-\n-        if options is not None:\n-            if not self._validate_options(options):\n-                raise IllegalConfiguration('in file: {0}'.format(path))\n-\n-        return options, should_inherit\n-\n-    def _merge_configuration(self, parent_config, child_options):\n-        \"\"\"Merge parent config into the child options.\n-\n-        The migration process requires an `options` object for the child in\n-        order to distinguish between mutually exclusive codes, add-select and\n-        add-ignore error codes.\n-\n-        \"\"\"\n-        # Copy the parent error codes so we won't override them\n-        error_codes = copy.deepcopy(parent_config.checked_codes)\n-        if self._has_exclusive_option(child_options):\n-            error_codes = self._get_exclusive_error_codes(child_options)\n-\n-        self._set_add_options(error_codes, child_options)\n-\n-        match = child_options.match \\\n-            if child_options.match is not None else parent_config.match\n-        match_dir = child_options.match_dir \\\n-            if child_options.match_dir is not None else parent_config.match_dir\n-\n-        return CheckConfiguration(checked_codes=error_codes,\n-                                  match=match,\n-                                  match_dir=match_dir)\n-\n-    def _parse_args(self, args=None, values=None):\n-        \"\"\"Parse the options using `self._parser` and reformat the options.\"\"\"\n-        options, arguments = self._parser.parse_args(args, values)\n-        return self._fix_set_options(options), arguments\n-\n-    @staticmethod\n-    def _create_run_config(options):\n-        \"\"\"Create a `RunConfiguration` object from `options`.\"\"\"\n-        values = dict([(opt, getattr(options, opt)) for opt in\n-                       RunConfiguration._fields])\n-        return RunConfiguration(**values)\n-\n-    @classmethod\n-    def _create_check_config(cls, options, use_dafaults=True):\n-        \"\"\"Create a `CheckConfiguration` object from `options`.\n-\n-        If `use_dafaults`, any of the match options that are `None` will\n-        be replaced with their default value and the default convention will be\n-        set for the checked codes.\n-\n-        \"\"\"\n-        match = cls.DEFAULT_MATCH_RE \\\n-            if options.match is None and use_dafaults \\\n-            else options.match\n-\n-        match_dir = cls.DEFAULT_MATCH_DIR_RE \\\n-            if options.match_dir is None and use_dafaults \\\n-            else options.match_dir\n-\n-        checked_codes = None\n-\n-        if cls._has_exclusive_option(options) or use_dafaults:\n-            checked_codes = cls._get_checked_errors(options)\n-\n-        return CheckConfiguration(checked_codes=checked_codes,\n-                                  match=match, match_dir=match_dir)\n-\n-    @classmethod\n-    def _get_section_name(cls, parser):\n-        \"\"\"Parse options from relevant section.\"\"\"\n-        for section_name in cls.POSSIBLE_SECTION_NAMES:\n-            if parser.has_section(section_name):\n-                return section_name\n-\n-        return None\n-\n-    @classmethod\n-    def _get_config_file_in_folder(cls, path):\n-        \"\"\"Look for a configuration file in `path`.\n-\n-        If exists return it's full path, otherwise None.\n-\n-        \"\"\"\n-        if os.path.isfile(path):\n-            path = os.path.dirname(path)\n-\n-        for fn in cls.PROJECT_CONFIG_FILES:\n-            config = RawConfigParser()\n-            full_path = os.path.join(path, fn)\n-            if config.read(full_path) and cls._get_section_name(config):\n-                return full_path\n-\n-    @staticmethod\n-    def _get_exclusive_error_codes(options):\n-        \"\"\"Extract the error codes from the selected exclusive option.\"\"\"\n-        codes = set(ErrorRegistry.get_error_codes())\n-        checked_codes = None\n-\n-        if options.ignore is not None:\n-            checked_codes = codes - options.ignore\n-        elif options.select is not None:\n-            checked_codes = options.select\n-        elif options.convention is not None:\n-            checked_codes = getattr(conventions, options.convention)\n-\n-        # To not override the conventions nor the options - copy them.\n-        return copy.deepcopy(checked_codes)\n-\n-    @staticmethod\n-    def _set_add_options(checked_codes, options):\n-        \"\"\"Set `checked_codes` by the `add_ignore` or `add_select` options.\"\"\"\n-        checked_codes |= options.add_select\n-        checked_codes -= options.add_ignore\n-\n-    @classmethod\n-    def _get_checked_errors(cls, options):\n-        \"\"\"Extract the codes needed to be checked from `options`.\"\"\"\n-        checked_codes = cls._get_exclusive_error_codes(options)\n-        if checked_codes is None:\n-            checked_codes = cls.DEFAULT_CONVENTION\n-\n-        cls._set_add_options(checked_codes, options)\n-\n-        return checked_codes\n-\n-    @classmethod\n-    def _validate_options(cls, options):\n-        \"\"\"Validate the mutually exclusive options.\n-\n-        Return `True` iff only zero or one of `BASE_ERROR_SELECTION_OPTIONS`\n-        was selected.\n-\n-        \"\"\"\n-        for opt1, opt2 in \\\n-                itertools.permutations(cls.BASE_ERROR_SELECTION_OPTIONS, 2):\n-            if getattr(options, opt1) and getattr(options, opt2):\n-                log.error('Cannot pass both {0} and {1}. They are '\n-                          'mutually exclusive.'.format(opt1, opt2))\n-                return False\n-\n-        if options.convention and options.convention not in conventions:\n-            log.error(\"Illegal convention '{0}'. Possible conventions: {1}\"\n-                      .format(options.convention,\n-                              ', '.join(conventions.keys())))\n-            return False\n+    def method_okay(self, foo=None, bar=None):\n+        \"\"\"This method should parse okay\"\"\"\n         return True\n \n-    @classmethod\n-    def _has_exclusive_option(cls, options):\n-        \"\"\"Return `True` iff one or more exclusive options were selected.\"\"\"\n-        return any([getattr(options, opt) is not None for opt in\n-                    cls.BASE_ERROR_SELECTION_OPTIONS])\n+    def method_multiline(self, foo=None, bar=None,\n+                         baz=None):\n+        \"\"\"This is on multiple lines, but should parse okay too\n \n-    @staticmethod\n-    def _fix_set_options(options):\n-        \"\"\"Alter the set options from None/strings to sets in place.\"\"\"\n-        optional_set_options = ('ignore', 'select')\n-        mandatory_set_options = ('add_ignore', 'add_select')\n+        pydocstyle gives us lines of source. Test if this means that multiline\n+        definitions are covered in the way we're anticipating here\n+        \"\"\"\n+        return True\n \n-        def _get_set(value_str):\n-            \"\"\"Split `value_str` by the delimiter `,` and return a set.\n+    def method_tricky(self, foo=None, bar=dict(foo=1, bar=2)):\n+        \"\"\"This will likely fail our argument testing\n \n-            Removes any occurrences of '' in the set.\n-\n-            \"\"\"\n-            return set(value_str.split(',')) - set([''])\n-\n-        for opt in optional_set_options:\n-            value = getattr(options, opt)\n-            if value is not None:\n-                setattr(options, opt, _get_set(value))\n-\n-        for opt in mandatory_set_options:\n-            value = getattr(options, opt)\n-            if value is None:\n-                value = ''\n-\n-            if not isinstance(value, Set):\n-                value = _get_set(value)\n-\n-            setattr(options, opt, value)\n-\n-        return options\n-\n-    @classmethod\n-    def _create_option_parser(cls):\n-        \"\"\"Return an option parser to parse the command line arguments.\"\"\"\n-        from optparse import OptionParser\n-\n-        parser = OptionParser(\n-            version=__version__,\n-            usage='Usage: pydocstyle [options] [<file|dir>...]')\n-\n-        option = parser.add_option\n-\n-        # Run configuration options\n-        option('-e', '--explain', action='store_true', default=False,\n-               help='show explanation of each error')\n-        option('-s', '--source', action='store_true', default=False,\n-               help='show source for each error')\n-        option('-d', '--debug', action='store_true', default=False,\n-               help='print debug information')\n-        option('-v', '--verbose', action='store_true', default=False,\n-               help='print status information')\n-        option('--count', action='store_true', default=False,\n-               help='print total number of errors to stdout')\n-\n-        # Error check options\n-        option('--select', metavar='<codes>', default=None,\n-               help='choose the basic list of checked errors by '\n-                    'specifying which errors to check for (with a list of '\n-                    'comma-separated error codes). '\n-                    'for example: --select=D101,D202')\n-        option('--ignore', metavar='<codes>', default=None,\n-               help='choose the basic list of checked errors by '\n-                    'specifying which errors to ignore (with a list of '\n-                    'comma-separated error codes). '\n-                    'for example: --ignore=D101,D202')\n-        option('--convention', metavar='<name>', default=None,\n-               help='choose the basic list of checked errors by specifying an '\n-                    'existing convention. Possible conventions: {0}'\n-                    .format(', '.join(conventions)))\n-        option('--add-select', metavar='<codes>', default=None,\n-               help='amend the list of errors to check for by specifying '\n-                    'more error codes to check.')\n-        option('--add-ignore', metavar='<codes>', default=None,\n-               help='amend the list of errors to check for by specifying '\n-                    'more error codes to ignore.')\n-\n-        # Match clauses\n-        option('--match', metavar='<pattern>', default=None,\n-               help=(\"check only files that exactly match <pattern> regular \"\n-                     \"expression; default is --match='{0}' which matches \"\n-                     \"files that don't start with 'test_' but end with \"\n-                     \"'.py'\").format(cls.DEFAULT_MATCH_RE))\n-        option('--match-dir', metavar='<pattern>', default=None,\n-               help=(\"search only dirs that exactly match <pattern> regular \"\n-                     \"expression; default is --match-dir='{0}', which \"\n-                     \"matches all dirs that don't start with \"\n-                     \"a dot\").format(cls.DEFAULT_MATCH_DIR_RE))\n-\n-        return parser\n-\n-\n-def check(filenames, select=None, ignore=None):\n-    \"\"\"Generate PEP 257 errors that exist in `filenames` iterable.\n-\n-    Only returns errors with error-codes defined in `checked_codes` iterable.\n-\n-    Example\n-    -------\n-    >>> check([ppydocstyle.py.py], checked_codes=['D100'])\n-    <generator object check at 0x...>\n-\n-    \"\"\"\n-    if select is not None and ignore is not None:\n-        raise IllegalConfiguration('Cannot pass both select and ignore. '\n-                                   'They are mutually exclusive.')\n-    elif select is not None:\n-        checked_codes = select\n-    elif ignore is not None:\n-        checked_codes = list(set(ErrorRegistry.get_error_codes()) -\n-                             set(ignore))\n-    else:\n-        checked_codes = conventions.pep257\n-\n-    for filename in filenames:\n-        log.info('Checking file %s.', filename)\n-        try:\n-            with tokenize_open(filename) as file:\n-                source = file.read()\n-            for error in PEP257Checker().check_source(source, filename):\n-                code = getattr(error, 'code', None)\n-                if code in checked_codes:\n-                    yield error\n-        except (EnvironmentError, AllError):\n-            yield sys.exc_info()[1]\n-        except tk.TokenError:\n-            yield SyntaxError('invalid syntax in file %s' % filename)\n-\n-\n-def setup_stream_handlers(conf):\n-    \"\"\"Setup logging stream handlers according to the options.\"\"\"\n-    class StdoutFilter(logging.Filter):\n-        def filter(self, record):\n-            return record.levelno in (logging.DEBUG, logging.INFO)\n-\n-    log.handlers = []\n-\n-    stdout_handler = logging.StreamHandler(sys.stdout)\n-    stdout_handler.setLevel(logging.WARNING)\n-    stdout_handler.addFilter(StdoutFilter())\n-    if conf.debug:\n-        stdout_handler.setLevel(logging.DEBUG)\n-    elif conf.verbose:\n-        stdout_handler.setLevel(logging.INFO)\n-    else:\n-        stdout_handler.setLevel(logging.WARNING)\n-    log.addHandler(stdout_handler)\n-\n-    stderr_handler = logging.StreamHandler(sys.stderr)\n-    stderr_handler.setLevel(logging.WARNING)\n-    log.addHandler(stderr_handler)\n-\n-\n-def run_pydocstyle(use_pep257=False):\n-    log.setLevel(logging.DEBUG)\n-    conf = ConfigurationParser()\n-    setup_stream_handlers(conf.get_default_run_configuration())\n-\n-    try:\n-        conf.parse()\n-    except IllegalConfiguration:\n-        return ReturnCode.invalid_options\n-\n-    run_conf = conf.get_user_run_configuration()\n-\n-    # Reset the logger according to the command line arguments\n-    setup_stream_handlers(run_conf)\n-\n-    if use_pep257:\n-        log.warning(\"Deprecation Warning:\\n\"\n-                    \"pep257 has been renamed to pydocstyle and the use of the \"\n-                    \"pep257 executable is deprecated and will be removed in \"\n-                    \"the next major version. Please use `pydocstyle` instead.\")\n-\n-    log.debug(\"starting in debug mode.\")\n-\n-    Error.explain = run_conf.explain\n-    Error.source = run_conf.source\n-\n-    errors = []\n-    try:\n-        for filename, checked_codes in conf.get_files_to_check():\n-            errors.extend(check((filename,), select=checked_codes))\n-    except IllegalConfiguration:\n-        # An illegal configuration file was found during file generation.\n-        return ReturnCode.invalid_options\n-\n-    code = ReturnCode.no_violations_found\n-    count = 0\n-    for error in errors:\n-        sys.stderr.write('%s\\n' % error)\n-        code = ReturnCode.violations_found\n-        count += 1\n-    if run_conf.count:\n-        print(count)\n-    return code\n-\n-\n-parse = Parser()\n-\n-\n-def check_for(kind, terminal=False):\n-    def decorator(f):\n-        f._check_for = kind\n-        f._terminal = terminal\n-        return f\n-    return decorator\n-\n-\n-class PEP257Checker(object):\n-    \"\"\"Checker for PEP 257.\n-\n-    D10x: Missing docstrings\n-    D20x: Whitespace issues\n-    D30x: Docstring formatting\n-    D40x: Docstring content issues\n-\n-    \"\"\"\n-\n-    def check_source(self, source, filename):\n-        module = parse(StringIO(source), filename)\n-        for definition in module:\n-            for check in self.checks:\n-                terminate = False\n-                if isinstance(definition, check._check_for):\n-                    error = check(None, definition, definition.docstring)\n-                    errors = error if hasattr(error, '__iter__') else [error]\n-                    for error in errors:\n-                        if error is not None:\n-                            partition = check.__doc__.partition('.\\n')\n-                            message, _, explanation = partition\n-                            error.set_context(explanation=explanation,\n-                                              definition=definition)\n-                            yield error\n-                            if check._terminal:\n-                                terminate = True\n-                                break\n-                if terminate:\n-                    break\n-\n-    @property\n-    def checks(self):\n-        all = [check for check in vars(type(self)).values()\n-               if hasattr(check, '_check_for')]\n-        return sorted(all, key=lambda check: not check._terminal)\n-\n-    @check_for(Definition, terminal=True)\n-    def check_docstring_missing(self, definition, docstring):\n-        \"\"\"D10{0,1,2,3}: Public definitions should have docstrings.\n-\n-        All modules should normally have docstrings.  [...] all functions and\n-        classes exported by a module should also have docstrings. Public\n-        methods (including the __init__ constructor) should also have\n-        docstrings.\n-\n-        Note: Public (exported) definitions are either those with names listed\n-              in __all__ variable (if present), or those that do not start\n-              with a single underscore.\n-\n+        We parse naively on commas, so the nested dictionary will throw this off\n         \"\"\"\n-        if (not docstring and definition.is_public or\n-                docstring and is_blank(ast.literal_eval(docstring))):\n-            codes = {Module: D100, Class: D101, NestedClass: D101,\n-                     Method: (lambda: D105() if is_magic(definition.name)\n-                              else D102()),\n-                     Function: D103, NestedFunction: D103, Package: D104}\n-            return codes[type(definition)]()\n-\n-    @check_for(Definition)\n-    def check_one_liners(self, definition, docstring):\n-        \"\"\"D200: One-liner docstrings should fit on one line with quotes.\n-\n-        The closing quotes are on the same line as the opening quotes.\n-        This looks better for one-liners.\n-\n-        \"\"\"\n-        if docstring:\n-            lines = ast.literal_eval(docstring).split('\\n')\n-            if len(lines) > 1:\n-                non_empty_lines = sum(1 for l in lines if not is_blank(l))\n-                if non_empty_lines == 1:\n-                    return D200(len(lines))\n-\n-    @check_for(Function)\n-    def check_no_blank_before(self, function, docstring):  # def\n-        \"\"\"D20{1,2}: No blank lines allowed around function/method docstring.\n-\n-        There's no blank line either before or after the docstring.\n-\n-        \"\"\"\n-        if docstring:\n-            before, _, after = function.source.partition(docstring)\n-            blanks_before = list(map(is_blank, before.split('\\n')[:-1]))\n-            blanks_after = list(map(is_blank, after.split('\\n')[1:]))\n-            blanks_before_count = sum(takewhile(bool, reversed(blanks_before)))\n-            blanks_after_count = sum(takewhile(bool, blanks_after))\n-            if blanks_before_count != 0:\n-                yield D201(blanks_before_count)\n-            if not all(blanks_after) and blanks_after_count != 0:\n-                yield D202(blanks_after_count)\n-\n-    @check_for(Class)\n-    def check_blank_before_after_class(self, class_, docstring):\n-        \"\"\"D20{3,4}: Class docstring should have 1 blank line around them.\n-\n-        Insert a blank line before and after all docstrings (one-line or\n-        multi-line) that document a class -- generally speaking, the class's\n-        methods are separated from each other by a single blank line, and the\n-        docstring needs to be offset from the first method by a blank line;\n-        for symmetry, put a blank line between the class header and the\n-        docstring.\n-\n-        \"\"\"\n-        # NOTE: this gives false-positive in this case\n-        # class Foo:\n-        #\n-        #     \"\"\"Docstring.\"\"\"\n-        #\n-        #\n-        # # comment here\n-        # def foo(): pass\n-        if docstring:\n-            before, _, after = class_.source.partition(docstring)\n-            blanks_before = list(map(is_blank, before.split('\\n')[:-1]))\n-            blanks_after = list(map(is_blank, after.split('\\n')[1:]))\n-            blanks_before_count = sum(takewhile(bool, reversed(blanks_before)))\n-            blanks_after_count = sum(takewhile(bool, blanks_after))\n-            if blanks_before_count != 0:\n-                yield D211(blanks_before_count)\n-            if blanks_before_count != 1:\n-                yield D203(blanks_before_count)\n-            if not all(blanks_after) and blanks_after_count != 1:\n-                yield D204(blanks_after_count)\n-\n-    @check_for(Definition)\n-    def check_blank_after_summary(self, definition, docstring):\n-        \"\"\"D205: Put one blank line between summary line and description.\n-\n-        Multi-line docstrings consist of a summary line just like a one-line\n-        docstring, followed by a blank line, followed by a more elaborate\n-        description. The summary line may be used by automatic indexing tools;\n-        it is important that it fits on one line and is separated from the\n-        rest of the docstring by a blank line.\n-\n-        \"\"\"\n-        if docstring:\n-            lines = ast.literal_eval(docstring).strip().split('\\n')\n-            if len(lines) > 1:\n-                post_summary_blanks = list(map(is_blank, lines[1:]))\n-                blanks_count = sum(takewhile(bool, post_summary_blanks))\n-                if blanks_count != 1:\n-                    return D205(blanks_count)\n-\n-    @check_for(Definition)\n-    def check_indent(self, definition, docstring):\n-        \"\"\"D20{6,7,8}: The entire docstring should be indented same as code.\n-\n-        The entire docstring is indented the same as the quotes at its\n-        first line.\n-\n-        \"\"\"\n-        if docstring:\n-            before_docstring, _, _ = definition.source.partition(docstring)\n-            _, _, indent = before_docstring.rpartition('\\n')\n-            lines = docstring.split('\\n')\n-            if len(lines) > 1:\n-                lines = lines[1:]  # First line does not need indent.\n-                indents = [leading_space(l) for l in lines if not is_blank(l)]\n-                if set(' \\t') == set(''.join(indents) + indent):\n-                    yield D206()\n-                if (len(indents) > 1 and min(indents[:-1]) > indent or\n-                        indents[-1] > indent):\n-                    yield D208()\n-                if min(indents) < indent:\n-                    yield D207()\n-\n-    @check_for(Definition)\n-    def check_newline_after_last_paragraph(self, definition, docstring):\n-        \"\"\"D209: Put multi-line docstring closing quotes on separate line.\n-\n-        Unless the entire docstring fits on a line, place the closing\n-        quotes on a line by themselves.\n-\n-        \"\"\"\n-        if docstring:\n-            lines = [l for l in ast.literal_eval(docstring).split('\\n')\n-                     if not is_blank(l)]\n-            if len(lines) > 1:\n-                if docstring.split(\"\\n\")[-1].strip() not in ['\"\"\"', \"'''\"]:\n-                    return D209()\n-\n-    @check_for(Definition)\n-    def check_surrounding_whitespaces(self, definition, docstring):\n-        \"\"\"D210: No whitespaces allowed surrounding docstring text.\"\"\"\n-        if docstring:\n-            lines = ast.literal_eval(docstring).split('\\n')\n-            if lines[0].startswith(' ') or \\\n-                    len(lines) == 1 and lines[0].endswith(' '):\n-                return D210()\n-\n-    @check_for(Definition)\n-    def check_multi_line_summary_start(self, definition, docstring):\n-        \"\"\"D21{2,3}: Multi-line docstring summary style check.\n-\n-        A multi-line docstring summary should start either at the first,\n-        or separately at the second line of a docstring.\n-\n-        \"\"\"\n-        if docstring:\n-            start_triple = [\n-                '\"\"\"', \"'''\",\n-                'u\"\"\"', \"u'''\",\n-                'r\"\"\"', \"r'''\",\n-                'ur\"\"\"', \"ur'''\"\n-            ]\n-\n-            lines = ast.literal_eval(docstring).split('\\n')\n-            if len(lines) > 1:\n-                first = docstring.split(\"\\n\")[0].strip().lower()\n-                if first in start_triple:\n-                    return D212()\n-                else:\n-                    return D213()\n-\n-    @check_for(Definition)\n-    def check_triple_double_quotes(self, definition, docstring):\n-        r'''D300: Use \"\"\"triple double quotes\"\"\".\n-\n-        For consistency, always use \"\"\"triple double quotes\"\"\" around\n-        docstrings. Use r\"\"\"raw triple double quotes\"\"\" if you use any\n-        backslashes in your docstrings. For Unicode docstrings, use\n-        u\"\"\"Unicode triple-quoted strings\"\"\".\n-\n-        Note: Exception to this is made if the docstring contains\n-              \"\"\" quotes in its body.\n-\n-        '''\n-        if docstring:\n-            opening = docstring[:5].lower()\n-            if '\"\"\"' in ast.literal_eval(docstring) and opening.startswith(\n-                    (\"'''\", \"r'''\", \"u'''\", \"ur'''\")):\n-                # Allow ''' quotes if docstring contains \"\"\", because\n-                # otherwise \"\"\" quotes could not be expressed inside\n-                # docstring. Not in PEP 257.\n-                return\n-            if not opening.startswith(('\"\"\"', 'r\"\"\"', 'u\"\"\"', 'ur\"\"\"')):\n-                quotes = \"'''\" if \"'''\" in opening else \"'\"\n-                return D300(quotes)\n-\n-    @check_for(Definition)\n-    def check_backslashes(self, definition, docstring):\n-        r'''D301: Use r\"\"\" if any backslashes in a docstring.\n-\n-        Use r\"\"\"raw triple double quotes\"\"\" if you use any backslashes\n-        (\\) in your docstrings.\n-\n-        '''\n-        # Just check that docstring is raw, check_triple_double_quotes\n-        # ensures the correct quotes.\n-        if docstring and '\\\\' in docstring and not docstring.startswith(\n-                ('r', 'ur')):\n-            return D301()\n-\n-    @check_for(Definition)\n-    def check_unicode_docstring(self, definition, docstring):\n-        r'''D302: Use u\"\"\" for docstrings with Unicode.\n-\n-        For Unicode docstrings, use u\"\"\"Unicode triple-quoted strings\"\"\".\n-\n-        '''\n-        if definition.module.future_imports['unicode_literals']:\n-            return\n-\n-        # Just check that docstring is unicode, check_triple_double_quotes\n-        # ensures the correct quotes.\n-        if docstring and sys.version_info[0] <= 2:\n-            if not is_ascii(docstring) and not docstring.startswith(\n-                    ('u', 'ur')):\n-                return D302()\n-\n-    @check_for(Definition)\n-    def check_ends_with_period(self, definition, docstring):\n-        \"\"\"D400: First line should end with a period.\n-\n-        The [first line of a] docstring is a phrase ending in a period.\n-\n-        \"\"\"\n-        if docstring:\n-            summary_line = ast.literal_eval(docstring).strip().split('\\n')[0]\n-            if not summary_line.endswith('.'):\n-                return D400(summary_line[-1])\n-\n-    @check_for(Function)\n-    def check_imperative_mood(self, function, docstring):  # def context\n-        \"\"\"D401: First line should be in imperative mood: 'Do', not 'Does'.\n-\n-        [Docstring] prescribes the function or method's effect as a command:\n-        (\"Do this\", \"Return that\"), not as a description; e.g. don't write\n-        \"Returns the pathname ...\".\n-\n-        \"\"\"\n-        if docstring:\n-            stripped = ast.literal_eval(docstring).strip()\n-            if stripped:\n-                first_word = stripped.split()[0]\n-                if first_word.endswith('s') and not first_word.endswith('ss'):\n-                    return D401(first_word[:-1], first_word)\n-\n-    @check_for(Function)\n-    def check_no_signature(self, function, docstring):  # def context\n-        \"\"\"D402: First line should not be function's or method's \"signature\".\n-\n-        The one-line docstring should NOT be a \"signature\" reiterating the\n-        function/method parameters (which can be obtained by introspection).\n-\n-        \"\"\"\n-        if docstring:\n-            first_line = ast.literal_eval(docstring).strip().split('\\n')[0]\n-            if function.name + '(' in first_line.replace(' ', ''):\n-                return D402()\n-\n-    @check_for(Function)\n-    def check_capitalized(self, function, docstring):\n-        \"\"\"D403: First word of the first line should be properly capitalized.\n-\n-        The [first line of a] docstring is a phrase ending in a period.\n-\n-        \"\"\"\n-        if docstring:\n-            first_word = ast.literal_eval(docstring).split()[0]\n-            if first_word == first_word.upper():\n-                return\n-            for char in first_word:\n-                if char not in string.ascii_letters and char != \"'\":\n-                    return\n-            if first_word != first_word.capitalize():\n-                return D403(first_word.capitalize(), first_word)\n-\n-    @check_for(Definition)\n-    def check_starts_with_this(self, function, docstring):\n-        \"\"\"D404: First word of the docstring should not be `This`.\n-\n-        Docstrings should use short, simple language. They should not begin\n-        with \"This class is [..]\" or \"This module contains [..]\".\n-\n-        \"\"\"\n-        if docstring:\n-            first_word = ast.literal_eval(docstring).split()[0]\n-            if first_word.lower() == 'this':\n-                return D404()\n-\n-    # Somewhat hard to determine if return value is mentioned.\n-    # @check(Function)\n-    def SKIP_check_return_type(self, function, docstring):\n-        \"\"\"D40x: Return value type should be mentioned.\n-\n-        [T]he nature of the return value cannot be determined by\n-        introspection, so it should be mentioned.\n-\n-        \"\"\"\n-        if docstring and function.returns_value:\n-            if 'return' not in docstring.lower():\n-                return Error()\n-\n-\n-def main(use_pep257=False):\n-    try:\n-        sys.exit(run_pydocstyle(use_pep257))\n-    except KeyboardInterrupt:\n-        pass\n-\n-\n-def main_pep257():\n-    main(use_pep257=True)\n-\n-\n-if __name__ == '__main__':\n-    main()\n+        return True\n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent": "\"\"\"Example module\n\nThis is a description\n\"\"\"\n\n\nclass Foo(object):\n\n    <IND>class_var = 42  #: Class var docstring\n\n    another_class_var = 42\n    \"\"\"Another class var docstring\"\"\"\n\n    class Meta(object):\n        <IND>\"\"\"A nested class just to test things out\"\"\"\n\n        @classmethod\n        def foo():\n            <IND>\"\"\"The foo class method\"\"\"\n            return True\n\n    <DED><DED>def method_okay(self, foo=None, bar=None):\n        <IND>\"\"\"This method should parse okay\"\"\"\n        return True\n\n    <DED>def method_multiline(self, foo=None, bar=None,\n                         baz=None):\n        <IND>\"\"\"This is on multiple lines, but should parse okay too\n\n        pydocstyle gives us lines of source. Test if this means that multiline\n        definitions are covered in the way we're anticipating here\n        \"\"\"\n        return True\n\n    <DED>def method_tricky(self, foo=None, bar=dict(foo=1, bar=2)):\n        <IND>\"\"\"This will likely fail our argument testing\n\n        We parse naively on commas, so the nested dictionary will throw this off\n        \"\"\"\n        return True\n",
        "target_code_with_indent_exact_match": true,
        "source_code_with_indent": "#! /usr/bin/env python\n\"\"\"Static analysis tool for checking docstring conventions and style.\n\nThe repository is located at:\nhttp://github.com/PyCQA/pydocstyle\n\n\"\"\"\nfrom __future__ import with_statement\n\nimport os\nimport string\nimport sys\nimport ast\nimport copy\nimport logging\nimport tokenize as tk\nfrom itertools import takewhile, dropwhile, chain\nfrom re import compile as re\nimport itertools\nfrom collections import defaultdict, namedtuple, Set\n\ntry:  # Python 3.x\n    <IND>from ConfigParser import RawConfigParser\n<DED>except ImportError:  # Python 2.x\n    <IND>from configparser import RawConfigParser\n\n<DED>log = logging.getLogger(__name__)\n\n\ntry:\n    <IND>from StringIO import StringIO\n<DED>except ImportError:  # Python 3.0 and later\n    <IND>from io import StringIO\n\n\n<DED>try:\n    <IND>next\n<DED>except NameError:  # Python 2.5 and earlier\n    <IND>nothing = object()\n\n    def next(obj, default=nothing):\n        <IND>if default == nothing:\n            <IND>return obj.next()\n        <DED>else:\n            <IND>try:\n                <IND>return obj.next()\n            <DED>except StopIteration:\n                <IND>return default\n\n\n# If possible (python >= 3.2) use tokenize.open to open files, so PEP 263\n# encoding markers are interpreted.\n<DED><DED><DED><DED>try:\n    <IND>tokenize_open = tk.open\n<DED>except AttributeError:\n    <IND>tokenize_open = open\n\n\n<DED>__version__ = '1.0.1-rc1'\n__all__ = ('check',)\n\n\nclass ReturnCode(object):\n    <IND>no_violations_found = 0\n    violations_found = 1\n    invalid_options = 2\n\n\n<DED>VARIADIC_MAGIC_METHODS = ('__init__', '__call__', '__new__')\n\n\ndef humanize(string):\n    <IND>return re(r'(.)([A-Z]+)').sub(r'\\1 \\2', string).lower()\n\n\n<DED>def is_magic(name):\n    <IND>return (name.startswith('__') and\n            name.endswith('__') and\n            name not in VARIADIC_MAGIC_METHODS)\n\n\n<DED>def is_ascii(string):\n    <IND>return all(ord(char) < 128 for char in string)\n\n\n<DED>def is_blank(string):\n    <IND>return not string.strip()\n\n\n<DED>def leading_space(string):\n    <IND>return re('\\s*').match(string).group()\n\n\n<DED>class Value(object):\n\n    <IND>def __init__(self, *args):\n        <IND>vars(self).update(zip(self._fields, args))\n\n    <DED>def __hash__(self):\n        <IND>return hash(repr(self))\n\n    <DED>def __eq__(self, other):\n        <IND>return other and vars(self) == vars(other)\n\n    <DED>def __repr__(self):\n        <IND>kwargs = ', '.join('{0}={1!r}'.format(field, getattr(self, field))\n                           for field in self._fields)\n        return '{0}({1})'.format(self.__class__.__name__, kwargs)\n\n\n<DED><DED>class Definition(Value):\n\n    <IND>_fields = ('name', '_source', 'start', 'end', 'decorators', 'docstring',\n               'children', 'parent')\n\n    _human = property(lambda self: humanize(type(self).__name__))\n    kind = property(lambda self: self._human.split()[-1])\n    module = property(lambda self: self.parent.module)\n    all = property(lambda self: self.module.all)\n    _slice = property(lambda self: slice(self.start - 1, self.end))\n    is_class = False\n\n    def __iter__(self):\n        <IND>return chain([self], *self.children)\n\n    <DED>@property\n    def _publicity(self):\n        <IND>return {True: 'public', False: 'private'}[self.is_public]\n\n    <DED>@property\n    def source(self):\n        <IND>\"\"\"Return the source code for the definition.\"\"\"\n        full_src = self._source[self._slice]\n\n        def is_empty_or_comment(line):\n            <IND>return line.strip() == '' or line.strip().startswith('#')\n\n        <DED>filtered_src = dropwhile(is_empty_or_comment, reversed(full_src))\n        return ''.join(reversed(list(filtered_src)))\n\n    <DED>def __str__(self):\n        <IND>return 'in %s %s `%s`' % (self._publicity, self._human, self.name)\n\n\n<DED><DED>class Module(Definition):\n\n    <IND>_fields = ('name', '_source', 'start', 'end', 'decorators', 'docstring',\n               'children', 'parent', '_all', 'future_imports')\n    is_public = True\n    _nest = staticmethod(lambda s: {'def': Function, 'class': Class}[s])\n    module = property(lambda self: self)\n    all = property(lambda self: self._all)\n\n    def __str__(self):\n        <IND>return 'at module level'\n\n\n<DED><DED>class Package(Module):\n    <IND>\"\"\"A package is a __init__.py module.\"\"\"\n\n\n<DED>class Function(Definition):\n\n    <IND>_nest = staticmethod(lambda s: {'def': NestedFunction,\n                                    'class': NestedClass}[s])\n\n    @property\n    def is_public(self):\n        <IND>if self.all is not None:\n            <IND>return self.name in self.all\n        <DED>else:\n            <IND>return not self.name.startswith('_')\n\n    <DED><DED>@property \n    def args(self):\n        <IND>sig = self.source.split('\\n')[0]\n        sig = sig.split('(')[1]\n        sig = sig.split(')')[0]\n        return sig.split(',')\n\n\n<DED><DED>class NestedFunction(Function):\n\n    <IND>is_public = False\n\n\n<DED>class Method(Function):\n\n    <IND>@property\n    def is_public(self):\n        # Check if we are a setter/deleter method, and mark as private if so.\n        <IND>for decorator in self.decorators:\n            # Given 'foo', match 'foo.bar' but not 'foobar' or 'sfoo'\n            <IND>if re(r\"^{0}\\.\".format(self.name)).match(decorator.name):\n                <IND>return False\n        <DED><DED>name_is_public = (not self.name.startswith('_') or\n                          self.name in VARIADIC_MAGIC_METHODS or\n                          is_magic(self.name))\n        return self.parent.is_public and name_is_public\n\n\n<DED><DED>class Class(Definition):\n\n    <IND>_nest = staticmethod(lambda s: {'def': Method, 'class': NestedClass}[s])\n    is_public = Function.is_public\n    is_class = True\n\n\n<DED>class NestedClass(Class):\n\n    <IND>@property\n    def is_public(self):\n        <IND>return (not self.name.startswith('_') and\n                self.parent.is_class and\n                self.parent.is_public)\n\n\n<DED><DED>class Decorator(Value):\n    <IND>\"\"\"A decorator for function, method or class.\"\"\"\n\n    _fields = 'name arguments'.split()\n\n\n<DED>class TokenKind(int):\n    <IND>def __repr__(self):\n        <IND>return \"tk.{0}\".format(tk.tok_name[self])\n\n\n<DED><DED>class Token(Value):\n\n    <IND>_fields = 'kind value start end source'.split()\n\n    def __init__(self, *args):\n        <IND>super(Token, self).__init__(*args)\n        self.kind = TokenKind(self.kind)\n\n\n<DED><DED>class TokenStream(object):\n\n    <IND>def __init__(self, filelike):\n        <IND>self._generator = tk.generate_tokens(filelike.readline)\n        self.current = Token(*next(self._generator, None))\n        self.line = self.current.start[0]\n\n    <DED>def move(self):\n        <IND>previous = self.current\n        current = next(self._generator, None)\n        self.current = None if current is None else Token(*current)\n        self.line = self.current.start[0] if self.current else self.line\n        return previous\n\n    <DED>def __iter__(self):\n        <IND>while True:\n            <IND>if self.current is not None:\n                <IND>yield self.current\n            <DED>else:\n                <IND>return\n            <DED>self.move()\n\n\n<DED><DED><DED>class AllError(Exception):\n\n    <IND>def __init__(self, message):\n        <IND>Exception.__init__(\n            self, message +\n            'That means pydocstyle cannot decide which definitions are public.'\n            ' Variable __all__ should be present at most once in each file, '\n            \"in form `__all__ = ('a_public_function', 'APublicClass', ...)`. \"\n            'More info on __all__: http://stackoverflow.com/q/44834/. ')\n\n\n<DED><DED>class Parser(object):\n\n    <IND>def __call__(self, filelike, filename):\n        <IND>self.source = filelike.readlines()\n        src = ''.join(self.source)\n        self.stream = TokenStream(StringIO(src))\n        self.filename = filename\n        self.all = None\n        self.future_imports = defaultdict(lambda: False)\n        self._accumulated_decorators = []\n        return self.parse_module()\n\n    <DED>current = property(lambda self: self.stream.current)\n    line = property(lambda self: self.stream.line)\n\n    def consume(self, kind):\n        <IND>\"\"\"Consume one token and verify it is of the expected kind.\"\"\"\n        next_token = self.stream.move()\n        assert next_token.kind == kind\n\n    <DED>def leapfrog(self, kind, value=None):\n        <IND>\"\"\"Skip tokens in the stream until a certain token kind is reached.\n\n        If `value` is specified, tokens whose values are different will also\n        be skipped.\n        \"\"\"\n        while self.current is not None:\n            <IND>if (self.current.kind == kind and\n               (value is None or self.current.value == value)):\n                <IND>self.consume(kind)\n                return\n            <DED>self.stream.move()\n\n    <DED><DED>def parse_docstring(self):\n        <IND>\"\"\"Parse a single docstring and return its value.\"\"\"\n        log.debug(\"parsing docstring, token is %r (%s)\",\n                  self.current.kind, self.current.value)\n        while self.current.kind in (tk.COMMENT, tk.NEWLINE, tk.NL):\n            <IND>self.stream.move()\n            log.debug(\"parsing docstring, token is %r (%s)\",\n                      self.current.kind, self.current.value)\n        <DED>if self.current.kind == tk.STRING:\n            <IND>docstring = self.current.value\n            self.stream.move()\n            return docstring\n        <DED>return None\n\n    <DED>def parse_decorators(self):\n        <IND>\"\"\"Called after first @ is found.\n\n        Parse decorators into self._accumulated_decorators.\n        Continue to do so until encountering the 'def' or 'class' start token.\n        \"\"\"\n        name = []\n        arguments = []\n        at_arguments = False\n\n        while self.current is not None:\n            <IND>if (self.current.kind == tk.NAME and\n                    self.current.value in ['def', 'class']):\n                # Done with decorators - found function or class proper\n                <IND>break\n            <DED>elif self.current.kind == tk.OP and self.current.value == '@':\n                # New decorator found. Store the decorator accumulated so far:\n                <IND>self._accumulated_decorators.append(\n                    Decorator(''.join(name), ''.join(arguments)))\n                # Now reset to begin accumulating the new decorator:\n                name = []\n                arguments = []\n                at_arguments = False\n            <DED>elif self.current.kind == tk.OP and self.current.value == '(':\n                <IND>at_arguments = True\n            <DED>elif self.current.kind == tk.OP and self.current.value == ')':\n                # Ignore close parenthesis\n                <IND>pass\n            <DED>elif self.current.kind == tk.NEWLINE or self.current.kind == tk.NL:\n                # Ignore newlines\n                <IND>pass\n            <DED>else:\n                # Keep accumulating current decorator's name or argument.\n                <IND>if not at_arguments:\n                    <IND>name.append(self.current.value)\n                <DED>else:\n                    <IND>arguments.append(self.current.value)\n            <DED><DED>self.stream.move()\n\n        # Add decorator accumulated so far\n        <DED>self._accumulated_decorators.append(\n            Decorator(''.join(name), ''.join(arguments)))\n\n    <DED>def parse_definitions(self, class_, all=False):\n        <IND>\"\"\"Parse multiple definitions and yield them.\"\"\"\n        while self.current is not None:\n            <IND>log.debug(\"parsing definition list, current token is %r (%s)\",\n                      self.current.kind, self.current.value)\n            if all and self.current.value == '__all__':\n                <IND>self.parse_all()\n            <DED>elif self.current.kind == tk.OP and self.current.value == '@':\n                <IND>self.consume(tk.OP)\n                self.parse_decorators()\n            <DED>elif self.current.value in ['def', 'class']:\n                <IND>yield self.parse_definition(class_._nest(self.current.value))\n            <DED>elif self.current.kind == tk.INDENT:\n                <IND>self.consume(tk.INDENT)\n                for definition in self.parse_definitions(class_):\n                    <IND>yield definition\n            <DED><DED>elif self.current.kind == tk.DEDENT:\n                <IND>self.consume(tk.DEDENT)\n                return\n            <DED>elif self.current.value == 'from':\n                <IND>self.parse_from_import_statement()\n            <DED>else:\n                <IND>self.stream.move()\n\n    <DED><DED><DED>def parse_all(self):\n        <IND>\"\"\"Parse the __all__ definition in a module.\"\"\"\n        assert self.current.value == '__all__'\n        self.consume(tk.NAME)\n        if self.current.value != '=':\n            <IND>raise AllError('Could not evaluate contents of __all__. ')\n        <DED>self.consume(tk.OP)\n        if self.current.value not in '([':\n            <IND>raise AllError('Could not evaluate contents of __all__. ')\n        <DED>if self.current.value == '[':\n            <IND>msg = (\"%s WARNING: __all__ is defined as a list, this means \"\n                   \"pydocstyle cannot reliably detect contents of the __all__ \"\n                   \"variable, because it can be mutated. Change __all__ to be \"\n                   \"an (immutable) tuple, to remove this warning. Note, \"\n                   \"pydocstyle uses __all__ to detect which definitions are \"\n                   \"public, to warn if public definitions are missing \"\n                   \"docstrings. If __all__ is a (mutable) list, pydocstyle \"\n                   \"cannot reliably assume its contents. pydocstyle will \"\n                   \"proceed assuming __all__ is not mutated.\\n\"\n                   % self.filename)\n            sys.stderr.write(msg)\n        <DED>self.consume(tk.OP)\n\n        self.all = []\n        all_content = \"(\"\n        while self.current.kind != tk.OP or self.current.value not in \")]\":\n            <IND>if self.current.kind in (tk.NL, tk.COMMENT):\n                <IND>pass\n            <DED>elif (self.current.kind == tk.STRING or\n                  self.current.value == ','):\n                <IND>all_content += self.current.value\n            <DED>else:\n                <IND>raise AllError('Unexpected token kind in  __all__: %r. ' %\n                               self.current.kind)\n            <DED>self.stream.move()\n        <DED>self.consume(tk.OP)\n        all_content += \")\"\n        try:\n            <IND>self.all = eval(all_content, {})\n        <DED>except BaseException as e:\n            <IND>raise AllError('Could not evaluate contents of __all__.'\n                           '\\bThe value was %s. The exception was:\\n%s'\n                           % (all_content, e))\n\n    <DED><DED>def parse_module(self):\n        <IND>\"\"\"Parse a module (and its children) and return a Module object.\"\"\"\n        log.debug(\"parsing module.\")\n        start = self.line\n        docstring = self.parse_docstring()\n        children = list(self.parse_definitions(Module, all=True))\n        assert self.current is None, self.current\n        end = self.line\n        cls = Module\n        if self.filename.endswith('__init__.py'):\n            <IND>cls = Package\n        <DED>module = cls(self.filename, self.source, start, end,\n                     [], docstring, children, None, self.all)\n        for child in module.children:\n            <IND>child.parent = module\n        <DED>module.future_imports = self.future_imports\n        log.debug(\"finished parsing module.\")\n        return module\n\n    <DED>def parse_definition(self, class_):\n        <IND>\"\"\"Parse a definition and return its value in a `class_` object.\"\"\"\n        start = self.line\n        self.consume(tk.NAME)\n        name = self.current.value\n        log.debug(\"parsing %s '%s'\", class_.__name__, name)\n        self.stream.move()\n        if self.current.kind == tk.OP and self.current.value == '(':\n            <IND>parenthesis_level = 0\n            while True:\n                <IND>if self.current.kind == tk.OP:\n                    <IND>if self.current.value == '(':\n                        <IND>parenthesis_level += 1\n                    <DED>elif self.current.value == ')':\n                        <IND>parenthesis_level -= 1\n                        if parenthesis_level == 0:\n                            <IND>break\n                <DED><DED><DED>self.stream.move()\n        <DED><DED>if self.current.kind != tk.OP or self.current.value != ':':\n            <IND>self.leapfrog(tk.OP, value=\":\")\n        <DED>else:\n            <IND>self.consume(tk.OP)\n        <DED>if self.current.kind in (tk.NEWLINE, tk.COMMENT):\n            <IND>self.leapfrog(tk.INDENT)\n            assert self.current.kind != tk.INDENT\n            docstring = self.parse_docstring()\n            decorators = self._accumulated_decorators\n            self._accumulated_decorators = []\n            log.debug(\"parsing nested definitions.\")\n            children = list(self.parse_definitions(class_))\n            log.debug(\"finished parsing nested definitions for '%s'\", name)\n            end = self.line - 1\n        <DED>else:  # one-liner definition\n            <IND>docstring = self.parse_docstring()\n            decorators = []  # TODO\n            children = []\n            end = self.line\n            self.leapfrog(tk.NEWLINE)\n        <DED>definition = class_(name, self.source, start, end,\n                            decorators, docstring, children, None)\n        for child in definition.children:\n            <IND>child.parent = definition\n        <DED>log.debug(\"finished parsing %s '%s'. Next token is %r (%s)\",\n                  class_.__name__, name, self.current.kind,\n                  self.current.value)\n        return definition\n\n    <DED>def parse_from_import_statement(self):\n        <IND>\"\"\"Parse a 'from x import y' statement.\n\n        The purpose is to find __future__ statements.\n\n        \"\"\"\n        log.debug('parsing from/import statement.')\n        assert self.current.value == 'from', self.current.value\n        self.stream.move()\n        if self.current.value != '__future__':\n            <IND>return\n        <DED>self.stream.move()\n        assert self.current.value == 'import', self.current.value\n        self.stream.move()\n        if self.current.value == '(':\n            <IND>self.consume(tk.OP)\n            expected_end_kind = tk.OP\n        <DED>else:\n            <IND>expected_end_kind = tk.NEWLINE\n        <DED>while self.current.kind != expected_end_kind and not(\n                self.current.kind == tk.OP and self.current.value == ';'):\n            <IND>if self.current.kind != tk.NAME:\n                <IND>self.stream.move()\n                continue\n            <DED>log.debug(\"parsing import, token is %r (%s)\",\n                      self.current.kind, self.current.value)\n            log.debug('found future import: %s', self.current.value)\n            self.future_imports[self.current.value] = True\n            self.consume(tk.NAME)\n            log.debug(\"parsing import, token is %r (%s)\",\n                      self.current.kind, self.current.value)\n            if self.current.kind == tk.NAME and self.current.value == 'as':\n                <IND>self.consume(tk.NAME)  # as\n                if self.current.kind == tk.NAME:\n                    <IND>self.consume(tk.NAME)  # new name, irrelevant\n            <DED><DED>if self.current.value == ',':\n                <IND>self.consume(tk.OP)\n            <DED>log.debug(\"parsing import, token is %r (%s)\",\n                      self.current.kind, self.current.value)\n\n\n<DED><DED><DED>class Error(object):\n    <IND>\"\"\"Error in docstring style.\"\"\"\n\n    # should be overridden by inheriting classes\n    code = None\n    short_desc = None\n    context = None\n\n    # Options that define how errors are printed:\n    explain = False\n    source = False\n\n    def __init__(self, *parameters):\n        <IND>self.parameters = parameters\n        self.definition = None\n        self.explanation = None\n\n    <DED>def set_context(self, definition, explanation):\n        <IND>self.definition = definition\n        self.explanation = explanation\n\n    <DED>filename = property(lambda self: self.definition.module.name)\n    line = property(lambda self: self.definition.start)\n\n    @property\n    def message(self):\n        <IND>ret = '%s: %s' % (self.code, self.short_desc)\n        if self.context is not None:\n            <IND>ret += ' (' + self.context % self.parameters + ')'\n        <DED>return ret\n\n    <DED>@property\n    def lines(self):\n        <IND>source = ''\n        lines = self.definition._source[self.definition._slice]\n        offset = self.definition.start\n        lines_stripped = list(reversed(list(dropwhile(is_blank,\n                                                      reversed(lines)))))\n        numbers_width = 0\n        for n, line in enumerate(lines_stripped):\n            <IND>numbers_width = max(numbers_width, n + offset)\n        <DED>numbers_width = len(str(numbers_width))\n        numbers_width = 6\n        for n, line in enumerate(lines_stripped):\n            <IND>source += '%*d: %s' % (numbers_width, n + offset, line)\n            if n > 5:\n                <IND>source += '        ...\\n'\n                break\n        <DED><DED>return source\n\n    <DED>def __str__(self):\n        <IND>self.explanation = '\\n'.join(l for l in self.explanation.split('\\n')\n                                     if not is_blank(l))\n        template = '%(filename)s:%(line)s %(definition)s:\\n        %(message)s'\n        if self.source and self.explain:\n            <IND>template += '\\n\\n%(explanation)s\\n\\n%(lines)s\\n'\n        <DED>elif self.source and not self.explain:\n            <IND>template += '\\n\\n%(lines)s\\n'\n        <DED>elif self.explain and not self.source:\n            <IND>template += '\\n\\n%(explanation)s\\n\\n'\n        <DED>return template % dict((name, getattr(self, name)) for name in\n                               ['filename', 'line', 'definition', 'message',\n                                'explanation', 'lines'])\n\n    <DED>__repr__ = __str__\n\n    def __lt__(self, other):\n        <IND>return (self.filename, self.line) < (other.filename, other.line)\n\n\n<DED><DED>class ErrorRegistry(object):\n    <IND>groups = []\n\n    class ErrorGroup(object):\n\n        <IND>def __init__(self, prefix, name):\n            <IND>self.prefix = prefix\n            self.name = name\n            self.errors = []\n\n        <DED>def create_error(self, error_code, error_desc, error_context=None):\n            # TODO: check prefix\n\n            <IND>class _Error(Error):\n                <IND>code = error_code\n                short_desc = error_desc\n                context = error_context\n\n            <DED>self.errors.append(_Error)\n            return _Error\n\n    <DED><DED>@classmethod\n    def create_group(cls, prefix, name):\n        <IND>group = cls.ErrorGroup(prefix, name)\n        cls.groups.append(group)\n        return group\n\n    <DED>@classmethod\n    def get_error_codes(cls):\n        <IND>for group in cls.groups:\n            <IND>for error in group.errors:\n                <IND>yield error.code\n\n    <DED><DED><DED>@classmethod\n    def to_rst(cls):\n        <IND>sep_line = '+' + 6 * '-' + '+' + '-' * 71 + '+\\n'\n        blank_line = '|' + 78 * ' ' + '|\\n'\n        table = ''\n        for group in cls.groups:\n            <IND>table += sep_line\n            table += blank_line\n            table += '|' + ('**%s**' % group.name).center(78) + '|\\n'\n            table += blank_line\n            for error in group.errors:\n                <IND>table += sep_line\n                table += ('|' + error.code.center(6) + '| ' +\n                          error.short_desc.ljust(70) + '|\\n')\n        <DED><DED>table += sep_line\n        return table\n\n\n<DED><DED>D1xx = ErrorRegistry.create_group('D1', 'Missing Docstrings')\nD100 = D1xx.create_error('D100', 'Missing docstring in public module')\nD101 = D1xx.create_error('D101', 'Missing docstring in public class')\nD102 = D1xx.create_error('D102', 'Missing docstring in public method')\nD103 = D1xx.create_error('D103', 'Missing docstring in public function')\nD104 = D1xx.create_error('D104', 'Missing docstring in public package')\nD105 = D1xx.create_error('D105', 'Missing docstring in magic method')\n\nD2xx = ErrorRegistry.create_group('D2', 'Whitespace Issues')\nD200 = D2xx.create_error('D200', 'One-line docstring should fit on one line '\n                                 'with quotes', 'found %s')\nD201 = D2xx.create_error('D201', 'No blank lines allowed before function '\n                                 'docstring', 'found %s')\nD202 = D2xx.create_error('D202', 'No blank lines allowed after function '\n                                 'docstring', 'found %s')\nD203 = D2xx.create_error('D203', '1 blank line required before class '\n                                 'docstring', 'found %s')\nD204 = D2xx.create_error('D204', '1 blank line required after class '\n                                 'docstring', 'found %s')\nD205 = D2xx.create_error('D205', '1 blank line required between summary line '\n                                 'and description', 'found %s')\nD206 = D2xx.create_error('D206', 'Docstring should be indented with spaces, '\n                                 'not tabs')\nD207 = D2xx.create_error('D207', 'Docstring is under-indented')\nD208 = D2xx.create_error('D208', 'Docstring is over-indented')\nD209 = D2xx.create_error('D209', 'Multi-line docstring closing quotes should '\n                                 'be on a separate line')\nD210 = D2xx.create_error('D210', 'No whitespaces allowed surrounding '\n                                 'docstring text')\nD211 = D2xx.create_error('D211', 'No blank lines allowed before class '\n                                 'docstring', 'found %s')\nD212 = D2xx.create_error('D212', 'Multi-line docstring summary should start '\n                                 'at the first line')\nD213 = D2xx.create_error('D213', 'Multi-line docstring summary should start '\n                                 'at the second line')\n\nD3xx = ErrorRegistry.create_group('D3', 'Quotes Issues')\nD300 = D3xx.create_error('D300', 'Use \"\"\"triple double quotes\"\"\"',\n                         'found %s-quotes')\nD301 = D3xx.create_error('D301', 'Use r\"\"\" if any backslashes in a docstring')\nD302 = D3xx.create_error('D302', 'Use u\"\"\" for Unicode docstrings')\n\nD4xx = ErrorRegistry.create_group('D4', 'Docstring Content Issues')\nD400 = D4xx.create_error('D400', 'First line should end with a period',\n                         'not %r')\nD401 = D4xx.create_error('D401', 'First line should be in imperative mood',\n                         '%r, not %r')\nD402 = D4xx.create_error('D402', 'First line should not be the function\\'s '\n                                 '\"signature\"')\nD403 = D4xx.create_error('D403', 'First word of the first line should be '\n                                 'properly capitalized', '%r, not %r')\nD404 = D4xx.create_error('D404', 'First word of the docstring should not '\n                                 'be `This`')\n\n\nclass AttrDict(dict):\n    <IND>def __getattr__(self, item):\n        <IND>return self[item]\n\n\n<DED><DED>conventions = AttrDict({\n    'pep257': set(ErrorRegistry.get_error_codes()) - set(['D203',\n                                                          'D212',\n                                                          'D213',\n                                                          'D404'])\n})\n\n\n# General configurations for pydocstyle run.\nRunConfiguration = namedtuple('RunConfiguration',\n                              ('explain', 'source', 'debug',\n                               'verbose', 'count'))\n\n\nclass IllegalConfiguration(Exception):\n    <IND>\"\"\"An exception for illegal configurations.\"\"\"\n\n    pass\n\n\n# Check configuration - used by the ConfigurationParser class.\n<DED>CheckConfiguration = namedtuple('CheckConfiguration',\n                                ('checked_codes', 'match', 'match_dir'))\n\n\ndef check_initialized(method):\n    <IND>\"\"\"Check that the configuration object was initialized.\"\"\"\n    def _decorator(self, *args, **kwargs):\n        <IND>if self._arguments is None or self._options is None:\n            <IND>raise RuntimeError('using an uninitialized configuration')\n        <DED>return method(self, *args, **kwargs)\n    <DED>return _decorator\n\n\n<DED>class ConfigurationParser(object):\n    <IND>\"\"\"Responsible for parsing configuration from files and CLI.\n\n    There are 2 types of configurations: Run configurations and Check\n    configurations.\n\n    Run Configurations:\n    -------------------\n\n    Responsible for deciding things that are related to the user interface,\n    e.g. verbosity, debug options, etc.\n    All run configurations default to `False` and are decided only by CLI.\n\n    Check Configurations:\n    ---------------------\n\n    Configurations that are related to which files and errors will be checked.\n    These are configurable in 2 ways: using the CLI, and using configuration\n    files.\n\n    Configuration files are nested within the file system, meaning that the\n    closer a configuration file is to a checked file, the more relevant it will\n    be. For instance, imagine this directory structure:\n\n    A\n    +-- tox.ini: sets `select=D100`\n    +-- B\n        +-- foo.py\n        +-- tox.ini: sets `add-ignore=D100`\n\n    Then `foo.py` will not be checked for `D100`.\n    The configuration build algorithm is described in `self._get_config`.\n\n    Note: If any of `BASE_ERROR_SELECTION_OPTIONS` was selected in the CLI, all\n    configuration files will be ignored and each file will be checked for\n    the error codes supplied in the CLI.\n\n    \"\"\"\n\n    CONFIG_FILE_OPTIONS = ('convention', 'select', 'ignore', 'add-select',\n                           'add-ignore', 'match', 'match-dir')\n    BASE_ERROR_SELECTION_OPTIONS = ('ignore', 'select', 'convention')\n\n    DEFAULT_MATCH_RE = '(?!test_).*\\.py'\n    DEFAULT_MATCH_DIR_RE = '[^\\.].*'\n    DEFAULT_CONVENTION = conventions.pep257\n\n    PROJECT_CONFIG_FILES = (\n        'setup.cfg',\n        'tox.ini',\n        '.pydocstyle',\n        '.pydocstylerc',\n        # The following is deprecated, but remains for backwards compatibility.\n        '.pep257',\n    )\n\n    POSSIBLE_SECTION_NAMES = ('pydocstyle', 'pep257')\n\n    def __init__(self):\n        <IND>\"\"\"Create a configuration parser.\"\"\"\n        self._cache = {}\n        self._override_by_cli = None\n        self._options = self._arguments = self._run_conf = None\n        self._parser = self._create_option_parser()\n\n    # ---------------------------- Public Methods -----------------------------\n\n    <DED>def get_default_run_configuration(self):\n        <IND>\"\"\"Return a `RunConfiguration` object set with default values.\"\"\"\n        options, _ = self._parse_args([])\n        return self._create_run_config(options)\n\n    <DED>def parse(self):\n        <IND>\"\"\"Parse the configuration.\n\n        If one of `BASE_ERROR_SELECTION_OPTIONS` was selected, overrides all\n        error codes to check and disregards any error code related\n        configurations from the configuration files.\n\n        \"\"\"\n        self._options, self._arguments = self._parse_args()\n        self._arguments = self._arguments or ['.']\n\n        if not self._validate_options(self._options):\n            <IND>raise IllegalConfiguration()\n\n        <DED>self._run_conf = self._create_run_config(self._options)\n\n        config = self._create_check_config(self._options, use_dafaults=False)\n        self._override_by_cli = config\n\n    <DED>@check_initialized\n    def get_user_run_configuration(self):\n        <IND>\"\"\"Return the run configuration for the script.\"\"\"\n        return self._run_conf\n\n    <DED>@check_initialized\n    def get_files_to_check(self):\n        <IND>\"\"\"Generate files and error codes to check on each one.\n\n        Walk dir trees under `self._arguments` and generate yield filnames\n        that `match` under each directory that `match_dir`.\n        The method locates the configuration for each file name and yields a\n        tuple of (filename, [error_codes]).\n\n        With every discovery of a new configuration file `IllegalConfiguration`\n        might be raised.\n\n        \"\"\"\n        def _get_matches(config):\n            <IND>\"\"\"Return the `match` and `match_dir` functions for `config`.\"\"\"\n            match_func = re(config.match + '$').match\n            match_dir_func = re(config.match_dir + '$').match\n            return match_func, match_dir_func\n\n        <DED>for name in self._arguments:\n            <IND>if os.path.isdir(name):\n                <IND>for root, dirs, filenames in os.walk(name):\n                    <IND>config = self._get_config(root)\n                    match, match_dir = _get_matches(config)\n\n                    # Skip any dirs that do not match match_dir\n                    dirs[:] = [dir for dir in dirs if match_dir(dir)]\n\n                    for filename in filenames:\n                        <IND>if match(filename):\n                            <IND>full_path = os.path.join(root, filename)\n                            yield full_path, list(config.checked_codes)\n            <DED><DED><DED><DED>else:\n                <IND>config = self._get_config(name)\n                match, _ = _get_matches(config)\n                if match(name):\n                    <IND>yield name, list(config.checked_codes)\n\n    # --------------------------- Private Methods -----------------------------\n\n    <DED><DED><DED><DED>def _get_config(self, node):\n        <IND>\"\"\"Get and cache the run configuration for `node`.\n\n        If no configuration exists (not local and not for the parend node),\n        returns and caches a default configuration.\n\n        The algorithm:\n        -------------\n        * If the current directory's configuration exists in\n           `self._cache` - return it.\n        * If a configuration file does not exist in this directory:\n          * If the directory is not a root directory:\n            * Cache its configuration as this directory's and return it.\n          * Else:\n            * Cache a default configuration and return it.\n        * Else:\n          * Read the configuration file.\n          * If a parent directory exists AND the configuration file\n            allows inheritance:\n            * Read the parent configuration by calling this function with the\n              parent directory as `node`.\n            * Merge the parent configuration with the current one and\n              cache it.\n        * If the user has specified one of `BASE_ERROR_SELECTION_OPTIONS` in\n          the CLI - return the CLI configuration with the configuration match\n          clauses\n        * Set the `--add-select` and `--add-ignore` CLI configurations.\n\n        \"\"\"\n        path = os.path.abspath(node)\n        path = path if os.path.isdir(path) else os.path.dirname(path)\n\n        if path in self._cache:\n            <IND>return self._cache[path]\n\n        <DED>config_file = self._get_config_file_in_folder(path)\n\n        if config_file is None:\n            <IND>parent_dir, tail = os.path.split(path)\n            if tail:\n                # No configuration file, simply take the parent's.\n                <IND>config = self._get_config(parent_dir)\n            <DED>else:\n                # There's no configuration file and no parent directory.\n                # Use the default configuration or the one given in the CLI.\n                <IND>config = self._create_check_config(self._options)\n        <DED><DED>else:\n            # There's a config file! Read it and merge if necessary.\n            <IND>options, inherit = self._read_configuration_file(config_file)\n\n            parent_dir, tail = os.path.split(path)\n            if tail and inherit:\n                # There is a parent dir and we should try to merge.\n                <IND>parent_config = self._get_config(parent_dir)\n                config = self._merge_configuration(parent_config, options)\n            <DED>else:\n                # No need to merge or parent dir does not exist.\n                <IND>config = self._create_check_config(options)\n\n        # Make the CLI always win\n        <DED><DED>final_config = {}\n        for attr in CheckConfiguration._fields:\n            <IND>cli_val = getattr(self._override_by_cli, attr)\n            conf_val = getattr(config, attr)\n            final_config[attr] = cli_val if cli_val is not None else conf_val\n\n        <DED>config = CheckConfiguration(**final_config)\n\n        self._set_add_options(config.checked_codes, self._options)\n        self._cache[path] = config\n        return self._cache[path]\n\n    <DED>def _read_configuration_file(self, path):\n        <IND>\"\"\"Try to read and parse `path` as a configuration file.\n\n        If the configurations were illegal (checked with\n        `self._validate_options`), raises `IllegalConfiguration`.\n\n        Returns (options, should_inherit).\n\n        \"\"\"\n        parser = RawConfigParser()\n        options = None\n        should_inherit = True\n\n        if parser.read(path) and self._get_section_name(parser):\n            <IND>option_list = dict([(o.dest, o.type or o.action)\n                                for o in self._parser.option_list])\n\n            # First, read the default values\n            new_options, _ = self._parse_args([])\n\n            # Second, parse the configuration\n            section_name = self._get_section_name(parser)\n            for opt in parser.options(section_name):\n                <IND>if opt == 'inherit':\n                    <IND>should_inherit = parser.getboolean(section_name, opt)\n                    continue\n\n                <DED>if opt.replace('_', '-') not in self.CONFIG_FILE_OPTIONS:\n                    <IND>log.warning(\"Unknown option '{0}' ignored\".format(opt))\n                    continue\n\n                <DED>normalized_opt = opt.replace('-', '_')\n                opt_type = option_list[normalized_opt]\n                if opt_type in ('int', 'count'):\n                    <IND>value = parser.getint(section_name, opt)\n                <DED>elif opt_type == 'string':\n                    <IND>value = parser.get(section_name, opt)\n                <DED>else:\n                    <IND>assert opt_type in ('store_true', 'store_false')\n                    value = parser.getboolean(section_name, opt)\n                <DED>setattr(new_options, normalized_opt, value)\n\n            # Third, fix the set-options\n            <DED>options = self._fix_set_options(new_options)\n\n        <DED>if options is not None:\n            <IND>if not self._validate_options(options):\n                <IND>raise IllegalConfiguration('in file: {0}'.format(path))\n\n        <DED><DED>return options, should_inherit\n\n    <DED>def _merge_configuration(self, parent_config, child_options):\n        <IND>\"\"\"Merge parent config into the child options.\n\n        The migration process requires an `options` object for the child in\n        order to distinguish between mutually exclusive codes, add-select and\n        add-ignore error codes.\n\n        \"\"\"\n        # Copy the parent error codes so we won't override them\n        error_codes = copy.deepcopy(parent_config.checked_codes)\n        if self._has_exclusive_option(child_options):\n            <IND>error_codes = self._get_exclusive_error_codes(child_options)\n\n        <DED>self._set_add_options(error_codes, child_options)\n\n        match = child_options.match            if child_options.match is not None else parent_config.match\n        match_dir = child_options.match_dir            if child_options.match_dir is not None else parent_config.match_dir\n\n        return CheckConfiguration(checked_codes=error_codes,\n                                  match=match,\n                                  match_dir=match_dir)\n\n    <DED>def _parse_args(self, args=None, values=None):\n        <IND>\"\"\"Parse the options using `self._parser` and reformat the options.\"\"\"\n        options, arguments = self._parser.parse_args(args, values)\n        return self._fix_set_options(options), arguments\n\n    <DED>@staticmethod\n    def _create_run_config(options):\n        <IND>\"\"\"Create a `RunConfiguration` object from `options`.\"\"\"\n        values = dict([(opt, getattr(options, opt)) for opt in\n                       RunConfiguration._fields])\n        return RunConfiguration(**values)\n\n    <DED>@classmethod\n    def _create_check_config(cls, options, use_dafaults=True):\n        <IND>\"\"\"Create a `CheckConfiguration` object from `options`.\n\n        If `use_dafaults`, any of the match options that are `None` will\n        be replaced with their default value and the default convention will be\n        set for the checked codes.\n\n        \"\"\"\n        match = cls.DEFAULT_MATCH_RE            if options.match is None and use_dafaults            else options.match\n\n        match_dir = cls.DEFAULT_MATCH_DIR_RE            if options.match_dir is None and use_dafaults            else options.match_dir\n\n        checked_codes = None\n\n        if cls._has_exclusive_option(options) or use_dafaults:\n            <IND>checked_codes = cls._get_checked_errors(options)\n\n        <DED>return CheckConfiguration(checked_codes=checked_codes,\n                                  match=match, match_dir=match_dir)\n\n    <DED>@classmethod\n    def _get_section_name(cls, parser):\n        <IND>\"\"\"Parse options from relevant section.\"\"\"\n        for section_name in cls.POSSIBLE_SECTION_NAMES:\n            <IND>if parser.has_section(section_name):\n                <IND>return section_name\n\n        <DED><DED>return None\n\n    <DED>@classmethod\n    def _get_config_file_in_folder(cls, path):\n        <IND>\"\"\"Look for a configuration file in `path`.\n\n        If exists return it's full path, otherwise None.\n\n        \"\"\"\n        if os.path.isfile(path):\n            <IND>path = os.path.dirname(path)\n\n        <DED>for fn in cls.PROJECT_CONFIG_FILES:\n            <IND>config = RawConfigParser()\n            full_path = os.path.join(path, fn)\n            if config.read(full_path) and cls._get_section_name(config):\n                <IND>return full_path\n\n    <DED><DED><DED>@staticmethod\n    def _get_exclusive_error_codes(options):\n        <IND>\"\"\"Extract the error codes from the selected exclusive option.\"\"\"\n        codes = set(ErrorRegistry.get_error_codes())\n        checked_codes = None\n\n        if options.ignore is not None:\n            <IND>checked_codes = codes - options.ignore\n        <DED>elif options.select is not None:\n            <IND>checked_codes = options.select\n        <DED>elif options.convention is not None:\n            <IND>checked_codes = getattr(conventions, options.convention)\n\n        # To not override the conventions nor the options - copy them.\n        <DED>return copy.deepcopy(checked_codes)\n\n    <DED>@staticmethod\n    def _set_add_options(checked_codes, options):\n        <IND>\"\"\"Set `checked_codes` by the `add_ignore` or `add_select` options.\"\"\"\n        checked_codes |= options.add_select\n        checked_codes -= options.add_ignore\n\n    <DED>@classmethod\n    def _get_checked_errors(cls, options):\n        <IND>\"\"\"Extract the codes needed to be checked from `options`.\"\"\"\n        checked_codes = cls._get_exclusive_error_codes(options)\n        if checked_codes is None:\n            <IND>checked_codes = cls.DEFAULT_CONVENTION\n\n        <DED>cls._set_add_options(checked_codes, options)\n\n        return checked_codes\n\n    <DED>@classmethod\n    def _validate_options(cls, options):\n        <IND>\"\"\"Validate the mutually exclusive options.\n\n        Return `True` iff only zero or one of `BASE_ERROR_SELECTION_OPTIONS`\n        was selected.\n\n        \"\"\"\n        for opt1, opt2 in                itertools.permutations(cls.BASE_ERROR_SELECTION_OPTIONS, 2):\n            <IND>if getattr(options, opt1) and getattr(options, opt2):\n                <IND>log.error('Cannot pass both {0} and {1}. They are '\n                          'mutually exclusive.'.format(opt1, opt2))\n                return False\n\n        <DED><DED>if options.convention and options.convention not in conventions:\n            <IND>log.error(\"Illegal convention '{0}'. Possible conventions: {1}\"\n                      .format(options.convention,\n                              ', '.join(conventions.keys())))\n            return False\n        <DED>return True\n\n    <DED>@classmethod\n    def _has_exclusive_option(cls, options):\n        <IND>\"\"\"Return `True` iff one or more exclusive options were selected.\"\"\"\n        return any([getattr(options, opt) is not None for opt in\n                    cls.BASE_ERROR_SELECTION_OPTIONS])\n\n    <DED>@staticmethod\n    def _fix_set_options(options):\n        <IND>\"\"\"Alter the set options from None/strings to sets in place.\"\"\"\n        optional_set_options = ('ignore', 'select')\n        mandatory_set_options = ('add_ignore', 'add_select')\n\n        def _get_set(value_str):\n            <IND>\"\"\"Split `value_str` by the delimiter `,` and return a set.\n\n            Removes any occurrences of '' in the set.\n\n            \"\"\"\n            return set(value_str.split(',')) - set([''])\n\n        <DED>for opt in optional_set_options:\n            <IND>value = getattr(options, opt)\n            if value is not None:\n                <IND>setattr(options, opt, _get_set(value))\n\n        <DED><DED>for opt in mandatory_set_options:\n            <IND>value = getattr(options, opt)\n            if value is None:\n                <IND>value = ''\n\n            <DED>if not isinstance(value, Set):\n                <IND>value = _get_set(value)\n\n            <DED>setattr(options, opt, value)\n\n        <DED>return options\n\n    <DED>@classmethod\n    def _create_option_parser(cls):\n        <IND>\"\"\"Return an option parser to parse the command line arguments.\"\"\"\n        from optparse import OptionParser\n\n        parser = OptionParser(\n            version=__version__,\n            usage='Usage: pydocstyle [options] [<file|dir>...]')\n\n        option = parser.add_option\n\n        # Run configuration options\n        option('-e', '--explain', action='store_true', default=False,\n               help='show explanation of each error')\n        option('-s', '--source', action='store_true', default=False,\n               help='show source for each error')\n        option('-d', '--debug', action='store_true', default=False,\n               help='print debug information')\n        option('-v', '--verbose', action='store_true', default=False,\n               help='print status information')\n        option('--count', action='store_true', default=False,\n               help='print total number of errors to stdout')\n\n        # Error check options\n        option('--select', metavar='<codes>', default=None,\n               help='choose the basic list of checked errors by '\n                    'specifying which errors to check for (with a list of '\n                    'comma-separated error codes). '\n                    'for example: --select=D101,D202')\n        option('--ignore', metavar='<codes>', default=None,\n               help='choose the basic list of checked errors by '\n                    'specifying which errors to ignore (with a list of '\n                    'comma-separated error codes). '\n                    'for example: --ignore=D101,D202')\n        option('--convention', metavar='<name>', default=None,\n               help='choose the basic list of checked errors by specifying an '\n                    'existing convention. Possible conventions: {0}'\n                    .format(', '.join(conventions)))\n        option('--add-select', metavar='<codes>', default=None,\n               help='amend the list of errors to check for by specifying '\n                    'more error codes to check.')\n        option('--add-ignore', metavar='<codes>', default=None,\n               help='amend the list of errors to check for by specifying '\n                    'more error codes to ignore.')\n\n        # Match clauses\n        option('--match', metavar='<pattern>', default=None,\n               help=(\"check only files that exactly match <pattern> regular \"\n                     \"expression; default is --match='{0}' which matches \"\n                     \"files that don't start with 'test_' but end with \"\n                     \"'.py'\").format(cls.DEFAULT_MATCH_RE))\n        option('--match-dir', metavar='<pattern>', default=None,\n               help=(\"search only dirs that exactly match <pattern> regular \"\n                     \"expression; default is --match-dir='{0}', which \"\n                     \"matches all dirs that don't start with \"\n                     \"a dot\").format(cls.DEFAULT_MATCH_DIR_RE))\n\n        return parser\n\n\n<DED><DED>def check(filenames, select=None, ignore=None):\n    <IND>\"\"\"Generate PEP 257 errors that exist in `filenames` iterable.\n\n    Only returns errors with error-codes defined in `checked_codes` iterable.\n\n    Example\n    -------\n    >>> check([ppydocstyle.py.py], checked_codes=['D100'])\n    <generator object check at 0x...>\n\n    \"\"\"\n    if select is not None and ignore is not None:\n        <IND>raise IllegalConfiguration('Cannot pass both select and ignore. '\n                                   'They are mutually exclusive.')\n    <DED>elif select is not None:\n        <IND>checked_codes = select\n    <DED>elif ignore is not None:\n        <IND>checked_codes = list(set(ErrorRegistry.get_error_codes()) -\n                             set(ignore))\n    <DED>else:\n        <IND>checked_codes = conventions.pep257\n\n    <DED>for filename in filenames:\n        <IND>log.info('Checking file %s.', filename)\n        try:\n            <IND>with tokenize_open(filename) as file:\n                <IND>source = file.read()\n            <DED>for error in PEP257Checker().check_source(source, filename):\n                <IND>code = getattr(error, 'code', None)\n                if code in checked_codes:\n                    <IND>yield error\n        <DED><DED><DED>except (EnvironmentError, AllError):\n            <IND>yield sys.exc_info()[1]\n        <DED>except tk.TokenError:\n            <IND>yield SyntaxError('invalid syntax in file %s' % filename)\n\n\n<DED><DED><DED>def setup_stream_handlers(conf):\n    <IND>\"\"\"Setup logging stream handlers according to the options.\"\"\"\n    class StdoutFilter(logging.Filter):\n        <IND>def filter(self, record):\n            <IND>return record.levelno in (logging.DEBUG, logging.INFO)\n\n    <DED><DED>log.handlers = []\n\n    stdout_handler = logging.StreamHandler(sys.stdout)\n    stdout_handler.setLevel(logging.WARNING)\n    stdout_handler.addFilter(StdoutFilter())\n    if conf.debug:\n        <IND>stdout_handler.setLevel(logging.DEBUG)\n    <DED>elif conf.verbose:\n        <IND>stdout_handler.setLevel(logging.INFO)\n    <DED>else:\n        <IND>stdout_handler.setLevel(logging.WARNING)\n    <DED>log.addHandler(stdout_handler)\n\n    stderr_handler = logging.StreamHandler(sys.stderr)\n    stderr_handler.setLevel(logging.WARNING)\n    log.addHandler(stderr_handler)\n\n\n<DED>def run_pydocstyle(use_pep257=False):\n    <IND>log.setLevel(logging.DEBUG)\n    conf = ConfigurationParser()\n    setup_stream_handlers(conf.get_default_run_configuration())\n\n    try:\n        <IND>conf.parse()\n    <DED>except IllegalConfiguration:\n        <IND>return ReturnCode.invalid_options\n\n    <DED>run_conf = conf.get_user_run_configuration()\n\n    # Reset the logger according to the command line arguments\n    setup_stream_handlers(run_conf)\n\n    if use_pep257:\n        <IND>log.warning(\"Deprecation Warning:\\n\"\n                    \"pep257 has been renamed to pydocstyle and the use of the \"\n                    \"pep257 executable is deprecated and will be removed in \"\n                    \"the next major version. Please use `pydocstyle` instead.\")\n\n    <DED>log.debug(\"starting in debug mode.\")\n\n    Error.explain = run_conf.explain\n    Error.source = run_conf.source\n\n    errors = []\n    try:\n        <IND>for filename, checked_codes in conf.get_files_to_check():\n            <IND>errors.extend(check((filename,), select=checked_codes))\n    <DED><DED>except IllegalConfiguration:\n        # An illegal configuration file was found during file generation.\n        <IND>return ReturnCode.invalid_options\n\n    <DED>code = ReturnCode.no_violations_found\n    count = 0\n    for error in errors:\n        <IND>sys.stderr.write('%s\\n' % error)\n        code = ReturnCode.violations_found\n        count += 1\n    <DED>if run_conf.count:\n        <IND>print(count)\n    <DED>return code\n\n\n<DED>parse = Parser()\n\n\ndef check_for(kind, terminal=False):\n    <IND>def decorator(f):\n        <IND>f._check_for = kind\n        f._terminal = terminal\n        return f\n    <DED>return decorator\n\n\n<DED>class PEP257Checker(object):\n    <IND>\"\"\"Checker for PEP 257.\n\n    D10x: Missing docstrings\n    D20x: Whitespace issues\n    D30x: Docstring formatting\n    D40x: Docstring content issues\n\n    \"\"\"\n\n    def check_source(self, source, filename):\n        <IND>module = parse(StringIO(source), filename)\n        for definition in module:\n            <IND>for check in self.checks:\n                <IND>terminate = False\n                if isinstance(definition, check._check_for):\n                    <IND>error = check(None, definition, definition.docstring)\n                    errors = error if hasattr(error, '__iter__') else [error]\n                    for error in errors:\n                        <IND>if error is not None:\n                            <IND>partition = check.__doc__.partition('.\\n')\n                            message, _, explanation = partition\n                            error.set_context(explanation=explanation,\n                                              definition=definition)\n                            yield error\n                            if check._terminal:\n                                <IND>terminate = True\n                                break\n                <DED><DED><DED><DED>if terminate:\n                    <IND>break\n\n    <DED><DED><DED><DED>@property\n    def checks(self):\n        <IND>all = [check for check in vars(type(self)).values()\n               if hasattr(check, '_check_for')]\n        return sorted(all, key=lambda check: not check._terminal)\n\n    <DED>@check_for(Definition, terminal=True)\n    def check_docstring_missing(self, definition, docstring):\n        <IND>\"\"\"D10{0,1,2,3}: Public definitions should have docstrings.\n\n        All modules should normally have docstrings.  [...] all functions and\n        classes exported by a module should also have docstrings. Public\n        methods (including the __init__ constructor) should also have\n        docstrings.\n\n        Note: Public (exported) definitions are either those with names listed\n              in __all__ variable (if present), or those that do not start\n              with a single underscore.\n\n        \"\"\"\n        if (not docstring and definition.is_public or\n                docstring and is_blank(ast.literal_eval(docstring))):\n            <IND>codes = {Module: D100, Class: D101, NestedClass: D101,\n                     Method: (lambda: D105() if is_magic(definition.name)\n                              else D102()),\n                     Function: D103, NestedFunction: D103, Package: D104}\n            return codes[type(definition)]()\n\n    <DED><DED>@check_for(Definition)\n    def check_one_liners(self, definition, docstring):\n        <IND>\"\"\"D200: One-liner docstrings should fit on one line with quotes.\n\n        The closing quotes are on the same line as the opening quotes.\n        This looks better for one-liners.\n\n        \"\"\"\n        if docstring:\n            <IND>lines = ast.literal_eval(docstring).split('\\n')\n            if len(lines) > 1:\n                <IND>non_empty_lines = sum(1 for l in lines if not is_blank(l))\n                if non_empty_lines == 1:\n                    <IND>return D200(len(lines))\n\n    <DED><DED><DED><DED>@check_for(Function)\n    def check_no_blank_before(self, function, docstring):  # def\n        <IND>\"\"\"D20{1,2}: No blank lines allowed around function/method docstring.\n\n        There's no blank line either before or after the docstring.\n\n        \"\"\"\n        if docstring:\n            <IND>before, _, after = function.source.partition(docstring)\n            blanks_before = list(map(is_blank, before.split('\\n')[:-1]))\n            blanks_after = list(map(is_blank, after.split('\\n')[1:]))\n            blanks_before_count = sum(takewhile(bool, reversed(blanks_before)))\n            blanks_after_count = sum(takewhile(bool, blanks_after))\n            if blanks_before_count != 0:\n                <IND>yield D201(blanks_before_count)\n            <DED>if not all(blanks_after) and blanks_after_count != 0:\n                <IND>yield D202(blanks_after_count)\n\n    <DED><DED><DED>@check_for(Class)\n    def check_blank_before_after_class(self, class_, docstring):\n        <IND>\"\"\"D20{3,4}: Class docstring should have 1 blank line around them.\n\n        Insert a blank line before and after all docstrings (one-line or\n        multi-line) that document a class -- generally speaking, the class's\n        methods are separated from each other by a single blank line, and the\n        docstring needs to be offset from the first method by a blank line;\n        for symmetry, put a blank line between the class header and the\n        docstring.\n\n        \"\"\"\n        # NOTE: this gives false-positive in this case\n        # class Foo:\n        #\n        #     \"\"\"Docstring.\"\"\"\n        #\n        #\n        # # comment here\n        # def foo(): pass\n        if docstring:\n            <IND>before, _, after = class_.source.partition(docstring)\n            blanks_before = list(map(is_blank, before.split('\\n')[:-1]))\n            blanks_after = list(map(is_blank, after.split('\\n')[1:]))\n            blanks_before_count = sum(takewhile(bool, reversed(blanks_before)))\n            blanks_after_count = sum(takewhile(bool, blanks_after))\n            if blanks_before_count != 0:\n                <IND>yield D211(blanks_before_count)\n            <DED>if blanks_before_count != 1:\n                <IND>yield D203(blanks_before_count)\n            <DED>if not all(blanks_after) and blanks_after_count != 1:\n                <IND>yield D204(blanks_after_count)\n\n    <DED><DED><DED>@check_for(Definition)\n    def check_blank_after_summary(self, definition, docstring):\n        <IND>\"\"\"D205: Put one blank line between summary line and description.\n\n        Multi-line docstrings consist of a summary line just like a one-line\n        docstring, followed by a blank line, followed by a more elaborate\n        description. The summary line may be used by automatic indexing tools;\n        it is important that it fits on one line and is separated from the\n        rest of the docstring by a blank line.\n\n        \"\"\"\n        if docstring:\n            <IND>lines = ast.literal_eval(docstring).strip().split('\\n')\n            if len(lines) > 1:\n                <IND>post_summary_blanks = list(map(is_blank, lines[1:]))\n                blanks_count = sum(takewhile(bool, post_summary_blanks))\n                if blanks_count != 1:\n                    <IND>return D205(blanks_count)\n\n    <DED><DED><DED><DED>@check_for(Definition)\n    def check_indent(self, definition, docstring):\n        <IND>\"\"\"D20{6,7,8}: The entire docstring should be indented same as code.\n\n        The entire docstring is indented the same as the quotes at its\n        first line.\n\n        \"\"\"\n        if docstring:\n            <IND>before_docstring, _, _ = definition.source.partition(docstring)\n            _, _, indent = before_docstring.rpartition('\\n')\n            lines = docstring.split('\\n')\n            if len(lines) > 1:\n                <IND>lines = lines[1:]  # First line does not need indent.\n                indents = [leading_space(l) for l in lines if not is_blank(l)]\n                if set(' \\t') == set(''.join(indents) + indent):\n                    <IND>yield D206()\n                <DED>if (len(indents) > 1 and min(indents[:-1]) > indent or\n                        indents[-1] > indent):\n                    <IND>yield D208()\n                <DED>if min(indents) < indent:\n                    <IND>yield D207()\n\n    <DED><DED><DED><DED>@check_for(Definition)\n    def check_newline_after_last_paragraph(self, definition, docstring):\n        <IND>\"\"\"D209: Put multi-line docstring closing quotes on separate line.\n\n        Unless the entire docstring fits on a line, place the closing\n        quotes on a line by themselves.\n\n        \"\"\"\n        if docstring:\n            <IND>lines = [l for l in ast.literal_eval(docstring).split('\\n')\n                     if not is_blank(l)]\n            if len(lines) > 1:\n                <IND>if docstring.split(\"\\n\")[-1].strip() not in ['\"\"\"', \"'''\"]:\n                    <IND>return D209()\n\n    <DED><DED><DED><DED>@check_for(Definition)\n    def check_surrounding_whitespaces(self, definition, docstring):\n        <IND>\"\"\"D210: No whitespaces allowed surrounding docstring text.\"\"\"\n        if docstring:\n            <IND>lines = ast.literal_eval(docstring).split('\\n')\n            if lines[0].startswith(' ') or                    len(lines) == 1 and lines[0].endswith(' '):\n                <IND>return D210()\n\n    <DED><DED><DED>@check_for(Definition)\n    def check_multi_line_summary_start(self, definition, docstring):\n        <IND>\"\"\"D21{2,3}: Multi-line docstring summary style check.\n\n        A multi-line docstring summary should start either at the first,\n        or separately at the second line of a docstring.\n\n        \"\"\"\n        if docstring:\n            <IND>start_triple = [\n                '\"\"\"', \"'''\",\n                'u\"\"\"', \"u'''\",\n                'r\"\"\"', \"r'''\",\n                'ur\"\"\"', \"ur'''\"\n            ]\n\n            lines = ast.literal_eval(docstring).split('\\n')\n            if len(lines) > 1:\n                <IND>first = docstring.split(\"\\n\")[0].strip().lower()\n                if first in start_triple:\n                    <IND>return D212()\n                <DED>else:\n                    <IND>return D213()\n\n    <DED><DED><DED><DED>@check_for(Definition)\n    def check_triple_double_quotes(self, definition, docstring):\n        <IND>r'''D300: Use \"\"\"triple double quotes\"\"\".\n\n        For consistency, always use \"\"\"triple double quotes\"\"\" around\n        docstrings. Use r\"\"\"raw triple double quotes\"\"\" if you use any\n        backslashes in your docstrings. For Unicode docstrings, use\n        u\"\"\"Unicode triple-quoted strings\"\"\".\n\n        Note: Exception to this is made if the docstring contains\n              \"\"\" quotes in its body.\n\n        '''\n        if docstring:\n            <IND>opening = docstring[:5].lower()\n            if '\"\"\"' in ast.literal_eval(docstring) and opening.startswith(\n                    (\"'''\", \"r'''\", \"u'''\", \"ur'''\")):\n                # Allow ''' quotes if docstring contains \"\"\", because\n                # otherwise \"\"\" quotes could not be expressed inside\n                # docstring. Not in PEP 257.\n                <IND>return\n            <DED>if not opening.startswith(('\"\"\"', 'r\"\"\"', 'u\"\"\"', 'ur\"\"\"')):\n                <IND>quotes = \"'''\" if \"'''\" in opening else \"'\"\n                return D300(quotes)\n\n    <DED><DED><DED>@check_for(Definition)\n    def check_backslashes(self, definition, docstring):\n        <IND>r'''D301: Use r\"\"\" if any backslashes in a docstring.\n\n        Use r\"\"\"raw triple double quotes\"\"\" if you use any backslashes\n        (\\) in your docstrings.\n\n        '''\n        # Just check that docstring is raw, check_triple_double_quotes\n        # ensures the correct quotes.\n        if docstring and '\\\\' in docstring and not docstring.startswith(\n                ('r', 'ur')):\n            <IND>return D301()\n\n    <DED><DED>@check_for(Definition)\n    def check_unicode_docstring(self, definition, docstring):\n        <IND>r'''D302: Use u\"\"\" for docstrings with Unicode.\n\n        For Unicode docstrings, use u\"\"\"Unicode triple-quoted strings\"\"\".\n\n        '''\n        if definition.module.future_imports['unicode_literals']:\n            <IND>return\n\n        # Just check that docstring is unicode, check_triple_double_quotes\n        # ensures the correct quotes.\n        <DED>if docstring and sys.version_info[0] <= 2:\n            <IND>if not is_ascii(docstring) and not docstring.startswith(\n                    ('u', 'ur')):\n                <IND>return D302()\n\n    <DED><DED><DED>@check_for(Definition)\n    def check_ends_with_period(self, definition, docstring):\n        <IND>\"\"\"D400: First line should end with a period.\n\n        The [first line of a] docstring is a phrase ending in a period.\n\n        \"\"\"\n        if docstring:\n            <IND>summary_line = ast.literal_eval(docstring).strip().split('\\n')[0]\n            if not summary_line.endswith('.'):\n                <IND>return D400(summary_line[-1])\n\n    <DED><DED><DED>@check_for(Function)\n    def check_imperative_mood(self, function, docstring):  # def context\n        <IND>\"\"\"D401: First line should be in imperative mood: 'Do', not 'Does'.\n\n        [Docstring] prescribes the function or method's effect as a command:\n        (\"Do this\", \"Return that\"), not as a description; e.g. don't write\n        \"Returns the pathname ...\".\n\n        \"\"\"\n        if docstring:\n            <IND>stripped = ast.literal_eval(docstring).strip()\n            if stripped:\n                <IND>first_word = stripped.split()[0]\n                if first_word.endswith('s') and not first_word.endswith('ss'):\n                    <IND>return D401(first_word[:-1], first_word)\n\n    <DED><DED><DED><DED>@check_for(Function)\n    def check_no_signature(self, function, docstring):  # def context\n        <IND>\"\"\"D402: First line should not be function's or method's \"signature\".\n\n        The one-line docstring should NOT be a \"signature\" reiterating the\n        function/method parameters (which can be obtained by introspection).\n\n        \"\"\"\n        if docstring:\n            <IND>first_line = ast.literal_eval(docstring).strip().split('\\n')[0]\n            if function.name + '(' in first_line.replace(' ', ''):\n                <IND>return D402()\n\n    <DED><DED><DED>@check_for(Function)\n    def check_capitalized(self, function, docstring):\n        <IND>\"\"\"D403: First word of the first line should be properly capitalized.\n\n        The [first line of a] docstring is a phrase ending in a period.\n\n        \"\"\"\n        if docstring:\n            <IND>first_word = ast.literal_eval(docstring).split()[0]\n            if first_word == first_word.upper():\n                <IND>return\n            <DED>for char in first_word:\n                <IND>if char not in string.ascii_letters and char != \"'\":\n                    <IND>return\n            <DED><DED>if first_word != first_word.capitalize():\n                <IND>return D403(first_word.capitalize(), first_word)\n\n    <DED><DED><DED>@check_for(Definition)\n    def check_starts_with_this(self, function, docstring):\n        <IND>\"\"\"D404: First word of the docstring should not be `This`.\n\n        Docstrings should use short, simple language. They should not begin\n        with \"This class is [..]\" or \"This module contains [..]\".\n\n        \"\"\"\n        if docstring:\n            <IND>first_word = ast.literal_eval(docstring).split()[0]\n            if first_word.lower() == 'this':\n                <IND>return D404()\n\n    # Somewhat hard to determine if return value is mentioned.\n    # @check(Function)\n    <DED><DED><DED>def SKIP_check_return_type(self, function, docstring):\n        <IND>\"\"\"D40x: Return value type should be mentioned.\n\n        [T]he nature of the return value cannot be determined by\n        introspection, so it should be mentioned.\n\n        \"\"\"\n        if docstring and function.returns_value:\n            <IND>if 'return' not in docstring.lower():\n                <IND>return Error()\n\n\n<DED><DED><DED><DED>def main(use_pep257=False):\n    <IND>try:\n        <IND>sys.exit(run_pydocstyle(use_pep257))\n    <DED>except KeyboardInterrupt:\n        <IND>pass\n\n\n<DED><DED>def main_pep257():\n    <IND>main(use_pep257=True)\n\n\n<DED>if __name__ == '__main__':\n    <IND>main()\n"
      }
    ]
  }
]