[
  {
    "project": "SeldonIO/alibi-detect",
    "commit": "b39406a6cf88f315f401562d4fea93a42aa6dcc1",
    "filename": "alibi_detect/cd/ks.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/SeldonIO-alibi-detect/alibi_detect/cd/ks.py",
    "file_hunks_size": 6,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": true,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "alibi_detect/cd/ks.py:224:61 Incompatible parameter type [6]: Expected `Dict[str, int]` for 4th positional only parameter to call `update_reference` but got `Optional[Dict[str, int]]`.",
    "message": " Expected `Dict[str, int]` for 4th positional only parameter to call `update_reference` but got `Optional[Dict[str, int]]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 224,
    "warning_line": "        self.X_ref = update_reference(self.X_ref, X, self.n, self.update_X_ref)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "        return p_val, dist\n\n    def score(self, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Compute the feature-wise drift score which is the p-value of the\n        Kolmogorov-Smirnov test and the test statistic.\n\n        Parameters\n        ----------\n        X\n            Batch of instances.\n\n        Returns\n        -------\n        Feature level p-values and K-S statistics.\n        \"\"\"\n        X_ref, X = self.preprocess(X)\n        score, dist = self.feature_score(X_ref, X)  # feature-wise K-S test\n        return score, dist\n\n    def predict(self, X: Union[np.ndarray, list], drift_type: str = 'batch',\n                return_p_val: bool = True, return_distance: bool = True) \\\n            -> Dict[Dict[str, str], Dict[str, Union[np.ndarray, int, float]]]:\n        \"\"\"\n        Predict whether a batch of data has drifted from the reference data.\n\n        Parameters\n        ----------\n        X\n            Batch of instances.\n        drift_type\n            Predict drift at the 'feature' or 'batch' level. For 'batch', the K-S statistics for\n            each feature are aggregated using the Bonferroni or False Discovery Rate correction.\n        return_p_val\n            Whether to return feature level p-values.\n        return_distance\n            Whether to return the K-S statistic between the features of the new batch and reference data.\n\n        Returns\n        -------\n        Dictionary containing 'meta' and 'data' dictionaries.\n        'meta' has the model's metadata.\n        'data' contains the drift predictions and both feature and batch level drift scores.\n        'data' contains the drift prediction and optionally the feature level p-values,\n         threshold after multivariate correction if needed and K-S statistics.\n        \"\"\"\n        # compute drift scores\n        p_vals, dist = self.score(X)\n\n        # values below p-value threshold are drift\n        if drift_type == 'feature':\n            drift_pred = (p_vals < self.p_val).astype(int)\n        elif drift_type == 'batch' and self.correction == 'bonferroni':\n            threshold = self.p_val / self.n_features\n            drift_pred = int((p_vals < threshold).any())\n        elif drift_type == 'batch' and self.correction == 'fdr':\n            drift_pred, threshold = fdr(p_vals, q_val=self.p_val)\n        else:\n            raise ValueError('`drift_type` needs to be either `feature` or `batch`.')\n\n        # update reference dataset\n        if (isinstance(self.update_X_ref, dict) and self.preprocess_fn is not None\n                and self.preprocess_X_ref):\n            X = self.preprocess_fn(X)\n        self.X_ref = update_reference(self.X_ref, X, self.n, self.update_X_ref)\n        # used for reservoir sampling\n        self.n += X.shape[0]  # type: ignore\n\n        # populate drift dict\n        cd = concept_drift_dict()\n        cd['meta'] = self.meta\n        cd['data']['is_drift'] = drift_pred\n        if return_p_val:\n            cd['data']['p_val'] = p_vals\n            cd['data']['threshold'] = self.p_val if drift_type == 'feature' else threshold\n        if return_distance:\n            cd['data']['distance'] = dist\n        return cd\n",
        "source_code_len": 3161,
        "target_code": "        return p_val, dist\n",
        "target_code_len": 27,
        "diff_format": "@@ -160,78 +102,1 @@\n         return p_val, dist\n-\n-    def score(self, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n-        \"\"\"\n-        Compute the feature-wise drift score which is the p-value of the\n-        Kolmogorov-Smirnov test and the test statistic.\n-\n-        Parameters\n-        ----------\n-        X\n-            Batch of instances.\n-\n-        Returns\n-        -------\n-        Feature level p-values and K-S statistics.\n-        \"\"\"\n-        X_ref, X = self.preprocess(X)\n-        score, dist = self.feature_score(X_ref, X)  # feature-wise K-S test\n-        return score, dist\n-\n-    def predict(self, X: Union[np.ndarray, list], drift_type: str = 'batch',\n-                return_p_val: bool = True, return_distance: bool = True) \\\n-            -> Dict[Dict[str, str], Dict[str, Union[np.ndarray, int, float]]]:\n-        \"\"\"\n-        Predict whether a batch of data has drifted from the reference data.\n-\n-        Parameters\n-        ----------\n-        X\n-            Batch of instances.\n-        drift_type\n-            Predict drift at the 'feature' or 'batch' level. For 'batch', the K-S statistics for\n-            each feature are aggregated using the Bonferroni or False Discovery Rate correction.\n-        return_p_val\n-            Whether to return feature level p-values.\n-        return_distance\n-            Whether to return the K-S statistic between the features of the new batch and reference data.\n-\n-        Returns\n-        -------\n-        Dictionary containing 'meta' and 'data' dictionaries.\n-        'meta' has the model's metadata.\n-        'data' contains the drift predictions and both feature and batch level drift scores.\n-        'data' contains the drift prediction and optionally the feature level p-values,\n-         threshold after multivariate correction if needed and K-S statistics.\n-        \"\"\"\n-        # compute drift scores\n-        p_vals, dist = self.score(X)\n-\n-        # values below p-value threshold are drift\n-        if drift_type == 'feature':\n-            drift_pred = (p_vals < self.p_val).astype(int)\n-        elif drift_type == 'batch' and self.correction == 'bonferroni':\n-            threshold = self.p_val / self.n_features\n-            drift_pred = int((p_vals < threshold).any())\n-        elif drift_type == 'batch' and self.correction == 'fdr':\n-            drift_pred, threshold = fdr(p_vals, q_val=self.p_val)\n-        else:\n-            raise ValueError('`drift_type` needs to be either `feature` or `batch`.')\n-\n-        # update reference dataset\n-        if (isinstance(self.update_X_ref, dict) and self.preprocess_fn is not None\n-                and self.preprocess_X_ref):\n-            X = self.preprocess_fn(X)\n-        self.X_ref = update_reference(self.X_ref, X, self.n, self.update_X_ref)\n-        # used for reservoir sampling\n-        self.n += X.shape[0]  # type: ignore\n-\n-        # populate drift dict\n-        cd = concept_drift_dict()\n-        cd['meta'] = self.meta\n-        cd['data']['is_drift'] = drift_pred\n-        if return_p_val:\n-            cd['data']['p_val'] = p_vals\n-            cd['data']['threshold'] = self.p_val if drift_type == 'feature' else threshold\n-        if return_distance:\n-            cd['data']['distance'] = dist\n-        return cd\n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent": "        <DED>return p_val, dist\n",
        "target_code_with_indent_exact_match": true,
        "source_code_with_indent": "        <DED>return p_val, dist\n\n    <DED>def score(self, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n        <IND>\"\"\"\n        Compute the feature-wise drift score which is the p-value of the\n        Kolmogorov-Smirnov test and the test statistic.\n\n        Parameters\n        ----------\n        X\n            Batch of instances.\n\n        Returns\n        -------\n        Feature level p-values and K-S statistics.\n        \"\"\"\n        X_ref, X = self.preprocess(X)\n        score, dist = self.feature_score(X_ref, X)  # feature-wise K-S test\n        return score, dist\n\n    <DED>def predict(self, X: Union[np.ndarray, list], drift_type: str = 'batch',\n                return_p_val: bool = True, return_distance: bool = True)            -> Dict[Dict[str, str], Dict[str, Union[np.ndarray, int, float]]]:\n        <IND>\"\"\"\n        Predict whether a batch of data has drifted from the reference data.\n\n        Parameters\n        ----------\n        X\n            Batch of instances.\n        drift_type\n            Predict drift at the 'feature' or 'batch' level. For 'batch', the K-S statistics for\n            each feature are aggregated using the Bonferroni or False Discovery Rate correction.\n        return_p_val\n            Whether to return feature level p-values.\n        return_distance\n            Whether to return the K-S statistic between the features of the new batch and reference data.\n\n        Returns\n        -------\n        Dictionary containing 'meta' and 'data' dictionaries.\n        'meta' has the model's metadata.\n        'data' contains the drift predictions and both feature and batch level drift scores.\n        'data' contains the drift prediction and optionally the feature level p-values,\n         threshold after multivariate correction if needed and K-S statistics.\n        \"\"\"\n        # compute drift scores\n        p_vals, dist = self.score(X)\n\n        # values below p-value threshold are drift\n        if drift_type == 'feature':\n            <IND>drift_pred = (p_vals < self.p_val).astype(int)\n        <DED>elif drift_type == 'batch' and self.correction == 'bonferroni':\n            <IND>threshold = self.p_val / self.n_features\n            drift_pred = int((p_vals < threshold).any())\n        <DED>elif drift_type == 'batch' and self.correction == 'fdr':\n            <IND>drift_pred, threshold = fdr(p_vals, q_val=self.p_val)\n        <DED>else:\n            <IND>raise ValueError('`drift_type` needs to be either `feature` or `batch`.')\n\n        # update reference dataset\n        <DED>if (isinstance(self.update_X_ref, dict) and self.preprocess_fn is not None\n                and self.preprocess_X_ref):\n            <IND>X = self.preprocess_fn(X)\n        <DED>self.X_ref = update_reference(self.X_ref, X, self.n, self.update_X_ref)\n        # used for reservoir sampling\n        self.n += X.shape[0]  # type: ignore\n\n        # populate drift dict\n        cd = concept_drift_dict()\n        cd['meta'] = self.meta\n        cd['data']['is_drift'] = drift_pred\n        if return_p_val:\n            <IND>cd['data']['p_val'] = p_vals\n            cd['data']['threshold'] = self.p_val if drift_type == 'feature' else threshold\n        <DED>if return_distance:\n            <IND>cd['data']['distance'] = dist\n        <DED>return cd\n"
      }
    ]
  }
]