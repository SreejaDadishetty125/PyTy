[
  {
    "project": "SeldonIO/alibi",
    "commit": "ab7dbf9b2a153ff49f29a372d5bdeac56dc7284a",
    "filename": "alibi/explainers/anchor_image.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/SeldonIO-alibi/alibi/explainers/anchor_image.py",
    "file_hunks_size": 12,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "alibi/explainers/anchor_image.py:86:8 Incompatible attribute type [8]: Attribute `segment_labels` declared in class `AnchorImage` has type `List[typing.Any]` but is used as type `None`.",
    "message": " Attribute `segment_labels` declared in class `AnchorImage` has type `List[typing.Any]` but is used as type `None`.",
    "rule_id": "Incompatible attribute type [8]",
    "warning_line_no": 86,
    "warning_line": "        self.segment_labels = None  # type: list",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "\nclass AnchorImage(Explainer):\n\n    def __init__(self, predictor: Callable, image_shape: tuple, segmentation_fn: Any = 'slic',\n",
        "source_code_len": 127,
        "target_code": "\ndef scale_image(image: np.ndarray, scale: tuple = (0, 255)) -> np.ndarray:\n    \"\"\"\n    Scales an image in a specified range.\n\n    Parameters\n    ----------\n    image\n        Image to be scale.\n    scale\n        The scaling interval.\n\n    Returns\n    -------\n    img_scaled\n        Scaled image.\n    \"\"\"\n\n    img_max, img_min = image.max(), image.min()\n    img_std = (image - img_min) / (img_max - img_min)\n    img_scaled = img_std * (scale[1] - scale[0]) + scale[0]\n\n    return img_scaled\n\n\nclass AnchorImageSampler:\n    def __init__(\n        self,\n        predictor: Callable,\n        segmentation_fn: Callable,\n        custom_segmentation: bool,\n        image: np.ndarray,\n        images_background: np.ndarray = None,\n        p_sample: float = 0.5,\n        n_covered_ex: int = 10,\n    ):\n        \"\"\"\n        Initialize anchor image sampler.\n\n        Parameters\n        ----------\n        predictor\n            A callable that takes a tensor of N data points as inputs and returns N outputs.\n        segmentation_fn\n            Function used to segment the images.\n        image\n            Image to be explained.\n        images_background\n            Images to overlay superpixels on.\n        p_sample\n            Probability for a pixel to be represented by the average value of its superpixel.\n        n_covered_ex\n            How many examples where anchors apply to store for each anchor sampled during search\n            (both examples where prediction on samples agrees/disagrees with desired_label are stored).\n        \"\"\"\n        self.predictor = predictor\n        self.segmentation_fn = segmentation_fn\n        self.custom_segmentation = custom_segmentation\n        self.image = image\n        self.images_background = images_background\n        self.n_covered_ex = n_covered_ex\n        self.p_sample = p_sample\n        self.segments = self.generate_superpixels(image)\n        self.segment_labels = list(np.unique(self.segments))\n        self.instance_label = self.predictor(image[np.newaxis, ...])[0]\n\n    def __call__(\n        self, anchor: Tuple[int, tuple], num_samples: int, compute_labels: bool = True\n    ) -> List[Union[np.ndarray, float, int]]:\n        \"\"\"\n        Sample images from a perturbation distribution by masking randomly chosen superpixels\n        from the original image and replacing them with pixel values from superimposed images\n        if background images are provided to the explainer. Otherwise, the superpixels from the\n        original image are replaced with their average values.\n\n        Parameters\n        ----------\n        anchor\n            int: order of anchor in the batch\n            tuple: features (= superpixels) present in the proposed anchor\n        num_samples\n            Number of samples used\n        compute_labels\n            If True, an array of comparisons between predictions on perturbed samples and\n            instance to be explained is returned.\n\n        Returns\n        -------\n            If compute_labels=True, a list containing the following is returned:\n                - covered_true: perturbed examples where the anchor applies and the model prediction\n                    on perturbed is the same as the instance prediction\n                - covered_false: perturbed examples where the anchor applies and the model prediction\n                    on pertrurbed sample is NOT the same as the instance prediction\n                - labels: num_samples ints indicating whether the prediction on the perturbed sample\n                    matches (1) the label of the instance to be explained or not (0)\n                - data: Matrix with 1s and 0s indicating whether the values in a superpixel will\n                    remain unchanged (1) or will be perturbed (0), for each sample\n                - 1.0: indicates exact coverage is not computed for this algorithm\n                - anchor[0]: position of anchor in the batch request\n            Otherwise, a list containing the data matrix only is returned.\n        \"\"\"\n\n        if compute_labels:\n            raw_data, data = self.perturbation(anchor[1], num_samples)\n            labels = self.compare_labels(raw_data)\n            covered_true = raw_data[labels][: self.n_covered_ex]\n            covered_true = [scale_image(img) for img in covered_true]\n            covered_false = raw_data[np.logical_not(labels)][: self.n_covered_ex]\n            covered_false = [scale_image(img) for img in covered_false]\n            # coverage set to -1.0 as we can't compute 'true'coverage for this model\n\n            return [covered_true, covered_false, labels.astype(int), data, -1.0, anchor[0]]  # type: ignore\n\n        else:\n            data = self._choose_superpixels(num_samples)\n            data[:, anchor[1]] = 1  # superpixels in candidate anchor are not perturbed\n\n            return [data]\n\n    def compare_labels(self, samples: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Compute the agreement between a classifier prediction on an instance to be explained\n        and the prediction on a set of samples which have a subset of perturbed superpixels.\n\n        Parameters\n        ----------\n        samples\n            Samples whose labels are to be compared with the instance label.\n\n        Returns\n        -------\n            A boolean array indicating whether the prediction was the same as the instance label.\n        \"\"\"\n\n        return self.predictor(samples) == self.instance_label\n\n    def _choose_superpixels(\n        self, num_samples: int, p_sample: float = 0.5\n    ) -> np.ndarray:\n        \"\"\"\n        Generates a binary mask of dimension [num_samples, M] where M is the number of\n        image superpixels (segments).\n\n        Parameters\n        ----------\n        num_samples\n            Number of perturbed images to be generated\n        p_sample:\n            The probability that a superpixel is perturbed\n\n        Returns\n        -------\n        data\n            Binary 2D mask, where each non-zero entry in a row indicates that\n            the values of the particular image segment will not be perturbed.\n        \"\"\"\n\n        n_features = len(self.segment_labels)\n        data = np.random.choice(\n            [0, 1], num_samples * n_features, p=[p_sample, 1 - p_sample]\n        )\n        data = data.reshape((num_samples, n_features))\n\n        return data\n\n    def perturbation(\n        self, anchor: tuple, num_samples: int\n    ) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Perturbs an image by altering the values of selected superpixels. If a dataset of image\n        backgrounds is provided to the explainer, then the superpixels are replaced with the\n        equivalent superpixels from the background image. Otherwise, the superpixels are replaced\n        by their average value.\n\n        Parameters\n        ----------\n        anchor:\n            Contains the superpixels whose values are not going to be perturbed.\n        num_samples:\n            Number of perturbed samples to be returned.\n\n        Returns\n        -------\n        imgs\n            A [num_samples, H, W, C] array of perturbed images.\n        segments_mask\n            A [num_samples, M] binary mask, where M is the number of image superpixels\n            segments. 1 indicates the values in that particular superpixels are not\n            perturbed.\n        \"\"\"\n\n        image = self.image\n        segments = self.segments\n\n        # choose superpixels to be perturbed\n        segments_mask = self._choose_superpixels(num_samples, p_sample=self.p_sample)\n        segments_mask[:, anchor] = 1\n\n        # for each sample, need to sample one of the background images if provided\n        if self.images_background:\n            backgrounds = np.random.choice(\n                range(len(self.images_background)),\n                segments_mask.shape[0],\n                replace=True,\n            )\n            segments_mask = np.hstack((segments_mask, backgrounds.reshape(-1, 1)))\n        else:\n            backgrounds = [None] * segments_mask.shape[0]\n            # create fudged image where the pixel value in each superpixel is set to the\n            # average over the superpixel for each channel\n            fudged_image = image.copy()\n            n_channels = image.shape[-1]\n            for x in np.unique(segments):\n                fudged_image[segments == x] = [\n                    np.mean(image[segments == x][:, i]) for i in range(n_channels)\n                ]\n\n        pert_imgs = []\n        for mask, background_idx in zip(segments_mask, backgrounds):\n            temp = copy.deepcopy(image)\n            to_perturb = np.where(mask == 0)[0]\n            # create mask for each superpixel not present in the sample\n            mask = np.zeros(segments.shape).astype(bool)\n            for superpixel in to_perturb:\n                mask[segments == superpixel] = True\n            if background_idx:\n                # replace values with those of background image\n                # TODO: Could images_background be None herre?\n                temp[mask] = self.images_background[background_idx][mask]\n            else:\n                # ... or with the averaged superpixel value\n                # TODO: Where is fudged_image defined?\n                temp[mask] = fudged_image[mask]\n            pert_imgs.append(temp)\n\n        return np.array(pert_imgs), segments_mask\n\n    def generate_superpixels(self, image: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Generates superpixels from (i.e., segments) an image.\n\n        Parameters\n        ----------\n        image\n            A grayscale or RGB image.\n\n        Returns\n        -------\n            A [H, W] array of integers. Each integer is a segment (superpixel) label.\n        \"\"\"\n\n        image_preproc = self._preprocess_img(image)\n\n        return self.segmentation_fn(image_preproc)\n\n    def _preprocess_img(self, image: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Applies necessary transformations to the image prior to segmentation.\n\n        Parameters\n        ----------\n        image\n            A grayscale or RGB image.\n\n        Returns\n        -------\n            A preprocessed image.\n        \"\"\"\n\n        # Grayscale images are repeated across channels\n        if not self.custom_segmentation and image.shape[-1] == 1:\n            image_preproc = np.repeat(image, 3, axis=2)\n        else:\n            image_preproc = image.copy()\n\n        return image_preproc\n\n\nclass AnchorImage(Explainer):\n    def __init__(self, predictor: Callable, image_shape: tuple, segmentation_fn: Any = 'slic',\n",
        "target_code_len": 10488,
        "diff_format": "@@ -24,4 +24,280 @@\n \n+def scale_image(image: np.ndarray, scale: tuple = (0, 255)) -> np.ndarray:\n+    \"\"\"\n+    Scales an image in a specified range.\n+\n+    Parameters\n+    ----------\n+    image\n+        Image to be scale.\n+    scale\n+        The scaling interval.\n+\n+    Returns\n+    -------\n+    img_scaled\n+        Scaled image.\n+    \"\"\"\n+\n+    img_max, img_min = image.max(), image.min()\n+    img_std = (image - img_min) / (img_max - img_min)\n+    img_scaled = img_std * (scale[1] - scale[0]) + scale[0]\n+\n+    return img_scaled\n+\n+\n+class AnchorImageSampler:\n+    def __init__(\n+        self,\n+        predictor: Callable,\n+        segmentation_fn: Callable,\n+        custom_segmentation: bool,\n+        image: np.ndarray,\n+        images_background: np.ndarray = None,\n+        p_sample: float = 0.5,\n+        n_covered_ex: int = 10,\n+    ):\n+        \"\"\"\n+        Initialize anchor image sampler.\n+\n+        Parameters\n+        ----------\n+        predictor\n+            A callable that takes a tensor of N data points as inputs and returns N outputs.\n+        segmentation_fn\n+            Function used to segment the images.\n+        image\n+            Image to be explained.\n+        images_background\n+            Images to overlay superpixels on.\n+        p_sample\n+            Probability for a pixel to be represented by the average value of its superpixel.\n+        n_covered_ex\n+            How many examples where anchors apply to store for each anchor sampled during search\n+            (both examples where prediction on samples agrees/disagrees with desired_label are stored).\n+        \"\"\"\n+        self.predictor = predictor\n+        self.segmentation_fn = segmentation_fn\n+        self.custom_segmentation = custom_segmentation\n+        self.image = image\n+        self.images_background = images_background\n+        self.n_covered_ex = n_covered_ex\n+        self.p_sample = p_sample\n+        self.segments = self.generate_superpixels(image)\n+        self.segment_labels = list(np.unique(self.segments))\n+        self.instance_label = self.predictor(image[np.newaxis, ...])[0]\n+\n+    def __call__(\n+        self, anchor: Tuple[int, tuple], num_samples: int, compute_labels: bool = True\n+    ) -> List[Union[np.ndarray, float, int]]:\n+        \"\"\"\n+        Sample images from a perturbation distribution by masking randomly chosen superpixels\n+        from the original image and replacing them with pixel values from superimposed images\n+        if background images are provided to the explainer. Otherwise, the superpixels from the\n+        original image are replaced with their average values.\n+\n+        Parameters\n+        ----------\n+        anchor\n+            int: order of anchor in the batch\n+            tuple: features (= superpixels) present in the proposed anchor\n+        num_samples\n+            Number of samples used\n+        compute_labels\n+            If True, an array of comparisons between predictions on perturbed samples and\n+            instance to be explained is returned.\n+\n+        Returns\n+        -------\n+            If compute_labels=True, a list containing the following is returned:\n+                - covered_true: perturbed examples where the anchor applies and the model prediction\n+                    on perturbed is the same as the instance prediction\n+                - covered_false: perturbed examples where the anchor applies and the model prediction\n+                    on pertrurbed sample is NOT the same as the instance prediction\n+                - labels: num_samples ints indicating whether the prediction on the perturbed sample\n+                    matches (1) the label of the instance to be explained or not (0)\n+                - data: Matrix with 1s and 0s indicating whether the values in a superpixel will\n+                    remain unchanged (1) or will be perturbed (0), for each sample\n+                - 1.0: indicates exact coverage is not computed for this algorithm\n+                - anchor[0]: position of anchor in the batch request\n+            Otherwise, a list containing the data matrix only is returned.\n+        \"\"\"\n+\n+        if compute_labels:\n+            raw_data, data = self.perturbation(anchor[1], num_samples)\n+            labels = self.compare_labels(raw_data)\n+            covered_true = raw_data[labels][: self.n_covered_ex]\n+            covered_true = [scale_image(img) for img in covered_true]\n+            covered_false = raw_data[np.logical_not(labels)][: self.n_covered_ex]\n+            covered_false = [scale_image(img) for img in covered_false]\n+            # coverage set to -1.0 as we can't compute 'true'coverage for this model\n+\n+            return [covered_true, covered_false, labels.astype(int), data, -1.0, anchor[0]]  # type: ignore\n+\n+        else:\n+            data = self._choose_superpixels(num_samples)\n+            data[:, anchor[1]] = 1  # superpixels in candidate anchor are not perturbed\n+\n+            return [data]\n+\n+    def compare_labels(self, samples: np.ndarray) -> np.ndarray:\n+        \"\"\"\n+        Compute the agreement between a classifier prediction on an instance to be explained\n+        and the prediction on a set of samples which have a subset of perturbed superpixels.\n+\n+        Parameters\n+        ----------\n+        samples\n+            Samples whose labels are to be compared with the instance label.\n+\n+        Returns\n+        -------\n+            A boolean array indicating whether the prediction was the same as the instance label.\n+        \"\"\"\n+\n+        return self.predictor(samples) == self.instance_label\n+\n+    def _choose_superpixels(\n+        self, num_samples: int, p_sample: float = 0.5\n+    ) -> np.ndarray:\n+        \"\"\"\n+        Generates a binary mask of dimension [num_samples, M] where M is the number of\n+        image superpixels (segments).\n+\n+        Parameters\n+        ----------\n+        num_samples\n+            Number of perturbed images to be generated\n+        p_sample:\n+            The probability that a superpixel is perturbed\n+\n+        Returns\n+        -------\n+        data\n+            Binary 2D mask, where each non-zero entry in a row indicates that\n+            the values of the particular image segment will not be perturbed.\n+        \"\"\"\n+\n+        n_features = len(self.segment_labels)\n+        data = np.random.choice(\n+            [0, 1], num_samples * n_features, p=[p_sample, 1 - p_sample]\n+        )\n+        data = data.reshape((num_samples, n_features))\n+\n+        return data\n+\n+    def perturbation(\n+        self, anchor: tuple, num_samples: int\n+    ) -> Tuple[np.ndarray, np.ndarray]:\n+        \"\"\"\n+        Perturbs an image by altering the values of selected superpixels. If a dataset of image\n+        backgrounds is provided to the explainer, then the superpixels are replaced with the\n+        equivalent superpixels from the background image. Otherwise, the superpixels are replaced\n+        by their average value.\n+\n+        Parameters\n+        ----------\n+        anchor:\n+            Contains the superpixels whose values are not going to be perturbed.\n+        num_samples:\n+            Number of perturbed samples to be returned.\n+\n+        Returns\n+        -------\n+        imgs\n+            A [num_samples, H, W, C] array of perturbed images.\n+        segments_mask\n+            A [num_samples, M] binary mask, where M is the number of image superpixels\n+            segments. 1 indicates the values in that particular superpixels are not\n+            perturbed.\n+        \"\"\"\n+\n+        image = self.image\n+        segments = self.segments\n+\n+        # choose superpixels to be perturbed\n+        segments_mask = self._choose_superpixels(num_samples, p_sample=self.p_sample)\n+        segments_mask[:, anchor] = 1\n+\n+        # for each sample, need to sample one of the background images if provided\n+        if self.images_background:\n+            backgrounds = np.random.choice(\n+                range(len(self.images_background)),\n+                segments_mask.shape[0],\n+                replace=True,\n+            )\n+            segments_mask = np.hstack((segments_mask, backgrounds.reshape(-1, 1)))\n+        else:\n+            backgrounds = [None] * segments_mask.shape[0]\n+            # create fudged image where the pixel value in each superpixel is set to the\n+            # average over the superpixel for each channel\n+            fudged_image = image.copy()\n+            n_channels = image.shape[-1]\n+            for x in np.unique(segments):\n+                fudged_image[segments == x] = [\n+                    np.mean(image[segments == x][:, i]) for i in range(n_channels)\n+                ]\n+\n+        pert_imgs = []\n+        for mask, background_idx in zip(segments_mask, backgrounds):\n+            temp = copy.deepcopy(image)\n+            to_perturb = np.where(mask == 0)[0]\n+            # create mask for each superpixel not present in the sample\n+            mask = np.zeros(segments.shape).astype(bool)\n+            for superpixel in to_perturb:\n+                mask[segments == superpixel] = True\n+            if background_idx:\n+                # replace values with those of background image\n+                # TODO: Could images_background be None herre?\n+                temp[mask] = self.images_background[background_idx][mask]\n+            else:\n+                # ... or with the averaged superpixel value\n+                # TODO: Where is fudged_image defined?\n+                temp[mask] = fudged_image[mask]\n+            pert_imgs.append(temp)\n+\n+        return np.array(pert_imgs), segments_mask\n+\n+    def generate_superpixels(self, image: np.ndarray) -> np.ndarray:\n+        \"\"\"\n+        Generates superpixels from (i.e., segments) an image.\n+\n+        Parameters\n+        ----------\n+        image\n+            A grayscale or RGB image.\n+\n+        Returns\n+        -------\n+            A [H, W] array of integers. Each integer is a segment (superpixel) label.\n+        \"\"\"\n+\n+        image_preproc = self._preprocess_img(image)\n+\n+        return self.segmentation_fn(image_preproc)\n+\n+    def _preprocess_img(self, image: np.ndarray) -> np.ndarray:\n+        \"\"\"\n+        Applies necessary transformations to the image prior to segmentation.\n+\n+        Parameters\n+        ----------\n+        image\n+            A grayscale or RGB image.\n+\n+        Returns\n+        -------\n+            A preprocessed image.\n+        \"\"\"\n+\n+        # Grayscale images are repeated across channels\n+        if not self.custom_segmentation and image.shape[-1] == 1:\n+            image_preproc = np.repeat(image, 3, axis=2)\n+        else:\n+            image_preproc = image.copy()\n+\n+        return image_preproc\n+\n+\n class AnchorImage(Explainer):\n-\n     def __init__(self, predictor: Callable, image_shape: tuple, segmentation_fn: Any = 'slic',\n",
        "source_code_with_indent": "\nclass AnchorImage(Explainer):\n\n    <IND>def __init__(self, predictor: Callable, image_shape: tuple, segmentation_fn: Any = 'slic',\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\ndef scale_image(image: np.ndarray, scale: tuple = (0, 255)) -> np.ndarray:\n    <IND>\"\"\"\n    Scales an image in a specified range.\n\n    Parameters\n    ----------\n    image\n        Image to be scale.\n    scale\n        The scaling interval.\n\n    Returns\n    -------\n    img_scaled\n        Scaled image.\n    \"\"\"\n\n    img_max, img_min = image.max(), image.min()\n    img_std = (image - img_min) / (img_max - img_min)\n    img_scaled = img_std * (scale[1] - scale[0]) + scale[0]\n\n    return img_scaled\n\n\n<DED>class AnchorImageSampler:\n    <IND>def __init__(\n        self,\n        predictor: Callable,\n        segmentation_fn: Callable,\n        custom_segmentation: bool,\n        image: np.ndarray,\n        images_background: np.ndarray = None,\n        p_sample: float = 0.5,\n        n_covered_ex: int = 10,\n    ):\n        <IND>\"\"\"\n        Initialize anchor image sampler.\n\n        Parameters\n        ----------\n        predictor\n            A callable that takes a tensor of N data points as inputs and returns N outputs.\n        segmentation_fn\n            Function used to segment the images.\n        image\n            Image to be explained.\n        images_background\n            Images to overlay superpixels on.\n        p_sample\n            Probability for a pixel to be represented by the average value of its superpixel.\n        n_covered_ex\n            How many examples where anchors apply to store for each anchor sampled during search\n            (both examples where prediction on samples agrees/disagrees with desired_label are stored).\n        \"\"\"\n        self.predictor = predictor\n        self.segmentation_fn = segmentation_fn\n        self.custom_segmentation = custom_segmentation\n        self.image = image\n        self.images_background = images_background\n        self.n_covered_ex = n_covered_ex\n        self.p_sample = p_sample\n        self.segments = self.generate_superpixels(image)\n        self.segment_labels = list(np.unique(self.segments))\n        self.instance_label = self.predictor(image[np.newaxis, ...])[0]\n\n    <DED>def __call__(\n        self, anchor: Tuple[int, tuple], num_samples: int, compute_labels: bool = True\n    ) -> List[Union[np.ndarray, float, int]]:\n        <IND>\"\"\"\n        Sample images from a perturbation distribution by masking randomly chosen superpixels\n        from the original image and replacing them with pixel values from superimposed images\n        if background images are provided to the explainer. Otherwise, the superpixels from the\n        original image are replaced with their average values.\n\n        Parameters\n        ----------\n        anchor\n            int: order of anchor in the batch\n            tuple: features (= superpixels) present in the proposed anchor\n        num_samples\n            Number of samples used\n        compute_labels\n            If True, an array of comparisons between predictions on perturbed samples and\n            instance to be explained is returned.\n\n        Returns\n        -------\n            If compute_labels=True, a list containing the following is returned:\n                - covered_true: perturbed examples where the anchor applies and the model prediction\n                    on perturbed is the same as the instance prediction\n                - covered_false: perturbed examples where the anchor applies and the model prediction\n                    on pertrurbed sample is NOT the same as the instance prediction\n                - labels: num_samples ints indicating whether the prediction on the perturbed sample\n                    matches (1) the label of the instance to be explained or not (0)\n                - data: Matrix with 1s and 0s indicating whether the values in a superpixel will\n                    remain unchanged (1) or will be perturbed (0), for each sample\n                - 1.0: indicates exact coverage is not computed for this algorithm\n                - anchor[0]: position of anchor in the batch request\n            Otherwise, a list containing the data matrix only is returned.\n        \"\"\"\n\n        if compute_labels:\n            <IND>raw_data, data = self.perturbation(anchor[1], num_samples)\n            labels = self.compare_labels(raw_data)\n            covered_true = raw_data[labels][: self.n_covered_ex]\n            covered_true = [scale_image(img) for img in covered_true]\n            covered_false = raw_data[np.logical_not(labels)][: self.n_covered_ex]\n            covered_false = [scale_image(img) for img in covered_false]\n            # coverage set to -1.0 as we can't compute 'true'coverage for this model\n\n            return [covered_true, covered_false, labels.astype(int), data, -1.0, anchor[0]]  # type: ignore\n\n        <DED>else:\n            <IND>data = self._choose_superpixels(num_samples)\n            data[:, anchor[1]] = 1  # superpixels in candidate anchor are not perturbed\n\n            return [data]\n\n    <DED><DED>def compare_labels(self, samples: np.ndarray) -> np.ndarray:\n        <IND>\"\"\"\n        Compute the agreement between a classifier prediction on an instance to be explained\n        and the prediction on a set of samples which have a subset of perturbed superpixels.\n\n        Parameters\n        ----------\n        samples\n            Samples whose labels are to be compared with the instance label.\n\n        Returns\n        -------\n            A boolean array indicating whether the prediction was the same as the instance label.\n        \"\"\"\n\n        return self.predictor(samples) == self.instance_label\n\n    <DED>def _choose_superpixels(\n        self, num_samples: int, p_sample: float = 0.5\n    ) -> np.ndarray:\n        <IND>\"\"\"\n        Generates a binary mask of dimension [num_samples, M] where M is the number of\n        image superpixels (segments).\n\n        Parameters\n        ----------\n        num_samples\n            Number of perturbed images to be generated\n        p_sample:\n            The probability that a superpixel is perturbed\n\n        Returns\n        -------\n        data\n            Binary 2D mask, where each non-zero entry in a row indicates that\n            the values of the particular image segment will not be perturbed.\n        \"\"\"\n\n        n_features = len(self.segment_labels)\n        data = np.random.choice(\n            [0, 1], num_samples * n_features, p=[p_sample, 1 - p_sample]\n        )\n        data = data.reshape((num_samples, n_features))\n\n        return data\n\n    <DED>def perturbation(\n        self, anchor: tuple, num_samples: int\n    ) -> Tuple[np.ndarray, np.ndarray]:\n        <IND>\"\"\"\n        Perturbs an image by altering the values of selected superpixels. If a dataset of image\n        backgrounds is provided to the explainer, then the superpixels are replaced with the\n        equivalent superpixels from the background image. Otherwise, the superpixels are replaced\n        by their average value.\n\n        Parameters\n        ----------\n        anchor:\n            Contains the superpixels whose values are not going to be perturbed.\n        num_samples:\n            Number of perturbed samples to be returned.\n\n        Returns\n        -------\n        imgs\n            A [num_samples, H, W, C] array of perturbed images.\n        segments_mask\n            A [num_samples, M] binary mask, where M is the number of image superpixels\n            segments. 1 indicates the values in that particular superpixels are not\n            perturbed.\n        \"\"\"\n\n        image = self.image\n        segments = self.segments\n\n        # choose superpixels to be perturbed\n        segments_mask = self._choose_superpixels(num_samples, p_sample=self.p_sample)\n        segments_mask[:, anchor] = 1\n\n        # for each sample, need to sample one of the background images if provided\n        if self.images_background:\n            <IND>backgrounds = np.random.choice(\n                range(len(self.images_background)),\n                segments_mask.shape[0],\n                replace=True,\n            )\n            segments_mask = np.hstack((segments_mask, backgrounds.reshape(-1, 1)))\n        <DED>else:\n            <IND>backgrounds = [None] * segments_mask.shape[0]\n            # create fudged image where the pixel value in each superpixel is set to the\n            # average over the superpixel for each channel\n            fudged_image = image.copy()\n            n_channels = image.shape[-1]\n            for x in np.unique(segments):\n                <IND>fudged_image[segments == x] = [\n                    np.mean(image[segments == x][:, i]) for i in range(n_channels)\n                ]\n\n        <DED><DED>pert_imgs = []\n        for mask, background_idx in zip(segments_mask, backgrounds):\n            <IND>temp = copy.deepcopy(image)\n            to_perturb = np.where(mask == 0)[0]\n            # create mask for each superpixel not present in the sample\n            mask = np.zeros(segments.shape).astype(bool)\n            for superpixel in to_perturb:\n                <IND>mask[segments == superpixel] = True\n            <DED>if background_idx:\n                # replace values with those of background image\n                # TODO: Could images_background be None herre?\n                <IND>temp[mask] = self.images_background[background_idx][mask]\n            <DED>else:\n                # ... or with the averaged superpixel value\n                # TODO: Where is fudged_image defined?\n                <IND>temp[mask] = fudged_image[mask]\n            <DED>pert_imgs.append(temp)\n\n        <DED>return np.array(pert_imgs), segments_mask\n\n    <DED>def generate_superpixels(self, image: np.ndarray) -> np.ndarray:\n        <IND>\"\"\"\n        Generates superpixels from (i.e., segments) an image.\n\n        Parameters\n        ----------\n        image\n            A grayscale or RGB image.\n\n        Returns\n        -------\n            A [H, W] array of integers. Each integer is a segment (superpixel) label.\n        \"\"\"\n\n        image_preproc = self._preprocess_img(image)\n\n        return self.segmentation_fn(image_preproc)\n\n    <DED>def _preprocess_img(self, image: np.ndarray) -> np.ndarray:\n        <IND>\"\"\"\n        Applies necessary transformations to the image prior to segmentation.\n\n        Parameters\n        ----------\n        image\n            A grayscale or RGB image.\n\n        Returns\n        -------\n            A preprocessed image.\n        \"\"\"\n\n        # Grayscale images are repeated across channels\n        if not self.custom_segmentation and image.shape[-1] == 1:\n            <IND>image_preproc = np.repeat(image, 3, axis=2)\n        <DED>else:\n            <IND>image_preproc = image.copy()\n\n        <DED>return image_preproc\n\n\n<DED><DED>class AnchorImage(Explainer):\n    <IND>def __init__(self, predictor: Callable, image_shape: tuple, segmentation_fn: Any = 'slic',\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "        self.images_background = images_background\n        # [H, W] int array; each int is a superpixel labels\n        self.segments = None  # type: np.ndarray\n        self.segment_labels = None  # type: list\n        self.image = None  # type: np.ndarray\n        # a superpixel is perturbed with prob 1 - p_sample\n",
        "source_code_len": 314,
        "target_code": "        self.images_background = images_background\n        # a superpixel is perturbed with prob 1 - p_sample\n",
        "target_code_len": 110,
        "diff_format": "@@ -83,6 +359,2 @@\n         self.images_background = images_background\n-        # [H, W] int array; each int is a superpixel labels\n-        self.segments = None  # type: np.ndarray\n-        self.segment_labels = None  # type: list\n-        self.image = None  # type: np.ndarray\n         # a superpixel is perturbed with prob 1 - p_sample\n",
        "source_code_with_indent": "        <DED>self.images_background = images_background\n        # [H, W] int array; each int is a superpixel labels\n        self.segments = None  # type: np.ndarray\n        self.segment_labels = None  # type: list\n        self.image = None  # type: np.ndarray\n        # a superpixel is perturbed with prob 1 - p_sample\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        <DED>self.images_background = images_background\n        # a superpixel is perturbed with prob 1 - p_sample\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "        return image_preproc\n\n    def _choose_superpixels(self, num_samples: int, p_sample: float = 0.5) -> np.ndarray:\n        \"\"\"\n        Generates a binary mask of dimension [num_samples, M] where M is the number of\n        image superpixels (segments).\n\n        Parameters\n        ----------\n        num_samples\n            Number of perturbed images to be generated\n        p_sample:\n            The probability that a superpixel is perturbed\n\n        Returns\n        -------\n        data\n            Binary 2D mask, where each non-zero entry in a row indicates that\n            the values of the particular image segment will not be perturbed.\n        \"\"\"\n\n        n_features = len(self.segment_labels)\n        data = np.random.choice([0, 1], num_samples * n_features, p=[p_sample, 1 - p_sample])\n        data = data.reshape((num_samples, n_features))\n\n        return data\n\n    def sampler(self, anchor: Tuple[int, tuple], num_samples: int, compute_labels: bool = True) -> \\\n            Union[List[Union[np.ndarray, np.ndarray, np.ndarray, np.ndarray, float, int]], List[np.ndarray]]:\n        \"\"\"\n        Sample images from a perturbation distribution by masking randomly chosen superpixels\n        from the original image and replacing them with pixel values from superimposed images\n        if background images are provided to the explainer. Otherwise, the superpixels from the\n        original image are replaced with their average values.\n\n        Parameters\n        ----------\n        anchor\n            int: order of anchor in the batch\n            tuple: features (= superpixels) present in the proposed anchor\n        num_samples\n            Number of samples used\n        compute_labels\n            If True, an array of comparisons between predictions on perturbed samples and\n            instance to be explained is returned.\n\n        Returns\n        -------\n            If compute_labels=True, a list containing the following is returned:\n                - covered_true: perturbed examples where the anchor applies and the model prediction\n                    on perturbed is the same as the instance prediction\n                - covered_false: perturbed examples where the anchor applies and the model prediction\n                    on pertrurbed sample is NOT the same as the instance prediction\n                - labels: num_samples ints indicating whether the prediction on the perturbed sample\n                    matches (1) the label of the instance to be explained or not (0)\n                - data: Matrix with 1s and 0s indicating whether the values in a superpixel will\n                    remain unchanged (1) or will be perturbed (0), for each sample\n                - 1.0: indicates exact coverage is not computed for this algorithm\n                - anchor[0]: position of anchor in the batch request\n            Otherwise, a list containing the data matrix only is returned.\n        \"\"\"\n\n        if compute_labels:\n            raw_data, data = self.perturbation(anchor[1], num_samples)\n            labels = self.compare_labels(raw_data)\n            covered_true = raw_data[labels][:self.n_covered_ex]\n            covered_true = [self._scale(img) for img in covered_true]\n            covered_false = raw_data[np.logical_not(labels)][:self.n_covered_ex]\n            covered_false = [self._scale(img) for img in covered_false]\n            # coverage set to -1.0 as we can't compute 'true'coverage for this model\n\n            return [covered_true, covered_false, labels.astype(int), data, -1.0, anchor[0]]  # type: ignore\n\n        else:\n            data = self._choose_superpixels(num_samples)\n            data[:, anchor[1]] = 1  # superpixels in candidate anchor are not perturbed\n\n            return [data]\n\n    def perturbation(self, anchor: tuple, num_samples: int) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Perturbs an image by altering the values of selected superpixels. If a dataset of image\n        backgrounds is provided to the explainer, then the superpixels are replaced with the\n        equivalent superpixels from the background image. Otherwise, the superpixels are replaced\n        by their average value.\n\n        Parameters\n        ----------\n        anchor:\n            Contains the superpixels whose values are not going to be perturbed.\n        num_samples:\n            Number of perturbed samples to be returned.\n\n        Returns\n        -------\n        imgs\n            A [num_samples, H, W, C] array of perturbed images.\n        segments_mask\n            A [num_samples, M] binary mask, where M is the number of image superpixels\n            segments. 1 indicates the values in that particular superpixels are not\n            perturbed.\n        \"\"\"\n\n        image = self.image\n        segments = self.segments\n\n        # choose superpixels to be perturbed\n        segments_mask = self._choose_superpixels(num_samples, p_sample=self.p_sample)\n        segments_mask[:, anchor] = 1\n\n        # for each sample, need to sample one of the background images if provided\n        if self.images_background:\n            backgrounds = np.random.choice(\n                range(len(self.images_background)),\n                segments_mask.shape[0],\n                replace=True,\n            )\n            segments_mask = np.hstack((segments_mask, backgrounds.reshape(-1, 1)))\n        else:\n            backgrounds = [None] * segments_mask.shape[0]\n            # create fudged image where the pixel value in each superpixel is set to the\n            # average over the superpixel for each channel\n            fudged_image = image.copy()\n            n_channels = image.shape[-1]\n            for x in np.unique(segments):\n                fudged_image[segments == x] = [np.mean(image[segments == x][:, i]) for i in range(n_channels)]\n\n        pert_imgs = []\n        for mask, background_idx in zip(segments_mask, backgrounds):\n            temp = copy.deepcopy(image)\n            to_perturb = np.where(mask == 0)[0]\n            # create mask for each superpixel not present in the sample\n            mask = np.zeros(segments.shape).astype(bool)\n            for superpixel in to_perturb:\n                mask[segments == superpixel] = True\n            if background_idx:\n                # replace values with those of background image\n                temp[mask] = self.images_background[background_idx][mask]\n            else:\n                # ... or with the averaged superpixel value\n                temp[mask] = fudged_image[mask]\n            pert_imgs.append(temp)\n\n        return np.array(pert_imgs), segments_mask\n\n    def compare_labels(self, samples: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Compute the agreement between a classifier prediction on an instance to be explained\n        and the prediction on a set of samples which have a subset of perturbed superpixels.\n\n        Parameters\n        ----------\n        samples\n            Samples whose labels are to be compared with the instance label.\n\n        Returns\n        -------\n            A boolean array indicating whether the prediction was the same as the instance label.\n        \"\"\"\n\n        return self.predictor(samples) == self.instance_label\n\n",
        "source_code_len": 7170,
        "target_code": "        return image_preproc\n\n",
        "target_code_len": 30,
        "diff_format": "@@ -143,162 +415,2 @@\n         return image_preproc\n-\n-    def _choose_superpixels(self, num_samples: int, p_sample: float = 0.5) -> np.ndarray:\n-        \"\"\"\n-        Generates a binary mask of dimension [num_samples, M] where M is the number of\n-        image superpixels (segments).\n-\n-        Parameters\n-        ----------\n-        num_samples\n-            Number of perturbed images to be generated\n-        p_sample:\n-            The probability that a superpixel is perturbed\n-\n-        Returns\n-        -------\n-        data\n-            Binary 2D mask, where each non-zero entry in a row indicates that\n-            the values of the particular image segment will not be perturbed.\n-        \"\"\"\n-\n-        n_features = len(self.segment_labels)\n-        data = np.random.choice([0, 1], num_samples * n_features, p=[p_sample, 1 - p_sample])\n-        data = data.reshape((num_samples, n_features))\n-\n-        return data\n-\n-    def sampler(self, anchor: Tuple[int, tuple], num_samples: int, compute_labels: bool = True) -> \\\n-            Union[List[Union[np.ndarray, np.ndarray, np.ndarray, np.ndarray, float, int]], List[np.ndarray]]:\n-        \"\"\"\n-        Sample images from a perturbation distribution by masking randomly chosen superpixels\n-        from the original image and replacing them with pixel values from superimposed images\n-        if background images are provided to the explainer. Otherwise, the superpixels from the\n-        original image are replaced with their average values.\n-\n-        Parameters\n-        ----------\n-        anchor\n-            int: order of anchor in the batch\n-            tuple: features (= superpixels) present in the proposed anchor\n-        num_samples\n-            Number of samples used\n-        compute_labels\n-            If True, an array of comparisons between predictions on perturbed samples and\n-            instance to be explained is returned.\n-\n-        Returns\n-        -------\n-            If compute_labels=True, a list containing the following is returned:\n-                - covered_true: perturbed examples where the anchor applies and the model prediction\n-                    on perturbed is the same as the instance prediction\n-                - covered_false: perturbed examples where the anchor applies and the model prediction\n-                    on pertrurbed sample is NOT the same as the instance prediction\n-                - labels: num_samples ints indicating whether the prediction on the perturbed sample\n-                    matches (1) the label of the instance to be explained or not (0)\n-                - data: Matrix with 1s and 0s indicating whether the values in a superpixel will\n-                    remain unchanged (1) or will be perturbed (0), for each sample\n-                - 1.0: indicates exact coverage is not computed for this algorithm\n-                - anchor[0]: position of anchor in the batch request\n-            Otherwise, a list containing the data matrix only is returned.\n-        \"\"\"\n-\n-        if compute_labels:\n-            raw_data, data = self.perturbation(anchor[1], num_samples)\n-            labels = self.compare_labels(raw_data)\n-            covered_true = raw_data[labels][:self.n_covered_ex]\n-            covered_true = [self._scale(img) for img in covered_true]\n-            covered_false = raw_data[np.logical_not(labels)][:self.n_covered_ex]\n-            covered_false = [self._scale(img) for img in covered_false]\n-            # coverage set to -1.0 as we can't compute 'true'coverage for this model\n-\n-            return [covered_true, covered_false, labels.astype(int), data, -1.0, anchor[0]]  # type: ignore\n-\n-        else:\n-            data = self._choose_superpixels(num_samples)\n-            data[:, anchor[1]] = 1  # superpixels in candidate anchor are not perturbed\n-\n-            return [data]\n-\n-    def perturbation(self, anchor: tuple, num_samples: int) -> Tuple[np.ndarray, np.ndarray]:\n-        \"\"\"\n-        Perturbs an image by altering the values of selected superpixels. If a dataset of image\n-        backgrounds is provided to the explainer, then the superpixels are replaced with the\n-        equivalent superpixels from the background image. Otherwise, the superpixels are replaced\n-        by their average value.\n-\n-        Parameters\n-        ----------\n-        anchor:\n-            Contains the superpixels whose values are not going to be perturbed.\n-        num_samples:\n-            Number of perturbed samples to be returned.\n-\n-        Returns\n-        -------\n-        imgs\n-            A [num_samples, H, W, C] array of perturbed images.\n-        segments_mask\n-            A [num_samples, M] binary mask, where M is the number of image superpixels\n-            segments. 1 indicates the values in that particular superpixels are not\n-            perturbed.\n-        \"\"\"\n-\n-        image = self.image\n-        segments = self.segments\n-\n-        # choose superpixels to be perturbed\n-        segments_mask = self._choose_superpixels(num_samples, p_sample=self.p_sample)\n-        segments_mask[:, anchor] = 1\n-\n-        # for each sample, need to sample one of the background images if provided\n-        if self.images_background:\n-            backgrounds = np.random.choice(\n-                range(len(self.images_background)),\n-                segments_mask.shape[0],\n-                replace=True,\n-            )\n-            segments_mask = np.hstack((segments_mask, backgrounds.reshape(-1, 1)))\n-        else:\n-            backgrounds = [None] * segments_mask.shape[0]\n-            # create fudged image where the pixel value in each superpixel is set to the\n-            # average over the superpixel for each channel\n-            fudged_image = image.copy()\n-            n_channels = image.shape[-1]\n-            for x in np.unique(segments):\n-                fudged_image[segments == x] = [np.mean(image[segments == x][:, i]) for i in range(n_channels)]\n-\n-        pert_imgs = []\n-        for mask, background_idx in zip(segments_mask, backgrounds):\n-            temp = copy.deepcopy(image)\n-            to_perturb = np.where(mask == 0)[0]\n-            # create mask for each superpixel not present in the sample\n-            mask = np.zeros(segments.shape).astype(bool)\n-            for superpixel in to_perturb:\n-                mask[segments == superpixel] = True\n-            if background_idx:\n-                # replace values with those of background image\n-                temp[mask] = self.images_background[background_idx][mask]\n-            else:\n-                # ... or with the averaged superpixel value\n-                temp[mask] = fudged_image[mask]\n-            pert_imgs.append(temp)\n-\n-        return np.array(pert_imgs), segments_mask\n-\n-    def compare_labels(self, samples: np.ndarray) -> np.ndarray:\n-        \"\"\"\n-        Compute the agreement between a classifier prediction on an instance to be explained\n-        and the prediction on a set of samples which have a subset of perturbed superpixels.\n-\n-        Parameters\n-        ----------\n-        samples\n-            Samples whose labels are to be compared with the instance label.\n-\n-        Returns\n-        -------\n-            A boolean array indicating whether the prediction was the same as the instance label.\n-        \"\"\"\n-\n-        return self.predictor(samples) == self.instance_label\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent": "        <DED>return image_preproc\n\n",
        "target_code_with_indent_exact_match": true,
        "source_code_with_indent": "        <DED>return image_preproc\n\n    <DED>def _choose_superpixels(self, num_samples: int, p_sample: float = 0.5) -> np.ndarray:\n        <IND>\"\"\"\n        Generates a binary mask of dimension [num_samples, M] where M is the number of\n        image superpixels (segments).\n\n        Parameters\n        ----------\n        num_samples\n            Number of perturbed images to be generated\n        p_sample:\n            The probability that a superpixel is perturbed\n\n        Returns\n        -------\n        data\n            Binary 2D mask, where each non-zero entry in a row indicates that\n            the values of the particular image segment will not be perturbed.\n        \"\"\"\n\n        n_features = len(self.segment_labels)\n        data = np.random.choice([0, 1], num_samples * n_features, p=[p_sample, 1 - p_sample])\n        data = data.reshape((num_samples, n_features))\n\n        return data\n\n    <DED>def sampler(self, anchor: Tuple[int, tuple], num_samples: int, compute_labels: bool = True) ->            Union[List[Union[np.ndarray, np.ndarray, np.ndarray, np.ndarray, float, int]], List[np.ndarray]]:\n        <IND>\"\"\"\n        Sample images from a perturbation distribution by masking randomly chosen superpixels\n        from the original image and replacing them with pixel values from superimposed images\n        if background images are provided to the explainer. Otherwise, the superpixels from the\n        original image are replaced with their average values.\n\n        Parameters\n        ----------\n        anchor\n            int: order of anchor in the batch\n            tuple: features (= superpixels) present in the proposed anchor\n        num_samples\n            Number of samples used\n        compute_labels\n            If True, an array of comparisons between predictions on perturbed samples and\n            instance to be explained is returned.\n\n        Returns\n        -------\n            If compute_labels=True, a list containing the following is returned:\n                - covered_true: perturbed examples where the anchor applies and the model prediction\n                    on perturbed is the same as the instance prediction\n                - covered_false: perturbed examples where the anchor applies and the model prediction\n                    on pertrurbed sample is NOT the same as the instance prediction\n                - labels: num_samples ints indicating whether the prediction on the perturbed sample\n                    matches (1) the label of the instance to be explained or not (0)\n                - data: Matrix with 1s and 0s indicating whether the values in a superpixel will\n                    remain unchanged (1) or will be perturbed (0), for each sample\n                - 1.0: indicates exact coverage is not computed for this algorithm\n                - anchor[0]: position of anchor in the batch request\n            Otherwise, a list containing the data matrix only is returned.\n        \"\"\"\n\n        if compute_labels:\n            <IND>raw_data, data = self.perturbation(anchor[1], num_samples)\n            labels = self.compare_labels(raw_data)\n            covered_true = raw_data[labels][:self.n_covered_ex]\n            covered_true = [self._scale(img) for img in covered_true]\n            covered_false = raw_data[np.logical_not(labels)][:self.n_covered_ex]\n            covered_false = [self._scale(img) for img in covered_false]\n            # coverage set to -1.0 as we can't compute 'true'coverage for this model\n\n            return [covered_true, covered_false, labels.astype(int), data, -1.0, anchor[0]]  # type: ignore\n\n        <DED>else:\n            <IND>data = self._choose_superpixels(num_samples)\n            data[:, anchor[1]] = 1  # superpixels in candidate anchor are not perturbed\n\n            return [data]\n\n    <DED><DED>def perturbation(self, anchor: tuple, num_samples: int) -> Tuple[np.ndarray, np.ndarray]:\n        <IND>\"\"\"\n        Perturbs an image by altering the values of selected superpixels. If a dataset of image\n        backgrounds is provided to the explainer, then the superpixels are replaced with the\n        equivalent superpixels from the background image. Otherwise, the superpixels are replaced\n        by their average value.\n\n        Parameters\n        ----------\n        anchor:\n            Contains the superpixels whose values are not going to be perturbed.\n        num_samples:\n            Number of perturbed samples to be returned.\n\n        Returns\n        -------\n        imgs\n            A [num_samples, H, W, C] array of perturbed images.\n        segments_mask\n            A [num_samples, M] binary mask, where M is the number of image superpixels\n            segments. 1 indicates the values in that particular superpixels are not\n            perturbed.\n        \"\"\"\n\n        image = self.image\n        segments = self.segments\n\n        # choose superpixels to be perturbed\n        segments_mask = self._choose_superpixels(num_samples, p_sample=self.p_sample)\n        segments_mask[:, anchor] = 1\n\n        # for each sample, need to sample one of the background images if provided\n        if self.images_background:\n            <IND>backgrounds = np.random.choice(\n                range(len(self.images_background)),\n                segments_mask.shape[0],\n                replace=True,\n            )\n            segments_mask = np.hstack((segments_mask, backgrounds.reshape(-1, 1)))\n        <DED>else:\n            <IND>backgrounds = [None] * segments_mask.shape[0]\n            # create fudged image where the pixel value in each superpixel is set to the\n            # average over the superpixel for each channel\n            fudged_image = image.copy()\n            n_channels = image.shape[-1]\n            for x in np.unique(segments):\n                <IND>fudged_image[segments == x] = [np.mean(image[segments == x][:, i]) for i in range(n_channels)]\n\n        <DED><DED>pert_imgs = []\n        for mask, background_idx in zip(segments_mask, backgrounds):\n            <IND>temp = copy.deepcopy(image)\n            to_perturb = np.where(mask == 0)[0]\n            # create mask for each superpixel not present in the sample\n            mask = np.zeros(segments.shape).astype(bool)\n            for superpixel in to_perturb:\n                <IND>mask[segments == superpixel] = True\n            <DED>if background_idx:\n                # replace values with those of background image\n                <IND>temp[mask] = self.images_background[background_idx][mask]\n            <DED>else:\n                # ... or with the averaged superpixel value\n                <IND>temp[mask] = fudged_image[mask]\n            <DED>pert_imgs.append(temp)\n\n        <DED>return np.array(pert_imgs), segments_mask\n\n    <DED>def compare_labels(self, samples: np.ndarray) -> np.ndarray:\n        <IND>\"\"\"\n        Compute the agreement between a classifier prediction on an instance to be explained\n        and the prediction on a set of samples which have a subset of perturbed superpixels.\n\n        Parameters\n        ----------\n        samples\n            Samples whose labels are to be compared with the instance label.\n\n        Returns\n        -------\n            A boolean array indicating whether the prediction was the same as the instance label.\n        \"\"\"\n\n        return self.predictor(samples) == self.instance_label\n\n"
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n        self.image = image\n        self.n_covered_ex = n_covered_ex\n        self.p_sample = p_sample\n        self.segments = self.generate_superpixels(image)\n        self.segment_labels = list(np.unique(self.segments))\n        self.instance_label = self.predictor(image[np.newaxis, ...])[0]\n\n",
        "source_code_len": 293,
        "target_code": "\n        sampler = AnchorImageSampler(\n            predictor=self.predictor,\n            segmentation_fn=self.segmentation_fn,\n            custom_segmentation=self.custom_segmentation,\n            image=image,\n            images_background=self.images_background,\n            p_sample=p_sample,\n            n_covered_ex=n_covered_ex,\n        )\n\n",
        "target_code_len": 345,
        "diff_format": "@@ -376,8 +487,11 @@\n \n-        self.image = image\n-        self.n_covered_ex = n_covered_ex\n-        self.p_sample = p_sample\n-        self.segments = self.generate_superpixels(image)\n-        self.segment_labels = list(np.unique(self.segments))\n-        self.instance_label = self.predictor(image[np.newaxis, ...])[0]\n+        sampler = AnchorImageSampler(\n+            predictor=self.predictor,\n+            segmentation_fn=self.segmentation_fn,\n+            custom_segmentation=self.custom_segmentation,\n+            image=image,\n+            images_background=self.images_background,\n+            p_sample=p_sample,\n+            n_covered_ex=n_covered_ex,\n+        )\n \n",
        "source_code_with_indent": "\n        <DED>self.image = image\n        self.n_covered_ex = n_covered_ex\n        self.p_sample = p_sample\n        self.segments = self.generate_superpixels(image)\n        self.segment_labels = list(np.unique(self.segments))\n        self.instance_label = self.predictor(image[np.newaxis, ...])[0]\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n        <DED>sampler = AnchorImageSampler(\n            predictor=self.predictor,\n            segmentation_fn=self.segmentation_fn,\n            custom_segmentation=self.custom_segmentation,\n            image=image,\n            images_background=self.images_background,\n            p_sample=p_sample,\n            n_covered_ex=n_covered_ex,\n        )\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        mab = AnchorBaseBeam(\n            samplers=[self.sampler],\n            sample_cache_size=binary_cache_size,\n",
        "source_code_len": 116,
        "target_code": "        mab = AnchorBaseBeam(\n            samplers=[sampler],\n            sample_cache_size=binary_cache_size,\n",
        "target_code_len": 111,
        "diff_format": "@@ -385,3 +499,3 @@\n         mab = AnchorBaseBeam(\n-            samplers=[self.sampler],\n+            samplers=[sampler],\n             sample_cache_size=binary_cache_size,\n",
        "source_code_with_indent": "        mab = AnchorBaseBeam(\n            samplers=[self.sampler],\n            sample_cache_size=binary_cache_size,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        mab = AnchorBaseBeam(\n            samplers=[sampler],\n            sample_cache_size=binary_cache_size,\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        )  # type: Any\n        self.mab = mab\n\n        return self.build_explanation(image, result, self.instance_label, params)\n\n    def build_explanation(self, image: np.ndarray, result: dict, predicted_label: int, params: dict) -> Explanation:\n        \"\"\"\n",
        "source_code_len": 259,
        "target_code": "        )  # type: Any\n\n        return self.build_explanation(\n            image, result, sampler.instance_label, params, sampler\n        )\n\n    def build_explanation(\n        self,\n        image: np.ndarray,\n        result: dict,\n        predicted_label: int,\n        params: dict,\n        sampler: AnchorImageSampler,\n    ) -> Explanation:\n        \"\"\"\n",
        "target_code_len": 354,
        "diff_format": "@@ -403,7 +517,15 @@\n         )  # type: Any\n-        self.mab = mab\n-\n-        return self.build_explanation(image, result, self.instance_label, params)\n-\n-    def build_explanation(self, image: np.ndarray, result: dict, predicted_label: int, params: dict) -> Explanation:\n+\n+        return self.build_explanation(\n+            image, result, sampler.instance_label, params, sampler\n+        )\n+\n+    def build_explanation(\n+        self,\n+        image: np.ndarray,\n+        result: dict,\n+        predicted_label: int,\n+        params: dict,\n+        sampler: AnchorImageSampler,\n+    ) -> Explanation:\n         \"\"\"\n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "        )  # type: Any\n        self.mab = mab\n\n        return self.build_explanation(image, result, self.instance_label, params)\n\n    <DED>def build_explanation(self, image: np.ndarray, result: dict, predicted_label: int, params: dict) -> Explanation:\n        <IND>",
        "target_code_with_indent": "        )  # type: Any\n\n        return self.build_explanation(\n            image, result, sampler.instance_label, params, sampler\n        )\n\n    <DED>def build_explanation(\n        self,\n        image: np.ndarray,\n        result: dict,\n        predicted_label: int,\n        params: dict,\n        sampler: AnchorImageSampler,\n    ) -> Explanation:\n        <IND>"
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        # overlay image with anchor mask\n        anchor = self.overlay_mask(image, self.segments, result['feature'])\n        exp = AnchorExplanation('image', result)\n",
        "source_code_len": 166,
        "target_code": "        # overlay image with anchor mask\n        anchor = self.overlay_mask(image, sampler.segments, result['feature'])\n        exp = AnchorExplanation('image', result)\n",
        "target_code_len": 169,
        "diff_format": "@@ -429,3 +551,3 @@\n         # overlay image with anchor mask\n-        anchor = self.overlay_mask(image, self.segments, result['feature'])\n+        anchor = self.overlay_mask(image, sampler.segments, result['feature'])\n         exp = AnchorExplanation('image', result)\n",
        "source_code_with_indent": "        # overlay image with anchor mask\n        anchor = self.overlay_mask(image, self.segments, result['feature'])\n        exp = AnchorExplanation('image', result)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        # overlay image with anchor mask\n        anchor = self.overlay_mask(image, sampler.segments, result['feature'])\n        exp = AnchorExplanation('image', result)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "            anchor=anchor,\n            segments=self.segments,\n            precision=exp.precision(),\n",
        "source_code_len": 102,
        "target_code": "            anchor=anchor,\n            segments=sampler.segments,\n            precision=exp.precision(),\n",
        "target_code_len": 105,
        "diff_format": "@@ -436,3 +558,3 @@\n             anchor=anchor,\n-            segments=self.segments,\n+            segments=sampler.segments,\n             precision=exp.precision(),\n",
        "source_code_with_indent": "            anchor=anchor,\n            segments=self.segments,\n            precision=exp.precision(),\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "            anchor=anchor,\n            segments=sampler.segments,\n            precision=exp.precision(),\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  }
]