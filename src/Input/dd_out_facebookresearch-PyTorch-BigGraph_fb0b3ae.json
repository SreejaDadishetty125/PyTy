[
  {
    "project": "facebookresearch/PyTorch-BigGraph",
    "commit": "fb0b3ae1a85087f31f730cd4cd43f733c2bd35a3",
    "filename": "torchbiggraph/converters/import_from_tsv.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/facebookresearch-PyTorch-BigGraph/torchbiggraph/converters/import_from_tsv.py",
    "file_hunks_size": 5,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": true,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "torchbiggraph/converters/import_from_tsv.py:51:32 Call error [29]: `typing._Alias` is not a function.",
    "message": " `typing._Alias` is not a function.",
    "rule_id": "Call error [29]",
    "warning_line_no": 51,
    "warning_line": "        counter: Counter[str] = Counter()",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "    ConfigSchema,\n    EntitySchema,\n    RelationSchema,\n    override_config_dict,\n)\nfrom torchbiggraph.converters.dictionary import Dictionary\nfrom torchbiggraph.edgelist import EdgeList\nfrom torchbiggraph.entitylist import EntityList\nfrom torchbiggraph.graph_storages import (\n    AbstractEdgeAppender,\n    AbstractEdgeStorage,\n    AbstractEntityStorage,\n    AbstractRelationTypeStorage,\n    EDGE_STORAGES,\n    ENTITY_STORAGES,\n    RELATION_TYPE_STORAGES,\n)\n\n\ndef collect_relation_types(\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    rel_col: Optional[int],\n    relation_type_min_count: int,\n) -> Dictionary:\n\n    if dynamic_relations:\n        if rel_col is None:\n            raise RuntimeError(\"Need to specify rel_col in dynamic mode.\")\n        print(\"Looking up relation types in the edge files...\")\n        counter: Counter[str] = Counter()\n        for edgepath in edge_paths:\n            with edgepath.open(\"rt\") as tf:\n                for line_num, line in enumerate(tf, start=1):\n                    words = line.split()\n                    try:\n                        rel_word = words[rel_col]\n                    except IndexError:\n                        raise RuntimeError(\n                            f\"Line {line_num} of {edgepath} has only {len(words)} words\"\n                        ) from None\n                    counter[rel_word] += 1\n        print(f\"- Found {len(counter)} relation types\")\n        if relation_type_min_count > 0:\n            print(f\"- Removing the ones with fewer than {relation_type_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= relation_type_min_count})\n            print(f\"- Left with {len(counter)} relation types\")\n        print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n\n    else:\n        names = [rconfig.name for rconfig in relation_configs]\n        print(f\"Using the {len(names)} relation types given in the config\")\n\n    return Dictionary(names)\n\n\ndef collect_entities_by_type(\n    relation_types: Dictionary,\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n    entity_min_count: int,\n) -> Dict[str, Dictionary]:\n\n    counters: Dict[str, Counter[str]] = {}\n    for entity_name in entity_configs.keys():\n        counters[entity_name] = Counter()\n\n    print(\"Searching for the entities in the edge files...\")\n    for edgepath in edge_paths:\n        with edgepath.open(\"rt\") as tf:\n            for line_num, line in enumerate(tf, start=1):\n                words = line.split()\n                try:\n                    lhs_word = words[lhs_col]\n                    rhs_word = words[rhs_col]\n                    rel_word = words[rel_col] if rel_col is not None else None\n                except IndexError:\n                    raise RuntimeError(\n                        \"Line %d of %s has only %d words\"\n                        % (line_num, edgepath, len(words))) from None\n\n                if dynamic_relations or rel_col is None:\n                    rel_id = 0\n                else:\n                    try:\n                        rel_id = relation_types.get_id(rel_word)\n                    except KeyError:\n                        raise RuntimeError(\"Could not find relation type in config\")\n\n                counters[relation_configs[rel_id].lhs][lhs_word] += 1\n                counters[relation_configs[rel_id].rhs][rhs_word] += 1\n\n    entities_by_type: Dict[str, Dictionary] = {}\n    for entity_name, counter in counters.items():\n        print(f\"Entity type {entity_name}:\")\n        print(f\"- Found {len(counter)} entities\")\n        if entity_min_count > 0:\n            print(f\"- Removing the ones with fewer than {entity_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= entity_min_count})\n            print(f\"- Left with {len(counter)} entities\")\n        print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n        entities_by_type[entity_name] = Dictionary(\n            names, num_parts=entity_configs[entity_name].num_partitions)\n\n    return entities_by_type\n\n\ndef generate_entity_path_files(\n    entity_storage: AbstractEntityStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_type_storage: AbstractRelationTypeStorage,\n    relation_types: Dictionary,\n    dynamic_relations: bool,\n) -> None:\n    print(f\"Preparing counts and dictionaries for entities and relation types:\")\n    entity_storage.prepare()\n    relation_type_storage.prepare()\n\n    for entity_name, entities in entities_by_type.items():\n        for part in range(entities.num_parts):\n            print(f\"- Writing count of entity type {entity_name} \"\n                  f\"and partition {part}\")\n            entity_storage.save_count(entity_name, part, entities.part_size(part))\n            entity_storage.save_names(entity_name, part, entities.get_part_list(part))\n\n    if dynamic_relations:\n        print(\"- Writing count of dynamic relations\")\n        relation_type_storage.save_count(relation_types.size())\n        relation_type_storage.save_names(relation_types.get_list())\n\n\ndef generate_edge_path_files(\n    edge_file_in: Path,\n    edge_path_out: Path,\n    edge_storage: AbstractEdgeStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_types: Dictionary,\n    relation_configs: List[RelationSchema],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n) -> None:\n    print(f\"Preparing edge path {edge_path_out}, \"\n          f\"out of the edges found in {edge_file_in}\")\n    edge_storage.prepare()\n\n    num_lhs_parts = max(entities_by_type[rconfig.lhs].num_parts\n                        for rconfig in relation_configs)\n    num_rhs_parts = max(entities_by_type[rconfig.rhs].num_parts\n                        for rconfig in relation_configs)\n\n    print(f\"- Edges will be partitioned in {num_lhs_parts} x {num_rhs_parts} buckets.\")\n\n    processed = 0\n    skipped = 0\n\n    # We use an ExitStack in order to close the dynamically-created edge appenders.\n    with edge_file_in.open(\"rt\") as tf, ExitStack() as appender_stack:\n        appenders: Dict[Tuple[int, int], AbstractEdgeAppender] = {}\n        for line_num, line in enumerate(tf, start=1):\n            words = line.split()\n            try:\n                lhs_word = words[lhs_col]\n                rhs_word = words[rhs_col]\n                rel_word = words[rel_col] if rel_col is not None else None\n            except IndexError:\n                raise RuntimeError(\n                    f\"Line {line_num} of {edge_file_in} has only {len(words)} words\"\n                ) from None\n\n            if rel_col is None:\n                rel_id = 0\n            else:\n                try:\n                    rel_id = relation_types.get_id(rel_word)\n                except KeyError:\n                    # Ignore edges whose relation type is not known.\n                    skipped += 1\n                    continue\n\n            if dynamic_relations:\n                lhs_type = relation_configs[0].lhs\n                rhs_type = relation_configs[0].rhs\n            else:\n                lhs_type = relation_configs[rel_id].lhs\n                rhs_type = relation_configs[rel_id].rhs\n\n            try:\n                lhs_part, lhs_offset = \\\n                    entities_by_type[lhs_type].get_partition(lhs_word)\n                rhs_part, rhs_offset = \\\n                    entities_by_type[rhs_type].get_partition(rhs_word)\n            except KeyError:\n                # Ignore edges whose entities are not known.\n                skipped += 1\n                continue\n\n            if (lhs_part, rhs_part) not in appenders:\n                appenders[lhs_part, rhs_part] = appender_stack.enter_context(\n                    edge_storage.save_edges_by_appending(lhs_part, rhs_part))\n            appenders[lhs_part, rhs_part].append_edges(EdgeList(\n                EntityList.from_tensor(torch.tensor([lhs_offset], dtype=torch.long)),\n                EntityList.from_tensor(torch.tensor([rhs_offset], dtype=torch.long)),\n                torch.tensor([rel_id], dtype=torch.long),\n            ))\n\n            processed = processed + 1\n            if processed % 100000 == 0:\n                print(f\"- Processed {processed} edges so far...\")\n\n    print(f\"- Processed {processed} edges in total\")\n    if skipped > 0:\n        print(f\"- Skipped {skipped} edges because their relation type or \"\n              f\"entities were unknown (either not given in the config or \"\n              f\"filtered out as too rare).\")\n\n\ndef convert_input_data(\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    entity_path: str,\n    edge_paths_out: List[str],\n    edge_paths_in: List[Path],\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int] = None,\n    entity_min_count: int = 1,\n    relation_type_min_count: int = 1,\n    dynamic_relations: bool = False,\n) -> None:\n    if len(edge_paths_in) != len(edge_paths_out):\n        raise ValueError(\n            f\"The edge paths passed as inputs ({edge_paths_in}) don't match \"\n            f\"the ones specified as outputs ({edge_paths_out})\")\n\n    entity_storage = ENTITY_STORAGES.make_instance(entity_path)\n    relation_type_storage = RELATION_TYPE_STORAGES.make_instance(entity_path)\n    edge_storages = [EDGE_STORAGES.make_instance(ep) for ep in edge_paths_out]\n\n    some_files_exists = []\n    some_files_exists.extend(\n        entity_storage.has_count(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    some_files_exists.extend(\n        entity_storage.has_names(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    if dynamic_relations:\n        some_files_exists.append(relation_type_storage.has_count())\n        some_files_exists.append(relation_type_storage.has_names())\n    some_files_exists.extend(\n        edge_storage.has_edges(0, 0) for edge_storage in edge_storages)\n\n    if all(some_files_exists):\n        print(\"Found some files that indicate that the input data \"\n              \"has already been preprocessed, not doing it again.\")\n        all_paths = \", \".join(str(p) for p in [entity_path] + edge_paths_out)\n        print(f\"These files are in: {all_paths}\")\n        return\n\n    relation_types = collect_relation_types(\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        rel_col,\n        relation_type_min_count,\n    )\n\n    entities_by_type = collect_entities_by_type(\n        relation_types,\n        entity_configs,\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        lhs_col,\n        rhs_col,\n        rel_col,\n        entity_min_count,\n    )\n\n    generate_entity_path_files(\n        entity_storage,\n        entities_by_type,\n        relation_type_storage,\n        relation_types,\n        dynamic_relations,\n    )\n\n    for edge_path_in, edge_path_out, edge_storage \\\n            in zip(edge_paths_in, edge_paths_out, edge_storages):\n        generate_edge_path_files(\n            edge_path_in,\n            edge_path_out,\n            edge_storage,\n            entities_by_type,\n            relation_types,\n            relation_configs,\n            dynamic_relations,\n            lhs_col,\n            rhs_col,\n            rel_col,\n        )\n\n\ndef parse_config_partial(\n    config_dict: Any,\n) -> Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]:\n    entities_config = config_dict.get(\"entities\")\n    relations_config = config_dict.get(\"relations\")\n    entity_path = config_dict.get(\"entity_path\")\n    edge_paths = config_dict.get(\"edge_paths\")\n    dynamic_relations = config_dict.get(\"dynamic_relations\", False)\n    if not isinstance(entities_config, dict):\n        raise TypeError(\"Config entities is not of type dict\")\n    if any(not isinstance(k, str) for k in entities_config.keys()):\n        raise TypeError(\"Config entities has some keys that are not of type str\")\n    if not isinstance(relations_config, list):\n        raise TypeError(\"Config relations is not of type list\")\n    if not isinstance(entity_path, str):\n        raise TypeError(\"Config entity_path is not of type str\")\n    if not isinstance(edge_paths, list):\n        raise TypeError(\"Config edge_paths is not of type list\")\n    if any(not isinstance(p, str) for p in edge_paths):\n        raise TypeError(\"Config edge_paths has some items that are not of type str\")\n    if not isinstance(dynamic_relations, bool):\n        raise TypeError(\"Config dynamic_relations is not of type bool\")\n\n    entities = {}\n    relations = []\n    for entity, entity_config in entities_config.items():\n        entities[entity] = EntitySchema.from_dict(entity_config)\n    for relation in relations_config:\n        relations.append(RelationSchema.from_dict(relation))\n\n    return entities, relations, entity_path, edge_paths, dynamic_relations\n\n\n",
        "source_code_len": 13269,
        "target_code": "    ConfigSchema,\n    override_config_dict,\n)\n\n",
        "target_code_len": 47,
        "diff_format": "@@ -20,351 +20,4 @@\n     ConfigSchema,\n-    EntitySchema,\n-    RelationSchema,\n     override_config_dict,\n )\n-from torchbiggraph.converters.dictionary import Dictionary\n-from torchbiggraph.edgelist import EdgeList\n-from torchbiggraph.entitylist import EntityList\n-from torchbiggraph.graph_storages import (\n-    AbstractEdgeAppender,\n-    AbstractEdgeStorage,\n-    AbstractEntityStorage,\n-    AbstractRelationTypeStorage,\n-    EDGE_STORAGES,\n-    ENTITY_STORAGES,\n-    RELATION_TYPE_STORAGES,\n-)\n-\n-\n-def collect_relation_types(\n-    relation_configs: List[RelationSchema],\n-    edge_paths: List[Path],\n-    dynamic_relations: bool,\n-    rel_col: Optional[int],\n-    relation_type_min_count: int,\n-) -> Dictionary:\n-\n-    if dynamic_relations:\n-        if rel_col is None:\n-            raise RuntimeError(\"Need to specify rel_col in dynamic mode.\")\n-        print(\"Looking up relation types in the edge files...\")\n-        counter: Counter[str] = Counter()\n-        for edgepath in edge_paths:\n-            with edgepath.open(\"rt\") as tf:\n-                for line_num, line in enumerate(tf, start=1):\n-                    words = line.split()\n-                    try:\n-                        rel_word = words[rel_col]\n-                    except IndexError:\n-                        raise RuntimeError(\n-                            f\"Line {line_num} of {edgepath} has only {len(words)} words\"\n-                        ) from None\n-                    counter[rel_word] += 1\n-        print(f\"- Found {len(counter)} relation types\")\n-        if relation_type_min_count > 0:\n-            print(f\"- Removing the ones with fewer than {relation_type_min_count} occurrences...\")\n-            counter = Counter({k: c for k, c in counter.items()\n-                               if c >= relation_type_min_count})\n-            print(f\"- Left with {len(counter)} relation types\")\n-        print(\"- Shuffling them...\")\n-        names = list(counter.keys())\n-        random.shuffle(names)\n-\n-    else:\n-        names = [rconfig.name for rconfig in relation_configs]\n-        print(f\"Using the {len(names)} relation types given in the config\")\n-\n-    return Dictionary(names)\n-\n-\n-def collect_entities_by_type(\n-    relation_types: Dictionary,\n-    entity_configs: Dict[str, EntitySchema],\n-    relation_configs: List[RelationSchema],\n-    edge_paths: List[Path],\n-    dynamic_relations: bool,\n-    lhs_col: int,\n-    rhs_col: int,\n-    rel_col: Optional[int],\n-    entity_min_count: int,\n-) -> Dict[str, Dictionary]:\n-\n-    counters: Dict[str, Counter[str]] = {}\n-    for entity_name in entity_configs.keys():\n-        counters[entity_name] = Counter()\n-\n-    print(\"Searching for the entities in the edge files...\")\n-    for edgepath in edge_paths:\n-        with edgepath.open(\"rt\") as tf:\n-            for line_num, line in enumerate(tf, start=1):\n-                words = line.split()\n-                try:\n-                    lhs_word = words[lhs_col]\n-                    rhs_word = words[rhs_col]\n-                    rel_word = words[rel_col] if rel_col is not None else None\n-                except IndexError:\n-                    raise RuntimeError(\n-                        \"Line %d of %s has only %d words\"\n-                        % (line_num, edgepath, len(words))) from None\n-\n-                if dynamic_relations or rel_col is None:\n-                    rel_id = 0\n-                else:\n-                    try:\n-                        rel_id = relation_types.get_id(rel_word)\n-                    except KeyError:\n-                        raise RuntimeError(\"Could not find relation type in config\")\n-\n-                counters[relation_configs[rel_id].lhs][lhs_word] += 1\n-                counters[relation_configs[rel_id].rhs][rhs_word] += 1\n-\n-    entities_by_type: Dict[str, Dictionary] = {}\n-    for entity_name, counter in counters.items():\n-        print(f\"Entity type {entity_name}:\")\n-        print(f\"- Found {len(counter)} entities\")\n-        if entity_min_count > 0:\n-            print(f\"- Removing the ones with fewer than {entity_min_count} occurrences...\")\n-            counter = Counter({k: c for k, c in counter.items()\n-                               if c >= entity_min_count})\n-            print(f\"- Left with {len(counter)} entities\")\n-        print(\"- Shuffling them...\")\n-        names = list(counter.keys())\n-        random.shuffle(names)\n-        entities_by_type[entity_name] = Dictionary(\n-            names, num_parts=entity_configs[entity_name].num_partitions)\n-\n-    return entities_by_type\n-\n-\n-def generate_entity_path_files(\n-    entity_storage: AbstractEntityStorage,\n-    entities_by_type: Dict[str, Dictionary],\n-    relation_type_storage: AbstractRelationTypeStorage,\n-    relation_types: Dictionary,\n-    dynamic_relations: bool,\n-) -> None:\n-    print(f\"Preparing counts and dictionaries for entities and relation types:\")\n-    entity_storage.prepare()\n-    relation_type_storage.prepare()\n-\n-    for entity_name, entities in entities_by_type.items():\n-        for part in range(entities.num_parts):\n-            print(f\"- Writing count of entity type {entity_name} \"\n-                  f\"and partition {part}\")\n-            entity_storage.save_count(entity_name, part, entities.part_size(part))\n-            entity_storage.save_names(entity_name, part, entities.get_part_list(part))\n-\n-    if dynamic_relations:\n-        print(\"- Writing count of dynamic relations\")\n-        relation_type_storage.save_count(relation_types.size())\n-        relation_type_storage.save_names(relation_types.get_list())\n-\n-\n-def generate_edge_path_files(\n-    edge_file_in: Path,\n-    edge_path_out: Path,\n-    edge_storage: AbstractEdgeStorage,\n-    entities_by_type: Dict[str, Dictionary],\n-    relation_types: Dictionary,\n-    relation_configs: List[RelationSchema],\n-    dynamic_relations: bool,\n-    lhs_col: int,\n-    rhs_col: int,\n-    rel_col: Optional[int],\n-) -> None:\n-    print(f\"Preparing edge path {edge_path_out}, \"\n-          f\"out of the edges found in {edge_file_in}\")\n-    edge_storage.prepare()\n-\n-    num_lhs_parts = max(entities_by_type[rconfig.lhs].num_parts\n-                        for rconfig in relation_configs)\n-    num_rhs_parts = max(entities_by_type[rconfig.rhs].num_parts\n-                        for rconfig in relation_configs)\n-\n-    print(f\"- Edges will be partitioned in {num_lhs_parts} x {num_rhs_parts} buckets.\")\n-\n-    processed = 0\n-    skipped = 0\n-\n-    # We use an ExitStack in order to close the dynamically-created edge appenders.\n-    with edge_file_in.open(\"rt\") as tf, ExitStack() as appender_stack:\n-        appenders: Dict[Tuple[int, int], AbstractEdgeAppender] = {}\n-        for line_num, line in enumerate(tf, start=1):\n-            words = line.split()\n-            try:\n-                lhs_word = words[lhs_col]\n-                rhs_word = words[rhs_col]\n-                rel_word = words[rel_col] if rel_col is not None else None\n-            except IndexError:\n-                raise RuntimeError(\n-                    f\"Line {line_num} of {edge_file_in} has only {len(words)} words\"\n-                ) from None\n-\n-            if rel_col is None:\n-                rel_id = 0\n-            else:\n-                try:\n-                    rel_id = relation_types.get_id(rel_word)\n-                except KeyError:\n-                    # Ignore edges whose relation type is not known.\n-                    skipped += 1\n-                    continue\n-\n-            if dynamic_relations:\n-                lhs_type = relation_configs[0].lhs\n-                rhs_type = relation_configs[0].rhs\n-            else:\n-                lhs_type = relation_configs[rel_id].lhs\n-                rhs_type = relation_configs[rel_id].rhs\n-\n-            try:\n-                lhs_part, lhs_offset = \\\n-                    entities_by_type[lhs_type].get_partition(lhs_word)\n-                rhs_part, rhs_offset = \\\n-                    entities_by_type[rhs_type].get_partition(rhs_word)\n-            except KeyError:\n-                # Ignore edges whose entities are not known.\n-                skipped += 1\n-                continue\n-\n-            if (lhs_part, rhs_part) not in appenders:\n-                appenders[lhs_part, rhs_part] = appender_stack.enter_context(\n-                    edge_storage.save_edges_by_appending(lhs_part, rhs_part))\n-            appenders[lhs_part, rhs_part].append_edges(EdgeList(\n-                EntityList.from_tensor(torch.tensor([lhs_offset], dtype=torch.long)),\n-                EntityList.from_tensor(torch.tensor([rhs_offset], dtype=torch.long)),\n-                torch.tensor([rel_id], dtype=torch.long),\n-            ))\n-\n-            processed = processed + 1\n-            if processed % 100000 == 0:\n-                print(f\"- Processed {processed} edges so far...\")\n-\n-    print(f\"- Processed {processed} edges in total\")\n-    if skipped > 0:\n-        print(f\"- Skipped {skipped} edges because their relation type or \"\n-              f\"entities were unknown (either not given in the config or \"\n-              f\"filtered out as too rare).\")\n-\n-\n-def convert_input_data(\n-    entity_configs: Dict[str, EntitySchema],\n-    relation_configs: List[RelationSchema],\n-    entity_path: str,\n-    edge_paths_out: List[str],\n-    edge_paths_in: List[Path],\n-    lhs_col: int,\n-    rhs_col: int,\n-    rel_col: Optional[int] = None,\n-    entity_min_count: int = 1,\n-    relation_type_min_count: int = 1,\n-    dynamic_relations: bool = False,\n-) -> None:\n-    if len(edge_paths_in) != len(edge_paths_out):\n-        raise ValueError(\n-            f\"The edge paths passed as inputs ({edge_paths_in}) don't match \"\n-            f\"the ones specified as outputs ({edge_paths_out})\")\n-\n-    entity_storage = ENTITY_STORAGES.make_instance(entity_path)\n-    relation_type_storage = RELATION_TYPE_STORAGES.make_instance(entity_path)\n-    edge_storages = [EDGE_STORAGES.make_instance(ep) for ep in edge_paths_out]\n-\n-    some_files_exists = []\n-    some_files_exists.extend(\n-        entity_storage.has_count(entity_name, partition)\n-        for entity_name, entity_config in entity_configs.items()\n-        for partition in range(entity_config.num_partitions))\n-    some_files_exists.extend(\n-        entity_storage.has_names(entity_name, partition)\n-        for entity_name, entity_config in entity_configs.items()\n-        for partition in range(entity_config.num_partitions))\n-    if dynamic_relations:\n-        some_files_exists.append(relation_type_storage.has_count())\n-        some_files_exists.append(relation_type_storage.has_names())\n-    some_files_exists.extend(\n-        edge_storage.has_edges(0, 0) for edge_storage in edge_storages)\n-\n-    if all(some_files_exists):\n-        print(\"Found some files that indicate that the input data \"\n-              \"has already been preprocessed, not doing it again.\")\n-        all_paths = \", \".join(str(p) for p in [entity_path] + edge_paths_out)\n-        print(f\"These files are in: {all_paths}\")\n-        return\n-\n-    relation_types = collect_relation_types(\n-        relation_configs,\n-        edge_paths_in,\n-        dynamic_relations,\n-        rel_col,\n-        relation_type_min_count,\n-    )\n-\n-    entities_by_type = collect_entities_by_type(\n-        relation_types,\n-        entity_configs,\n-        relation_configs,\n-        edge_paths_in,\n-        dynamic_relations,\n-        lhs_col,\n-        rhs_col,\n-        rel_col,\n-        entity_min_count,\n-    )\n-\n-    generate_entity_path_files(\n-        entity_storage,\n-        entities_by_type,\n-        relation_type_storage,\n-        relation_types,\n-        dynamic_relations,\n-    )\n-\n-    for edge_path_in, edge_path_out, edge_storage \\\n-            in zip(edge_paths_in, edge_paths_out, edge_storages):\n-        generate_edge_path_files(\n-            edge_path_in,\n-            edge_path_out,\n-            edge_storage,\n-            entities_by_type,\n-            relation_types,\n-            relation_configs,\n-            dynamic_relations,\n-            lhs_col,\n-            rhs_col,\n-            rel_col,\n-        )\n-\n-\n-def parse_config_partial(\n-    config_dict: Any,\n-) -> Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]:\n-    entities_config = config_dict.get(\"entities\")\n-    relations_config = config_dict.get(\"relations\")\n-    entity_path = config_dict.get(\"entity_path\")\n-    edge_paths = config_dict.get(\"edge_paths\")\n-    dynamic_relations = config_dict.get(\"dynamic_relations\", False)\n-    if not isinstance(entities_config, dict):\n-        raise TypeError(\"Config entities is not of type dict\")\n-    if any(not isinstance(k, str) for k in entities_config.keys()):\n-        raise TypeError(\"Config entities has some keys that are not of type str\")\n-    if not isinstance(relations_config, list):\n-        raise TypeError(\"Config relations is not of type list\")\n-    if not isinstance(entity_path, str):\n-        raise TypeError(\"Config entity_path is not of type str\")\n-    if not isinstance(edge_paths, list):\n-        raise TypeError(\"Config edge_paths is not of type list\")\n-    if any(not isinstance(p, str) for p in edge_paths):\n-        raise TypeError(\"Config edge_paths has some items that are not of type str\")\n-    if not isinstance(dynamic_relations, bool):\n-        raise TypeError(\"Config dynamic_relations is not of type bool\")\n-\n-    entities = {}\n-    relations = []\n-    for entity, entity_config in entities_config.items():\n-        entities[entity] = EntitySchema.from_dict(entity_config)\n-    for relation in relations_config:\n-        relations.append(RelationSchema.from_dict(relation))\n-\n-    return entities, relations, entity_path, edge_paths, dynamic_relations\n-\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent": "    ConfigSchema,\n    override_config_dict,\n)\n\n",
        "target_code_with_indent_exact_match": true,
        "source_code_with_indent": "    ConfigSchema,\n    EntitySchema,\n    RelationSchema,\n    override_config_dict,\n)\nfrom torchbiggraph.converters.dictionary import Dictionary\nfrom torchbiggraph.edgelist import EdgeList\nfrom torchbiggraph.entitylist import EntityList\nfrom torchbiggraph.graph_storages import (\n    AbstractEdgeAppender,\n    AbstractEdgeStorage,\n    AbstractEntityStorage,\n    AbstractRelationTypeStorage,\n    EDGE_STORAGES,\n    ENTITY_STORAGES,\n    RELATION_TYPE_STORAGES,\n)\n\n\ndef collect_relation_types(\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    rel_col: Optional[int],\n    relation_type_min_count: int,\n) -> Dictionary:\n\n    <IND>if dynamic_relations:\n        <IND>if rel_col is None:\n            <IND>raise RuntimeError(\"Need to specify rel_col in dynamic mode.\")\n        <DED>print(\"Looking up relation types in the edge files...\")\n        counter: Counter[str] = Counter()\n        for edgepath in edge_paths:\n            <IND>with edgepath.open(\"rt\") as tf:\n                <IND>for line_num, line in enumerate(tf, start=1):\n                    <IND>words = line.split()\n                    try:\n                        <IND>rel_word = words[rel_col]\n                    <DED>except IndexError:\n                        <IND>raise RuntimeError(\n                            f\"Line {line_num} of {edgepath} has only {len(words)} words\"\n                        ) from None\n                    <DED>counter[rel_word] += 1\n        <DED><DED><DED>print(f\"- Found {len(counter)} relation types\")\n        if relation_type_min_count > 0:\n            <IND>print(f\"- Removing the ones with fewer than {relation_type_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= relation_type_min_count})\n            print(f\"- Left with {len(counter)} relation types\")\n        <DED>print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n\n    <DED>else:\n        <IND>names = [rconfig.name for rconfig in relation_configs]\n        print(f\"Using the {len(names)} relation types given in the config\")\n\n    <DED>return Dictionary(names)\n\n\n<DED>def collect_entities_by_type(\n    relation_types: Dictionary,\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n    entity_min_count: int,\n) -> Dict[str, Dictionary]:\n\n    <IND>counters: Dict[str, Counter[str]] = {}\n    for entity_name in entity_configs.keys():\n        <IND>counters[entity_name] = Counter()\n\n    <DED>print(\"Searching for the entities in the edge files...\")\n    for edgepath in edge_paths:\n        <IND>with edgepath.open(\"rt\") as tf:\n            <IND>for line_num, line in enumerate(tf, start=1):\n                <IND>words = line.split()\n                try:\n                    <IND>lhs_word = words[lhs_col]\n                    rhs_word = words[rhs_col]\n                    rel_word = words[rel_col] if rel_col is not None else None\n                <DED>except IndexError:\n                    <IND>raise RuntimeError(\n                        \"Line %d of %s has only %d words\"\n                        % (line_num, edgepath, len(words))) from None\n\n                <DED>if dynamic_relations or rel_col is None:\n                    <IND>rel_id = 0\n                <DED>else:\n                    <IND>try:\n                        <IND>rel_id = relation_types.get_id(rel_word)\n                    <DED>except KeyError:\n                        <IND>raise RuntimeError(\"Could not find relation type in config\")\n\n                <DED><DED>counters[relation_configs[rel_id].lhs][lhs_word] += 1\n                counters[relation_configs[rel_id].rhs][rhs_word] += 1\n\n    <DED><DED><DED>entities_by_type: Dict[str, Dictionary] = {}\n    for entity_name, counter in counters.items():\n        <IND>print(f\"Entity type {entity_name}:\")\n        print(f\"- Found {len(counter)} entities\")\n        if entity_min_count > 0:\n            <IND>print(f\"- Removing the ones with fewer than {entity_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= entity_min_count})\n            print(f\"- Left with {len(counter)} entities\")\n        <DED>print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n        entities_by_type[entity_name] = Dictionary(\n            names, num_parts=entity_configs[entity_name].num_partitions)\n\n    <DED>return entities_by_type\n\n\n<DED>def generate_entity_path_files(\n    entity_storage: AbstractEntityStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_type_storage: AbstractRelationTypeStorage,\n    relation_types: Dictionary,\n    dynamic_relations: bool,\n) -> None:\n    <IND>print(f\"Preparing counts and dictionaries for entities and relation types:\")\n    entity_storage.prepare()\n    relation_type_storage.prepare()\n\n    for entity_name, entities in entities_by_type.items():\n        <IND>for part in range(entities.num_parts):\n            <IND>print(f\"- Writing count of entity type {entity_name} \"\n                  f\"and partition {part}\")\n            entity_storage.save_count(entity_name, part, entities.part_size(part))\n            entity_storage.save_names(entity_name, part, entities.get_part_list(part))\n\n    <DED><DED>if dynamic_relations:\n        <IND>print(\"- Writing count of dynamic relations\")\n        relation_type_storage.save_count(relation_types.size())\n        relation_type_storage.save_names(relation_types.get_list())\n\n\n<DED><DED>def generate_edge_path_files(\n    edge_file_in: Path,\n    edge_path_out: Path,\n    edge_storage: AbstractEdgeStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_types: Dictionary,\n    relation_configs: List[RelationSchema],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n) -> None:\n    <IND>print(f\"Preparing edge path {edge_path_out}, \"\n          f\"out of the edges found in {edge_file_in}\")\n    edge_storage.prepare()\n\n    num_lhs_parts = max(entities_by_type[rconfig.lhs].num_parts\n                        for rconfig in relation_configs)\n    num_rhs_parts = max(entities_by_type[rconfig.rhs].num_parts\n                        for rconfig in relation_configs)\n\n    print(f\"- Edges will be partitioned in {num_lhs_parts} x {num_rhs_parts} buckets.\")\n\n    processed = 0\n    skipped = 0\n\n    # We use an ExitStack in order to close the dynamically-created edge appenders.\n    with edge_file_in.open(\"rt\") as tf, ExitStack() as appender_stack:\n        <IND>appenders: Dict[Tuple[int, int], AbstractEdgeAppender] = {}\n        for line_num, line in enumerate(tf, start=1):\n            <IND>words = line.split()\n            try:\n                <IND>lhs_word = words[lhs_col]\n                rhs_word = words[rhs_col]\n                rel_word = words[rel_col] if rel_col is not None else None\n            <DED>except IndexError:\n                <IND>raise RuntimeError(\n                    f\"Line {line_num} of {edge_file_in} has only {len(words)} words\"\n                ) from None\n\n            <DED>if rel_col is None:\n                <IND>rel_id = 0\n            <DED>else:\n                <IND>try:\n                    <IND>rel_id = relation_types.get_id(rel_word)\n                <DED>except KeyError:\n                    # Ignore edges whose relation type is not known.\n                    <IND>skipped += 1\n                    continue\n\n            <DED><DED>if dynamic_relations:\n                <IND>lhs_type = relation_configs[0].lhs\n                rhs_type = relation_configs[0].rhs\n            <DED>else:\n                <IND>lhs_type = relation_configs[rel_id].lhs\n                rhs_type = relation_configs[rel_id].rhs\n\n            <DED>try:\n                <IND>lhs_part, lhs_offset =                    entities_by_type[lhs_type].get_partition(lhs_word)\n                rhs_part, rhs_offset =                    entities_by_type[rhs_type].get_partition(rhs_word)\n            <DED>except KeyError:\n                # Ignore edges whose entities are not known.\n                <IND>skipped += 1\n                continue\n\n            <DED>if (lhs_part, rhs_part) not in appenders:\n                <IND>appenders[lhs_part, rhs_part] = appender_stack.enter_context(\n                    edge_storage.save_edges_by_appending(lhs_part, rhs_part))\n            <DED>appenders[lhs_part, rhs_part].append_edges(EdgeList(\n                EntityList.from_tensor(torch.tensor([lhs_offset], dtype=torch.long)),\n                EntityList.from_tensor(torch.tensor([rhs_offset], dtype=torch.long)),\n                torch.tensor([rel_id], dtype=torch.long),\n            ))\n\n            processed = processed + 1\n            if processed % 100000 == 0:\n                <IND>print(f\"- Processed {processed} edges so far...\")\n\n    <DED><DED><DED>print(f\"- Processed {processed} edges in total\")\n    if skipped > 0:\n        <IND>print(f\"- Skipped {skipped} edges because their relation type or \"\n              f\"entities were unknown (either not given in the config or \"\n              f\"filtered out as too rare).\")\n\n\n<DED><DED>def convert_input_data(\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    entity_path: str,\n    edge_paths_out: List[str],\n    edge_paths_in: List[Path],\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int] = None,\n    entity_min_count: int = 1,\n    relation_type_min_count: int = 1,\n    dynamic_relations: bool = False,\n) -> None:\n    <IND>if len(edge_paths_in) != len(edge_paths_out):\n        <IND>raise ValueError(\n            f\"The edge paths passed as inputs ({edge_paths_in}) don't match \"\n            f\"the ones specified as outputs ({edge_paths_out})\")\n\n    <DED>entity_storage = ENTITY_STORAGES.make_instance(entity_path)\n    relation_type_storage = RELATION_TYPE_STORAGES.make_instance(entity_path)\n    edge_storages = [EDGE_STORAGES.make_instance(ep) for ep in edge_paths_out]\n\n    some_files_exists = []\n    some_files_exists.extend(\n        entity_storage.has_count(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    some_files_exists.extend(\n        entity_storage.has_names(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    if dynamic_relations:\n        <IND>some_files_exists.append(relation_type_storage.has_count())\n        some_files_exists.append(relation_type_storage.has_names())\n    <DED>some_files_exists.extend(\n        edge_storage.has_edges(0, 0) for edge_storage in edge_storages)\n\n    if all(some_files_exists):\n        <IND>print(\"Found some files that indicate that the input data \"\n              \"has already been preprocessed, not doing it again.\")\n        all_paths = \", \".join(str(p) for p in [entity_path] + edge_paths_out)\n        print(f\"These files are in: {all_paths}\")\n        return\n\n    <DED>relation_types = collect_relation_types(\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        rel_col,\n        relation_type_min_count,\n    )\n\n    entities_by_type = collect_entities_by_type(\n        relation_types,\n        entity_configs,\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        lhs_col,\n        rhs_col,\n        rel_col,\n        entity_min_count,\n    )\n\n    generate_entity_path_files(\n        entity_storage,\n        entities_by_type,\n        relation_type_storage,\n        relation_types,\n        dynamic_relations,\n    )\n\n    for edge_path_in, edge_path_out, edge_storage            in zip(edge_paths_in, edge_paths_out, edge_storages):\n        <IND>generate_edge_path_files(\n            edge_path_in,\n            edge_path_out,\n            edge_storage,\n            entities_by_type,\n            relation_types,\n            relation_configs,\n            dynamic_relations,\n            lhs_col,\n            rhs_col,\n            rel_col,\n        )\n\n\n<DED><DED>def parse_config_partial(\n    config_dict: Any,\n) -> Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]:\n    <IND>entities_config = config_dict.get(\"entities\")\n    relations_config = config_dict.get(\"relations\")\n    entity_path = config_dict.get(\"entity_path\")\n    edge_paths = config_dict.get(\"edge_paths\")\n    dynamic_relations = config_dict.get(\"dynamic_relations\", False)\n    if not isinstance(entities_config, dict):\n        <IND>raise TypeError(\"Config entities is not of type dict\")\n    <DED>if any(not isinstance(k, str) for k in entities_config.keys()):\n        <IND>raise TypeError(\"Config entities has some keys that are not of type str\")\n    <DED>if not isinstance(relations_config, list):\n        <IND>raise TypeError(\"Config relations is not of type list\")\n    <DED>if not isinstance(entity_path, str):\n        <IND>raise TypeError(\"Config entity_path is not of type str\")\n    <DED>if not isinstance(edge_paths, list):\n        <IND>raise TypeError(\"Config edge_paths is not of type list\")\n    <DED>if any(not isinstance(p, str) for p in edge_paths):\n        <IND>raise TypeError(\"Config edge_paths has some items that are not of type str\")\n    <DED>if not isinstance(dynamic_relations, bool):\n        <IND>raise TypeError(\"Config dynamic_relations is not of type bool\")\n\n    <DED>entities = {}\n    relations = []\n    for entity, entity_config in entities_config.items():\n        <IND>entities[entity] = EntitySchema.from_dict(entity_config)\n    <DED>for relation in relations_config:\n        <IND>relations.append(RelationSchema.from_dict(relation))\n\n    <DED>return entities, relations, entity_path, edge_paths, dynamic_relations\n\n\n"
      }
    ]
  },
  {
    "project": "facebookresearch/PyTorch-BigGraph",
    "commit": "fb0b3ae1a85087f31f730cd4cd43f733c2bd35a3",
    "filename": "torchbiggraph/converters/import_from_tsv.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/facebookresearch-PyTorch-BigGraph/torchbiggraph/converters/import_from_tsv.py",
    "file_hunks_size": 5,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": true,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "torchbiggraph/converters/import_from_tsv.py:66:22 Call error [29]: `typing._Alias` is not a function.",
    "message": " `typing._Alias` is not a function.",
    "rule_id": "Call error [29]",
    "warning_line_no": 66,
    "warning_line": "            counter = Counter({k: c for k, c in counter.items()",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "    ConfigSchema,\n    EntitySchema,\n    RelationSchema,\n    override_config_dict,\n)\nfrom torchbiggraph.converters.dictionary import Dictionary\nfrom torchbiggraph.edgelist import EdgeList\nfrom torchbiggraph.entitylist import EntityList\nfrom torchbiggraph.graph_storages import (\n    AbstractEdgeAppender,\n    AbstractEdgeStorage,\n    AbstractEntityStorage,\n    AbstractRelationTypeStorage,\n    EDGE_STORAGES,\n    ENTITY_STORAGES,\n    RELATION_TYPE_STORAGES,\n)\n\n\ndef collect_relation_types(\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    rel_col: Optional[int],\n    relation_type_min_count: int,\n) -> Dictionary:\n\n    if dynamic_relations:\n        if rel_col is None:\n            raise RuntimeError(\"Need to specify rel_col in dynamic mode.\")\n        print(\"Looking up relation types in the edge files...\")\n        counter: Counter[str] = Counter()\n        for edgepath in edge_paths:\n            with edgepath.open(\"rt\") as tf:\n                for line_num, line in enumerate(tf, start=1):\n                    words = line.split()\n                    try:\n                        rel_word = words[rel_col]\n                    except IndexError:\n                        raise RuntimeError(\n                            f\"Line {line_num} of {edgepath} has only {len(words)} words\"\n                        ) from None\n                    counter[rel_word] += 1\n        print(f\"- Found {len(counter)} relation types\")\n        if relation_type_min_count > 0:\n            print(f\"- Removing the ones with fewer than {relation_type_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= relation_type_min_count})\n            print(f\"- Left with {len(counter)} relation types\")\n        print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n\n    else:\n        names = [rconfig.name for rconfig in relation_configs]\n        print(f\"Using the {len(names)} relation types given in the config\")\n\n    return Dictionary(names)\n\n\ndef collect_entities_by_type(\n    relation_types: Dictionary,\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n    entity_min_count: int,\n) -> Dict[str, Dictionary]:\n\n    counters: Dict[str, Counter[str]] = {}\n    for entity_name in entity_configs.keys():\n        counters[entity_name] = Counter()\n\n    print(\"Searching for the entities in the edge files...\")\n    for edgepath in edge_paths:\n        with edgepath.open(\"rt\") as tf:\n            for line_num, line in enumerate(tf, start=1):\n                words = line.split()\n                try:\n                    lhs_word = words[lhs_col]\n                    rhs_word = words[rhs_col]\n                    rel_word = words[rel_col] if rel_col is not None else None\n                except IndexError:\n                    raise RuntimeError(\n                        \"Line %d of %s has only %d words\"\n                        % (line_num, edgepath, len(words))) from None\n\n                if dynamic_relations or rel_col is None:\n                    rel_id = 0\n                else:\n                    try:\n                        rel_id = relation_types.get_id(rel_word)\n                    except KeyError:\n                        raise RuntimeError(\"Could not find relation type in config\")\n\n                counters[relation_configs[rel_id].lhs][lhs_word] += 1\n                counters[relation_configs[rel_id].rhs][rhs_word] += 1\n\n    entities_by_type: Dict[str, Dictionary] = {}\n    for entity_name, counter in counters.items():\n        print(f\"Entity type {entity_name}:\")\n        print(f\"- Found {len(counter)} entities\")\n        if entity_min_count > 0:\n            print(f\"- Removing the ones with fewer than {entity_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= entity_min_count})\n            print(f\"- Left with {len(counter)} entities\")\n        print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n        entities_by_type[entity_name] = Dictionary(\n            names, num_parts=entity_configs[entity_name].num_partitions)\n\n    return entities_by_type\n\n\ndef generate_entity_path_files(\n    entity_storage: AbstractEntityStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_type_storage: AbstractRelationTypeStorage,\n    relation_types: Dictionary,\n    dynamic_relations: bool,\n) -> None:\n    print(f\"Preparing counts and dictionaries for entities and relation types:\")\n    entity_storage.prepare()\n    relation_type_storage.prepare()\n\n    for entity_name, entities in entities_by_type.items():\n        for part in range(entities.num_parts):\n            print(f\"- Writing count of entity type {entity_name} \"\n                  f\"and partition {part}\")\n            entity_storage.save_count(entity_name, part, entities.part_size(part))\n            entity_storage.save_names(entity_name, part, entities.get_part_list(part))\n\n    if dynamic_relations:\n        print(\"- Writing count of dynamic relations\")\n        relation_type_storage.save_count(relation_types.size())\n        relation_type_storage.save_names(relation_types.get_list())\n\n\ndef generate_edge_path_files(\n    edge_file_in: Path,\n    edge_path_out: Path,\n    edge_storage: AbstractEdgeStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_types: Dictionary,\n    relation_configs: List[RelationSchema],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n) -> None:\n    print(f\"Preparing edge path {edge_path_out}, \"\n          f\"out of the edges found in {edge_file_in}\")\n    edge_storage.prepare()\n\n    num_lhs_parts = max(entities_by_type[rconfig.lhs].num_parts\n                        for rconfig in relation_configs)\n    num_rhs_parts = max(entities_by_type[rconfig.rhs].num_parts\n                        for rconfig in relation_configs)\n\n    print(f\"- Edges will be partitioned in {num_lhs_parts} x {num_rhs_parts} buckets.\")\n\n    processed = 0\n    skipped = 0\n\n    # We use an ExitStack in order to close the dynamically-created edge appenders.\n    with edge_file_in.open(\"rt\") as tf, ExitStack() as appender_stack:\n        appenders: Dict[Tuple[int, int], AbstractEdgeAppender] = {}\n        for line_num, line in enumerate(tf, start=1):\n            words = line.split()\n            try:\n                lhs_word = words[lhs_col]\n                rhs_word = words[rhs_col]\n                rel_word = words[rel_col] if rel_col is not None else None\n            except IndexError:\n                raise RuntimeError(\n                    f\"Line {line_num} of {edge_file_in} has only {len(words)} words\"\n                ) from None\n\n            if rel_col is None:\n                rel_id = 0\n            else:\n                try:\n                    rel_id = relation_types.get_id(rel_word)\n                except KeyError:\n                    # Ignore edges whose relation type is not known.\n                    skipped += 1\n                    continue\n\n            if dynamic_relations:\n                lhs_type = relation_configs[0].lhs\n                rhs_type = relation_configs[0].rhs\n            else:\n                lhs_type = relation_configs[rel_id].lhs\n                rhs_type = relation_configs[rel_id].rhs\n\n            try:\n                lhs_part, lhs_offset = \\\n                    entities_by_type[lhs_type].get_partition(lhs_word)\n                rhs_part, rhs_offset = \\\n                    entities_by_type[rhs_type].get_partition(rhs_word)\n            except KeyError:\n                # Ignore edges whose entities are not known.\n                skipped += 1\n                continue\n\n            if (lhs_part, rhs_part) not in appenders:\n                appenders[lhs_part, rhs_part] = appender_stack.enter_context(\n                    edge_storage.save_edges_by_appending(lhs_part, rhs_part))\n            appenders[lhs_part, rhs_part].append_edges(EdgeList(\n                EntityList.from_tensor(torch.tensor([lhs_offset], dtype=torch.long)),\n                EntityList.from_tensor(torch.tensor([rhs_offset], dtype=torch.long)),\n                torch.tensor([rel_id], dtype=torch.long),\n            ))\n\n            processed = processed + 1\n            if processed % 100000 == 0:\n                print(f\"- Processed {processed} edges so far...\")\n\n    print(f\"- Processed {processed} edges in total\")\n    if skipped > 0:\n        print(f\"- Skipped {skipped} edges because their relation type or \"\n              f\"entities were unknown (either not given in the config or \"\n              f\"filtered out as too rare).\")\n\n\ndef convert_input_data(\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    entity_path: str,\n    edge_paths_out: List[str],\n    edge_paths_in: List[Path],\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int] = None,\n    entity_min_count: int = 1,\n    relation_type_min_count: int = 1,\n    dynamic_relations: bool = False,\n) -> None:\n    if len(edge_paths_in) != len(edge_paths_out):\n        raise ValueError(\n            f\"The edge paths passed as inputs ({edge_paths_in}) don't match \"\n            f\"the ones specified as outputs ({edge_paths_out})\")\n\n    entity_storage = ENTITY_STORAGES.make_instance(entity_path)\n    relation_type_storage = RELATION_TYPE_STORAGES.make_instance(entity_path)\n    edge_storages = [EDGE_STORAGES.make_instance(ep) for ep in edge_paths_out]\n\n    some_files_exists = []\n    some_files_exists.extend(\n        entity_storage.has_count(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    some_files_exists.extend(\n        entity_storage.has_names(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    if dynamic_relations:\n        some_files_exists.append(relation_type_storage.has_count())\n        some_files_exists.append(relation_type_storage.has_names())\n    some_files_exists.extend(\n        edge_storage.has_edges(0, 0) for edge_storage in edge_storages)\n\n    if all(some_files_exists):\n        print(\"Found some files that indicate that the input data \"\n              \"has already been preprocessed, not doing it again.\")\n        all_paths = \", \".join(str(p) for p in [entity_path] + edge_paths_out)\n        print(f\"These files are in: {all_paths}\")\n        return\n\n    relation_types = collect_relation_types(\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        rel_col,\n        relation_type_min_count,\n    )\n\n    entities_by_type = collect_entities_by_type(\n        relation_types,\n        entity_configs,\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        lhs_col,\n        rhs_col,\n        rel_col,\n        entity_min_count,\n    )\n\n    generate_entity_path_files(\n        entity_storage,\n        entities_by_type,\n        relation_type_storage,\n        relation_types,\n        dynamic_relations,\n    )\n\n    for edge_path_in, edge_path_out, edge_storage \\\n            in zip(edge_paths_in, edge_paths_out, edge_storages):\n        generate_edge_path_files(\n            edge_path_in,\n            edge_path_out,\n            edge_storage,\n            entities_by_type,\n            relation_types,\n            relation_configs,\n            dynamic_relations,\n            lhs_col,\n            rhs_col,\n            rel_col,\n        )\n\n\ndef parse_config_partial(\n    config_dict: Any,\n) -> Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]:\n    entities_config = config_dict.get(\"entities\")\n    relations_config = config_dict.get(\"relations\")\n    entity_path = config_dict.get(\"entity_path\")\n    edge_paths = config_dict.get(\"edge_paths\")\n    dynamic_relations = config_dict.get(\"dynamic_relations\", False)\n    if not isinstance(entities_config, dict):\n        raise TypeError(\"Config entities is not of type dict\")\n    if any(not isinstance(k, str) for k in entities_config.keys()):\n        raise TypeError(\"Config entities has some keys that are not of type str\")\n    if not isinstance(relations_config, list):\n        raise TypeError(\"Config relations is not of type list\")\n    if not isinstance(entity_path, str):\n        raise TypeError(\"Config entity_path is not of type str\")\n    if not isinstance(edge_paths, list):\n        raise TypeError(\"Config edge_paths is not of type list\")\n    if any(not isinstance(p, str) for p in edge_paths):\n        raise TypeError(\"Config edge_paths has some items that are not of type str\")\n    if not isinstance(dynamic_relations, bool):\n        raise TypeError(\"Config dynamic_relations is not of type bool\")\n\n    entities = {}\n    relations = []\n    for entity, entity_config in entities_config.items():\n        entities[entity] = EntitySchema.from_dict(entity_config)\n    for relation in relations_config:\n        relations.append(RelationSchema.from_dict(relation))\n\n    return entities, relations, entity_path, edge_paths, dynamic_relations\n\n\n",
        "source_code_len": 13269,
        "target_code": "    ConfigSchema,\n    override_config_dict,\n)\n\n",
        "target_code_len": 47,
        "diff_format": "@@ -20,351 +20,4 @@\n     ConfigSchema,\n-    EntitySchema,\n-    RelationSchema,\n     override_config_dict,\n )\n-from torchbiggraph.converters.dictionary import Dictionary\n-from torchbiggraph.edgelist import EdgeList\n-from torchbiggraph.entitylist import EntityList\n-from torchbiggraph.graph_storages import (\n-    AbstractEdgeAppender,\n-    AbstractEdgeStorage,\n-    AbstractEntityStorage,\n-    AbstractRelationTypeStorage,\n-    EDGE_STORAGES,\n-    ENTITY_STORAGES,\n-    RELATION_TYPE_STORAGES,\n-)\n-\n-\n-def collect_relation_types(\n-    relation_configs: List[RelationSchema],\n-    edge_paths: List[Path],\n-    dynamic_relations: bool,\n-    rel_col: Optional[int],\n-    relation_type_min_count: int,\n-) -> Dictionary:\n-\n-    if dynamic_relations:\n-        if rel_col is None:\n-            raise RuntimeError(\"Need to specify rel_col in dynamic mode.\")\n-        print(\"Looking up relation types in the edge files...\")\n-        counter: Counter[str] = Counter()\n-        for edgepath in edge_paths:\n-            with edgepath.open(\"rt\") as tf:\n-                for line_num, line in enumerate(tf, start=1):\n-                    words = line.split()\n-                    try:\n-                        rel_word = words[rel_col]\n-                    except IndexError:\n-                        raise RuntimeError(\n-                            f\"Line {line_num} of {edgepath} has only {len(words)} words\"\n-                        ) from None\n-                    counter[rel_word] += 1\n-        print(f\"- Found {len(counter)} relation types\")\n-        if relation_type_min_count > 0:\n-            print(f\"- Removing the ones with fewer than {relation_type_min_count} occurrences...\")\n-            counter = Counter({k: c for k, c in counter.items()\n-                               if c >= relation_type_min_count})\n-            print(f\"- Left with {len(counter)} relation types\")\n-        print(\"- Shuffling them...\")\n-        names = list(counter.keys())\n-        random.shuffle(names)\n-\n-    else:\n-        names = [rconfig.name for rconfig in relation_configs]\n-        print(f\"Using the {len(names)} relation types given in the config\")\n-\n-    return Dictionary(names)\n-\n-\n-def collect_entities_by_type(\n-    relation_types: Dictionary,\n-    entity_configs: Dict[str, EntitySchema],\n-    relation_configs: List[RelationSchema],\n-    edge_paths: List[Path],\n-    dynamic_relations: bool,\n-    lhs_col: int,\n-    rhs_col: int,\n-    rel_col: Optional[int],\n-    entity_min_count: int,\n-) -> Dict[str, Dictionary]:\n-\n-    counters: Dict[str, Counter[str]] = {}\n-    for entity_name in entity_configs.keys():\n-        counters[entity_name] = Counter()\n-\n-    print(\"Searching for the entities in the edge files...\")\n-    for edgepath in edge_paths:\n-        with edgepath.open(\"rt\") as tf:\n-            for line_num, line in enumerate(tf, start=1):\n-                words = line.split()\n-                try:\n-                    lhs_word = words[lhs_col]\n-                    rhs_word = words[rhs_col]\n-                    rel_word = words[rel_col] if rel_col is not None else None\n-                except IndexError:\n-                    raise RuntimeError(\n-                        \"Line %d of %s has only %d words\"\n-                        % (line_num, edgepath, len(words))) from None\n-\n-                if dynamic_relations or rel_col is None:\n-                    rel_id = 0\n-                else:\n-                    try:\n-                        rel_id = relation_types.get_id(rel_word)\n-                    except KeyError:\n-                        raise RuntimeError(\"Could not find relation type in config\")\n-\n-                counters[relation_configs[rel_id].lhs][lhs_word] += 1\n-                counters[relation_configs[rel_id].rhs][rhs_word] += 1\n-\n-    entities_by_type: Dict[str, Dictionary] = {}\n-    for entity_name, counter in counters.items():\n-        print(f\"Entity type {entity_name}:\")\n-        print(f\"- Found {len(counter)} entities\")\n-        if entity_min_count > 0:\n-            print(f\"- Removing the ones with fewer than {entity_min_count} occurrences...\")\n-            counter = Counter({k: c for k, c in counter.items()\n-                               if c >= entity_min_count})\n-            print(f\"- Left with {len(counter)} entities\")\n-        print(\"- Shuffling them...\")\n-        names = list(counter.keys())\n-        random.shuffle(names)\n-        entities_by_type[entity_name] = Dictionary(\n-            names, num_parts=entity_configs[entity_name].num_partitions)\n-\n-    return entities_by_type\n-\n-\n-def generate_entity_path_files(\n-    entity_storage: AbstractEntityStorage,\n-    entities_by_type: Dict[str, Dictionary],\n-    relation_type_storage: AbstractRelationTypeStorage,\n-    relation_types: Dictionary,\n-    dynamic_relations: bool,\n-) -> None:\n-    print(f\"Preparing counts and dictionaries for entities and relation types:\")\n-    entity_storage.prepare()\n-    relation_type_storage.prepare()\n-\n-    for entity_name, entities in entities_by_type.items():\n-        for part in range(entities.num_parts):\n-            print(f\"- Writing count of entity type {entity_name} \"\n-                  f\"and partition {part}\")\n-            entity_storage.save_count(entity_name, part, entities.part_size(part))\n-            entity_storage.save_names(entity_name, part, entities.get_part_list(part))\n-\n-    if dynamic_relations:\n-        print(\"- Writing count of dynamic relations\")\n-        relation_type_storage.save_count(relation_types.size())\n-        relation_type_storage.save_names(relation_types.get_list())\n-\n-\n-def generate_edge_path_files(\n-    edge_file_in: Path,\n-    edge_path_out: Path,\n-    edge_storage: AbstractEdgeStorage,\n-    entities_by_type: Dict[str, Dictionary],\n-    relation_types: Dictionary,\n-    relation_configs: List[RelationSchema],\n-    dynamic_relations: bool,\n-    lhs_col: int,\n-    rhs_col: int,\n-    rel_col: Optional[int],\n-) -> None:\n-    print(f\"Preparing edge path {edge_path_out}, \"\n-          f\"out of the edges found in {edge_file_in}\")\n-    edge_storage.prepare()\n-\n-    num_lhs_parts = max(entities_by_type[rconfig.lhs].num_parts\n-                        for rconfig in relation_configs)\n-    num_rhs_parts = max(entities_by_type[rconfig.rhs].num_parts\n-                        for rconfig in relation_configs)\n-\n-    print(f\"- Edges will be partitioned in {num_lhs_parts} x {num_rhs_parts} buckets.\")\n-\n-    processed = 0\n-    skipped = 0\n-\n-    # We use an ExitStack in order to close the dynamically-created edge appenders.\n-    with edge_file_in.open(\"rt\") as tf, ExitStack() as appender_stack:\n-        appenders: Dict[Tuple[int, int], AbstractEdgeAppender] = {}\n-        for line_num, line in enumerate(tf, start=1):\n-            words = line.split()\n-            try:\n-                lhs_word = words[lhs_col]\n-                rhs_word = words[rhs_col]\n-                rel_word = words[rel_col] if rel_col is not None else None\n-            except IndexError:\n-                raise RuntimeError(\n-                    f\"Line {line_num} of {edge_file_in} has only {len(words)} words\"\n-                ) from None\n-\n-            if rel_col is None:\n-                rel_id = 0\n-            else:\n-                try:\n-                    rel_id = relation_types.get_id(rel_word)\n-                except KeyError:\n-                    # Ignore edges whose relation type is not known.\n-                    skipped += 1\n-                    continue\n-\n-            if dynamic_relations:\n-                lhs_type = relation_configs[0].lhs\n-                rhs_type = relation_configs[0].rhs\n-            else:\n-                lhs_type = relation_configs[rel_id].lhs\n-                rhs_type = relation_configs[rel_id].rhs\n-\n-            try:\n-                lhs_part, lhs_offset = \\\n-                    entities_by_type[lhs_type].get_partition(lhs_word)\n-                rhs_part, rhs_offset = \\\n-                    entities_by_type[rhs_type].get_partition(rhs_word)\n-            except KeyError:\n-                # Ignore edges whose entities are not known.\n-                skipped += 1\n-                continue\n-\n-            if (lhs_part, rhs_part) not in appenders:\n-                appenders[lhs_part, rhs_part] = appender_stack.enter_context(\n-                    edge_storage.save_edges_by_appending(lhs_part, rhs_part))\n-            appenders[lhs_part, rhs_part].append_edges(EdgeList(\n-                EntityList.from_tensor(torch.tensor([lhs_offset], dtype=torch.long)),\n-                EntityList.from_tensor(torch.tensor([rhs_offset], dtype=torch.long)),\n-                torch.tensor([rel_id], dtype=torch.long),\n-            ))\n-\n-            processed = processed + 1\n-            if processed % 100000 == 0:\n-                print(f\"- Processed {processed} edges so far...\")\n-\n-    print(f\"- Processed {processed} edges in total\")\n-    if skipped > 0:\n-        print(f\"- Skipped {skipped} edges because their relation type or \"\n-              f\"entities were unknown (either not given in the config or \"\n-              f\"filtered out as too rare).\")\n-\n-\n-def convert_input_data(\n-    entity_configs: Dict[str, EntitySchema],\n-    relation_configs: List[RelationSchema],\n-    entity_path: str,\n-    edge_paths_out: List[str],\n-    edge_paths_in: List[Path],\n-    lhs_col: int,\n-    rhs_col: int,\n-    rel_col: Optional[int] = None,\n-    entity_min_count: int = 1,\n-    relation_type_min_count: int = 1,\n-    dynamic_relations: bool = False,\n-) -> None:\n-    if len(edge_paths_in) != len(edge_paths_out):\n-        raise ValueError(\n-            f\"The edge paths passed as inputs ({edge_paths_in}) don't match \"\n-            f\"the ones specified as outputs ({edge_paths_out})\")\n-\n-    entity_storage = ENTITY_STORAGES.make_instance(entity_path)\n-    relation_type_storage = RELATION_TYPE_STORAGES.make_instance(entity_path)\n-    edge_storages = [EDGE_STORAGES.make_instance(ep) for ep in edge_paths_out]\n-\n-    some_files_exists = []\n-    some_files_exists.extend(\n-        entity_storage.has_count(entity_name, partition)\n-        for entity_name, entity_config in entity_configs.items()\n-        for partition in range(entity_config.num_partitions))\n-    some_files_exists.extend(\n-        entity_storage.has_names(entity_name, partition)\n-        for entity_name, entity_config in entity_configs.items()\n-        for partition in range(entity_config.num_partitions))\n-    if dynamic_relations:\n-        some_files_exists.append(relation_type_storage.has_count())\n-        some_files_exists.append(relation_type_storage.has_names())\n-    some_files_exists.extend(\n-        edge_storage.has_edges(0, 0) for edge_storage in edge_storages)\n-\n-    if all(some_files_exists):\n-        print(\"Found some files that indicate that the input data \"\n-              \"has already been preprocessed, not doing it again.\")\n-        all_paths = \", \".join(str(p) for p in [entity_path] + edge_paths_out)\n-        print(f\"These files are in: {all_paths}\")\n-        return\n-\n-    relation_types = collect_relation_types(\n-        relation_configs,\n-        edge_paths_in,\n-        dynamic_relations,\n-        rel_col,\n-        relation_type_min_count,\n-    )\n-\n-    entities_by_type = collect_entities_by_type(\n-        relation_types,\n-        entity_configs,\n-        relation_configs,\n-        edge_paths_in,\n-        dynamic_relations,\n-        lhs_col,\n-        rhs_col,\n-        rel_col,\n-        entity_min_count,\n-    )\n-\n-    generate_entity_path_files(\n-        entity_storage,\n-        entities_by_type,\n-        relation_type_storage,\n-        relation_types,\n-        dynamic_relations,\n-    )\n-\n-    for edge_path_in, edge_path_out, edge_storage \\\n-            in zip(edge_paths_in, edge_paths_out, edge_storages):\n-        generate_edge_path_files(\n-            edge_path_in,\n-            edge_path_out,\n-            edge_storage,\n-            entities_by_type,\n-            relation_types,\n-            relation_configs,\n-            dynamic_relations,\n-            lhs_col,\n-            rhs_col,\n-            rel_col,\n-        )\n-\n-\n-def parse_config_partial(\n-    config_dict: Any,\n-) -> Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]:\n-    entities_config = config_dict.get(\"entities\")\n-    relations_config = config_dict.get(\"relations\")\n-    entity_path = config_dict.get(\"entity_path\")\n-    edge_paths = config_dict.get(\"edge_paths\")\n-    dynamic_relations = config_dict.get(\"dynamic_relations\", False)\n-    if not isinstance(entities_config, dict):\n-        raise TypeError(\"Config entities is not of type dict\")\n-    if any(not isinstance(k, str) for k in entities_config.keys()):\n-        raise TypeError(\"Config entities has some keys that are not of type str\")\n-    if not isinstance(relations_config, list):\n-        raise TypeError(\"Config relations is not of type list\")\n-    if not isinstance(entity_path, str):\n-        raise TypeError(\"Config entity_path is not of type str\")\n-    if not isinstance(edge_paths, list):\n-        raise TypeError(\"Config edge_paths is not of type list\")\n-    if any(not isinstance(p, str) for p in edge_paths):\n-        raise TypeError(\"Config edge_paths has some items that are not of type str\")\n-    if not isinstance(dynamic_relations, bool):\n-        raise TypeError(\"Config dynamic_relations is not of type bool\")\n-\n-    entities = {}\n-    relations = []\n-    for entity, entity_config in entities_config.items():\n-        entities[entity] = EntitySchema.from_dict(entity_config)\n-    for relation in relations_config:\n-        relations.append(RelationSchema.from_dict(relation))\n-\n-    return entities, relations, entity_path, edge_paths, dynamic_relations\n-\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent": "    ConfigSchema,\n    override_config_dict,\n)\n\n",
        "target_code_with_indent_exact_match": true,
        "source_code_with_indent": "    ConfigSchema,\n    EntitySchema,\n    RelationSchema,\n    override_config_dict,\n)\nfrom torchbiggraph.converters.dictionary import Dictionary\nfrom torchbiggraph.edgelist import EdgeList\nfrom torchbiggraph.entitylist import EntityList\nfrom torchbiggraph.graph_storages import (\n    AbstractEdgeAppender,\n    AbstractEdgeStorage,\n    AbstractEntityStorage,\n    AbstractRelationTypeStorage,\n    EDGE_STORAGES,\n    ENTITY_STORAGES,\n    RELATION_TYPE_STORAGES,\n)\n\n\ndef collect_relation_types(\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    rel_col: Optional[int],\n    relation_type_min_count: int,\n) -> Dictionary:\n\n    <IND>if dynamic_relations:\n        <IND>if rel_col is None:\n            <IND>raise RuntimeError(\"Need to specify rel_col in dynamic mode.\")\n        <DED>print(\"Looking up relation types in the edge files...\")\n        counter: Counter[str] = Counter()\n        for edgepath in edge_paths:\n            <IND>with edgepath.open(\"rt\") as tf:\n                <IND>for line_num, line in enumerate(tf, start=1):\n                    <IND>words = line.split()\n                    try:\n                        <IND>rel_word = words[rel_col]\n                    <DED>except IndexError:\n                        <IND>raise RuntimeError(\n                            f\"Line {line_num} of {edgepath} has only {len(words)} words\"\n                        ) from None\n                    <DED>counter[rel_word] += 1\n        <DED><DED><DED>print(f\"- Found {len(counter)} relation types\")\n        if relation_type_min_count > 0:\n            <IND>print(f\"- Removing the ones with fewer than {relation_type_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= relation_type_min_count})\n            print(f\"- Left with {len(counter)} relation types\")\n        <DED>print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n\n    <DED>else:\n        <IND>names = [rconfig.name for rconfig in relation_configs]\n        print(f\"Using the {len(names)} relation types given in the config\")\n\n    <DED>return Dictionary(names)\n\n\n<DED>def collect_entities_by_type(\n    relation_types: Dictionary,\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n    entity_min_count: int,\n) -> Dict[str, Dictionary]:\n\n    <IND>counters: Dict[str, Counter[str]] = {}\n    for entity_name in entity_configs.keys():\n        <IND>counters[entity_name] = Counter()\n\n    <DED>print(\"Searching for the entities in the edge files...\")\n    for edgepath in edge_paths:\n        <IND>with edgepath.open(\"rt\") as tf:\n            <IND>for line_num, line in enumerate(tf, start=1):\n                <IND>words = line.split()\n                try:\n                    <IND>lhs_word = words[lhs_col]\n                    rhs_word = words[rhs_col]\n                    rel_word = words[rel_col] if rel_col is not None else None\n                <DED>except IndexError:\n                    <IND>raise RuntimeError(\n                        \"Line %d of %s has only %d words\"\n                        % (line_num, edgepath, len(words))) from None\n\n                <DED>if dynamic_relations or rel_col is None:\n                    <IND>rel_id = 0\n                <DED>else:\n                    <IND>try:\n                        <IND>rel_id = relation_types.get_id(rel_word)\n                    <DED>except KeyError:\n                        <IND>raise RuntimeError(\"Could not find relation type in config\")\n\n                <DED><DED>counters[relation_configs[rel_id].lhs][lhs_word] += 1\n                counters[relation_configs[rel_id].rhs][rhs_word] += 1\n\n    <DED><DED><DED>entities_by_type: Dict[str, Dictionary] = {}\n    for entity_name, counter in counters.items():\n        <IND>print(f\"Entity type {entity_name}:\")\n        print(f\"- Found {len(counter)} entities\")\n        if entity_min_count > 0:\n            <IND>print(f\"- Removing the ones with fewer than {entity_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= entity_min_count})\n            print(f\"- Left with {len(counter)} entities\")\n        <DED>print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n        entities_by_type[entity_name] = Dictionary(\n            names, num_parts=entity_configs[entity_name].num_partitions)\n\n    <DED>return entities_by_type\n\n\n<DED>def generate_entity_path_files(\n    entity_storage: AbstractEntityStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_type_storage: AbstractRelationTypeStorage,\n    relation_types: Dictionary,\n    dynamic_relations: bool,\n) -> None:\n    <IND>print(f\"Preparing counts and dictionaries for entities and relation types:\")\n    entity_storage.prepare()\n    relation_type_storage.prepare()\n\n    for entity_name, entities in entities_by_type.items():\n        <IND>for part in range(entities.num_parts):\n            <IND>print(f\"- Writing count of entity type {entity_name} \"\n                  f\"and partition {part}\")\n            entity_storage.save_count(entity_name, part, entities.part_size(part))\n            entity_storage.save_names(entity_name, part, entities.get_part_list(part))\n\n    <DED><DED>if dynamic_relations:\n        <IND>print(\"- Writing count of dynamic relations\")\n        relation_type_storage.save_count(relation_types.size())\n        relation_type_storage.save_names(relation_types.get_list())\n\n\n<DED><DED>def generate_edge_path_files(\n    edge_file_in: Path,\n    edge_path_out: Path,\n    edge_storage: AbstractEdgeStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_types: Dictionary,\n    relation_configs: List[RelationSchema],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n) -> None:\n    <IND>print(f\"Preparing edge path {edge_path_out}, \"\n          f\"out of the edges found in {edge_file_in}\")\n    edge_storage.prepare()\n\n    num_lhs_parts = max(entities_by_type[rconfig.lhs].num_parts\n                        for rconfig in relation_configs)\n    num_rhs_parts = max(entities_by_type[rconfig.rhs].num_parts\n                        for rconfig in relation_configs)\n\n    print(f\"- Edges will be partitioned in {num_lhs_parts} x {num_rhs_parts} buckets.\")\n\n    processed = 0\n    skipped = 0\n\n    # We use an ExitStack in order to close the dynamically-created edge appenders.\n    with edge_file_in.open(\"rt\") as tf, ExitStack() as appender_stack:\n        <IND>appenders: Dict[Tuple[int, int], AbstractEdgeAppender] = {}\n        for line_num, line in enumerate(tf, start=1):\n            <IND>words = line.split()\n            try:\n                <IND>lhs_word = words[lhs_col]\n                rhs_word = words[rhs_col]\n                rel_word = words[rel_col] if rel_col is not None else None\n            <DED>except IndexError:\n                <IND>raise RuntimeError(\n                    f\"Line {line_num} of {edge_file_in} has only {len(words)} words\"\n                ) from None\n\n            <DED>if rel_col is None:\n                <IND>rel_id = 0\n            <DED>else:\n                <IND>try:\n                    <IND>rel_id = relation_types.get_id(rel_word)\n                <DED>except KeyError:\n                    # Ignore edges whose relation type is not known.\n                    <IND>skipped += 1\n                    continue\n\n            <DED><DED>if dynamic_relations:\n                <IND>lhs_type = relation_configs[0].lhs\n                rhs_type = relation_configs[0].rhs\n            <DED>else:\n                <IND>lhs_type = relation_configs[rel_id].lhs\n                rhs_type = relation_configs[rel_id].rhs\n\n            <DED>try:\n                <IND>lhs_part, lhs_offset =                    entities_by_type[lhs_type].get_partition(lhs_word)\n                rhs_part, rhs_offset =                    entities_by_type[rhs_type].get_partition(rhs_word)\n            <DED>except KeyError:\n                # Ignore edges whose entities are not known.\n                <IND>skipped += 1\n                continue\n\n            <DED>if (lhs_part, rhs_part) not in appenders:\n                <IND>appenders[lhs_part, rhs_part] = appender_stack.enter_context(\n                    edge_storage.save_edges_by_appending(lhs_part, rhs_part))\n            <DED>appenders[lhs_part, rhs_part].append_edges(EdgeList(\n                EntityList.from_tensor(torch.tensor([lhs_offset], dtype=torch.long)),\n                EntityList.from_tensor(torch.tensor([rhs_offset], dtype=torch.long)),\n                torch.tensor([rel_id], dtype=torch.long),\n            ))\n\n            processed = processed + 1\n            if processed % 100000 == 0:\n                <IND>print(f\"- Processed {processed} edges so far...\")\n\n    <DED><DED><DED>print(f\"- Processed {processed} edges in total\")\n    if skipped > 0:\n        <IND>print(f\"- Skipped {skipped} edges because their relation type or \"\n              f\"entities were unknown (either not given in the config or \"\n              f\"filtered out as too rare).\")\n\n\n<DED><DED>def convert_input_data(\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    entity_path: str,\n    edge_paths_out: List[str],\n    edge_paths_in: List[Path],\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int] = None,\n    entity_min_count: int = 1,\n    relation_type_min_count: int = 1,\n    dynamic_relations: bool = False,\n) -> None:\n    <IND>if len(edge_paths_in) != len(edge_paths_out):\n        <IND>raise ValueError(\n            f\"The edge paths passed as inputs ({edge_paths_in}) don't match \"\n            f\"the ones specified as outputs ({edge_paths_out})\")\n\n    <DED>entity_storage = ENTITY_STORAGES.make_instance(entity_path)\n    relation_type_storage = RELATION_TYPE_STORAGES.make_instance(entity_path)\n    edge_storages = [EDGE_STORAGES.make_instance(ep) for ep in edge_paths_out]\n\n    some_files_exists = []\n    some_files_exists.extend(\n        entity_storage.has_count(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    some_files_exists.extend(\n        entity_storage.has_names(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    if dynamic_relations:\n        <IND>some_files_exists.append(relation_type_storage.has_count())\n        some_files_exists.append(relation_type_storage.has_names())\n    <DED>some_files_exists.extend(\n        edge_storage.has_edges(0, 0) for edge_storage in edge_storages)\n\n    if all(some_files_exists):\n        <IND>print(\"Found some files that indicate that the input data \"\n              \"has already been preprocessed, not doing it again.\")\n        all_paths = \", \".join(str(p) for p in [entity_path] + edge_paths_out)\n        print(f\"These files are in: {all_paths}\")\n        return\n\n    <DED>relation_types = collect_relation_types(\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        rel_col,\n        relation_type_min_count,\n    )\n\n    entities_by_type = collect_entities_by_type(\n        relation_types,\n        entity_configs,\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        lhs_col,\n        rhs_col,\n        rel_col,\n        entity_min_count,\n    )\n\n    generate_entity_path_files(\n        entity_storage,\n        entities_by_type,\n        relation_type_storage,\n        relation_types,\n        dynamic_relations,\n    )\n\n    for edge_path_in, edge_path_out, edge_storage            in zip(edge_paths_in, edge_paths_out, edge_storages):\n        <IND>generate_edge_path_files(\n            edge_path_in,\n            edge_path_out,\n            edge_storage,\n            entities_by_type,\n            relation_types,\n            relation_configs,\n            dynamic_relations,\n            lhs_col,\n            rhs_col,\n            rel_col,\n        )\n\n\n<DED><DED>def parse_config_partial(\n    config_dict: Any,\n) -> Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]:\n    <IND>entities_config = config_dict.get(\"entities\")\n    relations_config = config_dict.get(\"relations\")\n    entity_path = config_dict.get(\"entity_path\")\n    edge_paths = config_dict.get(\"edge_paths\")\n    dynamic_relations = config_dict.get(\"dynamic_relations\", False)\n    if not isinstance(entities_config, dict):\n        <IND>raise TypeError(\"Config entities is not of type dict\")\n    <DED>if any(not isinstance(k, str) for k in entities_config.keys()):\n        <IND>raise TypeError(\"Config entities has some keys that are not of type str\")\n    <DED>if not isinstance(relations_config, list):\n        <IND>raise TypeError(\"Config relations is not of type list\")\n    <DED>if not isinstance(entity_path, str):\n        <IND>raise TypeError(\"Config entity_path is not of type str\")\n    <DED>if not isinstance(edge_paths, list):\n        <IND>raise TypeError(\"Config edge_paths is not of type list\")\n    <DED>if any(not isinstance(p, str) for p in edge_paths):\n        <IND>raise TypeError(\"Config edge_paths has some items that are not of type str\")\n    <DED>if not isinstance(dynamic_relations, bool):\n        <IND>raise TypeError(\"Config dynamic_relations is not of type bool\")\n\n    <DED>entities = {}\n    relations = []\n    for entity, entity_config in entities_config.items():\n        <IND>entities[entity] = EntitySchema.from_dict(entity_config)\n    <DED>for relation in relations_config:\n        <IND>relations.append(RelationSchema.from_dict(relation))\n\n    <DED>return entities, relations, entity_path, edge_paths, dynamic_relations\n\n\n"
      }
    ]
  },
  {
    "project": "facebookresearch/PyTorch-BigGraph",
    "commit": "fb0b3ae1a85087f31f730cd4cd43f733c2bd35a3",
    "filename": "torchbiggraph/converters/import_from_tsv.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/facebookresearch-PyTorch-BigGraph/torchbiggraph/converters/import_from_tsv.py",
    "file_hunks_size": 5,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": true,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "torchbiggraph/converters/import_from_tsv.py:94:32 Call error [29]: `typing._Alias` is not a function.",
    "message": " `typing._Alias` is not a function.",
    "rule_id": "Call error [29]",
    "warning_line_no": 94,
    "warning_line": "        counters[entity_name] = Counter()",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "    ConfigSchema,\n    EntitySchema,\n    RelationSchema,\n    override_config_dict,\n)\nfrom torchbiggraph.converters.dictionary import Dictionary\nfrom torchbiggraph.edgelist import EdgeList\nfrom torchbiggraph.entitylist import EntityList\nfrom torchbiggraph.graph_storages import (\n    AbstractEdgeAppender,\n    AbstractEdgeStorage,\n    AbstractEntityStorage,\n    AbstractRelationTypeStorage,\n    EDGE_STORAGES,\n    ENTITY_STORAGES,\n    RELATION_TYPE_STORAGES,\n)\n\n\ndef collect_relation_types(\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    rel_col: Optional[int],\n    relation_type_min_count: int,\n) -> Dictionary:\n\n    if dynamic_relations:\n        if rel_col is None:\n            raise RuntimeError(\"Need to specify rel_col in dynamic mode.\")\n        print(\"Looking up relation types in the edge files...\")\n        counter: Counter[str] = Counter()\n        for edgepath in edge_paths:\n            with edgepath.open(\"rt\") as tf:\n                for line_num, line in enumerate(tf, start=1):\n                    words = line.split()\n                    try:\n                        rel_word = words[rel_col]\n                    except IndexError:\n                        raise RuntimeError(\n                            f\"Line {line_num} of {edgepath} has only {len(words)} words\"\n                        ) from None\n                    counter[rel_word] += 1\n        print(f\"- Found {len(counter)} relation types\")\n        if relation_type_min_count > 0:\n            print(f\"- Removing the ones with fewer than {relation_type_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= relation_type_min_count})\n            print(f\"- Left with {len(counter)} relation types\")\n        print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n\n    else:\n        names = [rconfig.name for rconfig in relation_configs]\n        print(f\"Using the {len(names)} relation types given in the config\")\n\n    return Dictionary(names)\n\n\ndef collect_entities_by_type(\n    relation_types: Dictionary,\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n    entity_min_count: int,\n) -> Dict[str, Dictionary]:\n\n    counters: Dict[str, Counter[str]] = {}\n    for entity_name in entity_configs.keys():\n        counters[entity_name] = Counter()\n\n    print(\"Searching for the entities in the edge files...\")\n    for edgepath in edge_paths:\n        with edgepath.open(\"rt\") as tf:\n            for line_num, line in enumerate(tf, start=1):\n                words = line.split()\n                try:\n                    lhs_word = words[lhs_col]\n                    rhs_word = words[rhs_col]\n                    rel_word = words[rel_col] if rel_col is not None else None\n                except IndexError:\n                    raise RuntimeError(\n                        \"Line %d of %s has only %d words\"\n                        % (line_num, edgepath, len(words))) from None\n\n                if dynamic_relations or rel_col is None:\n                    rel_id = 0\n                else:\n                    try:\n                        rel_id = relation_types.get_id(rel_word)\n                    except KeyError:\n                        raise RuntimeError(\"Could not find relation type in config\")\n\n                counters[relation_configs[rel_id].lhs][lhs_word] += 1\n                counters[relation_configs[rel_id].rhs][rhs_word] += 1\n\n    entities_by_type: Dict[str, Dictionary] = {}\n    for entity_name, counter in counters.items():\n        print(f\"Entity type {entity_name}:\")\n        print(f\"- Found {len(counter)} entities\")\n        if entity_min_count > 0:\n            print(f\"- Removing the ones with fewer than {entity_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= entity_min_count})\n            print(f\"- Left with {len(counter)} entities\")\n        print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n        entities_by_type[entity_name] = Dictionary(\n            names, num_parts=entity_configs[entity_name].num_partitions)\n\n    return entities_by_type\n\n\ndef generate_entity_path_files(\n    entity_storage: AbstractEntityStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_type_storage: AbstractRelationTypeStorage,\n    relation_types: Dictionary,\n    dynamic_relations: bool,\n) -> None:\n    print(f\"Preparing counts and dictionaries for entities and relation types:\")\n    entity_storage.prepare()\n    relation_type_storage.prepare()\n\n    for entity_name, entities in entities_by_type.items():\n        for part in range(entities.num_parts):\n            print(f\"- Writing count of entity type {entity_name} \"\n                  f\"and partition {part}\")\n            entity_storage.save_count(entity_name, part, entities.part_size(part))\n            entity_storage.save_names(entity_name, part, entities.get_part_list(part))\n\n    if dynamic_relations:\n        print(\"- Writing count of dynamic relations\")\n        relation_type_storage.save_count(relation_types.size())\n        relation_type_storage.save_names(relation_types.get_list())\n\n\ndef generate_edge_path_files(\n    edge_file_in: Path,\n    edge_path_out: Path,\n    edge_storage: AbstractEdgeStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_types: Dictionary,\n    relation_configs: List[RelationSchema],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n) -> None:\n    print(f\"Preparing edge path {edge_path_out}, \"\n          f\"out of the edges found in {edge_file_in}\")\n    edge_storage.prepare()\n\n    num_lhs_parts = max(entities_by_type[rconfig.lhs].num_parts\n                        for rconfig in relation_configs)\n    num_rhs_parts = max(entities_by_type[rconfig.rhs].num_parts\n                        for rconfig in relation_configs)\n\n    print(f\"- Edges will be partitioned in {num_lhs_parts} x {num_rhs_parts} buckets.\")\n\n    processed = 0\n    skipped = 0\n\n    # We use an ExitStack in order to close the dynamically-created edge appenders.\n    with edge_file_in.open(\"rt\") as tf, ExitStack() as appender_stack:\n        appenders: Dict[Tuple[int, int], AbstractEdgeAppender] = {}\n        for line_num, line in enumerate(tf, start=1):\n            words = line.split()\n            try:\n                lhs_word = words[lhs_col]\n                rhs_word = words[rhs_col]\n                rel_word = words[rel_col] if rel_col is not None else None\n            except IndexError:\n                raise RuntimeError(\n                    f\"Line {line_num} of {edge_file_in} has only {len(words)} words\"\n                ) from None\n\n            if rel_col is None:\n                rel_id = 0\n            else:\n                try:\n                    rel_id = relation_types.get_id(rel_word)\n                except KeyError:\n                    # Ignore edges whose relation type is not known.\n                    skipped += 1\n                    continue\n\n            if dynamic_relations:\n                lhs_type = relation_configs[0].lhs\n                rhs_type = relation_configs[0].rhs\n            else:\n                lhs_type = relation_configs[rel_id].lhs\n                rhs_type = relation_configs[rel_id].rhs\n\n            try:\n                lhs_part, lhs_offset = \\\n                    entities_by_type[lhs_type].get_partition(lhs_word)\n                rhs_part, rhs_offset = \\\n                    entities_by_type[rhs_type].get_partition(rhs_word)\n            except KeyError:\n                # Ignore edges whose entities are not known.\n                skipped += 1\n                continue\n\n            if (lhs_part, rhs_part) not in appenders:\n                appenders[lhs_part, rhs_part] = appender_stack.enter_context(\n                    edge_storage.save_edges_by_appending(lhs_part, rhs_part))\n            appenders[lhs_part, rhs_part].append_edges(EdgeList(\n                EntityList.from_tensor(torch.tensor([lhs_offset], dtype=torch.long)),\n                EntityList.from_tensor(torch.tensor([rhs_offset], dtype=torch.long)),\n                torch.tensor([rel_id], dtype=torch.long),\n            ))\n\n            processed = processed + 1\n            if processed % 100000 == 0:\n                print(f\"- Processed {processed} edges so far...\")\n\n    print(f\"- Processed {processed} edges in total\")\n    if skipped > 0:\n        print(f\"- Skipped {skipped} edges because their relation type or \"\n              f\"entities were unknown (either not given in the config or \"\n              f\"filtered out as too rare).\")\n\n\ndef convert_input_data(\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    entity_path: str,\n    edge_paths_out: List[str],\n    edge_paths_in: List[Path],\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int] = None,\n    entity_min_count: int = 1,\n    relation_type_min_count: int = 1,\n    dynamic_relations: bool = False,\n) -> None:\n    if len(edge_paths_in) != len(edge_paths_out):\n        raise ValueError(\n            f\"The edge paths passed as inputs ({edge_paths_in}) don't match \"\n            f\"the ones specified as outputs ({edge_paths_out})\")\n\n    entity_storage = ENTITY_STORAGES.make_instance(entity_path)\n    relation_type_storage = RELATION_TYPE_STORAGES.make_instance(entity_path)\n    edge_storages = [EDGE_STORAGES.make_instance(ep) for ep in edge_paths_out]\n\n    some_files_exists = []\n    some_files_exists.extend(\n        entity_storage.has_count(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    some_files_exists.extend(\n        entity_storage.has_names(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    if dynamic_relations:\n        some_files_exists.append(relation_type_storage.has_count())\n        some_files_exists.append(relation_type_storage.has_names())\n    some_files_exists.extend(\n        edge_storage.has_edges(0, 0) for edge_storage in edge_storages)\n\n    if all(some_files_exists):\n        print(\"Found some files that indicate that the input data \"\n              \"has already been preprocessed, not doing it again.\")\n        all_paths = \", \".join(str(p) for p in [entity_path] + edge_paths_out)\n        print(f\"These files are in: {all_paths}\")\n        return\n\n    relation_types = collect_relation_types(\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        rel_col,\n        relation_type_min_count,\n    )\n\n    entities_by_type = collect_entities_by_type(\n        relation_types,\n        entity_configs,\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        lhs_col,\n        rhs_col,\n        rel_col,\n        entity_min_count,\n    )\n\n    generate_entity_path_files(\n        entity_storage,\n        entities_by_type,\n        relation_type_storage,\n        relation_types,\n        dynamic_relations,\n    )\n\n    for edge_path_in, edge_path_out, edge_storage \\\n            in zip(edge_paths_in, edge_paths_out, edge_storages):\n        generate_edge_path_files(\n            edge_path_in,\n            edge_path_out,\n            edge_storage,\n            entities_by_type,\n            relation_types,\n            relation_configs,\n            dynamic_relations,\n            lhs_col,\n            rhs_col,\n            rel_col,\n        )\n\n\ndef parse_config_partial(\n    config_dict: Any,\n) -> Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]:\n    entities_config = config_dict.get(\"entities\")\n    relations_config = config_dict.get(\"relations\")\n    entity_path = config_dict.get(\"entity_path\")\n    edge_paths = config_dict.get(\"edge_paths\")\n    dynamic_relations = config_dict.get(\"dynamic_relations\", False)\n    if not isinstance(entities_config, dict):\n        raise TypeError(\"Config entities is not of type dict\")\n    if any(not isinstance(k, str) for k in entities_config.keys()):\n        raise TypeError(\"Config entities has some keys that are not of type str\")\n    if not isinstance(relations_config, list):\n        raise TypeError(\"Config relations is not of type list\")\n    if not isinstance(entity_path, str):\n        raise TypeError(\"Config entity_path is not of type str\")\n    if not isinstance(edge_paths, list):\n        raise TypeError(\"Config edge_paths is not of type list\")\n    if any(not isinstance(p, str) for p in edge_paths):\n        raise TypeError(\"Config edge_paths has some items that are not of type str\")\n    if not isinstance(dynamic_relations, bool):\n        raise TypeError(\"Config dynamic_relations is not of type bool\")\n\n    entities = {}\n    relations = []\n    for entity, entity_config in entities_config.items():\n        entities[entity] = EntitySchema.from_dict(entity_config)\n    for relation in relations_config:\n        relations.append(RelationSchema.from_dict(relation))\n\n    return entities, relations, entity_path, edge_paths, dynamic_relations\n\n\n",
        "source_code_len": 13269,
        "target_code": "    ConfigSchema,\n    override_config_dict,\n)\n\n",
        "target_code_len": 47,
        "diff_format": "@@ -20,351 +20,4 @@\n     ConfigSchema,\n-    EntitySchema,\n-    RelationSchema,\n     override_config_dict,\n )\n-from torchbiggraph.converters.dictionary import Dictionary\n-from torchbiggraph.edgelist import EdgeList\n-from torchbiggraph.entitylist import EntityList\n-from torchbiggraph.graph_storages import (\n-    AbstractEdgeAppender,\n-    AbstractEdgeStorage,\n-    AbstractEntityStorage,\n-    AbstractRelationTypeStorage,\n-    EDGE_STORAGES,\n-    ENTITY_STORAGES,\n-    RELATION_TYPE_STORAGES,\n-)\n-\n-\n-def collect_relation_types(\n-    relation_configs: List[RelationSchema],\n-    edge_paths: List[Path],\n-    dynamic_relations: bool,\n-    rel_col: Optional[int],\n-    relation_type_min_count: int,\n-) -> Dictionary:\n-\n-    if dynamic_relations:\n-        if rel_col is None:\n-            raise RuntimeError(\"Need to specify rel_col in dynamic mode.\")\n-        print(\"Looking up relation types in the edge files...\")\n-        counter: Counter[str] = Counter()\n-        for edgepath in edge_paths:\n-            with edgepath.open(\"rt\") as tf:\n-                for line_num, line in enumerate(tf, start=1):\n-                    words = line.split()\n-                    try:\n-                        rel_word = words[rel_col]\n-                    except IndexError:\n-                        raise RuntimeError(\n-                            f\"Line {line_num} of {edgepath} has only {len(words)} words\"\n-                        ) from None\n-                    counter[rel_word] += 1\n-        print(f\"- Found {len(counter)} relation types\")\n-        if relation_type_min_count > 0:\n-            print(f\"- Removing the ones with fewer than {relation_type_min_count} occurrences...\")\n-            counter = Counter({k: c for k, c in counter.items()\n-                               if c >= relation_type_min_count})\n-            print(f\"- Left with {len(counter)} relation types\")\n-        print(\"- Shuffling them...\")\n-        names = list(counter.keys())\n-        random.shuffle(names)\n-\n-    else:\n-        names = [rconfig.name for rconfig in relation_configs]\n-        print(f\"Using the {len(names)} relation types given in the config\")\n-\n-    return Dictionary(names)\n-\n-\n-def collect_entities_by_type(\n-    relation_types: Dictionary,\n-    entity_configs: Dict[str, EntitySchema],\n-    relation_configs: List[RelationSchema],\n-    edge_paths: List[Path],\n-    dynamic_relations: bool,\n-    lhs_col: int,\n-    rhs_col: int,\n-    rel_col: Optional[int],\n-    entity_min_count: int,\n-) -> Dict[str, Dictionary]:\n-\n-    counters: Dict[str, Counter[str]] = {}\n-    for entity_name in entity_configs.keys():\n-        counters[entity_name] = Counter()\n-\n-    print(\"Searching for the entities in the edge files...\")\n-    for edgepath in edge_paths:\n-        with edgepath.open(\"rt\") as tf:\n-            for line_num, line in enumerate(tf, start=1):\n-                words = line.split()\n-                try:\n-                    lhs_word = words[lhs_col]\n-                    rhs_word = words[rhs_col]\n-                    rel_word = words[rel_col] if rel_col is not None else None\n-                except IndexError:\n-                    raise RuntimeError(\n-                        \"Line %d of %s has only %d words\"\n-                        % (line_num, edgepath, len(words))) from None\n-\n-                if dynamic_relations or rel_col is None:\n-                    rel_id = 0\n-                else:\n-                    try:\n-                        rel_id = relation_types.get_id(rel_word)\n-                    except KeyError:\n-                        raise RuntimeError(\"Could not find relation type in config\")\n-\n-                counters[relation_configs[rel_id].lhs][lhs_word] += 1\n-                counters[relation_configs[rel_id].rhs][rhs_word] += 1\n-\n-    entities_by_type: Dict[str, Dictionary] = {}\n-    for entity_name, counter in counters.items():\n-        print(f\"Entity type {entity_name}:\")\n-        print(f\"- Found {len(counter)} entities\")\n-        if entity_min_count > 0:\n-            print(f\"- Removing the ones with fewer than {entity_min_count} occurrences...\")\n-            counter = Counter({k: c for k, c in counter.items()\n-                               if c >= entity_min_count})\n-            print(f\"- Left with {len(counter)} entities\")\n-        print(\"- Shuffling them...\")\n-        names = list(counter.keys())\n-        random.shuffle(names)\n-        entities_by_type[entity_name] = Dictionary(\n-            names, num_parts=entity_configs[entity_name].num_partitions)\n-\n-    return entities_by_type\n-\n-\n-def generate_entity_path_files(\n-    entity_storage: AbstractEntityStorage,\n-    entities_by_type: Dict[str, Dictionary],\n-    relation_type_storage: AbstractRelationTypeStorage,\n-    relation_types: Dictionary,\n-    dynamic_relations: bool,\n-) -> None:\n-    print(f\"Preparing counts and dictionaries for entities and relation types:\")\n-    entity_storage.prepare()\n-    relation_type_storage.prepare()\n-\n-    for entity_name, entities in entities_by_type.items():\n-        for part in range(entities.num_parts):\n-            print(f\"- Writing count of entity type {entity_name} \"\n-                  f\"and partition {part}\")\n-            entity_storage.save_count(entity_name, part, entities.part_size(part))\n-            entity_storage.save_names(entity_name, part, entities.get_part_list(part))\n-\n-    if dynamic_relations:\n-        print(\"- Writing count of dynamic relations\")\n-        relation_type_storage.save_count(relation_types.size())\n-        relation_type_storage.save_names(relation_types.get_list())\n-\n-\n-def generate_edge_path_files(\n-    edge_file_in: Path,\n-    edge_path_out: Path,\n-    edge_storage: AbstractEdgeStorage,\n-    entities_by_type: Dict[str, Dictionary],\n-    relation_types: Dictionary,\n-    relation_configs: List[RelationSchema],\n-    dynamic_relations: bool,\n-    lhs_col: int,\n-    rhs_col: int,\n-    rel_col: Optional[int],\n-) -> None:\n-    print(f\"Preparing edge path {edge_path_out}, \"\n-          f\"out of the edges found in {edge_file_in}\")\n-    edge_storage.prepare()\n-\n-    num_lhs_parts = max(entities_by_type[rconfig.lhs].num_parts\n-                        for rconfig in relation_configs)\n-    num_rhs_parts = max(entities_by_type[rconfig.rhs].num_parts\n-                        for rconfig in relation_configs)\n-\n-    print(f\"- Edges will be partitioned in {num_lhs_parts} x {num_rhs_parts} buckets.\")\n-\n-    processed = 0\n-    skipped = 0\n-\n-    # We use an ExitStack in order to close the dynamically-created edge appenders.\n-    with edge_file_in.open(\"rt\") as tf, ExitStack() as appender_stack:\n-        appenders: Dict[Tuple[int, int], AbstractEdgeAppender] = {}\n-        for line_num, line in enumerate(tf, start=1):\n-            words = line.split()\n-            try:\n-                lhs_word = words[lhs_col]\n-                rhs_word = words[rhs_col]\n-                rel_word = words[rel_col] if rel_col is not None else None\n-            except IndexError:\n-                raise RuntimeError(\n-                    f\"Line {line_num} of {edge_file_in} has only {len(words)} words\"\n-                ) from None\n-\n-            if rel_col is None:\n-                rel_id = 0\n-            else:\n-                try:\n-                    rel_id = relation_types.get_id(rel_word)\n-                except KeyError:\n-                    # Ignore edges whose relation type is not known.\n-                    skipped += 1\n-                    continue\n-\n-            if dynamic_relations:\n-                lhs_type = relation_configs[0].lhs\n-                rhs_type = relation_configs[0].rhs\n-            else:\n-                lhs_type = relation_configs[rel_id].lhs\n-                rhs_type = relation_configs[rel_id].rhs\n-\n-            try:\n-                lhs_part, lhs_offset = \\\n-                    entities_by_type[lhs_type].get_partition(lhs_word)\n-                rhs_part, rhs_offset = \\\n-                    entities_by_type[rhs_type].get_partition(rhs_word)\n-            except KeyError:\n-                # Ignore edges whose entities are not known.\n-                skipped += 1\n-                continue\n-\n-            if (lhs_part, rhs_part) not in appenders:\n-                appenders[lhs_part, rhs_part] = appender_stack.enter_context(\n-                    edge_storage.save_edges_by_appending(lhs_part, rhs_part))\n-            appenders[lhs_part, rhs_part].append_edges(EdgeList(\n-                EntityList.from_tensor(torch.tensor([lhs_offset], dtype=torch.long)),\n-                EntityList.from_tensor(torch.tensor([rhs_offset], dtype=torch.long)),\n-                torch.tensor([rel_id], dtype=torch.long),\n-            ))\n-\n-            processed = processed + 1\n-            if processed % 100000 == 0:\n-                print(f\"- Processed {processed} edges so far...\")\n-\n-    print(f\"- Processed {processed} edges in total\")\n-    if skipped > 0:\n-        print(f\"- Skipped {skipped} edges because their relation type or \"\n-              f\"entities were unknown (either not given in the config or \"\n-              f\"filtered out as too rare).\")\n-\n-\n-def convert_input_data(\n-    entity_configs: Dict[str, EntitySchema],\n-    relation_configs: List[RelationSchema],\n-    entity_path: str,\n-    edge_paths_out: List[str],\n-    edge_paths_in: List[Path],\n-    lhs_col: int,\n-    rhs_col: int,\n-    rel_col: Optional[int] = None,\n-    entity_min_count: int = 1,\n-    relation_type_min_count: int = 1,\n-    dynamic_relations: bool = False,\n-) -> None:\n-    if len(edge_paths_in) != len(edge_paths_out):\n-        raise ValueError(\n-            f\"The edge paths passed as inputs ({edge_paths_in}) don't match \"\n-            f\"the ones specified as outputs ({edge_paths_out})\")\n-\n-    entity_storage = ENTITY_STORAGES.make_instance(entity_path)\n-    relation_type_storage = RELATION_TYPE_STORAGES.make_instance(entity_path)\n-    edge_storages = [EDGE_STORAGES.make_instance(ep) for ep in edge_paths_out]\n-\n-    some_files_exists = []\n-    some_files_exists.extend(\n-        entity_storage.has_count(entity_name, partition)\n-        for entity_name, entity_config in entity_configs.items()\n-        for partition in range(entity_config.num_partitions))\n-    some_files_exists.extend(\n-        entity_storage.has_names(entity_name, partition)\n-        for entity_name, entity_config in entity_configs.items()\n-        for partition in range(entity_config.num_partitions))\n-    if dynamic_relations:\n-        some_files_exists.append(relation_type_storage.has_count())\n-        some_files_exists.append(relation_type_storage.has_names())\n-    some_files_exists.extend(\n-        edge_storage.has_edges(0, 0) for edge_storage in edge_storages)\n-\n-    if all(some_files_exists):\n-        print(\"Found some files that indicate that the input data \"\n-              \"has already been preprocessed, not doing it again.\")\n-        all_paths = \", \".join(str(p) for p in [entity_path] + edge_paths_out)\n-        print(f\"These files are in: {all_paths}\")\n-        return\n-\n-    relation_types = collect_relation_types(\n-        relation_configs,\n-        edge_paths_in,\n-        dynamic_relations,\n-        rel_col,\n-        relation_type_min_count,\n-    )\n-\n-    entities_by_type = collect_entities_by_type(\n-        relation_types,\n-        entity_configs,\n-        relation_configs,\n-        edge_paths_in,\n-        dynamic_relations,\n-        lhs_col,\n-        rhs_col,\n-        rel_col,\n-        entity_min_count,\n-    )\n-\n-    generate_entity_path_files(\n-        entity_storage,\n-        entities_by_type,\n-        relation_type_storage,\n-        relation_types,\n-        dynamic_relations,\n-    )\n-\n-    for edge_path_in, edge_path_out, edge_storage \\\n-            in zip(edge_paths_in, edge_paths_out, edge_storages):\n-        generate_edge_path_files(\n-            edge_path_in,\n-            edge_path_out,\n-            edge_storage,\n-            entities_by_type,\n-            relation_types,\n-            relation_configs,\n-            dynamic_relations,\n-            lhs_col,\n-            rhs_col,\n-            rel_col,\n-        )\n-\n-\n-def parse_config_partial(\n-    config_dict: Any,\n-) -> Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]:\n-    entities_config = config_dict.get(\"entities\")\n-    relations_config = config_dict.get(\"relations\")\n-    entity_path = config_dict.get(\"entity_path\")\n-    edge_paths = config_dict.get(\"edge_paths\")\n-    dynamic_relations = config_dict.get(\"dynamic_relations\", False)\n-    if not isinstance(entities_config, dict):\n-        raise TypeError(\"Config entities is not of type dict\")\n-    if any(not isinstance(k, str) for k in entities_config.keys()):\n-        raise TypeError(\"Config entities has some keys that are not of type str\")\n-    if not isinstance(relations_config, list):\n-        raise TypeError(\"Config relations is not of type list\")\n-    if not isinstance(entity_path, str):\n-        raise TypeError(\"Config entity_path is not of type str\")\n-    if not isinstance(edge_paths, list):\n-        raise TypeError(\"Config edge_paths is not of type list\")\n-    if any(not isinstance(p, str) for p in edge_paths):\n-        raise TypeError(\"Config edge_paths has some items that are not of type str\")\n-    if not isinstance(dynamic_relations, bool):\n-        raise TypeError(\"Config dynamic_relations is not of type bool\")\n-\n-    entities = {}\n-    relations = []\n-    for entity, entity_config in entities_config.items():\n-        entities[entity] = EntitySchema.from_dict(entity_config)\n-    for relation in relations_config:\n-        relations.append(RelationSchema.from_dict(relation))\n-\n-    return entities, relations, entity_path, edge_paths, dynamic_relations\n-\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent": "    ConfigSchema,\n    override_config_dict,\n)\n\n",
        "target_code_with_indent_exact_match": true,
        "source_code_with_indent": "    ConfigSchema,\n    EntitySchema,\n    RelationSchema,\n    override_config_dict,\n)\nfrom torchbiggraph.converters.dictionary import Dictionary\nfrom torchbiggraph.edgelist import EdgeList\nfrom torchbiggraph.entitylist import EntityList\nfrom torchbiggraph.graph_storages import (\n    AbstractEdgeAppender,\n    AbstractEdgeStorage,\n    AbstractEntityStorage,\n    AbstractRelationTypeStorage,\n    EDGE_STORAGES,\n    ENTITY_STORAGES,\n    RELATION_TYPE_STORAGES,\n)\n\n\ndef collect_relation_types(\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    rel_col: Optional[int],\n    relation_type_min_count: int,\n) -> Dictionary:\n\n    <IND>if dynamic_relations:\n        <IND>if rel_col is None:\n            <IND>raise RuntimeError(\"Need to specify rel_col in dynamic mode.\")\n        <DED>print(\"Looking up relation types in the edge files...\")\n        counter: Counter[str] = Counter()\n        for edgepath in edge_paths:\n            <IND>with edgepath.open(\"rt\") as tf:\n                <IND>for line_num, line in enumerate(tf, start=1):\n                    <IND>words = line.split()\n                    try:\n                        <IND>rel_word = words[rel_col]\n                    <DED>except IndexError:\n                        <IND>raise RuntimeError(\n                            f\"Line {line_num} of {edgepath} has only {len(words)} words\"\n                        ) from None\n                    <DED>counter[rel_word] += 1\n        <DED><DED><DED>print(f\"- Found {len(counter)} relation types\")\n        if relation_type_min_count > 0:\n            <IND>print(f\"- Removing the ones with fewer than {relation_type_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= relation_type_min_count})\n            print(f\"- Left with {len(counter)} relation types\")\n        <DED>print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n\n    <DED>else:\n        <IND>names = [rconfig.name for rconfig in relation_configs]\n        print(f\"Using the {len(names)} relation types given in the config\")\n\n    <DED>return Dictionary(names)\n\n\n<DED>def collect_entities_by_type(\n    relation_types: Dictionary,\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n    entity_min_count: int,\n) -> Dict[str, Dictionary]:\n\n    <IND>counters: Dict[str, Counter[str]] = {}\n    for entity_name in entity_configs.keys():\n        <IND>counters[entity_name] = Counter()\n\n    <DED>print(\"Searching for the entities in the edge files...\")\n    for edgepath in edge_paths:\n        <IND>with edgepath.open(\"rt\") as tf:\n            <IND>for line_num, line in enumerate(tf, start=1):\n                <IND>words = line.split()\n                try:\n                    <IND>lhs_word = words[lhs_col]\n                    rhs_word = words[rhs_col]\n                    rel_word = words[rel_col] if rel_col is not None else None\n                <DED>except IndexError:\n                    <IND>raise RuntimeError(\n                        \"Line %d of %s has only %d words\"\n                        % (line_num, edgepath, len(words))) from None\n\n                <DED>if dynamic_relations or rel_col is None:\n                    <IND>rel_id = 0\n                <DED>else:\n                    <IND>try:\n                        <IND>rel_id = relation_types.get_id(rel_word)\n                    <DED>except KeyError:\n                        <IND>raise RuntimeError(\"Could not find relation type in config\")\n\n                <DED><DED>counters[relation_configs[rel_id].lhs][lhs_word] += 1\n                counters[relation_configs[rel_id].rhs][rhs_word] += 1\n\n    <DED><DED><DED>entities_by_type: Dict[str, Dictionary] = {}\n    for entity_name, counter in counters.items():\n        <IND>print(f\"Entity type {entity_name}:\")\n        print(f\"- Found {len(counter)} entities\")\n        if entity_min_count > 0:\n            <IND>print(f\"- Removing the ones with fewer than {entity_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= entity_min_count})\n            print(f\"- Left with {len(counter)} entities\")\n        <DED>print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n        entities_by_type[entity_name] = Dictionary(\n            names, num_parts=entity_configs[entity_name].num_partitions)\n\n    <DED>return entities_by_type\n\n\n<DED>def generate_entity_path_files(\n    entity_storage: AbstractEntityStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_type_storage: AbstractRelationTypeStorage,\n    relation_types: Dictionary,\n    dynamic_relations: bool,\n) -> None:\n    <IND>print(f\"Preparing counts and dictionaries for entities and relation types:\")\n    entity_storage.prepare()\n    relation_type_storage.prepare()\n\n    for entity_name, entities in entities_by_type.items():\n        <IND>for part in range(entities.num_parts):\n            <IND>print(f\"- Writing count of entity type {entity_name} \"\n                  f\"and partition {part}\")\n            entity_storage.save_count(entity_name, part, entities.part_size(part))\n            entity_storage.save_names(entity_name, part, entities.get_part_list(part))\n\n    <DED><DED>if dynamic_relations:\n        <IND>print(\"- Writing count of dynamic relations\")\n        relation_type_storage.save_count(relation_types.size())\n        relation_type_storage.save_names(relation_types.get_list())\n\n\n<DED><DED>def generate_edge_path_files(\n    edge_file_in: Path,\n    edge_path_out: Path,\n    edge_storage: AbstractEdgeStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_types: Dictionary,\n    relation_configs: List[RelationSchema],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n) -> None:\n    <IND>print(f\"Preparing edge path {edge_path_out}, \"\n          f\"out of the edges found in {edge_file_in}\")\n    edge_storage.prepare()\n\n    num_lhs_parts = max(entities_by_type[rconfig.lhs].num_parts\n                        for rconfig in relation_configs)\n    num_rhs_parts = max(entities_by_type[rconfig.rhs].num_parts\n                        for rconfig in relation_configs)\n\n    print(f\"- Edges will be partitioned in {num_lhs_parts} x {num_rhs_parts} buckets.\")\n\n    processed = 0\n    skipped = 0\n\n    # We use an ExitStack in order to close the dynamically-created edge appenders.\n    with edge_file_in.open(\"rt\") as tf, ExitStack() as appender_stack:\n        <IND>appenders: Dict[Tuple[int, int], AbstractEdgeAppender] = {}\n        for line_num, line in enumerate(tf, start=1):\n            <IND>words = line.split()\n            try:\n                <IND>lhs_word = words[lhs_col]\n                rhs_word = words[rhs_col]\n                rel_word = words[rel_col] if rel_col is not None else None\n            <DED>except IndexError:\n                <IND>raise RuntimeError(\n                    f\"Line {line_num} of {edge_file_in} has only {len(words)} words\"\n                ) from None\n\n            <DED>if rel_col is None:\n                <IND>rel_id = 0\n            <DED>else:\n                <IND>try:\n                    <IND>rel_id = relation_types.get_id(rel_word)\n                <DED>except KeyError:\n                    # Ignore edges whose relation type is not known.\n                    <IND>skipped += 1\n                    continue\n\n            <DED><DED>if dynamic_relations:\n                <IND>lhs_type = relation_configs[0].lhs\n                rhs_type = relation_configs[0].rhs\n            <DED>else:\n                <IND>lhs_type = relation_configs[rel_id].lhs\n                rhs_type = relation_configs[rel_id].rhs\n\n            <DED>try:\n                <IND>lhs_part, lhs_offset =                    entities_by_type[lhs_type].get_partition(lhs_word)\n                rhs_part, rhs_offset =                    entities_by_type[rhs_type].get_partition(rhs_word)\n            <DED>except KeyError:\n                # Ignore edges whose entities are not known.\n                <IND>skipped += 1\n                continue\n\n            <DED>if (lhs_part, rhs_part) not in appenders:\n                <IND>appenders[lhs_part, rhs_part] = appender_stack.enter_context(\n                    edge_storage.save_edges_by_appending(lhs_part, rhs_part))\n            <DED>appenders[lhs_part, rhs_part].append_edges(EdgeList(\n                EntityList.from_tensor(torch.tensor([lhs_offset], dtype=torch.long)),\n                EntityList.from_tensor(torch.tensor([rhs_offset], dtype=torch.long)),\n                torch.tensor([rel_id], dtype=torch.long),\n            ))\n\n            processed = processed + 1\n            if processed % 100000 == 0:\n                <IND>print(f\"- Processed {processed} edges so far...\")\n\n    <DED><DED><DED>print(f\"- Processed {processed} edges in total\")\n    if skipped > 0:\n        <IND>print(f\"- Skipped {skipped} edges because their relation type or \"\n              f\"entities were unknown (either not given in the config or \"\n              f\"filtered out as too rare).\")\n\n\n<DED><DED>def convert_input_data(\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    entity_path: str,\n    edge_paths_out: List[str],\n    edge_paths_in: List[Path],\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int] = None,\n    entity_min_count: int = 1,\n    relation_type_min_count: int = 1,\n    dynamic_relations: bool = False,\n) -> None:\n    <IND>if len(edge_paths_in) != len(edge_paths_out):\n        <IND>raise ValueError(\n            f\"The edge paths passed as inputs ({edge_paths_in}) don't match \"\n            f\"the ones specified as outputs ({edge_paths_out})\")\n\n    <DED>entity_storage = ENTITY_STORAGES.make_instance(entity_path)\n    relation_type_storage = RELATION_TYPE_STORAGES.make_instance(entity_path)\n    edge_storages = [EDGE_STORAGES.make_instance(ep) for ep in edge_paths_out]\n\n    some_files_exists = []\n    some_files_exists.extend(\n        entity_storage.has_count(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    some_files_exists.extend(\n        entity_storage.has_names(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    if dynamic_relations:\n        <IND>some_files_exists.append(relation_type_storage.has_count())\n        some_files_exists.append(relation_type_storage.has_names())\n    <DED>some_files_exists.extend(\n        edge_storage.has_edges(0, 0) for edge_storage in edge_storages)\n\n    if all(some_files_exists):\n        <IND>print(\"Found some files that indicate that the input data \"\n              \"has already been preprocessed, not doing it again.\")\n        all_paths = \", \".join(str(p) for p in [entity_path] + edge_paths_out)\n        print(f\"These files are in: {all_paths}\")\n        return\n\n    <DED>relation_types = collect_relation_types(\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        rel_col,\n        relation_type_min_count,\n    )\n\n    entities_by_type = collect_entities_by_type(\n        relation_types,\n        entity_configs,\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        lhs_col,\n        rhs_col,\n        rel_col,\n        entity_min_count,\n    )\n\n    generate_entity_path_files(\n        entity_storage,\n        entities_by_type,\n        relation_type_storage,\n        relation_types,\n        dynamic_relations,\n    )\n\n    for edge_path_in, edge_path_out, edge_storage            in zip(edge_paths_in, edge_paths_out, edge_storages):\n        <IND>generate_edge_path_files(\n            edge_path_in,\n            edge_path_out,\n            edge_storage,\n            entities_by_type,\n            relation_types,\n            relation_configs,\n            dynamic_relations,\n            lhs_col,\n            rhs_col,\n            rel_col,\n        )\n\n\n<DED><DED>def parse_config_partial(\n    config_dict: Any,\n) -> Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]:\n    <IND>entities_config = config_dict.get(\"entities\")\n    relations_config = config_dict.get(\"relations\")\n    entity_path = config_dict.get(\"entity_path\")\n    edge_paths = config_dict.get(\"edge_paths\")\n    dynamic_relations = config_dict.get(\"dynamic_relations\", False)\n    if not isinstance(entities_config, dict):\n        <IND>raise TypeError(\"Config entities is not of type dict\")\n    <DED>if any(not isinstance(k, str) for k in entities_config.keys()):\n        <IND>raise TypeError(\"Config entities has some keys that are not of type str\")\n    <DED>if not isinstance(relations_config, list):\n        <IND>raise TypeError(\"Config relations is not of type list\")\n    <DED>if not isinstance(entity_path, str):\n        <IND>raise TypeError(\"Config entity_path is not of type str\")\n    <DED>if not isinstance(edge_paths, list):\n        <IND>raise TypeError(\"Config edge_paths is not of type list\")\n    <DED>if any(not isinstance(p, str) for p in edge_paths):\n        <IND>raise TypeError(\"Config edge_paths has some items that are not of type str\")\n    <DED>if not isinstance(dynamic_relations, bool):\n        <IND>raise TypeError(\"Config dynamic_relations is not of type bool\")\n\n    <DED>entities = {}\n    relations = []\n    for entity, entity_config in entities_config.items():\n        <IND>entities[entity] = EntitySchema.from_dict(entity_config)\n    <DED>for relation in relations_config:\n        <IND>relations.append(RelationSchema.from_dict(relation))\n\n    <DED>return entities, relations, entity_path, edge_paths, dynamic_relations\n\n\n"
      }
    ]
  },
  {
    "project": "facebookresearch/PyTorch-BigGraph",
    "commit": "fb0b3ae1a85087f31f730cd4cd43f733c2bd35a3",
    "filename": "torchbiggraph/converters/import_from_tsv.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/facebookresearch-PyTorch-BigGraph/torchbiggraph/converters/import_from_tsv.py",
    "file_hunks_size": 5,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": true,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "torchbiggraph/converters/import_from_tsv.py:114:55 Incompatible parameter type [6]: Expected `str` for 1st positional only parameter to call `Dictionary.get_id` but got `Optional[str]`.",
    "message": " Expected `str` for 1st positional only parameter to call `Dictionary.get_id` but got `Optional[str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 114,
    "warning_line": "                        rel_id = relation_types.get_id(rel_word)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "    ConfigSchema,\n    EntitySchema,\n    RelationSchema,\n    override_config_dict,\n)\nfrom torchbiggraph.converters.dictionary import Dictionary\nfrom torchbiggraph.edgelist import EdgeList\nfrom torchbiggraph.entitylist import EntityList\nfrom torchbiggraph.graph_storages import (\n    AbstractEdgeAppender,\n    AbstractEdgeStorage,\n    AbstractEntityStorage,\n    AbstractRelationTypeStorage,\n    EDGE_STORAGES,\n    ENTITY_STORAGES,\n    RELATION_TYPE_STORAGES,\n)\n\n\ndef collect_relation_types(\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    rel_col: Optional[int],\n    relation_type_min_count: int,\n) -> Dictionary:\n\n    if dynamic_relations:\n        if rel_col is None:\n            raise RuntimeError(\"Need to specify rel_col in dynamic mode.\")\n        print(\"Looking up relation types in the edge files...\")\n        counter: Counter[str] = Counter()\n        for edgepath in edge_paths:\n            with edgepath.open(\"rt\") as tf:\n                for line_num, line in enumerate(tf, start=1):\n                    words = line.split()\n                    try:\n                        rel_word = words[rel_col]\n                    except IndexError:\n                        raise RuntimeError(\n                            f\"Line {line_num} of {edgepath} has only {len(words)} words\"\n                        ) from None\n                    counter[rel_word] += 1\n        print(f\"- Found {len(counter)} relation types\")\n        if relation_type_min_count > 0:\n            print(f\"- Removing the ones with fewer than {relation_type_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= relation_type_min_count})\n            print(f\"- Left with {len(counter)} relation types\")\n        print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n\n    else:\n        names = [rconfig.name for rconfig in relation_configs]\n        print(f\"Using the {len(names)} relation types given in the config\")\n\n    return Dictionary(names)\n\n\ndef collect_entities_by_type(\n    relation_types: Dictionary,\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n    entity_min_count: int,\n) -> Dict[str, Dictionary]:\n\n    counters: Dict[str, Counter[str]] = {}\n    for entity_name in entity_configs.keys():\n        counters[entity_name] = Counter()\n\n    print(\"Searching for the entities in the edge files...\")\n    for edgepath in edge_paths:\n        with edgepath.open(\"rt\") as tf:\n            for line_num, line in enumerate(tf, start=1):\n                words = line.split()\n                try:\n                    lhs_word = words[lhs_col]\n                    rhs_word = words[rhs_col]\n                    rel_word = words[rel_col] if rel_col is not None else None\n                except IndexError:\n                    raise RuntimeError(\n                        \"Line %d of %s has only %d words\"\n                        % (line_num, edgepath, len(words))) from None\n\n                if dynamic_relations or rel_col is None:\n                    rel_id = 0\n                else:\n                    try:\n                        rel_id = relation_types.get_id(rel_word)\n                    except KeyError:\n                        raise RuntimeError(\"Could not find relation type in config\")\n\n                counters[relation_configs[rel_id].lhs][lhs_word] += 1\n                counters[relation_configs[rel_id].rhs][rhs_word] += 1\n\n    entities_by_type: Dict[str, Dictionary] = {}\n    for entity_name, counter in counters.items():\n        print(f\"Entity type {entity_name}:\")\n        print(f\"- Found {len(counter)} entities\")\n        if entity_min_count > 0:\n            print(f\"- Removing the ones with fewer than {entity_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= entity_min_count})\n            print(f\"- Left with {len(counter)} entities\")\n        print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n        entities_by_type[entity_name] = Dictionary(\n            names, num_parts=entity_configs[entity_name].num_partitions)\n\n    return entities_by_type\n\n\ndef generate_entity_path_files(\n    entity_storage: AbstractEntityStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_type_storage: AbstractRelationTypeStorage,\n    relation_types: Dictionary,\n    dynamic_relations: bool,\n) -> None:\n    print(f\"Preparing counts and dictionaries for entities and relation types:\")\n    entity_storage.prepare()\n    relation_type_storage.prepare()\n\n    for entity_name, entities in entities_by_type.items():\n        for part in range(entities.num_parts):\n            print(f\"- Writing count of entity type {entity_name} \"\n                  f\"and partition {part}\")\n            entity_storage.save_count(entity_name, part, entities.part_size(part))\n            entity_storage.save_names(entity_name, part, entities.get_part_list(part))\n\n    if dynamic_relations:\n        print(\"- Writing count of dynamic relations\")\n        relation_type_storage.save_count(relation_types.size())\n        relation_type_storage.save_names(relation_types.get_list())\n\n\ndef generate_edge_path_files(\n    edge_file_in: Path,\n    edge_path_out: Path,\n    edge_storage: AbstractEdgeStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_types: Dictionary,\n    relation_configs: List[RelationSchema],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n) -> None:\n    print(f\"Preparing edge path {edge_path_out}, \"\n          f\"out of the edges found in {edge_file_in}\")\n    edge_storage.prepare()\n\n    num_lhs_parts = max(entities_by_type[rconfig.lhs].num_parts\n                        for rconfig in relation_configs)\n    num_rhs_parts = max(entities_by_type[rconfig.rhs].num_parts\n                        for rconfig in relation_configs)\n\n    print(f\"- Edges will be partitioned in {num_lhs_parts} x {num_rhs_parts} buckets.\")\n\n    processed = 0\n    skipped = 0\n\n    # We use an ExitStack in order to close the dynamically-created edge appenders.\n    with edge_file_in.open(\"rt\") as tf, ExitStack() as appender_stack:\n        appenders: Dict[Tuple[int, int], AbstractEdgeAppender] = {}\n        for line_num, line in enumerate(tf, start=1):\n            words = line.split()\n            try:\n                lhs_word = words[lhs_col]\n                rhs_word = words[rhs_col]\n                rel_word = words[rel_col] if rel_col is not None else None\n            except IndexError:\n                raise RuntimeError(\n                    f\"Line {line_num} of {edge_file_in} has only {len(words)} words\"\n                ) from None\n\n            if rel_col is None:\n                rel_id = 0\n            else:\n                try:\n                    rel_id = relation_types.get_id(rel_word)\n                except KeyError:\n                    # Ignore edges whose relation type is not known.\n                    skipped += 1\n                    continue\n\n            if dynamic_relations:\n                lhs_type = relation_configs[0].lhs\n                rhs_type = relation_configs[0].rhs\n            else:\n                lhs_type = relation_configs[rel_id].lhs\n                rhs_type = relation_configs[rel_id].rhs\n\n            try:\n                lhs_part, lhs_offset = \\\n                    entities_by_type[lhs_type].get_partition(lhs_word)\n                rhs_part, rhs_offset = \\\n                    entities_by_type[rhs_type].get_partition(rhs_word)\n            except KeyError:\n                # Ignore edges whose entities are not known.\n                skipped += 1\n                continue\n\n            if (lhs_part, rhs_part) not in appenders:\n                appenders[lhs_part, rhs_part] = appender_stack.enter_context(\n                    edge_storage.save_edges_by_appending(lhs_part, rhs_part))\n            appenders[lhs_part, rhs_part].append_edges(EdgeList(\n                EntityList.from_tensor(torch.tensor([lhs_offset], dtype=torch.long)),\n                EntityList.from_tensor(torch.tensor([rhs_offset], dtype=torch.long)),\n                torch.tensor([rel_id], dtype=torch.long),\n            ))\n\n            processed = processed + 1\n            if processed % 100000 == 0:\n                print(f\"- Processed {processed} edges so far...\")\n\n    print(f\"- Processed {processed} edges in total\")\n    if skipped > 0:\n        print(f\"- Skipped {skipped} edges because their relation type or \"\n              f\"entities were unknown (either not given in the config or \"\n              f\"filtered out as too rare).\")\n\n\ndef convert_input_data(\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    entity_path: str,\n    edge_paths_out: List[str],\n    edge_paths_in: List[Path],\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int] = None,\n    entity_min_count: int = 1,\n    relation_type_min_count: int = 1,\n    dynamic_relations: bool = False,\n) -> None:\n    if len(edge_paths_in) != len(edge_paths_out):\n        raise ValueError(\n            f\"The edge paths passed as inputs ({edge_paths_in}) don't match \"\n            f\"the ones specified as outputs ({edge_paths_out})\")\n\n    entity_storage = ENTITY_STORAGES.make_instance(entity_path)\n    relation_type_storage = RELATION_TYPE_STORAGES.make_instance(entity_path)\n    edge_storages = [EDGE_STORAGES.make_instance(ep) for ep in edge_paths_out]\n\n    some_files_exists = []\n    some_files_exists.extend(\n        entity_storage.has_count(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    some_files_exists.extend(\n        entity_storage.has_names(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    if dynamic_relations:\n        some_files_exists.append(relation_type_storage.has_count())\n        some_files_exists.append(relation_type_storage.has_names())\n    some_files_exists.extend(\n        edge_storage.has_edges(0, 0) for edge_storage in edge_storages)\n\n    if all(some_files_exists):\n        print(\"Found some files that indicate that the input data \"\n              \"has already been preprocessed, not doing it again.\")\n        all_paths = \", \".join(str(p) for p in [entity_path] + edge_paths_out)\n        print(f\"These files are in: {all_paths}\")\n        return\n\n    relation_types = collect_relation_types(\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        rel_col,\n        relation_type_min_count,\n    )\n\n    entities_by_type = collect_entities_by_type(\n        relation_types,\n        entity_configs,\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        lhs_col,\n        rhs_col,\n        rel_col,\n        entity_min_count,\n    )\n\n    generate_entity_path_files(\n        entity_storage,\n        entities_by_type,\n        relation_type_storage,\n        relation_types,\n        dynamic_relations,\n    )\n\n    for edge_path_in, edge_path_out, edge_storage \\\n            in zip(edge_paths_in, edge_paths_out, edge_storages):\n        generate_edge_path_files(\n            edge_path_in,\n            edge_path_out,\n            edge_storage,\n            entities_by_type,\n            relation_types,\n            relation_configs,\n            dynamic_relations,\n            lhs_col,\n            rhs_col,\n            rel_col,\n        )\n\n\ndef parse_config_partial(\n    config_dict: Any,\n) -> Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]:\n    entities_config = config_dict.get(\"entities\")\n    relations_config = config_dict.get(\"relations\")\n    entity_path = config_dict.get(\"entity_path\")\n    edge_paths = config_dict.get(\"edge_paths\")\n    dynamic_relations = config_dict.get(\"dynamic_relations\", False)\n    if not isinstance(entities_config, dict):\n        raise TypeError(\"Config entities is not of type dict\")\n    if any(not isinstance(k, str) for k in entities_config.keys()):\n        raise TypeError(\"Config entities has some keys that are not of type str\")\n    if not isinstance(relations_config, list):\n        raise TypeError(\"Config relations is not of type list\")\n    if not isinstance(entity_path, str):\n        raise TypeError(\"Config entity_path is not of type str\")\n    if not isinstance(edge_paths, list):\n        raise TypeError(\"Config edge_paths is not of type list\")\n    if any(not isinstance(p, str) for p in edge_paths):\n        raise TypeError(\"Config edge_paths has some items that are not of type str\")\n    if not isinstance(dynamic_relations, bool):\n        raise TypeError(\"Config dynamic_relations is not of type bool\")\n\n    entities = {}\n    relations = []\n    for entity, entity_config in entities_config.items():\n        entities[entity] = EntitySchema.from_dict(entity_config)\n    for relation in relations_config:\n        relations.append(RelationSchema.from_dict(relation))\n\n    return entities, relations, entity_path, edge_paths, dynamic_relations\n\n\n",
        "source_code_len": 13269,
        "target_code": "    ConfigSchema,\n    override_config_dict,\n)\n\n",
        "target_code_len": 47,
        "diff_format": "@@ -20,351 +20,4 @@\n     ConfigSchema,\n-    EntitySchema,\n-    RelationSchema,\n     override_config_dict,\n )\n-from torchbiggraph.converters.dictionary import Dictionary\n-from torchbiggraph.edgelist import EdgeList\n-from torchbiggraph.entitylist import EntityList\n-from torchbiggraph.graph_storages import (\n-    AbstractEdgeAppender,\n-    AbstractEdgeStorage,\n-    AbstractEntityStorage,\n-    AbstractRelationTypeStorage,\n-    EDGE_STORAGES,\n-    ENTITY_STORAGES,\n-    RELATION_TYPE_STORAGES,\n-)\n-\n-\n-def collect_relation_types(\n-    relation_configs: List[RelationSchema],\n-    edge_paths: List[Path],\n-    dynamic_relations: bool,\n-    rel_col: Optional[int],\n-    relation_type_min_count: int,\n-) -> Dictionary:\n-\n-    if dynamic_relations:\n-        if rel_col is None:\n-            raise RuntimeError(\"Need to specify rel_col in dynamic mode.\")\n-        print(\"Looking up relation types in the edge files...\")\n-        counter: Counter[str] = Counter()\n-        for edgepath in edge_paths:\n-            with edgepath.open(\"rt\") as tf:\n-                for line_num, line in enumerate(tf, start=1):\n-                    words = line.split()\n-                    try:\n-                        rel_word = words[rel_col]\n-                    except IndexError:\n-                        raise RuntimeError(\n-                            f\"Line {line_num} of {edgepath} has only {len(words)} words\"\n-                        ) from None\n-                    counter[rel_word] += 1\n-        print(f\"- Found {len(counter)} relation types\")\n-        if relation_type_min_count > 0:\n-            print(f\"- Removing the ones with fewer than {relation_type_min_count} occurrences...\")\n-            counter = Counter({k: c for k, c in counter.items()\n-                               if c >= relation_type_min_count})\n-            print(f\"- Left with {len(counter)} relation types\")\n-        print(\"- Shuffling them...\")\n-        names = list(counter.keys())\n-        random.shuffle(names)\n-\n-    else:\n-        names = [rconfig.name for rconfig in relation_configs]\n-        print(f\"Using the {len(names)} relation types given in the config\")\n-\n-    return Dictionary(names)\n-\n-\n-def collect_entities_by_type(\n-    relation_types: Dictionary,\n-    entity_configs: Dict[str, EntitySchema],\n-    relation_configs: List[RelationSchema],\n-    edge_paths: List[Path],\n-    dynamic_relations: bool,\n-    lhs_col: int,\n-    rhs_col: int,\n-    rel_col: Optional[int],\n-    entity_min_count: int,\n-) -> Dict[str, Dictionary]:\n-\n-    counters: Dict[str, Counter[str]] = {}\n-    for entity_name in entity_configs.keys():\n-        counters[entity_name] = Counter()\n-\n-    print(\"Searching for the entities in the edge files...\")\n-    for edgepath in edge_paths:\n-        with edgepath.open(\"rt\") as tf:\n-            for line_num, line in enumerate(tf, start=1):\n-                words = line.split()\n-                try:\n-                    lhs_word = words[lhs_col]\n-                    rhs_word = words[rhs_col]\n-                    rel_word = words[rel_col] if rel_col is not None else None\n-                except IndexError:\n-                    raise RuntimeError(\n-                        \"Line %d of %s has only %d words\"\n-                        % (line_num, edgepath, len(words))) from None\n-\n-                if dynamic_relations or rel_col is None:\n-                    rel_id = 0\n-                else:\n-                    try:\n-                        rel_id = relation_types.get_id(rel_word)\n-                    except KeyError:\n-                        raise RuntimeError(\"Could not find relation type in config\")\n-\n-                counters[relation_configs[rel_id].lhs][lhs_word] += 1\n-                counters[relation_configs[rel_id].rhs][rhs_word] += 1\n-\n-    entities_by_type: Dict[str, Dictionary] = {}\n-    for entity_name, counter in counters.items():\n-        print(f\"Entity type {entity_name}:\")\n-        print(f\"- Found {len(counter)} entities\")\n-        if entity_min_count > 0:\n-            print(f\"- Removing the ones with fewer than {entity_min_count} occurrences...\")\n-            counter = Counter({k: c for k, c in counter.items()\n-                               if c >= entity_min_count})\n-            print(f\"- Left with {len(counter)} entities\")\n-        print(\"- Shuffling them...\")\n-        names = list(counter.keys())\n-        random.shuffle(names)\n-        entities_by_type[entity_name] = Dictionary(\n-            names, num_parts=entity_configs[entity_name].num_partitions)\n-\n-    return entities_by_type\n-\n-\n-def generate_entity_path_files(\n-    entity_storage: AbstractEntityStorage,\n-    entities_by_type: Dict[str, Dictionary],\n-    relation_type_storage: AbstractRelationTypeStorage,\n-    relation_types: Dictionary,\n-    dynamic_relations: bool,\n-) -> None:\n-    print(f\"Preparing counts and dictionaries for entities and relation types:\")\n-    entity_storage.prepare()\n-    relation_type_storage.prepare()\n-\n-    for entity_name, entities in entities_by_type.items():\n-        for part in range(entities.num_parts):\n-            print(f\"- Writing count of entity type {entity_name} \"\n-                  f\"and partition {part}\")\n-            entity_storage.save_count(entity_name, part, entities.part_size(part))\n-            entity_storage.save_names(entity_name, part, entities.get_part_list(part))\n-\n-    if dynamic_relations:\n-        print(\"- Writing count of dynamic relations\")\n-        relation_type_storage.save_count(relation_types.size())\n-        relation_type_storage.save_names(relation_types.get_list())\n-\n-\n-def generate_edge_path_files(\n-    edge_file_in: Path,\n-    edge_path_out: Path,\n-    edge_storage: AbstractEdgeStorage,\n-    entities_by_type: Dict[str, Dictionary],\n-    relation_types: Dictionary,\n-    relation_configs: List[RelationSchema],\n-    dynamic_relations: bool,\n-    lhs_col: int,\n-    rhs_col: int,\n-    rel_col: Optional[int],\n-) -> None:\n-    print(f\"Preparing edge path {edge_path_out}, \"\n-          f\"out of the edges found in {edge_file_in}\")\n-    edge_storage.prepare()\n-\n-    num_lhs_parts = max(entities_by_type[rconfig.lhs].num_parts\n-                        for rconfig in relation_configs)\n-    num_rhs_parts = max(entities_by_type[rconfig.rhs].num_parts\n-                        for rconfig in relation_configs)\n-\n-    print(f\"- Edges will be partitioned in {num_lhs_parts} x {num_rhs_parts} buckets.\")\n-\n-    processed = 0\n-    skipped = 0\n-\n-    # We use an ExitStack in order to close the dynamically-created edge appenders.\n-    with edge_file_in.open(\"rt\") as tf, ExitStack() as appender_stack:\n-        appenders: Dict[Tuple[int, int], AbstractEdgeAppender] = {}\n-        for line_num, line in enumerate(tf, start=1):\n-            words = line.split()\n-            try:\n-                lhs_word = words[lhs_col]\n-                rhs_word = words[rhs_col]\n-                rel_word = words[rel_col] if rel_col is not None else None\n-            except IndexError:\n-                raise RuntimeError(\n-                    f\"Line {line_num} of {edge_file_in} has only {len(words)} words\"\n-                ) from None\n-\n-            if rel_col is None:\n-                rel_id = 0\n-            else:\n-                try:\n-                    rel_id = relation_types.get_id(rel_word)\n-                except KeyError:\n-                    # Ignore edges whose relation type is not known.\n-                    skipped += 1\n-                    continue\n-\n-            if dynamic_relations:\n-                lhs_type = relation_configs[0].lhs\n-                rhs_type = relation_configs[0].rhs\n-            else:\n-                lhs_type = relation_configs[rel_id].lhs\n-                rhs_type = relation_configs[rel_id].rhs\n-\n-            try:\n-                lhs_part, lhs_offset = \\\n-                    entities_by_type[lhs_type].get_partition(lhs_word)\n-                rhs_part, rhs_offset = \\\n-                    entities_by_type[rhs_type].get_partition(rhs_word)\n-            except KeyError:\n-                # Ignore edges whose entities are not known.\n-                skipped += 1\n-                continue\n-\n-            if (lhs_part, rhs_part) not in appenders:\n-                appenders[lhs_part, rhs_part] = appender_stack.enter_context(\n-                    edge_storage.save_edges_by_appending(lhs_part, rhs_part))\n-            appenders[lhs_part, rhs_part].append_edges(EdgeList(\n-                EntityList.from_tensor(torch.tensor([lhs_offset], dtype=torch.long)),\n-                EntityList.from_tensor(torch.tensor([rhs_offset], dtype=torch.long)),\n-                torch.tensor([rel_id], dtype=torch.long),\n-            ))\n-\n-            processed = processed + 1\n-            if processed % 100000 == 0:\n-                print(f\"- Processed {processed} edges so far...\")\n-\n-    print(f\"- Processed {processed} edges in total\")\n-    if skipped > 0:\n-        print(f\"- Skipped {skipped} edges because their relation type or \"\n-              f\"entities were unknown (either not given in the config or \"\n-              f\"filtered out as too rare).\")\n-\n-\n-def convert_input_data(\n-    entity_configs: Dict[str, EntitySchema],\n-    relation_configs: List[RelationSchema],\n-    entity_path: str,\n-    edge_paths_out: List[str],\n-    edge_paths_in: List[Path],\n-    lhs_col: int,\n-    rhs_col: int,\n-    rel_col: Optional[int] = None,\n-    entity_min_count: int = 1,\n-    relation_type_min_count: int = 1,\n-    dynamic_relations: bool = False,\n-) -> None:\n-    if len(edge_paths_in) != len(edge_paths_out):\n-        raise ValueError(\n-            f\"The edge paths passed as inputs ({edge_paths_in}) don't match \"\n-            f\"the ones specified as outputs ({edge_paths_out})\")\n-\n-    entity_storage = ENTITY_STORAGES.make_instance(entity_path)\n-    relation_type_storage = RELATION_TYPE_STORAGES.make_instance(entity_path)\n-    edge_storages = [EDGE_STORAGES.make_instance(ep) for ep in edge_paths_out]\n-\n-    some_files_exists = []\n-    some_files_exists.extend(\n-        entity_storage.has_count(entity_name, partition)\n-        for entity_name, entity_config in entity_configs.items()\n-        for partition in range(entity_config.num_partitions))\n-    some_files_exists.extend(\n-        entity_storage.has_names(entity_name, partition)\n-        for entity_name, entity_config in entity_configs.items()\n-        for partition in range(entity_config.num_partitions))\n-    if dynamic_relations:\n-        some_files_exists.append(relation_type_storage.has_count())\n-        some_files_exists.append(relation_type_storage.has_names())\n-    some_files_exists.extend(\n-        edge_storage.has_edges(0, 0) for edge_storage in edge_storages)\n-\n-    if all(some_files_exists):\n-        print(\"Found some files that indicate that the input data \"\n-              \"has already been preprocessed, not doing it again.\")\n-        all_paths = \", \".join(str(p) for p in [entity_path] + edge_paths_out)\n-        print(f\"These files are in: {all_paths}\")\n-        return\n-\n-    relation_types = collect_relation_types(\n-        relation_configs,\n-        edge_paths_in,\n-        dynamic_relations,\n-        rel_col,\n-        relation_type_min_count,\n-    )\n-\n-    entities_by_type = collect_entities_by_type(\n-        relation_types,\n-        entity_configs,\n-        relation_configs,\n-        edge_paths_in,\n-        dynamic_relations,\n-        lhs_col,\n-        rhs_col,\n-        rel_col,\n-        entity_min_count,\n-    )\n-\n-    generate_entity_path_files(\n-        entity_storage,\n-        entities_by_type,\n-        relation_type_storage,\n-        relation_types,\n-        dynamic_relations,\n-    )\n-\n-    for edge_path_in, edge_path_out, edge_storage \\\n-            in zip(edge_paths_in, edge_paths_out, edge_storages):\n-        generate_edge_path_files(\n-            edge_path_in,\n-            edge_path_out,\n-            edge_storage,\n-            entities_by_type,\n-            relation_types,\n-            relation_configs,\n-            dynamic_relations,\n-            lhs_col,\n-            rhs_col,\n-            rel_col,\n-        )\n-\n-\n-def parse_config_partial(\n-    config_dict: Any,\n-) -> Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]:\n-    entities_config = config_dict.get(\"entities\")\n-    relations_config = config_dict.get(\"relations\")\n-    entity_path = config_dict.get(\"entity_path\")\n-    edge_paths = config_dict.get(\"edge_paths\")\n-    dynamic_relations = config_dict.get(\"dynamic_relations\", False)\n-    if not isinstance(entities_config, dict):\n-        raise TypeError(\"Config entities is not of type dict\")\n-    if any(not isinstance(k, str) for k in entities_config.keys()):\n-        raise TypeError(\"Config entities has some keys that are not of type str\")\n-    if not isinstance(relations_config, list):\n-        raise TypeError(\"Config relations is not of type list\")\n-    if not isinstance(entity_path, str):\n-        raise TypeError(\"Config entity_path is not of type str\")\n-    if not isinstance(edge_paths, list):\n-        raise TypeError(\"Config edge_paths is not of type list\")\n-    if any(not isinstance(p, str) for p in edge_paths):\n-        raise TypeError(\"Config edge_paths has some items that are not of type str\")\n-    if not isinstance(dynamic_relations, bool):\n-        raise TypeError(\"Config dynamic_relations is not of type bool\")\n-\n-    entities = {}\n-    relations = []\n-    for entity, entity_config in entities_config.items():\n-        entities[entity] = EntitySchema.from_dict(entity_config)\n-    for relation in relations_config:\n-        relations.append(RelationSchema.from_dict(relation))\n-\n-    return entities, relations, entity_path, edge_paths, dynamic_relations\n-\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent": "    ConfigSchema,\n    override_config_dict,\n)\n\n",
        "target_code_with_indent_exact_match": true,
        "source_code_with_indent": "    ConfigSchema,\n    EntitySchema,\n    RelationSchema,\n    override_config_dict,\n)\nfrom torchbiggraph.converters.dictionary import Dictionary\nfrom torchbiggraph.edgelist import EdgeList\nfrom torchbiggraph.entitylist import EntityList\nfrom torchbiggraph.graph_storages import (\n    AbstractEdgeAppender,\n    AbstractEdgeStorage,\n    AbstractEntityStorage,\n    AbstractRelationTypeStorage,\n    EDGE_STORAGES,\n    ENTITY_STORAGES,\n    RELATION_TYPE_STORAGES,\n)\n\n\ndef collect_relation_types(\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    rel_col: Optional[int],\n    relation_type_min_count: int,\n) -> Dictionary:\n\n    <IND>if dynamic_relations:\n        <IND>if rel_col is None:\n            <IND>raise RuntimeError(\"Need to specify rel_col in dynamic mode.\")\n        <DED>print(\"Looking up relation types in the edge files...\")\n        counter: Counter[str] = Counter()\n        for edgepath in edge_paths:\n            <IND>with edgepath.open(\"rt\") as tf:\n                <IND>for line_num, line in enumerate(tf, start=1):\n                    <IND>words = line.split()\n                    try:\n                        <IND>rel_word = words[rel_col]\n                    <DED>except IndexError:\n                        <IND>raise RuntimeError(\n                            f\"Line {line_num} of {edgepath} has only {len(words)} words\"\n                        ) from None\n                    <DED>counter[rel_word] += 1\n        <DED><DED><DED>print(f\"- Found {len(counter)} relation types\")\n        if relation_type_min_count > 0:\n            <IND>print(f\"- Removing the ones with fewer than {relation_type_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= relation_type_min_count})\n            print(f\"- Left with {len(counter)} relation types\")\n        <DED>print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n\n    <DED>else:\n        <IND>names = [rconfig.name for rconfig in relation_configs]\n        print(f\"Using the {len(names)} relation types given in the config\")\n\n    <DED>return Dictionary(names)\n\n\n<DED>def collect_entities_by_type(\n    relation_types: Dictionary,\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n    entity_min_count: int,\n) -> Dict[str, Dictionary]:\n\n    <IND>counters: Dict[str, Counter[str]] = {}\n    for entity_name in entity_configs.keys():\n        <IND>counters[entity_name] = Counter()\n\n    <DED>print(\"Searching for the entities in the edge files...\")\n    for edgepath in edge_paths:\n        <IND>with edgepath.open(\"rt\") as tf:\n            <IND>for line_num, line in enumerate(tf, start=1):\n                <IND>words = line.split()\n                try:\n                    <IND>lhs_word = words[lhs_col]\n                    rhs_word = words[rhs_col]\n                    rel_word = words[rel_col] if rel_col is not None else None\n                <DED>except IndexError:\n                    <IND>raise RuntimeError(\n                        \"Line %d of %s has only %d words\"\n                        % (line_num, edgepath, len(words))) from None\n\n                <DED>if dynamic_relations or rel_col is None:\n                    <IND>rel_id = 0\n                <DED>else:\n                    <IND>try:\n                        <IND>rel_id = relation_types.get_id(rel_word)\n                    <DED>except KeyError:\n                        <IND>raise RuntimeError(\"Could not find relation type in config\")\n\n                <DED><DED>counters[relation_configs[rel_id].lhs][lhs_word] += 1\n                counters[relation_configs[rel_id].rhs][rhs_word] += 1\n\n    <DED><DED><DED>entities_by_type: Dict[str, Dictionary] = {}\n    for entity_name, counter in counters.items():\n        <IND>print(f\"Entity type {entity_name}:\")\n        print(f\"- Found {len(counter)} entities\")\n        if entity_min_count > 0:\n            <IND>print(f\"- Removing the ones with fewer than {entity_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= entity_min_count})\n            print(f\"- Left with {len(counter)} entities\")\n        <DED>print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n        entities_by_type[entity_name] = Dictionary(\n            names, num_parts=entity_configs[entity_name].num_partitions)\n\n    <DED>return entities_by_type\n\n\n<DED>def generate_entity_path_files(\n    entity_storage: AbstractEntityStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_type_storage: AbstractRelationTypeStorage,\n    relation_types: Dictionary,\n    dynamic_relations: bool,\n) -> None:\n    <IND>print(f\"Preparing counts and dictionaries for entities and relation types:\")\n    entity_storage.prepare()\n    relation_type_storage.prepare()\n\n    for entity_name, entities in entities_by_type.items():\n        <IND>for part in range(entities.num_parts):\n            <IND>print(f\"- Writing count of entity type {entity_name} \"\n                  f\"and partition {part}\")\n            entity_storage.save_count(entity_name, part, entities.part_size(part))\n            entity_storage.save_names(entity_name, part, entities.get_part_list(part))\n\n    <DED><DED>if dynamic_relations:\n        <IND>print(\"- Writing count of dynamic relations\")\n        relation_type_storage.save_count(relation_types.size())\n        relation_type_storage.save_names(relation_types.get_list())\n\n\n<DED><DED>def generate_edge_path_files(\n    edge_file_in: Path,\n    edge_path_out: Path,\n    edge_storage: AbstractEdgeStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_types: Dictionary,\n    relation_configs: List[RelationSchema],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n) -> None:\n    <IND>print(f\"Preparing edge path {edge_path_out}, \"\n          f\"out of the edges found in {edge_file_in}\")\n    edge_storage.prepare()\n\n    num_lhs_parts = max(entities_by_type[rconfig.lhs].num_parts\n                        for rconfig in relation_configs)\n    num_rhs_parts = max(entities_by_type[rconfig.rhs].num_parts\n                        for rconfig in relation_configs)\n\n    print(f\"- Edges will be partitioned in {num_lhs_parts} x {num_rhs_parts} buckets.\")\n\n    processed = 0\n    skipped = 0\n\n    # We use an ExitStack in order to close the dynamically-created edge appenders.\n    with edge_file_in.open(\"rt\") as tf, ExitStack() as appender_stack:\n        <IND>appenders: Dict[Tuple[int, int], AbstractEdgeAppender] = {}\n        for line_num, line in enumerate(tf, start=1):\n            <IND>words = line.split()\n            try:\n                <IND>lhs_word = words[lhs_col]\n                rhs_word = words[rhs_col]\n                rel_word = words[rel_col] if rel_col is not None else None\n            <DED>except IndexError:\n                <IND>raise RuntimeError(\n                    f\"Line {line_num} of {edge_file_in} has only {len(words)} words\"\n                ) from None\n\n            <DED>if rel_col is None:\n                <IND>rel_id = 0\n            <DED>else:\n                <IND>try:\n                    <IND>rel_id = relation_types.get_id(rel_word)\n                <DED>except KeyError:\n                    # Ignore edges whose relation type is not known.\n                    <IND>skipped += 1\n                    continue\n\n            <DED><DED>if dynamic_relations:\n                <IND>lhs_type = relation_configs[0].lhs\n                rhs_type = relation_configs[0].rhs\n            <DED>else:\n                <IND>lhs_type = relation_configs[rel_id].lhs\n                rhs_type = relation_configs[rel_id].rhs\n\n            <DED>try:\n                <IND>lhs_part, lhs_offset =                    entities_by_type[lhs_type].get_partition(lhs_word)\n                rhs_part, rhs_offset =                    entities_by_type[rhs_type].get_partition(rhs_word)\n            <DED>except KeyError:\n                # Ignore edges whose entities are not known.\n                <IND>skipped += 1\n                continue\n\n            <DED>if (lhs_part, rhs_part) not in appenders:\n                <IND>appenders[lhs_part, rhs_part] = appender_stack.enter_context(\n                    edge_storage.save_edges_by_appending(lhs_part, rhs_part))\n            <DED>appenders[lhs_part, rhs_part].append_edges(EdgeList(\n                EntityList.from_tensor(torch.tensor([lhs_offset], dtype=torch.long)),\n                EntityList.from_tensor(torch.tensor([rhs_offset], dtype=torch.long)),\n                torch.tensor([rel_id], dtype=torch.long),\n            ))\n\n            processed = processed + 1\n            if processed % 100000 == 0:\n                <IND>print(f\"- Processed {processed} edges so far...\")\n\n    <DED><DED><DED>print(f\"- Processed {processed} edges in total\")\n    if skipped > 0:\n        <IND>print(f\"- Skipped {skipped} edges because their relation type or \"\n              f\"entities were unknown (either not given in the config or \"\n              f\"filtered out as too rare).\")\n\n\n<DED><DED>def convert_input_data(\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    entity_path: str,\n    edge_paths_out: List[str],\n    edge_paths_in: List[Path],\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int] = None,\n    entity_min_count: int = 1,\n    relation_type_min_count: int = 1,\n    dynamic_relations: bool = False,\n) -> None:\n    <IND>if len(edge_paths_in) != len(edge_paths_out):\n        <IND>raise ValueError(\n            f\"The edge paths passed as inputs ({edge_paths_in}) don't match \"\n            f\"the ones specified as outputs ({edge_paths_out})\")\n\n    <DED>entity_storage = ENTITY_STORAGES.make_instance(entity_path)\n    relation_type_storage = RELATION_TYPE_STORAGES.make_instance(entity_path)\n    edge_storages = [EDGE_STORAGES.make_instance(ep) for ep in edge_paths_out]\n\n    some_files_exists = []\n    some_files_exists.extend(\n        entity_storage.has_count(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    some_files_exists.extend(\n        entity_storage.has_names(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    if dynamic_relations:\n        <IND>some_files_exists.append(relation_type_storage.has_count())\n        some_files_exists.append(relation_type_storage.has_names())\n    <DED>some_files_exists.extend(\n        edge_storage.has_edges(0, 0) for edge_storage in edge_storages)\n\n    if all(some_files_exists):\n        <IND>print(\"Found some files that indicate that the input data \"\n              \"has already been preprocessed, not doing it again.\")\n        all_paths = \", \".join(str(p) for p in [entity_path] + edge_paths_out)\n        print(f\"These files are in: {all_paths}\")\n        return\n\n    <DED>relation_types = collect_relation_types(\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        rel_col,\n        relation_type_min_count,\n    )\n\n    entities_by_type = collect_entities_by_type(\n        relation_types,\n        entity_configs,\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        lhs_col,\n        rhs_col,\n        rel_col,\n        entity_min_count,\n    )\n\n    generate_entity_path_files(\n        entity_storage,\n        entities_by_type,\n        relation_type_storage,\n        relation_types,\n        dynamic_relations,\n    )\n\n    for edge_path_in, edge_path_out, edge_storage            in zip(edge_paths_in, edge_paths_out, edge_storages):\n        <IND>generate_edge_path_files(\n            edge_path_in,\n            edge_path_out,\n            edge_storage,\n            entities_by_type,\n            relation_types,\n            relation_configs,\n            dynamic_relations,\n            lhs_col,\n            rhs_col,\n            rel_col,\n        )\n\n\n<DED><DED>def parse_config_partial(\n    config_dict: Any,\n) -> Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]:\n    <IND>entities_config = config_dict.get(\"entities\")\n    relations_config = config_dict.get(\"relations\")\n    entity_path = config_dict.get(\"entity_path\")\n    edge_paths = config_dict.get(\"edge_paths\")\n    dynamic_relations = config_dict.get(\"dynamic_relations\", False)\n    if not isinstance(entities_config, dict):\n        <IND>raise TypeError(\"Config entities is not of type dict\")\n    <DED>if any(not isinstance(k, str) for k in entities_config.keys()):\n        <IND>raise TypeError(\"Config entities has some keys that are not of type str\")\n    <DED>if not isinstance(relations_config, list):\n        <IND>raise TypeError(\"Config relations is not of type list\")\n    <DED>if not isinstance(entity_path, str):\n        <IND>raise TypeError(\"Config entity_path is not of type str\")\n    <DED>if not isinstance(edge_paths, list):\n        <IND>raise TypeError(\"Config edge_paths is not of type list\")\n    <DED>if any(not isinstance(p, str) for p in edge_paths):\n        <IND>raise TypeError(\"Config edge_paths has some items that are not of type str\")\n    <DED>if not isinstance(dynamic_relations, bool):\n        <IND>raise TypeError(\"Config dynamic_relations is not of type bool\")\n\n    <DED>entities = {}\n    relations = []\n    for entity, entity_config in entities_config.items():\n        <IND>entities[entity] = EntitySchema.from_dict(entity_config)\n    <DED>for relation in relations_config:\n        <IND>relations.append(RelationSchema.from_dict(relation))\n\n    <DED>return entities, relations, entity_path, edge_paths, dynamic_relations\n\n\n"
      }
    ]
  },
  {
    "project": "facebookresearch/PyTorch-BigGraph",
    "commit": "fb0b3ae1a85087f31f730cd4cd43f733c2bd35a3",
    "filename": "torchbiggraph/converters/import_from_tsv.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/facebookresearch-PyTorch-BigGraph/torchbiggraph/converters/import_from_tsv.py",
    "file_hunks_size": 5,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": true,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "torchbiggraph/converters/import_from_tsv.py:127:22 Call error [29]: `typing._Alias` is not a function.",
    "message": " `typing._Alias` is not a function.",
    "rule_id": "Call error [29]",
    "warning_line_no": 127,
    "warning_line": "            counter = Counter({k: c for k, c in counter.items()",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "    ConfigSchema,\n    EntitySchema,\n    RelationSchema,\n    override_config_dict,\n)\nfrom torchbiggraph.converters.dictionary import Dictionary\nfrom torchbiggraph.edgelist import EdgeList\nfrom torchbiggraph.entitylist import EntityList\nfrom torchbiggraph.graph_storages import (\n    AbstractEdgeAppender,\n    AbstractEdgeStorage,\n    AbstractEntityStorage,\n    AbstractRelationTypeStorage,\n    EDGE_STORAGES,\n    ENTITY_STORAGES,\n    RELATION_TYPE_STORAGES,\n)\n\n\ndef collect_relation_types(\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    rel_col: Optional[int],\n    relation_type_min_count: int,\n) -> Dictionary:\n\n    if dynamic_relations:\n        if rel_col is None:\n            raise RuntimeError(\"Need to specify rel_col in dynamic mode.\")\n        print(\"Looking up relation types in the edge files...\")\n        counter: Counter[str] = Counter()\n        for edgepath in edge_paths:\n            with edgepath.open(\"rt\") as tf:\n                for line_num, line in enumerate(tf, start=1):\n                    words = line.split()\n                    try:\n                        rel_word = words[rel_col]\n                    except IndexError:\n                        raise RuntimeError(\n                            f\"Line {line_num} of {edgepath} has only {len(words)} words\"\n                        ) from None\n                    counter[rel_word] += 1\n        print(f\"- Found {len(counter)} relation types\")\n        if relation_type_min_count > 0:\n            print(f\"- Removing the ones with fewer than {relation_type_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= relation_type_min_count})\n            print(f\"- Left with {len(counter)} relation types\")\n        print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n\n    else:\n        names = [rconfig.name for rconfig in relation_configs]\n        print(f\"Using the {len(names)} relation types given in the config\")\n\n    return Dictionary(names)\n\n\ndef collect_entities_by_type(\n    relation_types: Dictionary,\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n    entity_min_count: int,\n) -> Dict[str, Dictionary]:\n\n    counters: Dict[str, Counter[str]] = {}\n    for entity_name in entity_configs.keys():\n        counters[entity_name] = Counter()\n\n    print(\"Searching for the entities in the edge files...\")\n    for edgepath in edge_paths:\n        with edgepath.open(\"rt\") as tf:\n            for line_num, line in enumerate(tf, start=1):\n                words = line.split()\n                try:\n                    lhs_word = words[lhs_col]\n                    rhs_word = words[rhs_col]\n                    rel_word = words[rel_col] if rel_col is not None else None\n                except IndexError:\n                    raise RuntimeError(\n                        \"Line %d of %s has only %d words\"\n                        % (line_num, edgepath, len(words))) from None\n\n                if dynamic_relations or rel_col is None:\n                    rel_id = 0\n                else:\n                    try:\n                        rel_id = relation_types.get_id(rel_word)\n                    except KeyError:\n                        raise RuntimeError(\"Could not find relation type in config\")\n\n                counters[relation_configs[rel_id].lhs][lhs_word] += 1\n                counters[relation_configs[rel_id].rhs][rhs_word] += 1\n\n    entities_by_type: Dict[str, Dictionary] = {}\n    for entity_name, counter in counters.items():\n        print(f\"Entity type {entity_name}:\")\n        print(f\"- Found {len(counter)} entities\")\n        if entity_min_count > 0:\n            print(f\"- Removing the ones with fewer than {entity_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= entity_min_count})\n            print(f\"- Left with {len(counter)} entities\")\n        print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n        entities_by_type[entity_name] = Dictionary(\n            names, num_parts=entity_configs[entity_name].num_partitions)\n\n    return entities_by_type\n\n\ndef generate_entity_path_files(\n    entity_storage: AbstractEntityStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_type_storage: AbstractRelationTypeStorage,\n    relation_types: Dictionary,\n    dynamic_relations: bool,\n) -> None:\n    print(f\"Preparing counts and dictionaries for entities and relation types:\")\n    entity_storage.prepare()\n    relation_type_storage.prepare()\n\n    for entity_name, entities in entities_by_type.items():\n        for part in range(entities.num_parts):\n            print(f\"- Writing count of entity type {entity_name} \"\n                  f\"and partition {part}\")\n            entity_storage.save_count(entity_name, part, entities.part_size(part))\n            entity_storage.save_names(entity_name, part, entities.get_part_list(part))\n\n    if dynamic_relations:\n        print(\"- Writing count of dynamic relations\")\n        relation_type_storage.save_count(relation_types.size())\n        relation_type_storage.save_names(relation_types.get_list())\n\n\ndef generate_edge_path_files(\n    edge_file_in: Path,\n    edge_path_out: Path,\n    edge_storage: AbstractEdgeStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_types: Dictionary,\n    relation_configs: List[RelationSchema],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n) -> None:\n    print(f\"Preparing edge path {edge_path_out}, \"\n          f\"out of the edges found in {edge_file_in}\")\n    edge_storage.prepare()\n\n    num_lhs_parts = max(entities_by_type[rconfig.lhs].num_parts\n                        for rconfig in relation_configs)\n    num_rhs_parts = max(entities_by_type[rconfig.rhs].num_parts\n                        for rconfig in relation_configs)\n\n    print(f\"- Edges will be partitioned in {num_lhs_parts} x {num_rhs_parts} buckets.\")\n\n    processed = 0\n    skipped = 0\n\n    # We use an ExitStack in order to close the dynamically-created edge appenders.\n    with edge_file_in.open(\"rt\") as tf, ExitStack() as appender_stack:\n        appenders: Dict[Tuple[int, int], AbstractEdgeAppender] = {}\n        for line_num, line in enumerate(tf, start=1):\n            words = line.split()\n            try:\n                lhs_word = words[lhs_col]\n                rhs_word = words[rhs_col]\n                rel_word = words[rel_col] if rel_col is not None else None\n            except IndexError:\n                raise RuntimeError(\n                    f\"Line {line_num} of {edge_file_in} has only {len(words)} words\"\n                ) from None\n\n            if rel_col is None:\n                rel_id = 0\n            else:\n                try:\n                    rel_id = relation_types.get_id(rel_word)\n                except KeyError:\n                    # Ignore edges whose relation type is not known.\n                    skipped += 1\n                    continue\n\n            if dynamic_relations:\n                lhs_type = relation_configs[0].lhs\n                rhs_type = relation_configs[0].rhs\n            else:\n                lhs_type = relation_configs[rel_id].lhs\n                rhs_type = relation_configs[rel_id].rhs\n\n            try:\n                lhs_part, lhs_offset = \\\n                    entities_by_type[lhs_type].get_partition(lhs_word)\n                rhs_part, rhs_offset = \\\n                    entities_by_type[rhs_type].get_partition(rhs_word)\n            except KeyError:\n                # Ignore edges whose entities are not known.\n                skipped += 1\n                continue\n\n            if (lhs_part, rhs_part) not in appenders:\n                appenders[lhs_part, rhs_part] = appender_stack.enter_context(\n                    edge_storage.save_edges_by_appending(lhs_part, rhs_part))\n            appenders[lhs_part, rhs_part].append_edges(EdgeList(\n                EntityList.from_tensor(torch.tensor([lhs_offset], dtype=torch.long)),\n                EntityList.from_tensor(torch.tensor([rhs_offset], dtype=torch.long)),\n                torch.tensor([rel_id], dtype=torch.long),\n            ))\n\n            processed = processed + 1\n            if processed % 100000 == 0:\n                print(f\"- Processed {processed} edges so far...\")\n\n    print(f\"- Processed {processed} edges in total\")\n    if skipped > 0:\n        print(f\"- Skipped {skipped} edges because their relation type or \"\n              f\"entities were unknown (either not given in the config or \"\n              f\"filtered out as too rare).\")\n\n\ndef convert_input_data(\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    entity_path: str,\n    edge_paths_out: List[str],\n    edge_paths_in: List[Path],\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int] = None,\n    entity_min_count: int = 1,\n    relation_type_min_count: int = 1,\n    dynamic_relations: bool = False,\n) -> None:\n    if len(edge_paths_in) != len(edge_paths_out):\n        raise ValueError(\n            f\"The edge paths passed as inputs ({edge_paths_in}) don't match \"\n            f\"the ones specified as outputs ({edge_paths_out})\")\n\n    entity_storage = ENTITY_STORAGES.make_instance(entity_path)\n    relation_type_storage = RELATION_TYPE_STORAGES.make_instance(entity_path)\n    edge_storages = [EDGE_STORAGES.make_instance(ep) for ep in edge_paths_out]\n\n    some_files_exists = []\n    some_files_exists.extend(\n        entity_storage.has_count(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    some_files_exists.extend(\n        entity_storage.has_names(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    if dynamic_relations:\n        some_files_exists.append(relation_type_storage.has_count())\n        some_files_exists.append(relation_type_storage.has_names())\n    some_files_exists.extend(\n        edge_storage.has_edges(0, 0) for edge_storage in edge_storages)\n\n    if all(some_files_exists):\n        print(\"Found some files that indicate that the input data \"\n              \"has already been preprocessed, not doing it again.\")\n        all_paths = \", \".join(str(p) for p in [entity_path] + edge_paths_out)\n        print(f\"These files are in: {all_paths}\")\n        return\n\n    relation_types = collect_relation_types(\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        rel_col,\n        relation_type_min_count,\n    )\n\n    entities_by_type = collect_entities_by_type(\n        relation_types,\n        entity_configs,\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        lhs_col,\n        rhs_col,\n        rel_col,\n        entity_min_count,\n    )\n\n    generate_entity_path_files(\n        entity_storage,\n        entities_by_type,\n        relation_type_storage,\n        relation_types,\n        dynamic_relations,\n    )\n\n    for edge_path_in, edge_path_out, edge_storage \\\n            in zip(edge_paths_in, edge_paths_out, edge_storages):\n        generate_edge_path_files(\n            edge_path_in,\n            edge_path_out,\n            edge_storage,\n            entities_by_type,\n            relation_types,\n            relation_configs,\n            dynamic_relations,\n            lhs_col,\n            rhs_col,\n            rel_col,\n        )\n\n\ndef parse_config_partial(\n    config_dict: Any,\n) -> Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]:\n    entities_config = config_dict.get(\"entities\")\n    relations_config = config_dict.get(\"relations\")\n    entity_path = config_dict.get(\"entity_path\")\n    edge_paths = config_dict.get(\"edge_paths\")\n    dynamic_relations = config_dict.get(\"dynamic_relations\", False)\n    if not isinstance(entities_config, dict):\n        raise TypeError(\"Config entities is not of type dict\")\n    if any(not isinstance(k, str) for k in entities_config.keys()):\n        raise TypeError(\"Config entities has some keys that are not of type str\")\n    if not isinstance(relations_config, list):\n        raise TypeError(\"Config relations is not of type list\")\n    if not isinstance(entity_path, str):\n        raise TypeError(\"Config entity_path is not of type str\")\n    if not isinstance(edge_paths, list):\n        raise TypeError(\"Config edge_paths is not of type list\")\n    if any(not isinstance(p, str) for p in edge_paths):\n        raise TypeError(\"Config edge_paths has some items that are not of type str\")\n    if not isinstance(dynamic_relations, bool):\n        raise TypeError(\"Config dynamic_relations is not of type bool\")\n\n    entities = {}\n    relations = []\n    for entity, entity_config in entities_config.items():\n        entities[entity] = EntitySchema.from_dict(entity_config)\n    for relation in relations_config:\n        relations.append(RelationSchema.from_dict(relation))\n\n    return entities, relations, entity_path, edge_paths, dynamic_relations\n\n\n",
        "source_code_len": 13269,
        "target_code": "    ConfigSchema,\n    override_config_dict,\n)\n\n",
        "target_code_len": 47,
        "diff_format": "@@ -20,351 +20,4 @@\n     ConfigSchema,\n-    EntitySchema,\n-    RelationSchema,\n     override_config_dict,\n )\n-from torchbiggraph.converters.dictionary import Dictionary\n-from torchbiggraph.edgelist import EdgeList\n-from torchbiggraph.entitylist import EntityList\n-from torchbiggraph.graph_storages import (\n-    AbstractEdgeAppender,\n-    AbstractEdgeStorage,\n-    AbstractEntityStorage,\n-    AbstractRelationTypeStorage,\n-    EDGE_STORAGES,\n-    ENTITY_STORAGES,\n-    RELATION_TYPE_STORAGES,\n-)\n-\n-\n-def collect_relation_types(\n-    relation_configs: List[RelationSchema],\n-    edge_paths: List[Path],\n-    dynamic_relations: bool,\n-    rel_col: Optional[int],\n-    relation_type_min_count: int,\n-) -> Dictionary:\n-\n-    if dynamic_relations:\n-        if rel_col is None:\n-            raise RuntimeError(\"Need to specify rel_col in dynamic mode.\")\n-        print(\"Looking up relation types in the edge files...\")\n-        counter: Counter[str] = Counter()\n-        for edgepath in edge_paths:\n-            with edgepath.open(\"rt\") as tf:\n-                for line_num, line in enumerate(tf, start=1):\n-                    words = line.split()\n-                    try:\n-                        rel_word = words[rel_col]\n-                    except IndexError:\n-                        raise RuntimeError(\n-                            f\"Line {line_num} of {edgepath} has only {len(words)} words\"\n-                        ) from None\n-                    counter[rel_word] += 1\n-        print(f\"- Found {len(counter)} relation types\")\n-        if relation_type_min_count > 0:\n-            print(f\"- Removing the ones with fewer than {relation_type_min_count} occurrences...\")\n-            counter = Counter({k: c for k, c in counter.items()\n-                               if c >= relation_type_min_count})\n-            print(f\"- Left with {len(counter)} relation types\")\n-        print(\"- Shuffling them...\")\n-        names = list(counter.keys())\n-        random.shuffle(names)\n-\n-    else:\n-        names = [rconfig.name for rconfig in relation_configs]\n-        print(f\"Using the {len(names)} relation types given in the config\")\n-\n-    return Dictionary(names)\n-\n-\n-def collect_entities_by_type(\n-    relation_types: Dictionary,\n-    entity_configs: Dict[str, EntitySchema],\n-    relation_configs: List[RelationSchema],\n-    edge_paths: List[Path],\n-    dynamic_relations: bool,\n-    lhs_col: int,\n-    rhs_col: int,\n-    rel_col: Optional[int],\n-    entity_min_count: int,\n-) -> Dict[str, Dictionary]:\n-\n-    counters: Dict[str, Counter[str]] = {}\n-    for entity_name in entity_configs.keys():\n-        counters[entity_name] = Counter()\n-\n-    print(\"Searching for the entities in the edge files...\")\n-    for edgepath in edge_paths:\n-        with edgepath.open(\"rt\") as tf:\n-            for line_num, line in enumerate(tf, start=1):\n-                words = line.split()\n-                try:\n-                    lhs_word = words[lhs_col]\n-                    rhs_word = words[rhs_col]\n-                    rel_word = words[rel_col] if rel_col is not None else None\n-                except IndexError:\n-                    raise RuntimeError(\n-                        \"Line %d of %s has only %d words\"\n-                        % (line_num, edgepath, len(words))) from None\n-\n-                if dynamic_relations or rel_col is None:\n-                    rel_id = 0\n-                else:\n-                    try:\n-                        rel_id = relation_types.get_id(rel_word)\n-                    except KeyError:\n-                        raise RuntimeError(\"Could not find relation type in config\")\n-\n-                counters[relation_configs[rel_id].lhs][lhs_word] += 1\n-                counters[relation_configs[rel_id].rhs][rhs_word] += 1\n-\n-    entities_by_type: Dict[str, Dictionary] = {}\n-    for entity_name, counter in counters.items():\n-        print(f\"Entity type {entity_name}:\")\n-        print(f\"- Found {len(counter)} entities\")\n-        if entity_min_count > 0:\n-            print(f\"- Removing the ones with fewer than {entity_min_count} occurrences...\")\n-            counter = Counter({k: c for k, c in counter.items()\n-                               if c >= entity_min_count})\n-            print(f\"- Left with {len(counter)} entities\")\n-        print(\"- Shuffling them...\")\n-        names = list(counter.keys())\n-        random.shuffle(names)\n-        entities_by_type[entity_name] = Dictionary(\n-            names, num_parts=entity_configs[entity_name].num_partitions)\n-\n-    return entities_by_type\n-\n-\n-def generate_entity_path_files(\n-    entity_storage: AbstractEntityStorage,\n-    entities_by_type: Dict[str, Dictionary],\n-    relation_type_storage: AbstractRelationTypeStorage,\n-    relation_types: Dictionary,\n-    dynamic_relations: bool,\n-) -> None:\n-    print(f\"Preparing counts and dictionaries for entities and relation types:\")\n-    entity_storage.prepare()\n-    relation_type_storage.prepare()\n-\n-    for entity_name, entities in entities_by_type.items():\n-        for part in range(entities.num_parts):\n-            print(f\"- Writing count of entity type {entity_name} \"\n-                  f\"and partition {part}\")\n-            entity_storage.save_count(entity_name, part, entities.part_size(part))\n-            entity_storage.save_names(entity_name, part, entities.get_part_list(part))\n-\n-    if dynamic_relations:\n-        print(\"- Writing count of dynamic relations\")\n-        relation_type_storage.save_count(relation_types.size())\n-        relation_type_storage.save_names(relation_types.get_list())\n-\n-\n-def generate_edge_path_files(\n-    edge_file_in: Path,\n-    edge_path_out: Path,\n-    edge_storage: AbstractEdgeStorage,\n-    entities_by_type: Dict[str, Dictionary],\n-    relation_types: Dictionary,\n-    relation_configs: List[RelationSchema],\n-    dynamic_relations: bool,\n-    lhs_col: int,\n-    rhs_col: int,\n-    rel_col: Optional[int],\n-) -> None:\n-    print(f\"Preparing edge path {edge_path_out}, \"\n-          f\"out of the edges found in {edge_file_in}\")\n-    edge_storage.prepare()\n-\n-    num_lhs_parts = max(entities_by_type[rconfig.lhs].num_parts\n-                        for rconfig in relation_configs)\n-    num_rhs_parts = max(entities_by_type[rconfig.rhs].num_parts\n-                        for rconfig in relation_configs)\n-\n-    print(f\"- Edges will be partitioned in {num_lhs_parts} x {num_rhs_parts} buckets.\")\n-\n-    processed = 0\n-    skipped = 0\n-\n-    # We use an ExitStack in order to close the dynamically-created edge appenders.\n-    with edge_file_in.open(\"rt\") as tf, ExitStack() as appender_stack:\n-        appenders: Dict[Tuple[int, int], AbstractEdgeAppender] = {}\n-        for line_num, line in enumerate(tf, start=1):\n-            words = line.split()\n-            try:\n-                lhs_word = words[lhs_col]\n-                rhs_word = words[rhs_col]\n-                rel_word = words[rel_col] if rel_col is not None else None\n-            except IndexError:\n-                raise RuntimeError(\n-                    f\"Line {line_num} of {edge_file_in} has only {len(words)} words\"\n-                ) from None\n-\n-            if rel_col is None:\n-                rel_id = 0\n-            else:\n-                try:\n-                    rel_id = relation_types.get_id(rel_word)\n-                except KeyError:\n-                    # Ignore edges whose relation type is not known.\n-                    skipped += 1\n-                    continue\n-\n-            if dynamic_relations:\n-                lhs_type = relation_configs[0].lhs\n-                rhs_type = relation_configs[0].rhs\n-            else:\n-                lhs_type = relation_configs[rel_id].lhs\n-                rhs_type = relation_configs[rel_id].rhs\n-\n-            try:\n-                lhs_part, lhs_offset = \\\n-                    entities_by_type[lhs_type].get_partition(lhs_word)\n-                rhs_part, rhs_offset = \\\n-                    entities_by_type[rhs_type].get_partition(rhs_word)\n-            except KeyError:\n-                # Ignore edges whose entities are not known.\n-                skipped += 1\n-                continue\n-\n-            if (lhs_part, rhs_part) not in appenders:\n-                appenders[lhs_part, rhs_part] = appender_stack.enter_context(\n-                    edge_storage.save_edges_by_appending(lhs_part, rhs_part))\n-            appenders[lhs_part, rhs_part].append_edges(EdgeList(\n-                EntityList.from_tensor(torch.tensor([lhs_offset], dtype=torch.long)),\n-                EntityList.from_tensor(torch.tensor([rhs_offset], dtype=torch.long)),\n-                torch.tensor([rel_id], dtype=torch.long),\n-            ))\n-\n-            processed = processed + 1\n-            if processed % 100000 == 0:\n-                print(f\"- Processed {processed} edges so far...\")\n-\n-    print(f\"- Processed {processed} edges in total\")\n-    if skipped > 0:\n-        print(f\"- Skipped {skipped} edges because their relation type or \"\n-              f\"entities were unknown (either not given in the config or \"\n-              f\"filtered out as too rare).\")\n-\n-\n-def convert_input_data(\n-    entity_configs: Dict[str, EntitySchema],\n-    relation_configs: List[RelationSchema],\n-    entity_path: str,\n-    edge_paths_out: List[str],\n-    edge_paths_in: List[Path],\n-    lhs_col: int,\n-    rhs_col: int,\n-    rel_col: Optional[int] = None,\n-    entity_min_count: int = 1,\n-    relation_type_min_count: int = 1,\n-    dynamic_relations: bool = False,\n-) -> None:\n-    if len(edge_paths_in) != len(edge_paths_out):\n-        raise ValueError(\n-            f\"The edge paths passed as inputs ({edge_paths_in}) don't match \"\n-            f\"the ones specified as outputs ({edge_paths_out})\")\n-\n-    entity_storage = ENTITY_STORAGES.make_instance(entity_path)\n-    relation_type_storage = RELATION_TYPE_STORAGES.make_instance(entity_path)\n-    edge_storages = [EDGE_STORAGES.make_instance(ep) for ep in edge_paths_out]\n-\n-    some_files_exists = []\n-    some_files_exists.extend(\n-        entity_storage.has_count(entity_name, partition)\n-        for entity_name, entity_config in entity_configs.items()\n-        for partition in range(entity_config.num_partitions))\n-    some_files_exists.extend(\n-        entity_storage.has_names(entity_name, partition)\n-        for entity_name, entity_config in entity_configs.items()\n-        for partition in range(entity_config.num_partitions))\n-    if dynamic_relations:\n-        some_files_exists.append(relation_type_storage.has_count())\n-        some_files_exists.append(relation_type_storage.has_names())\n-    some_files_exists.extend(\n-        edge_storage.has_edges(0, 0) for edge_storage in edge_storages)\n-\n-    if all(some_files_exists):\n-        print(\"Found some files that indicate that the input data \"\n-              \"has already been preprocessed, not doing it again.\")\n-        all_paths = \", \".join(str(p) for p in [entity_path] + edge_paths_out)\n-        print(f\"These files are in: {all_paths}\")\n-        return\n-\n-    relation_types = collect_relation_types(\n-        relation_configs,\n-        edge_paths_in,\n-        dynamic_relations,\n-        rel_col,\n-        relation_type_min_count,\n-    )\n-\n-    entities_by_type = collect_entities_by_type(\n-        relation_types,\n-        entity_configs,\n-        relation_configs,\n-        edge_paths_in,\n-        dynamic_relations,\n-        lhs_col,\n-        rhs_col,\n-        rel_col,\n-        entity_min_count,\n-    )\n-\n-    generate_entity_path_files(\n-        entity_storage,\n-        entities_by_type,\n-        relation_type_storage,\n-        relation_types,\n-        dynamic_relations,\n-    )\n-\n-    for edge_path_in, edge_path_out, edge_storage \\\n-            in zip(edge_paths_in, edge_paths_out, edge_storages):\n-        generate_edge_path_files(\n-            edge_path_in,\n-            edge_path_out,\n-            edge_storage,\n-            entities_by_type,\n-            relation_types,\n-            relation_configs,\n-            dynamic_relations,\n-            lhs_col,\n-            rhs_col,\n-            rel_col,\n-        )\n-\n-\n-def parse_config_partial(\n-    config_dict: Any,\n-) -> Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]:\n-    entities_config = config_dict.get(\"entities\")\n-    relations_config = config_dict.get(\"relations\")\n-    entity_path = config_dict.get(\"entity_path\")\n-    edge_paths = config_dict.get(\"edge_paths\")\n-    dynamic_relations = config_dict.get(\"dynamic_relations\", False)\n-    if not isinstance(entities_config, dict):\n-        raise TypeError(\"Config entities is not of type dict\")\n-    if any(not isinstance(k, str) for k in entities_config.keys()):\n-        raise TypeError(\"Config entities has some keys that are not of type str\")\n-    if not isinstance(relations_config, list):\n-        raise TypeError(\"Config relations is not of type list\")\n-    if not isinstance(entity_path, str):\n-        raise TypeError(\"Config entity_path is not of type str\")\n-    if not isinstance(edge_paths, list):\n-        raise TypeError(\"Config edge_paths is not of type list\")\n-    if any(not isinstance(p, str) for p in edge_paths):\n-        raise TypeError(\"Config edge_paths has some items that are not of type str\")\n-    if not isinstance(dynamic_relations, bool):\n-        raise TypeError(\"Config dynamic_relations is not of type bool\")\n-\n-    entities = {}\n-    relations = []\n-    for entity, entity_config in entities_config.items():\n-        entities[entity] = EntitySchema.from_dict(entity_config)\n-    for relation in relations_config:\n-        relations.append(RelationSchema.from_dict(relation))\n-\n-    return entities, relations, entity_path, edge_paths, dynamic_relations\n-\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent": "    ConfigSchema,\n    override_config_dict,\n)\n\n",
        "target_code_with_indent_exact_match": true,
        "source_code_with_indent": "    ConfigSchema,\n    EntitySchema,\n    RelationSchema,\n    override_config_dict,\n)\nfrom torchbiggraph.converters.dictionary import Dictionary\nfrom torchbiggraph.edgelist import EdgeList\nfrom torchbiggraph.entitylist import EntityList\nfrom torchbiggraph.graph_storages import (\n    AbstractEdgeAppender,\n    AbstractEdgeStorage,\n    AbstractEntityStorage,\n    AbstractRelationTypeStorage,\n    EDGE_STORAGES,\n    ENTITY_STORAGES,\n    RELATION_TYPE_STORAGES,\n)\n\n\ndef collect_relation_types(\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    rel_col: Optional[int],\n    relation_type_min_count: int,\n) -> Dictionary:\n\n    <IND>if dynamic_relations:\n        <IND>if rel_col is None:\n            <IND>raise RuntimeError(\"Need to specify rel_col in dynamic mode.\")\n        <DED>print(\"Looking up relation types in the edge files...\")\n        counter: Counter[str] = Counter()\n        for edgepath in edge_paths:\n            <IND>with edgepath.open(\"rt\") as tf:\n                <IND>for line_num, line in enumerate(tf, start=1):\n                    <IND>words = line.split()\n                    try:\n                        <IND>rel_word = words[rel_col]\n                    <DED>except IndexError:\n                        <IND>raise RuntimeError(\n                            f\"Line {line_num} of {edgepath} has only {len(words)} words\"\n                        ) from None\n                    <DED>counter[rel_word] += 1\n        <DED><DED><DED>print(f\"- Found {len(counter)} relation types\")\n        if relation_type_min_count > 0:\n            <IND>print(f\"- Removing the ones with fewer than {relation_type_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= relation_type_min_count})\n            print(f\"- Left with {len(counter)} relation types\")\n        <DED>print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n\n    <DED>else:\n        <IND>names = [rconfig.name for rconfig in relation_configs]\n        print(f\"Using the {len(names)} relation types given in the config\")\n\n    <DED>return Dictionary(names)\n\n\n<DED>def collect_entities_by_type(\n    relation_types: Dictionary,\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n    entity_min_count: int,\n) -> Dict[str, Dictionary]:\n\n    <IND>counters: Dict[str, Counter[str]] = {}\n    for entity_name in entity_configs.keys():\n        <IND>counters[entity_name] = Counter()\n\n    <DED>print(\"Searching for the entities in the edge files...\")\n    for edgepath in edge_paths:\n        <IND>with edgepath.open(\"rt\") as tf:\n            <IND>for line_num, line in enumerate(tf, start=1):\n                <IND>words = line.split()\n                try:\n                    <IND>lhs_word = words[lhs_col]\n                    rhs_word = words[rhs_col]\n                    rel_word = words[rel_col] if rel_col is not None else None\n                <DED>except IndexError:\n                    <IND>raise RuntimeError(\n                        \"Line %d of %s has only %d words\"\n                        % (line_num, edgepath, len(words))) from None\n\n                <DED>if dynamic_relations or rel_col is None:\n                    <IND>rel_id = 0\n                <DED>else:\n                    <IND>try:\n                        <IND>rel_id = relation_types.get_id(rel_word)\n                    <DED>except KeyError:\n                        <IND>raise RuntimeError(\"Could not find relation type in config\")\n\n                <DED><DED>counters[relation_configs[rel_id].lhs][lhs_word] += 1\n                counters[relation_configs[rel_id].rhs][rhs_word] += 1\n\n    <DED><DED><DED>entities_by_type: Dict[str, Dictionary] = {}\n    for entity_name, counter in counters.items():\n        <IND>print(f\"Entity type {entity_name}:\")\n        print(f\"- Found {len(counter)} entities\")\n        if entity_min_count > 0:\n            <IND>print(f\"- Removing the ones with fewer than {entity_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= entity_min_count})\n            print(f\"- Left with {len(counter)} entities\")\n        <DED>print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n        entities_by_type[entity_name] = Dictionary(\n            names, num_parts=entity_configs[entity_name].num_partitions)\n\n    <DED>return entities_by_type\n\n\n<DED>def generate_entity_path_files(\n    entity_storage: AbstractEntityStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_type_storage: AbstractRelationTypeStorage,\n    relation_types: Dictionary,\n    dynamic_relations: bool,\n) -> None:\n    <IND>print(f\"Preparing counts and dictionaries for entities and relation types:\")\n    entity_storage.prepare()\n    relation_type_storage.prepare()\n\n    for entity_name, entities in entities_by_type.items():\n        <IND>for part in range(entities.num_parts):\n            <IND>print(f\"- Writing count of entity type {entity_name} \"\n                  f\"and partition {part}\")\n            entity_storage.save_count(entity_name, part, entities.part_size(part))\n            entity_storage.save_names(entity_name, part, entities.get_part_list(part))\n\n    <DED><DED>if dynamic_relations:\n        <IND>print(\"- Writing count of dynamic relations\")\n        relation_type_storage.save_count(relation_types.size())\n        relation_type_storage.save_names(relation_types.get_list())\n\n\n<DED><DED>def generate_edge_path_files(\n    edge_file_in: Path,\n    edge_path_out: Path,\n    edge_storage: AbstractEdgeStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_types: Dictionary,\n    relation_configs: List[RelationSchema],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n) -> None:\n    <IND>print(f\"Preparing edge path {edge_path_out}, \"\n          f\"out of the edges found in {edge_file_in}\")\n    edge_storage.prepare()\n\n    num_lhs_parts = max(entities_by_type[rconfig.lhs].num_parts\n                        for rconfig in relation_configs)\n    num_rhs_parts = max(entities_by_type[rconfig.rhs].num_parts\n                        for rconfig in relation_configs)\n\n    print(f\"- Edges will be partitioned in {num_lhs_parts} x {num_rhs_parts} buckets.\")\n\n    processed = 0\n    skipped = 0\n\n    # We use an ExitStack in order to close the dynamically-created edge appenders.\n    with edge_file_in.open(\"rt\") as tf, ExitStack() as appender_stack:\n        <IND>appenders: Dict[Tuple[int, int], AbstractEdgeAppender] = {}\n        for line_num, line in enumerate(tf, start=1):\n            <IND>words = line.split()\n            try:\n                <IND>lhs_word = words[lhs_col]\n                rhs_word = words[rhs_col]\n                rel_word = words[rel_col] if rel_col is not None else None\n            <DED>except IndexError:\n                <IND>raise RuntimeError(\n                    f\"Line {line_num} of {edge_file_in} has only {len(words)} words\"\n                ) from None\n\n            <DED>if rel_col is None:\n                <IND>rel_id = 0\n            <DED>else:\n                <IND>try:\n                    <IND>rel_id = relation_types.get_id(rel_word)\n                <DED>except KeyError:\n                    # Ignore edges whose relation type is not known.\n                    <IND>skipped += 1\n                    continue\n\n            <DED><DED>if dynamic_relations:\n                <IND>lhs_type = relation_configs[0].lhs\n                rhs_type = relation_configs[0].rhs\n            <DED>else:\n                <IND>lhs_type = relation_configs[rel_id].lhs\n                rhs_type = relation_configs[rel_id].rhs\n\n            <DED>try:\n                <IND>lhs_part, lhs_offset =                    entities_by_type[lhs_type].get_partition(lhs_word)\n                rhs_part, rhs_offset =                    entities_by_type[rhs_type].get_partition(rhs_word)\n            <DED>except KeyError:\n                # Ignore edges whose entities are not known.\n                <IND>skipped += 1\n                continue\n\n            <DED>if (lhs_part, rhs_part) not in appenders:\n                <IND>appenders[lhs_part, rhs_part] = appender_stack.enter_context(\n                    edge_storage.save_edges_by_appending(lhs_part, rhs_part))\n            <DED>appenders[lhs_part, rhs_part].append_edges(EdgeList(\n                EntityList.from_tensor(torch.tensor([lhs_offset], dtype=torch.long)),\n                EntityList.from_tensor(torch.tensor([rhs_offset], dtype=torch.long)),\n                torch.tensor([rel_id], dtype=torch.long),\n            ))\n\n            processed = processed + 1\n            if processed % 100000 == 0:\n                <IND>print(f\"- Processed {processed} edges so far...\")\n\n    <DED><DED><DED>print(f\"- Processed {processed} edges in total\")\n    if skipped > 0:\n        <IND>print(f\"- Skipped {skipped} edges because their relation type or \"\n              f\"entities were unknown (either not given in the config or \"\n              f\"filtered out as too rare).\")\n\n\n<DED><DED>def convert_input_data(\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    entity_path: str,\n    edge_paths_out: List[str],\n    edge_paths_in: List[Path],\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int] = None,\n    entity_min_count: int = 1,\n    relation_type_min_count: int = 1,\n    dynamic_relations: bool = False,\n) -> None:\n    <IND>if len(edge_paths_in) != len(edge_paths_out):\n        <IND>raise ValueError(\n            f\"The edge paths passed as inputs ({edge_paths_in}) don't match \"\n            f\"the ones specified as outputs ({edge_paths_out})\")\n\n    <DED>entity_storage = ENTITY_STORAGES.make_instance(entity_path)\n    relation_type_storage = RELATION_TYPE_STORAGES.make_instance(entity_path)\n    edge_storages = [EDGE_STORAGES.make_instance(ep) for ep in edge_paths_out]\n\n    some_files_exists = []\n    some_files_exists.extend(\n        entity_storage.has_count(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    some_files_exists.extend(\n        entity_storage.has_names(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    if dynamic_relations:\n        <IND>some_files_exists.append(relation_type_storage.has_count())\n        some_files_exists.append(relation_type_storage.has_names())\n    <DED>some_files_exists.extend(\n        edge_storage.has_edges(0, 0) for edge_storage in edge_storages)\n\n    if all(some_files_exists):\n        <IND>print(\"Found some files that indicate that the input data \"\n              \"has already been preprocessed, not doing it again.\")\n        all_paths = \", \".join(str(p) for p in [entity_path] + edge_paths_out)\n        print(f\"These files are in: {all_paths}\")\n        return\n\n    <DED>relation_types = collect_relation_types(\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        rel_col,\n        relation_type_min_count,\n    )\n\n    entities_by_type = collect_entities_by_type(\n        relation_types,\n        entity_configs,\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        lhs_col,\n        rhs_col,\n        rel_col,\n        entity_min_count,\n    )\n\n    generate_entity_path_files(\n        entity_storage,\n        entities_by_type,\n        relation_type_storage,\n        relation_types,\n        dynamic_relations,\n    )\n\n    for edge_path_in, edge_path_out, edge_storage            in zip(edge_paths_in, edge_paths_out, edge_storages):\n        <IND>generate_edge_path_files(\n            edge_path_in,\n            edge_path_out,\n            edge_storage,\n            entities_by_type,\n            relation_types,\n            relation_configs,\n            dynamic_relations,\n            lhs_col,\n            rhs_col,\n            rel_col,\n        )\n\n\n<DED><DED>def parse_config_partial(\n    config_dict: Any,\n) -> Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]:\n    <IND>entities_config = config_dict.get(\"entities\")\n    relations_config = config_dict.get(\"relations\")\n    entity_path = config_dict.get(\"entity_path\")\n    edge_paths = config_dict.get(\"edge_paths\")\n    dynamic_relations = config_dict.get(\"dynamic_relations\", False)\n    if not isinstance(entities_config, dict):\n        <IND>raise TypeError(\"Config entities is not of type dict\")\n    <DED>if any(not isinstance(k, str) for k in entities_config.keys()):\n        <IND>raise TypeError(\"Config entities has some keys that are not of type str\")\n    <DED>if not isinstance(relations_config, list):\n        <IND>raise TypeError(\"Config relations is not of type list\")\n    <DED>if not isinstance(entity_path, str):\n        <IND>raise TypeError(\"Config entity_path is not of type str\")\n    <DED>if not isinstance(edge_paths, list):\n        <IND>raise TypeError(\"Config edge_paths is not of type list\")\n    <DED>if any(not isinstance(p, str) for p in edge_paths):\n        <IND>raise TypeError(\"Config edge_paths has some items that are not of type str\")\n    <DED>if not isinstance(dynamic_relations, bool):\n        <IND>raise TypeError(\"Config dynamic_relations is not of type bool\")\n\n    <DED>entities = {}\n    relations = []\n    for entity, entity_config in entities_config.items():\n        <IND>entities[entity] = EntitySchema.from_dict(entity_config)\n    <DED>for relation in relations_config:\n        <IND>relations.append(RelationSchema.from_dict(relation))\n\n    <DED>return entities, relations, entity_path, edge_paths, dynamic_relations\n\n\n"
      }
    ]
  },
  {
    "project": "facebookresearch/PyTorch-BigGraph",
    "commit": "fb0b3ae1a85087f31f730cd4cd43f733c2bd35a3",
    "filename": "torchbiggraph/converters/import_from_tsv.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/facebookresearch-PyTorch-BigGraph/torchbiggraph/converters/import_from_tsv.py",
    "file_hunks_size": 5,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": true,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "torchbiggraph/converters/import_from_tsv.py:207:51 Incompatible parameter type [6]: Expected `str` for 1st positional only parameter to call `Dictionary.get_id` but got `Optional[str]`.",
    "message": " Expected `str` for 1st positional only parameter to call `Dictionary.get_id` but got `Optional[str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 207,
    "warning_line": "                    rel_id = relation_types.get_id(rel_word)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "    ConfigSchema,\n    EntitySchema,\n    RelationSchema,\n    override_config_dict,\n)\nfrom torchbiggraph.converters.dictionary import Dictionary\nfrom torchbiggraph.edgelist import EdgeList\nfrom torchbiggraph.entitylist import EntityList\nfrom torchbiggraph.graph_storages import (\n    AbstractEdgeAppender,\n    AbstractEdgeStorage,\n    AbstractEntityStorage,\n    AbstractRelationTypeStorage,\n    EDGE_STORAGES,\n    ENTITY_STORAGES,\n    RELATION_TYPE_STORAGES,\n)\n\n\ndef collect_relation_types(\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    rel_col: Optional[int],\n    relation_type_min_count: int,\n) -> Dictionary:\n\n    if dynamic_relations:\n        if rel_col is None:\n            raise RuntimeError(\"Need to specify rel_col in dynamic mode.\")\n        print(\"Looking up relation types in the edge files...\")\n        counter: Counter[str] = Counter()\n        for edgepath in edge_paths:\n            with edgepath.open(\"rt\") as tf:\n                for line_num, line in enumerate(tf, start=1):\n                    words = line.split()\n                    try:\n                        rel_word = words[rel_col]\n                    except IndexError:\n                        raise RuntimeError(\n                            f\"Line {line_num} of {edgepath} has only {len(words)} words\"\n                        ) from None\n                    counter[rel_word] += 1\n        print(f\"- Found {len(counter)} relation types\")\n        if relation_type_min_count > 0:\n            print(f\"- Removing the ones with fewer than {relation_type_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= relation_type_min_count})\n            print(f\"- Left with {len(counter)} relation types\")\n        print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n\n    else:\n        names = [rconfig.name for rconfig in relation_configs]\n        print(f\"Using the {len(names)} relation types given in the config\")\n\n    return Dictionary(names)\n\n\ndef collect_entities_by_type(\n    relation_types: Dictionary,\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n    entity_min_count: int,\n) -> Dict[str, Dictionary]:\n\n    counters: Dict[str, Counter[str]] = {}\n    for entity_name in entity_configs.keys():\n        counters[entity_name] = Counter()\n\n    print(\"Searching for the entities in the edge files...\")\n    for edgepath in edge_paths:\n        with edgepath.open(\"rt\") as tf:\n            for line_num, line in enumerate(tf, start=1):\n                words = line.split()\n                try:\n                    lhs_word = words[lhs_col]\n                    rhs_word = words[rhs_col]\n                    rel_word = words[rel_col] if rel_col is not None else None\n                except IndexError:\n                    raise RuntimeError(\n                        \"Line %d of %s has only %d words\"\n                        % (line_num, edgepath, len(words))) from None\n\n                if dynamic_relations or rel_col is None:\n                    rel_id = 0\n                else:\n                    try:\n                        rel_id = relation_types.get_id(rel_word)\n                    except KeyError:\n                        raise RuntimeError(\"Could not find relation type in config\")\n\n                counters[relation_configs[rel_id].lhs][lhs_word] += 1\n                counters[relation_configs[rel_id].rhs][rhs_word] += 1\n\n    entities_by_type: Dict[str, Dictionary] = {}\n    for entity_name, counter in counters.items():\n        print(f\"Entity type {entity_name}:\")\n        print(f\"- Found {len(counter)} entities\")\n        if entity_min_count > 0:\n            print(f\"- Removing the ones with fewer than {entity_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= entity_min_count})\n            print(f\"- Left with {len(counter)} entities\")\n        print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n        entities_by_type[entity_name] = Dictionary(\n            names, num_parts=entity_configs[entity_name].num_partitions)\n\n    return entities_by_type\n\n\ndef generate_entity_path_files(\n    entity_storage: AbstractEntityStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_type_storage: AbstractRelationTypeStorage,\n    relation_types: Dictionary,\n    dynamic_relations: bool,\n) -> None:\n    print(f\"Preparing counts and dictionaries for entities and relation types:\")\n    entity_storage.prepare()\n    relation_type_storage.prepare()\n\n    for entity_name, entities in entities_by_type.items():\n        for part in range(entities.num_parts):\n            print(f\"- Writing count of entity type {entity_name} \"\n                  f\"and partition {part}\")\n            entity_storage.save_count(entity_name, part, entities.part_size(part))\n            entity_storage.save_names(entity_name, part, entities.get_part_list(part))\n\n    if dynamic_relations:\n        print(\"- Writing count of dynamic relations\")\n        relation_type_storage.save_count(relation_types.size())\n        relation_type_storage.save_names(relation_types.get_list())\n\n\ndef generate_edge_path_files(\n    edge_file_in: Path,\n    edge_path_out: Path,\n    edge_storage: AbstractEdgeStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_types: Dictionary,\n    relation_configs: List[RelationSchema],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n) -> None:\n    print(f\"Preparing edge path {edge_path_out}, \"\n          f\"out of the edges found in {edge_file_in}\")\n    edge_storage.prepare()\n\n    num_lhs_parts = max(entities_by_type[rconfig.lhs].num_parts\n                        for rconfig in relation_configs)\n    num_rhs_parts = max(entities_by_type[rconfig.rhs].num_parts\n                        for rconfig in relation_configs)\n\n    print(f\"- Edges will be partitioned in {num_lhs_parts} x {num_rhs_parts} buckets.\")\n\n    processed = 0\n    skipped = 0\n\n    # We use an ExitStack in order to close the dynamically-created edge appenders.\n    with edge_file_in.open(\"rt\") as tf, ExitStack() as appender_stack:\n        appenders: Dict[Tuple[int, int], AbstractEdgeAppender] = {}\n        for line_num, line in enumerate(tf, start=1):\n            words = line.split()\n            try:\n                lhs_word = words[lhs_col]\n                rhs_word = words[rhs_col]\n                rel_word = words[rel_col] if rel_col is not None else None\n            except IndexError:\n                raise RuntimeError(\n                    f\"Line {line_num} of {edge_file_in} has only {len(words)} words\"\n                ) from None\n\n            if rel_col is None:\n                rel_id = 0\n            else:\n                try:\n                    rel_id = relation_types.get_id(rel_word)\n                except KeyError:\n                    # Ignore edges whose relation type is not known.\n                    skipped += 1\n                    continue\n\n            if dynamic_relations:\n                lhs_type = relation_configs[0].lhs\n                rhs_type = relation_configs[0].rhs\n            else:\n                lhs_type = relation_configs[rel_id].lhs\n                rhs_type = relation_configs[rel_id].rhs\n\n            try:\n                lhs_part, lhs_offset = \\\n                    entities_by_type[lhs_type].get_partition(lhs_word)\n                rhs_part, rhs_offset = \\\n                    entities_by_type[rhs_type].get_partition(rhs_word)\n            except KeyError:\n                # Ignore edges whose entities are not known.\n                skipped += 1\n                continue\n\n            if (lhs_part, rhs_part) not in appenders:\n                appenders[lhs_part, rhs_part] = appender_stack.enter_context(\n                    edge_storage.save_edges_by_appending(lhs_part, rhs_part))\n            appenders[lhs_part, rhs_part].append_edges(EdgeList(\n                EntityList.from_tensor(torch.tensor([lhs_offset], dtype=torch.long)),\n                EntityList.from_tensor(torch.tensor([rhs_offset], dtype=torch.long)),\n                torch.tensor([rel_id], dtype=torch.long),\n            ))\n\n            processed = processed + 1\n            if processed % 100000 == 0:\n                print(f\"- Processed {processed} edges so far...\")\n\n    print(f\"- Processed {processed} edges in total\")\n    if skipped > 0:\n        print(f\"- Skipped {skipped} edges because their relation type or \"\n              f\"entities were unknown (either not given in the config or \"\n              f\"filtered out as too rare).\")\n\n\ndef convert_input_data(\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    entity_path: str,\n    edge_paths_out: List[str],\n    edge_paths_in: List[Path],\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int] = None,\n    entity_min_count: int = 1,\n    relation_type_min_count: int = 1,\n    dynamic_relations: bool = False,\n) -> None:\n    if len(edge_paths_in) != len(edge_paths_out):\n        raise ValueError(\n            f\"The edge paths passed as inputs ({edge_paths_in}) don't match \"\n            f\"the ones specified as outputs ({edge_paths_out})\")\n\n    entity_storage = ENTITY_STORAGES.make_instance(entity_path)\n    relation_type_storage = RELATION_TYPE_STORAGES.make_instance(entity_path)\n    edge_storages = [EDGE_STORAGES.make_instance(ep) for ep in edge_paths_out]\n\n    some_files_exists = []\n    some_files_exists.extend(\n        entity_storage.has_count(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    some_files_exists.extend(\n        entity_storage.has_names(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    if dynamic_relations:\n        some_files_exists.append(relation_type_storage.has_count())\n        some_files_exists.append(relation_type_storage.has_names())\n    some_files_exists.extend(\n        edge_storage.has_edges(0, 0) for edge_storage in edge_storages)\n\n    if all(some_files_exists):\n        print(\"Found some files that indicate that the input data \"\n              \"has already been preprocessed, not doing it again.\")\n        all_paths = \", \".join(str(p) for p in [entity_path] + edge_paths_out)\n        print(f\"These files are in: {all_paths}\")\n        return\n\n    relation_types = collect_relation_types(\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        rel_col,\n        relation_type_min_count,\n    )\n\n    entities_by_type = collect_entities_by_type(\n        relation_types,\n        entity_configs,\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        lhs_col,\n        rhs_col,\n        rel_col,\n        entity_min_count,\n    )\n\n    generate_entity_path_files(\n        entity_storage,\n        entities_by_type,\n        relation_type_storage,\n        relation_types,\n        dynamic_relations,\n    )\n\n    for edge_path_in, edge_path_out, edge_storage \\\n            in zip(edge_paths_in, edge_paths_out, edge_storages):\n        generate_edge_path_files(\n            edge_path_in,\n            edge_path_out,\n            edge_storage,\n            entities_by_type,\n            relation_types,\n            relation_configs,\n            dynamic_relations,\n            lhs_col,\n            rhs_col,\n            rel_col,\n        )\n\n\ndef parse_config_partial(\n    config_dict: Any,\n) -> Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]:\n    entities_config = config_dict.get(\"entities\")\n    relations_config = config_dict.get(\"relations\")\n    entity_path = config_dict.get(\"entity_path\")\n    edge_paths = config_dict.get(\"edge_paths\")\n    dynamic_relations = config_dict.get(\"dynamic_relations\", False)\n    if not isinstance(entities_config, dict):\n        raise TypeError(\"Config entities is not of type dict\")\n    if any(not isinstance(k, str) for k in entities_config.keys()):\n        raise TypeError(\"Config entities has some keys that are not of type str\")\n    if not isinstance(relations_config, list):\n        raise TypeError(\"Config relations is not of type list\")\n    if not isinstance(entity_path, str):\n        raise TypeError(\"Config entity_path is not of type str\")\n    if not isinstance(edge_paths, list):\n        raise TypeError(\"Config edge_paths is not of type list\")\n    if any(not isinstance(p, str) for p in edge_paths):\n        raise TypeError(\"Config edge_paths has some items that are not of type str\")\n    if not isinstance(dynamic_relations, bool):\n        raise TypeError(\"Config dynamic_relations is not of type bool\")\n\n    entities = {}\n    relations = []\n    for entity, entity_config in entities_config.items():\n        entities[entity] = EntitySchema.from_dict(entity_config)\n    for relation in relations_config:\n        relations.append(RelationSchema.from_dict(relation))\n\n    return entities, relations, entity_path, edge_paths, dynamic_relations\n\n\n",
        "source_code_len": 13269,
        "target_code": "    ConfigSchema,\n    override_config_dict,\n)\n\n",
        "target_code_len": 47,
        "diff_format": "@@ -20,351 +20,4 @@\n     ConfigSchema,\n-    EntitySchema,\n-    RelationSchema,\n     override_config_dict,\n )\n-from torchbiggraph.converters.dictionary import Dictionary\n-from torchbiggraph.edgelist import EdgeList\n-from torchbiggraph.entitylist import EntityList\n-from torchbiggraph.graph_storages import (\n-    AbstractEdgeAppender,\n-    AbstractEdgeStorage,\n-    AbstractEntityStorage,\n-    AbstractRelationTypeStorage,\n-    EDGE_STORAGES,\n-    ENTITY_STORAGES,\n-    RELATION_TYPE_STORAGES,\n-)\n-\n-\n-def collect_relation_types(\n-    relation_configs: List[RelationSchema],\n-    edge_paths: List[Path],\n-    dynamic_relations: bool,\n-    rel_col: Optional[int],\n-    relation_type_min_count: int,\n-) -> Dictionary:\n-\n-    if dynamic_relations:\n-        if rel_col is None:\n-            raise RuntimeError(\"Need to specify rel_col in dynamic mode.\")\n-        print(\"Looking up relation types in the edge files...\")\n-        counter: Counter[str] = Counter()\n-        for edgepath in edge_paths:\n-            with edgepath.open(\"rt\") as tf:\n-                for line_num, line in enumerate(tf, start=1):\n-                    words = line.split()\n-                    try:\n-                        rel_word = words[rel_col]\n-                    except IndexError:\n-                        raise RuntimeError(\n-                            f\"Line {line_num} of {edgepath} has only {len(words)} words\"\n-                        ) from None\n-                    counter[rel_word] += 1\n-        print(f\"- Found {len(counter)} relation types\")\n-        if relation_type_min_count > 0:\n-            print(f\"- Removing the ones with fewer than {relation_type_min_count} occurrences...\")\n-            counter = Counter({k: c for k, c in counter.items()\n-                               if c >= relation_type_min_count})\n-            print(f\"- Left with {len(counter)} relation types\")\n-        print(\"- Shuffling them...\")\n-        names = list(counter.keys())\n-        random.shuffle(names)\n-\n-    else:\n-        names = [rconfig.name for rconfig in relation_configs]\n-        print(f\"Using the {len(names)} relation types given in the config\")\n-\n-    return Dictionary(names)\n-\n-\n-def collect_entities_by_type(\n-    relation_types: Dictionary,\n-    entity_configs: Dict[str, EntitySchema],\n-    relation_configs: List[RelationSchema],\n-    edge_paths: List[Path],\n-    dynamic_relations: bool,\n-    lhs_col: int,\n-    rhs_col: int,\n-    rel_col: Optional[int],\n-    entity_min_count: int,\n-) -> Dict[str, Dictionary]:\n-\n-    counters: Dict[str, Counter[str]] = {}\n-    for entity_name in entity_configs.keys():\n-        counters[entity_name] = Counter()\n-\n-    print(\"Searching for the entities in the edge files...\")\n-    for edgepath in edge_paths:\n-        with edgepath.open(\"rt\") as tf:\n-            for line_num, line in enumerate(tf, start=1):\n-                words = line.split()\n-                try:\n-                    lhs_word = words[lhs_col]\n-                    rhs_word = words[rhs_col]\n-                    rel_word = words[rel_col] if rel_col is not None else None\n-                except IndexError:\n-                    raise RuntimeError(\n-                        \"Line %d of %s has only %d words\"\n-                        % (line_num, edgepath, len(words))) from None\n-\n-                if dynamic_relations or rel_col is None:\n-                    rel_id = 0\n-                else:\n-                    try:\n-                        rel_id = relation_types.get_id(rel_word)\n-                    except KeyError:\n-                        raise RuntimeError(\"Could not find relation type in config\")\n-\n-                counters[relation_configs[rel_id].lhs][lhs_word] += 1\n-                counters[relation_configs[rel_id].rhs][rhs_word] += 1\n-\n-    entities_by_type: Dict[str, Dictionary] = {}\n-    for entity_name, counter in counters.items():\n-        print(f\"Entity type {entity_name}:\")\n-        print(f\"- Found {len(counter)} entities\")\n-        if entity_min_count > 0:\n-            print(f\"- Removing the ones with fewer than {entity_min_count} occurrences...\")\n-            counter = Counter({k: c for k, c in counter.items()\n-                               if c >= entity_min_count})\n-            print(f\"- Left with {len(counter)} entities\")\n-        print(\"- Shuffling them...\")\n-        names = list(counter.keys())\n-        random.shuffle(names)\n-        entities_by_type[entity_name] = Dictionary(\n-            names, num_parts=entity_configs[entity_name].num_partitions)\n-\n-    return entities_by_type\n-\n-\n-def generate_entity_path_files(\n-    entity_storage: AbstractEntityStorage,\n-    entities_by_type: Dict[str, Dictionary],\n-    relation_type_storage: AbstractRelationTypeStorage,\n-    relation_types: Dictionary,\n-    dynamic_relations: bool,\n-) -> None:\n-    print(f\"Preparing counts and dictionaries for entities and relation types:\")\n-    entity_storage.prepare()\n-    relation_type_storage.prepare()\n-\n-    for entity_name, entities in entities_by_type.items():\n-        for part in range(entities.num_parts):\n-            print(f\"- Writing count of entity type {entity_name} \"\n-                  f\"and partition {part}\")\n-            entity_storage.save_count(entity_name, part, entities.part_size(part))\n-            entity_storage.save_names(entity_name, part, entities.get_part_list(part))\n-\n-    if dynamic_relations:\n-        print(\"- Writing count of dynamic relations\")\n-        relation_type_storage.save_count(relation_types.size())\n-        relation_type_storage.save_names(relation_types.get_list())\n-\n-\n-def generate_edge_path_files(\n-    edge_file_in: Path,\n-    edge_path_out: Path,\n-    edge_storage: AbstractEdgeStorage,\n-    entities_by_type: Dict[str, Dictionary],\n-    relation_types: Dictionary,\n-    relation_configs: List[RelationSchema],\n-    dynamic_relations: bool,\n-    lhs_col: int,\n-    rhs_col: int,\n-    rel_col: Optional[int],\n-) -> None:\n-    print(f\"Preparing edge path {edge_path_out}, \"\n-          f\"out of the edges found in {edge_file_in}\")\n-    edge_storage.prepare()\n-\n-    num_lhs_parts = max(entities_by_type[rconfig.lhs].num_parts\n-                        for rconfig in relation_configs)\n-    num_rhs_parts = max(entities_by_type[rconfig.rhs].num_parts\n-                        for rconfig in relation_configs)\n-\n-    print(f\"- Edges will be partitioned in {num_lhs_parts} x {num_rhs_parts} buckets.\")\n-\n-    processed = 0\n-    skipped = 0\n-\n-    # We use an ExitStack in order to close the dynamically-created edge appenders.\n-    with edge_file_in.open(\"rt\") as tf, ExitStack() as appender_stack:\n-        appenders: Dict[Tuple[int, int], AbstractEdgeAppender] = {}\n-        for line_num, line in enumerate(tf, start=1):\n-            words = line.split()\n-            try:\n-                lhs_word = words[lhs_col]\n-                rhs_word = words[rhs_col]\n-                rel_word = words[rel_col] if rel_col is not None else None\n-            except IndexError:\n-                raise RuntimeError(\n-                    f\"Line {line_num} of {edge_file_in} has only {len(words)} words\"\n-                ) from None\n-\n-            if rel_col is None:\n-                rel_id = 0\n-            else:\n-                try:\n-                    rel_id = relation_types.get_id(rel_word)\n-                except KeyError:\n-                    # Ignore edges whose relation type is not known.\n-                    skipped += 1\n-                    continue\n-\n-            if dynamic_relations:\n-                lhs_type = relation_configs[0].lhs\n-                rhs_type = relation_configs[0].rhs\n-            else:\n-                lhs_type = relation_configs[rel_id].lhs\n-                rhs_type = relation_configs[rel_id].rhs\n-\n-            try:\n-                lhs_part, lhs_offset = \\\n-                    entities_by_type[lhs_type].get_partition(lhs_word)\n-                rhs_part, rhs_offset = \\\n-                    entities_by_type[rhs_type].get_partition(rhs_word)\n-            except KeyError:\n-                # Ignore edges whose entities are not known.\n-                skipped += 1\n-                continue\n-\n-            if (lhs_part, rhs_part) not in appenders:\n-                appenders[lhs_part, rhs_part] = appender_stack.enter_context(\n-                    edge_storage.save_edges_by_appending(lhs_part, rhs_part))\n-            appenders[lhs_part, rhs_part].append_edges(EdgeList(\n-                EntityList.from_tensor(torch.tensor([lhs_offset], dtype=torch.long)),\n-                EntityList.from_tensor(torch.tensor([rhs_offset], dtype=torch.long)),\n-                torch.tensor([rel_id], dtype=torch.long),\n-            ))\n-\n-            processed = processed + 1\n-            if processed % 100000 == 0:\n-                print(f\"- Processed {processed} edges so far...\")\n-\n-    print(f\"- Processed {processed} edges in total\")\n-    if skipped > 0:\n-        print(f\"- Skipped {skipped} edges because their relation type or \"\n-              f\"entities were unknown (either not given in the config or \"\n-              f\"filtered out as too rare).\")\n-\n-\n-def convert_input_data(\n-    entity_configs: Dict[str, EntitySchema],\n-    relation_configs: List[RelationSchema],\n-    entity_path: str,\n-    edge_paths_out: List[str],\n-    edge_paths_in: List[Path],\n-    lhs_col: int,\n-    rhs_col: int,\n-    rel_col: Optional[int] = None,\n-    entity_min_count: int = 1,\n-    relation_type_min_count: int = 1,\n-    dynamic_relations: bool = False,\n-) -> None:\n-    if len(edge_paths_in) != len(edge_paths_out):\n-        raise ValueError(\n-            f\"The edge paths passed as inputs ({edge_paths_in}) don't match \"\n-            f\"the ones specified as outputs ({edge_paths_out})\")\n-\n-    entity_storage = ENTITY_STORAGES.make_instance(entity_path)\n-    relation_type_storage = RELATION_TYPE_STORAGES.make_instance(entity_path)\n-    edge_storages = [EDGE_STORAGES.make_instance(ep) for ep in edge_paths_out]\n-\n-    some_files_exists = []\n-    some_files_exists.extend(\n-        entity_storage.has_count(entity_name, partition)\n-        for entity_name, entity_config in entity_configs.items()\n-        for partition in range(entity_config.num_partitions))\n-    some_files_exists.extend(\n-        entity_storage.has_names(entity_name, partition)\n-        for entity_name, entity_config in entity_configs.items()\n-        for partition in range(entity_config.num_partitions))\n-    if dynamic_relations:\n-        some_files_exists.append(relation_type_storage.has_count())\n-        some_files_exists.append(relation_type_storage.has_names())\n-    some_files_exists.extend(\n-        edge_storage.has_edges(0, 0) for edge_storage in edge_storages)\n-\n-    if all(some_files_exists):\n-        print(\"Found some files that indicate that the input data \"\n-              \"has already been preprocessed, not doing it again.\")\n-        all_paths = \", \".join(str(p) for p in [entity_path] + edge_paths_out)\n-        print(f\"These files are in: {all_paths}\")\n-        return\n-\n-    relation_types = collect_relation_types(\n-        relation_configs,\n-        edge_paths_in,\n-        dynamic_relations,\n-        rel_col,\n-        relation_type_min_count,\n-    )\n-\n-    entities_by_type = collect_entities_by_type(\n-        relation_types,\n-        entity_configs,\n-        relation_configs,\n-        edge_paths_in,\n-        dynamic_relations,\n-        lhs_col,\n-        rhs_col,\n-        rel_col,\n-        entity_min_count,\n-    )\n-\n-    generate_entity_path_files(\n-        entity_storage,\n-        entities_by_type,\n-        relation_type_storage,\n-        relation_types,\n-        dynamic_relations,\n-    )\n-\n-    for edge_path_in, edge_path_out, edge_storage \\\n-            in zip(edge_paths_in, edge_paths_out, edge_storages):\n-        generate_edge_path_files(\n-            edge_path_in,\n-            edge_path_out,\n-            edge_storage,\n-            entities_by_type,\n-            relation_types,\n-            relation_configs,\n-            dynamic_relations,\n-            lhs_col,\n-            rhs_col,\n-            rel_col,\n-        )\n-\n-\n-def parse_config_partial(\n-    config_dict: Any,\n-) -> Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]:\n-    entities_config = config_dict.get(\"entities\")\n-    relations_config = config_dict.get(\"relations\")\n-    entity_path = config_dict.get(\"entity_path\")\n-    edge_paths = config_dict.get(\"edge_paths\")\n-    dynamic_relations = config_dict.get(\"dynamic_relations\", False)\n-    if not isinstance(entities_config, dict):\n-        raise TypeError(\"Config entities is not of type dict\")\n-    if any(not isinstance(k, str) for k in entities_config.keys()):\n-        raise TypeError(\"Config entities has some keys that are not of type str\")\n-    if not isinstance(relations_config, list):\n-        raise TypeError(\"Config relations is not of type list\")\n-    if not isinstance(entity_path, str):\n-        raise TypeError(\"Config entity_path is not of type str\")\n-    if not isinstance(edge_paths, list):\n-        raise TypeError(\"Config edge_paths is not of type list\")\n-    if any(not isinstance(p, str) for p in edge_paths):\n-        raise TypeError(\"Config edge_paths has some items that are not of type str\")\n-    if not isinstance(dynamic_relations, bool):\n-        raise TypeError(\"Config dynamic_relations is not of type bool\")\n-\n-    entities = {}\n-    relations = []\n-    for entity, entity_config in entities_config.items():\n-        entities[entity] = EntitySchema.from_dict(entity_config)\n-    for relation in relations_config:\n-        relations.append(RelationSchema.from_dict(relation))\n-\n-    return entities, relations, entity_path, edge_paths, dynamic_relations\n-\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent": "    ConfigSchema,\n    override_config_dict,\n)\n\n",
        "target_code_with_indent_exact_match": true,
        "source_code_with_indent": "    ConfigSchema,\n    EntitySchema,\n    RelationSchema,\n    override_config_dict,\n)\nfrom torchbiggraph.converters.dictionary import Dictionary\nfrom torchbiggraph.edgelist import EdgeList\nfrom torchbiggraph.entitylist import EntityList\nfrom torchbiggraph.graph_storages import (\n    AbstractEdgeAppender,\n    AbstractEdgeStorage,\n    AbstractEntityStorage,\n    AbstractRelationTypeStorage,\n    EDGE_STORAGES,\n    ENTITY_STORAGES,\n    RELATION_TYPE_STORAGES,\n)\n\n\ndef collect_relation_types(\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    rel_col: Optional[int],\n    relation_type_min_count: int,\n) -> Dictionary:\n\n    <IND>if dynamic_relations:\n        <IND>if rel_col is None:\n            <IND>raise RuntimeError(\"Need to specify rel_col in dynamic mode.\")\n        <DED>print(\"Looking up relation types in the edge files...\")\n        counter: Counter[str] = Counter()\n        for edgepath in edge_paths:\n            <IND>with edgepath.open(\"rt\") as tf:\n                <IND>for line_num, line in enumerate(tf, start=1):\n                    <IND>words = line.split()\n                    try:\n                        <IND>rel_word = words[rel_col]\n                    <DED>except IndexError:\n                        <IND>raise RuntimeError(\n                            f\"Line {line_num} of {edgepath} has only {len(words)} words\"\n                        ) from None\n                    <DED>counter[rel_word] += 1\n        <DED><DED><DED>print(f\"- Found {len(counter)} relation types\")\n        if relation_type_min_count > 0:\n            <IND>print(f\"- Removing the ones with fewer than {relation_type_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= relation_type_min_count})\n            print(f\"- Left with {len(counter)} relation types\")\n        <DED>print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n\n    <DED>else:\n        <IND>names = [rconfig.name for rconfig in relation_configs]\n        print(f\"Using the {len(names)} relation types given in the config\")\n\n    <DED>return Dictionary(names)\n\n\n<DED>def collect_entities_by_type(\n    relation_types: Dictionary,\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n    entity_min_count: int,\n) -> Dict[str, Dictionary]:\n\n    <IND>counters: Dict[str, Counter[str]] = {}\n    for entity_name in entity_configs.keys():\n        <IND>counters[entity_name] = Counter()\n\n    <DED>print(\"Searching for the entities in the edge files...\")\n    for edgepath in edge_paths:\n        <IND>with edgepath.open(\"rt\") as tf:\n            <IND>for line_num, line in enumerate(tf, start=1):\n                <IND>words = line.split()\n                try:\n                    <IND>lhs_word = words[lhs_col]\n                    rhs_word = words[rhs_col]\n                    rel_word = words[rel_col] if rel_col is not None else None\n                <DED>except IndexError:\n                    <IND>raise RuntimeError(\n                        \"Line %d of %s has only %d words\"\n                        % (line_num, edgepath, len(words))) from None\n\n                <DED>if dynamic_relations or rel_col is None:\n                    <IND>rel_id = 0\n                <DED>else:\n                    <IND>try:\n                        <IND>rel_id = relation_types.get_id(rel_word)\n                    <DED>except KeyError:\n                        <IND>raise RuntimeError(\"Could not find relation type in config\")\n\n                <DED><DED>counters[relation_configs[rel_id].lhs][lhs_word] += 1\n                counters[relation_configs[rel_id].rhs][rhs_word] += 1\n\n    <DED><DED><DED>entities_by_type: Dict[str, Dictionary] = {}\n    for entity_name, counter in counters.items():\n        <IND>print(f\"Entity type {entity_name}:\")\n        print(f\"- Found {len(counter)} entities\")\n        if entity_min_count > 0:\n            <IND>print(f\"- Removing the ones with fewer than {entity_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= entity_min_count})\n            print(f\"- Left with {len(counter)} entities\")\n        <DED>print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n        entities_by_type[entity_name] = Dictionary(\n            names, num_parts=entity_configs[entity_name].num_partitions)\n\n    <DED>return entities_by_type\n\n\n<DED>def generate_entity_path_files(\n    entity_storage: AbstractEntityStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_type_storage: AbstractRelationTypeStorage,\n    relation_types: Dictionary,\n    dynamic_relations: bool,\n) -> None:\n    <IND>print(f\"Preparing counts and dictionaries for entities and relation types:\")\n    entity_storage.prepare()\n    relation_type_storage.prepare()\n\n    for entity_name, entities in entities_by_type.items():\n        <IND>for part in range(entities.num_parts):\n            <IND>print(f\"- Writing count of entity type {entity_name} \"\n                  f\"and partition {part}\")\n            entity_storage.save_count(entity_name, part, entities.part_size(part))\n            entity_storage.save_names(entity_name, part, entities.get_part_list(part))\n\n    <DED><DED>if dynamic_relations:\n        <IND>print(\"- Writing count of dynamic relations\")\n        relation_type_storage.save_count(relation_types.size())\n        relation_type_storage.save_names(relation_types.get_list())\n\n\n<DED><DED>def generate_edge_path_files(\n    edge_file_in: Path,\n    edge_path_out: Path,\n    edge_storage: AbstractEdgeStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_types: Dictionary,\n    relation_configs: List[RelationSchema],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n) -> None:\n    <IND>print(f\"Preparing edge path {edge_path_out}, \"\n          f\"out of the edges found in {edge_file_in}\")\n    edge_storage.prepare()\n\n    num_lhs_parts = max(entities_by_type[rconfig.lhs].num_parts\n                        for rconfig in relation_configs)\n    num_rhs_parts = max(entities_by_type[rconfig.rhs].num_parts\n                        for rconfig in relation_configs)\n\n    print(f\"- Edges will be partitioned in {num_lhs_parts} x {num_rhs_parts} buckets.\")\n\n    processed = 0\n    skipped = 0\n\n    # We use an ExitStack in order to close the dynamically-created edge appenders.\n    with edge_file_in.open(\"rt\") as tf, ExitStack() as appender_stack:\n        <IND>appenders: Dict[Tuple[int, int], AbstractEdgeAppender] = {}\n        for line_num, line in enumerate(tf, start=1):\n            <IND>words = line.split()\n            try:\n                <IND>lhs_word = words[lhs_col]\n                rhs_word = words[rhs_col]\n                rel_word = words[rel_col] if rel_col is not None else None\n            <DED>except IndexError:\n                <IND>raise RuntimeError(\n                    f\"Line {line_num} of {edge_file_in} has only {len(words)} words\"\n                ) from None\n\n            <DED>if rel_col is None:\n                <IND>rel_id = 0\n            <DED>else:\n                <IND>try:\n                    <IND>rel_id = relation_types.get_id(rel_word)\n                <DED>except KeyError:\n                    # Ignore edges whose relation type is not known.\n                    <IND>skipped += 1\n                    continue\n\n            <DED><DED>if dynamic_relations:\n                <IND>lhs_type = relation_configs[0].lhs\n                rhs_type = relation_configs[0].rhs\n            <DED>else:\n                <IND>lhs_type = relation_configs[rel_id].lhs\n                rhs_type = relation_configs[rel_id].rhs\n\n            <DED>try:\n                <IND>lhs_part, lhs_offset =                    entities_by_type[lhs_type].get_partition(lhs_word)\n                rhs_part, rhs_offset =                    entities_by_type[rhs_type].get_partition(rhs_word)\n            <DED>except KeyError:\n                # Ignore edges whose entities are not known.\n                <IND>skipped += 1\n                continue\n\n            <DED>if (lhs_part, rhs_part) not in appenders:\n                <IND>appenders[lhs_part, rhs_part] = appender_stack.enter_context(\n                    edge_storage.save_edges_by_appending(lhs_part, rhs_part))\n            <DED>appenders[lhs_part, rhs_part].append_edges(EdgeList(\n                EntityList.from_tensor(torch.tensor([lhs_offset], dtype=torch.long)),\n                EntityList.from_tensor(torch.tensor([rhs_offset], dtype=torch.long)),\n                torch.tensor([rel_id], dtype=torch.long),\n            ))\n\n            processed = processed + 1\n            if processed % 100000 == 0:\n                <IND>print(f\"- Processed {processed} edges so far...\")\n\n    <DED><DED><DED>print(f\"- Processed {processed} edges in total\")\n    if skipped > 0:\n        <IND>print(f\"- Skipped {skipped} edges because their relation type or \"\n              f\"entities were unknown (either not given in the config or \"\n              f\"filtered out as too rare).\")\n\n\n<DED><DED>def convert_input_data(\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    entity_path: str,\n    edge_paths_out: List[str],\n    edge_paths_in: List[Path],\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int] = None,\n    entity_min_count: int = 1,\n    relation_type_min_count: int = 1,\n    dynamic_relations: bool = False,\n) -> None:\n    <IND>if len(edge_paths_in) != len(edge_paths_out):\n        <IND>raise ValueError(\n            f\"The edge paths passed as inputs ({edge_paths_in}) don't match \"\n            f\"the ones specified as outputs ({edge_paths_out})\")\n\n    <DED>entity_storage = ENTITY_STORAGES.make_instance(entity_path)\n    relation_type_storage = RELATION_TYPE_STORAGES.make_instance(entity_path)\n    edge_storages = [EDGE_STORAGES.make_instance(ep) for ep in edge_paths_out]\n\n    some_files_exists = []\n    some_files_exists.extend(\n        entity_storage.has_count(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    some_files_exists.extend(\n        entity_storage.has_names(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    if dynamic_relations:\n        <IND>some_files_exists.append(relation_type_storage.has_count())\n        some_files_exists.append(relation_type_storage.has_names())\n    <DED>some_files_exists.extend(\n        edge_storage.has_edges(0, 0) for edge_storage in edge_storages)\n\n    if all(some_files_exists):\n        <IND>print(\"Found some files that indicate that the input data \"\n              \"has already been preprocessed, not doing it again.\")\n        all_paths = \", \".join(str(p) for p in [entity_path] + edge_paths_out)\n        print(f\"These files are in: {all_paths}\")\n        return\n\n    <DED>relation_types = collect_relation_types(\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        rel_col,\n        relation_type_min_count,\n    )\n\n    entities_by_type = collect_entities_by_type(\n        relation_types,\n        entity_configs,\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        lhs_col,\n        rhs_col,\n        rel_col,\n        entity_min_count,\n    )\n\n    generate_entity_path_files(\n        entity_storage,\n        entities_by_type,\n        relation_type_storage,\n        relation_types,\n        dynamic_relations,\n    )\n\n    for edge_path_in, edge_path_out, edge_storage            in zip(edge_paths_in, edge_paths_out, edge_storages):\n        <IND>generate_edge_path_files(\n            edge_path_in,\n            edge_path_out,\n            edge_storage,\n            entities_by_type,\n            relation_types,\n            relation_configs,\n            dynamic_relations,\n            lhs_col,\n            rhs_col,\n            rel_col,\n        )\n\n\n<DED><DED>def parse_config_partial(\n    config_dict: Any,\n) -> Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]:\n    <IND>entities_config = config_dict.get(\"entities\")\n    relations_config = config_dict.get(\"relations\")\n    entity_path = config_dict.get(\"entity_path\")\n    edge_paths = config_dict.get(\"edge_paths\")\n    dynamic_relations = config_dict.get(\"dynamic_relations\", False)\n    if not isinstance(entities_config, dict):\n        <IND>raise TypeError(\"Config entities is not of type dict\")\n    <DED>if any(not isinstance(k, str) for k in entities_config.keys()):\n        <IND>raise TypeError(\"Config entities has some keys that are not of type str\")\n    <DED>if not isinstance(relations_config, list):\n        <IND>raise TypeError(\"Config relations is not of type list\")\n    <DED>if not isinstance(entity_path, str):\n        <IND>raise TypeError(\"Config entity_path is not of type str\")\n    <DED>if not isinstance(edge_paths, list):\n        <IND>raise TypeError(\"Config edge_paths is not of type list\")\n    <DED>if any(not isinstance(p, str) for p in edge_paths):\n        <IND>raise TypeError(\"Config edge_paths has some items that are not of type str\")\n    <DED>if not isinstance(dynamic_relations, bool):\n        <IND>raise TypeError(\"Config dynamic_relations is not of type bool\")\n\n    <DED>entities = {}\n    relations = []\n    for entity, entity_config in entities_config.items():\n        <IND>entities[entity] = EntitySchema.from_dict(entity_config)\n    <DED>for relation in relations_config:\n        <IND>relations.append(RelationSchema.from_dict(relation))\n\n    <DED>return entities, relations, entity_path, edge_paths, dynamic_relations\n\n\n"
      }
    ]
  },
  {
    "project": "facebookresearch/PyTorch-BigGraph",
    "commit": "fb0b3ae1a85087f31f730cd4cd43f733c2bd35a3",
    "filename": "torchbiggraph/converters/import_from_tsv.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/facebookresearch-PyTorch-BigGraph/torchbiggraph/converters/import_from_tsv.py",
    "file_hunks_size": 5,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": true,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "torchbiggraph/converters/import_from_tsv.py:368:4 Incompatible return type [7]: Expected `Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]` but got `Tuple[Dict[typing.Any, typing.Any], List[typing.Any], str, List[typing.Any], bool]`.",
    "message": " Expected `Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]` but got `Tuple[Dict[typing.Any, typing.Any], List[typing.Any], str, List[typing.Any], bool]`.",
    "rule_id": "Incompatible return type [7]",
    "warning_line_no": 368,
    "warning_line": "    return entities, relations, entity_path, edge_paths, dynamic_relations",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "    ConfigSchema,\n    EntitySchema,\n    RelationSchema,\n    override_config_dict,\n)\nfrom torchbiggraph.converters.dictionary import Dictionary\nfrom torchbiggraph.edgelist import EdgeList\nfrom torchbiggraph.entitylist import EntityList\nfrom torchbiggraph.graph_storages import (\n    AbstractEdgeAppender,\n    AbstractEdgeStorage,\n    AbstractEntityStorage,\n    AbstractRelationTypeStorage,\n    EDGE_STORAGES,\n    ENTITY_STORAGES,\n    RELATION_TYPE_STORAGES,\n)\n\n\ndef collect_relation_types(\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    rel_col: Optional[int],\n    relation_type_min_count: int,\n) -> Dictionary:\n\n    if dynamic_relations:\n        if rel_col is None:\n            raise RuntimeError(\"Need to specify rel_col in dynamic mode.\")\n        print(\"Looking up relation types in the edge files...\")\n        counter: Counter[str] = Counter()\n        for edgepath in edge_paths:\n            with edgepath.open(\"rt\") as tf:\n                for line_num, line in enumerate(tf, start=1):\n                    words = line.split()\n                    try:\n                        rel_word = words[rel_col]\n                    except IndexError:\n                        raise RuntimeError(\n                            f\"Line {line_num} of {edgepath} has only {len(words)} words\"\n                        ) from None\n                    counter[rel_word] += 1\n        print(f\"- Found {len(counter)} relation types\")\n        if relation_type_min_count > 0:\n            print(f\"- Removing the ones with fewer than {relation_type_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= relation_type_min_count})\n            print(f\"- Left with {len(counter)} relation types\")\n        print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n\n    else:\n        names = [rconfig.name for rconfig in relation_configs]\n        print(f\"Using the {len(names)} relation types given in the config\")\n\n    return Dictionary(names)\n\n\ndef collect_entities_by_type(\n    relation_types: Dictionary,\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n    entity_min_count: int,\n) -> Dict[str, Dictionary]:\n\n    counters: Dict[str, Counter[str]] = {}\n    for entity_name in entity_configs.keys():\n        counters[entity_name] = Counter()\n\n    print(\"Searching for the entities in the edge files...\")\n    for edgepath in edge_paths:\n        with edgepath.open(\"rt\") as tf:\n            for line_num, line in enumerate(tf, start=1):\n                words = line.split()\n                try:\n                    lhs_word = words[lhs_col]\n                    rhs_word = words[rhs_col]\n                    rel_word = words[rel_col] if rel_col is not None else None\n                except IndexError:\n                    raise RuntimeError(\n                        \"Line %d of %s has only %d words\"\n                        % (line_num, edgepath, len(words))) from None\n\n                if dynamic_relations or rel_col is None:\n                    rel_id = 0\n                else:\n                    try:\n                        rel_id = relation_types.get_id(rel_word)\n                    except KeyError:\n                        raise RuntimeError(\"Could not find relation type in config\")\n\n                counters[relation_configs[rel_id].lhs][lhs_word] += 1\n                counters[relation_configs[rel_id].rhs][rhs_word] += 1\n\n    entities_by_type: Dict[str, Dictionary] = {}\n    for entity_name, counter in counters.items():\n        print(f\"Entity type {entity_name}:\")\n        print(f\"- Found {len(counter)} entities\")\n        if entity_min_count > 0:\n            print(f\"- Removing the ones with fewer than {entity_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= entity_min_count})\n            print(f\"- Left with {len(counter)} entities\")\n        print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n        entities_by_type[entity_name] = Dictionary(\n            names, num_parts=entity_configs[entity_name].num_partitions)\n\n    return entities_by_type\n\n\ndef generate_entity_path_files(\n    entity_storage: AbstractEntityStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_type_storage: AbstractRelationTypeStorage,\n    relation_types: Dictionary,\n    dynamic_relations: bool,\n) -> None:\n    print(f\"Preparing counts and dictionaries for entities and relation types:\")\n    entity_storage.prepare()\n    relation_type_storage.prepare()\n\n    for entity_name, entities in entities_by_type.items():\n        for part in range(entities.num_parts):\n            print(f\"- Writing count of entity type {entity_name} \"\n                  f\"and partition {part}\")\n            entity_storage.save_count(entity_name, part, entities.part_size(part))\n            entity_storage.save_names(entity_name, part, entities.get_part_list(part))\n\n    if dynamic_relations:\n        print(\"- Writing count of dynamic relations\")\n        relation_type_storage.save_count(relation_types.size())\n        relation_type_storage.save_names(relation_types.get_list())\n\n\ndef generate_edge_path_files(\n    edge_file_in: Path,\n    edge_path_out: Path,\n    edge_storage: AbstractEdgeStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_types: Dictionary,\n    relation_configs: List[RelationSchema],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n) -> None:\n    print(f\"Preparing edge path {edge_path_out}, \"\n          f\"out of the edges found in {edge_file_in}\")\n    edge_storage.prepare()\n\n    num_lhs_parts = max(entities_by_type[rconfig.lhs].num_parts\n                        for rconfig in relation_configs)\n    num_rhs_parts = max(entities_by_type[rconfig.rhs].num_parts\n                        for rconfig in relation_configs)\n\n    print(f\"- Edges will be partitioned in {num_lhs_parts} x {num_rhs_parts} buckets.\")\n\n    processed = 0\n    skipped = 0\n\n    # We use an ExitStack in order to close the dynamically-created edge appenders.\n    with edge_file_in.open(\"rt\") as tf, ExitStack() as appender_stack:\n        appenders: Dict[Tuple[int, int], AbstractEdgeAppender] = {}\n        for line_num, line in enumerate(tf, start=1):\n            words = line.split()\n            try:\n                lhs_word = words[lhs_col]\n                rhs_word = words[rhs_col]\n                rel_word = words[rel_col] if rel_col is not None else None\n            except IndexError:\n                raise RuntimeError(\n                    f\"Line {line_num} of {edge_file_in} has only {len(words)} words\"\n                ) from None\n\n            if rel_col is None:\n                rel_id = 0\n            else:\n                try:\n                    rel_id = relation_types.get_id(rel_word)\n                except KeyError:\n                    # Ignore edges whose relation type is not known.\n                    skipped += 1\n                    continue\n\n            if dynamic_relations:\n                lhs_type = relation_configs[0].lhs\n                rhs_type = relation_configs[0].rhs\n            else:\n                lhs_type = relation_configs[rel_id].lhs\n                rhs_type = relation_configs[rel_id].rhs\n\n            try:\n                lhs_part, lhs_offset = \\\n                    entities_by_type[lhs_type].get_partition(lhs_word)\n                rhs_part, rhs_offset = \\\n                    entities_by_type[rhs_type].get_partition(rhs_word)\n            except KeyError:\n                # Ignore edges whose entities are not known.\n                skipped += 1\n                continue\n\n            if (lhs_part, rhs_part) not in appenders:\n                appenders[lhs_part, rhs_part] = appender_stack.enter_context(\n                    edge_storage.save_edges_by_appending(lhs_part, rhs_part))\n            appenders[lhs_part, rhs_part].append_edges(EdgeList(\n                EntityList.from_tensor(torch.tensor([lhs_offset], dtype=torch.long)),\n                EntityList.from_tensor(torch.tensor([rhs_offset], dtype=torch.long)),\n                torch.tensor([rel_id], dtype=torch.long),\n            ))\n\n            processed = processed + 1\n            if processed % 100000 == 0:\n                print(f\"- Processed {processed} edges so far...\")\n\n    print(f\"- Processed {processed} edges in total\")\n    if skipped > 0:\n        print(f\"- Skipped {skipped} edges because their relation type or \"\n              f\"entities were unknown (either not given in the config or \"\n              f\"filtered out as too rare).\")\n\n\ndef convert_input_data(\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    entity_path: str,\n    edge_paths_out: List[str],\n    edge_paths_in: List[Path],\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int] = None,\n    entity_min_count: int = 1,\n    relation_type_min_count: int = 1,\n    dynamic_relations: bool = False,\n) -> None:\n    if len(edge_paths_in) != len(edge_paths_out):\n        raise ValueError(\n            f\"The edge paths passed as inputs ({edge_paths_in}) don't match \"\n            f\"the ones specified as outputs ({edge_paths_out})\")\n\n    entity_storage = ENTITY_STORAGES.make_instance(entity_path)\n    relation_type_storage = RELATION_TYPE_STORAGES.make_instance(entity_path)\n    edge_storages = [EDGE_STORAGES.make_instance(ep) for ep in edge_paths_out]\n\n    some_files_exists = []\n    some_files_exists.extend(\n        entity_storage.has_count(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    some_files_exists.extend(\n        entity_storage.has_names(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    if dynamic_relations:\n        some_files_exists.append(relation_type_storage.has_count())\n        some_files_exists.append(relation_type_storage.has_names())\n    some_files_exists.extend(\n        edge_storage.has_edges(0, 0) for edge_storage in edge_storages)\n\n    if all(some_files_exists):\n        print(\"Found some files that indicate that the input data \"\n              \"has already been preprocessed, not doing it again.\")\n        all_paths = \", \".join(str(p) for p in [entity_path] + edge_paths_out)\n        print(f\"These files are in: {all_paths}\")\n        return\n\n    relation_types = collect_relation_types(\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        rel_col,\n        relation_type_min_count,\n    )\n\n    entities_by_type = collect_entities_by_type(\n        relation_types,\n        entity_configs,\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        lhs_col,\n        rhs_col,\n        rel_col,\n        entity_min_count,\n    )\n\n    generate_entity_path_files(\n        entity_storage,\n        entities_by_type,\n        relation_type_storage,\n        relation_types,\n        dynamic_relations,\n    )\n\n    for edge_path_in, edge_path_out, edge_storage \\\n            in zip(edge_paths_in, edge_paths_out, edge_storages):\n        generate_edge_path_files(\n            edge_path_in,\n            edge_path_out,\n            edge_storage,\n            entities_by_type,\n            relation_types,\n            relation_configs,\n            dynamic_relations,\n            lhs_col,\n            rhs_col,\n            rel_col,\n        )\n\n\ndef parse_config_partial(\n    config_dict: Any,\n) -> Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]:\n    entities_config = config_dict.get(\"entities\")\n    relations_config = config_dict.get(\"relations\")\n    entity_path = config_dict.get(\"entity_path\")\n    edge_paths = config_dict.get(\"edge_paths\")\n    dynamic_relations = config_dict.get(\"dynamic_relations\", False)\n    if not isinstance(entities_config, dict):\n        raise TypeError(\"Config entities is not of type dict\")\n    if any(not isinstance(k, str) for k in entities_config.keys()):\n        raise TypeError(\"Config entities has some keys that are not of type str\")\n    if not isinstance(relations_config, list):\n        raise TypeError(\"Config relations is not of type list\")\n    if not isinstance(entity_path, str):\n        raise TypeError(\"Config entity_path is not of type str\")\n    if not isinstance(edge_paths, list):\n        raise TypeError(\"Config edge_paths is not of type list\")\n    if any(not isinstance(p, str) for p in edge_paths):\n        raise TypeError(\"Config edge_paths has some items that are not of type str\")\n    if not isinstance(dynamic_relations, bool):\n        raise TypeError(\"Config dynamic_relations is not of type bool\")\n\n    entities = {}\n    relations = []\n    for entity, entity_config in entities_config.items():\n        entities[entity] = EntitySchema.from_dict(entity_config)\n    for relation in relations_config:\n        relations.append(RelationSchema.from_dict(relation))\n\n    return entities, relations, entity_path, edge_paths, dynamic_relations\n\n\n",
        "source_code_len": 13269,
        "target_code": "    ConfigSchema,\n    override_config_dict,\n)\n\n",
        "target_code_len": 47,
        "diff_format": "@@ -20,351 +20,4 @@\n     ConfigSchema,\n-    EntitySchema,\n-    RelationSchema,\n     override_config_dict,\n )\n-from torchbiggraph.converters.dictionary import Dictionary\n-from torchbiggraph.edgelist import EdgeList\n-from torchbiggraph.entitylist import EntityList\n-from torchbiggraph.graph_storages import (\n-    AbstractEdgeAppender,\n-    AbstractEdgeStorage,\n-    AbstractEntityStorage,\n-    AbstractRelationTypeStorage,\n-    EDGE_STORAGES,\n-    ENTITY_STORAGES,\n-    RELATION_TYPE_STORAGES,\n-)\n-\n-\n-def collect_relation_types(\n-    relation_configs: List[RelationSchema],\n-    edge_paths: List[Path],\n-    dynamic_relations: bool,\n-    rel_col: Optional[int],\n-    relation_type_min_count: int,\n-) -> Dictionary:\n-\n-    if dynamic_relations:\n-        if rel_col is None:\n-            raise RuntimeError(\"Need to specify rel_col in dynamic mode.\")\n-        print(\"Looking up relation types in the edge files...\")\n-        counter: Counter[str] = Counter()\n-        for edgepath in edge_paths:\n-            with edgepath.open(\"rt\") as tf:\n-                for line_num, line in enumerate(tf, start=1):\n-                    words = line.split()\n-                    try:\n-                        rel_word = words[rel_col]\n-                    except IndexError:\n-                        raise RuntimeError(\n-                            f\"Line {line_num} of {edgepath} has only {len(words)} words\"\n-                        ) from None\n-                    counter[rel_word] += 1\n-        print(f\"- Found {len(counter)} relation types\")\n-        if relation_type_min_count > 0:\n-            print(f\"- Removing the ones with fewer than {relation_type_min_count} occurrences...\")\n-            counter = Counter({k: c for k, c in counter.items()\n-                               if c >= relation_type_min_count})\n-            print(f\"- Left with {len(counter)} relation types\")\n-        print(\"- Shuffling them...\")\n-        names = list(counter.keys())\n-        random.shuffle(names)\n-\n-    else:\n-        names = [rconfig.name for rconfig in relation_configs]\n-        print(f\"Using the {len(names)} relation types given in the config\")\n-\n-    return Dictionary(names)\n-\n-\n-def collect_entities_by_type(\n-    relation_types: Dictionary,\n-    entity_configs: Dict[str, EntitySchema],\n-    relation_configs: List[RelationSchema],\n-    edge_paths: List[Path],\n-    dynamic_relations: bool,\n-    lhs_col: int,\n-    rhs_col: int,\n-    rel_col: Optional[int],\n-    entity_min_count: int,\n-) -> Dict[str, Dictionary]:\n-\n-    counters: Dict[str, Counter[str]] = {}\n-    for entity_name in entity_configs.keys():\n-        counters[entity_name] = Counter()\n-\n-    print(\"Searching for the entities in the edge files...\")\n-    for edgepath in edge_paths:\n-        with edgepath.open(\"rt\") as tf:\n-            for line_num, line in enumerate(tf, start=1):\n-                words = line.split()\n-                try:\n-                    lhs_word = words[lhs_col]\n-                    rhs_word = words[rhs_col]\n-                    rel_word = words[rel_col] if rel_col is not None else None\n-                except IndexError:\n-                    raise RuntimeError(\n-                        \"Line %d of %s has only %d words\"\n-                        % (line_num, edgepath, len(words))) from None\n-\n-                if dynamic_relations or rel_col is None:\n-                    rel_id = 0\n-                else:\n-                    try:\n-                        rel_id = relation_types.get_id(rel_word)\n-                    except KeyError:\n-                        raise RuntimeError(\"Could not find relation type in config\")\n-\n-                counters[relation_configs[rel_id].lhs][lhs_word] += 1\n-                counters[relation_configs[rel_id].rhs][rhs_word] += 1\n-\n-    entities_by_type: Dict[str, Dictionary] = {}\n-    for entity_name, counter in counters.items():\n-        print(f\"Entity type {entity_name}:\")\n-        print(f\"- Found {len(counter)} entities\")\n-        if entity_min_count > 0:\n-            print(f\"- Removing the ones with fewer than {entity_min_count} occurrences...\")\n-            counter = Counter({k: c for k, c in counter.items()\n-                               if c >= entity_min_count})\n-            print(f\"- Left with {len(counter)} entities\")\n-        print(\"- Shuffling them...\")\n-        names = list(counter.keys())\n-        random.shuffle(names)\n-        entities_by_type[entity_name] = Dictionary(\n-            names, num_parts=entity_configs[entity_name].num_partitions)\n-\n-    return entities_by_type\n-\n-\n-def generate_entity_path_files(\n-    entity_storage: AbstractEntityStorage,\n-    entities_by_type: Dict[str, Dictionary],\n-    relation_type_storage: AbstractRelationTypeStorage,\n-    relation_types: Dictionary,\n-    dynamic_relations: bool,\n-) -> None:\n-    print(f\"Preparing counts and dictionaries for entities and relation types:\")\n-    entity_storage.prepare()\n-    relation_type_storage.prepare()\n-\n-    for entity_name, entities in entities_by_type.items():\n-        for part in range(entities.num_parts):\n-            print(f\"- Writing count of entity type {entity_name} \"\n-                  f\"and partition {part}\")\n-            entity_storage.save_count(entity_name, part, entities.part_size(part))\n-            entity_storage.save_names(entity_name, part, entities.get_part_list(part))\n-\n-    if dynamic_relations:\n-        print(\"- Writing count of dynamic relations\")\n-        relation_type_storage.save_count(relation_types.size())\n-        relation_type_storage.save_names(relation_types.get_list())\n-\n-\n-def generate_edge_path_files(\n-    edge_file_in: Path,\n-    edge_path_out: Path,\n-    edge_storage: AbstractEdgeStorage,\n-    entities_by_type: Dict[str, Dictionary],\n-    relation_types: Dictionary,\n-    relation_configs: List[RelationSchema],\n-    dynamic_relations: bool,\n-    lhs_col: int,\n-    rhs_col: int,\n-    rel_col: Optional[int],\n-) -> None:\n-    print(f\"Preparing edge path {edge_path_out}, \"\n-          f\"out of the edges found in {edge_file_in}\")\n-    edge_storage.prepare()\n-\n-    num_lhs_parts = max(entities_by_type[rconfig.lhs].num_parts\n-                        for rconfig in relation_configs)\n-    num_rhs_parts = max(entities_by_type[rconfig.rhs].num_parts\n-                        for rconfig in relation_configs)\n-\n-    print(f\"- Edges will be partitioned in {num_lhs_parts} x {num_rhs_parts} buckets.\")\n-\n-    processed = 0\n-    skipped = 0\n-\n-    # We use an ExitStack in order to close the dynamically-created edge appenders.\n-    with edge_file_in.open(\"rt\") as tf, ExitStack() as appender_stack:\n-        appenders: Dict[Tuple[int, int], AbstractEdgeAppender] = {}\n-        for line_num, line in enumerate(tf, start=1):\n-            words = line.split()\n-            try:\n-                lhs_word = words[lhs_col]\n-                rhs_word = words[rhs_col]\n-                rel_word = words[rel_col] if rel_col is not None else None\n-            except IndexError:\n-                raise RuntimeError(\n-                    f\"Line {line_num} of {edge_file_in} has only {len(words)} words\"\n-                ) from None\n-\n-            if rel_col is None:\n-                rel_id = 0\n-            else:\n-                try:\n-                    rel_id = relation_types.get_id(rel_word)\n-                except KeyError:\n-                    # Ignore edges whose relation type is not known.\n-                    skipped += 1\n-                    continue\n-\n-            if dynamic_relations:\n-                lhs_type = relation_configs[0].lhs\n-                rhs_type = relation_configs[0].rhs\n-            else:\n-                lhs_type = relation_configs[rel_id].lhs\n-                rhs_type = relation_configs[rel_id].rhs\n-\n-            try:\n-                lhs_part, lhs_offset = \\\n-                    entities_by_type[lhs_type].get_partition(lhs_word)\n-                rhs_part, rhs_offset = \\\n-                    entities_by_type[rhs_type].get_partition(rhs_word)\n-            except KeyError:\n-                # Ignore edges whose entities are not known.\n-                skipped += 1\n-                continue\n-\n-            if (lhs_part, rhs_part) not in appenders:\n-                appenders[lhs_part, rhs_part] = appender_stack.enter_context(\n-                    edge_storage.save_edges_by_appending(lhs_part, rhs_part))\n-            appenders[lhs_part, rhs_part].append_edges(EdgeList(\n-                EntityList.from_tensor(torch.tensor([lhs_offset], dtype=torch.long)),\n-                EntityList.from_tensor(torch.tensor([rhs_offset], dtype=torch.long)),\n-                torch.tensor([rel_id], dtype=torch.long),\n-            ))\n-\n-            processed = processed + 1\n-            if processed % 100000 == 0:\n-                print(f\"- Processed {processed} edges so far...\")\n-\n-    print(f\"- Processed {processed} edges in total\")\n-    if skipped > 0:\n-        print(f\"- Skipped {skipped} edges because their relation type or \"\n-              f\"entities were unknown (either not given in the config or \"\n-              f\"filtered out as too rare).\")\n-\n-\n-def convert_input_data(\n-    entity_configs: Dict[str, EntitySchema],\n-    relation_configs: List[RelationSchema],\n-    entity_path: str,\n-    edge_paths_out: List[str],\n-    edge_paths_in: List[Path],\n-    lhs_col: int,\n-    rhs_col: int,\n-    rel_col: Optional[int] = None,\n-    entity_min_count: int = 1,\n-    relation_type_min_count: int = 1,\n-    dynamic_relations: bool = False,\n-) -> None:\n-    if len(edge_paths_in) != len(edge_paths_out):\n-        raise ValueError(\n-            f\"The edge paths passed as inputs ({edge_paths_in}) don't match \"\n-            f\"the ones specified as outputs ({edge_paths_out})\")\n-\n-    entity_storage = ENTITY_STORAGES.make_instance(entity_path)\n-    relation_type_storage = RELATION_TYPE_STORAGES.make_instance(entity_path)\n-    edge_storages = [EDGE_STORAGES.make_instance(ep) for ep in edge_paths_out]\n-\n-    some_files_exists = []\n-    some_files_exists.extend(\n-        entity_storage.has_count(entity_name, partition)\n-        for entity_name, entity_config in entity_configs.items()\n-        for partition in range(entity_config.num_partitions))\n-    some_files_exists.extend(\n-        entity_storage.has_names(entity_name, partition)\n-        for entity_name, entity_config in entity_configs.items()\n-        for partition in range(entity_config.num_partitions))\n-    if dynamic_relations:\n-        some_files_exists.append(relation_type_storage.has_count())\n-        some_files_exists.append(relation_type_storage.has_names())\n-    some_files_exists.extend(\n-        edge_storage.has_edges(0, 0) for edge_storage in edge_storages)\n-\n-    if all(some_files_exists):\n-        print(\"Found some files that indicate that the input data \"\n-              \"has already been preprocessed, not doing it again.\")\n-        all_paths = \", \".join(str(p) for p in [entity_path] + edge_paths_out)\n-        print(f\"These files are in: {all_paths}\")\n-        return\n-\n-    relation_types = collect_relation_types(\n-        relation_configs,\n-        edge_paths_in,\n-        dynamic_relations,\n-        rel_col,\n-        relation_type_min_count,\n-    )\n-\n-    entities_by_type = collect_entities_by_type(\n-        relation_types,\n-        entity_configs,\n-        relation_configs,\n-        edge_paths_in,\n-        dynamic_relations,\n-        lhs_col,\n-        rhs_col,\n-        rel_col,\n-        entity_min_count,\n-    )\n-\n-    generate_entity_path_files(\n-        entity_storage,\n-        entities_by_type,\n-        relation_type_storage,\n-        relation_types,\n-        dynamic_relations,\n-    )\n-\n-    for edge_path_in, edge_path_out, edge_storage \\\n-            in zip(edge_paths_in, edge_paths_out, edge_storages):\n-        generate_edge_path_files(\n-            edge_path_in,\n-            edge_path_out,\n-            edge_storage,\n-            entities_by_type,\n-            relation_types,\n-            relation_configs,\n-            dynamic_relations,\n-            lhs_col,\n-            rhs_col,\n-            rel_col,\n-        )\n-\n-\n-def parse_config_partial(\n-    config_dict: Any,\n-) -> Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]:\n-    entities_config = config_dict.get(\"entities\")\n-    relations_config = config_dict.get(\"relations\")\n-    entity_path = config_dict.get(\"entity_path\")\n-    edge_paths = config_dict.get(\"edge_paths\")\n-    dynamic_relations = config_dict.get(\"dynamic_relations\", False)\n-    if not isinstance(entities_config, dict):\n-        raise TypeError(\"Config entities is not of type dict\")\n-    if any(not isinstance(k, str) for k in entities_config.keys()):\n-        raise TypeError(\"Config entities has some keys that are not of type str\")\n-    if not isinstance(relations_config, list):\n-        raise TypeError(\"Config relations is not of type list\")\n-    if not isinstance(entity_path, str):\n-        raise TypeError(\"Config entity_path is not of type str\")\n-    if not isinstance(edge_paths, list):\n-        raise TypeError(\"Config edge_paths is not of type list\")\n-    if any(not isinstance(p, str) for p in edge_paths):\n-        raise TypeError(\"Config edge_paths has some items that are not of type str\")\n-    if not isinstance(dynamic_relations, bool):\n-        raise TypeError(\"Config dynamic_relations is not of type bool\")\n-\n-    entities = {}\n-    relations = []\n-    for entity, entity_config in entities_config.items():\n-        entities[entity] = EntitySchema.from_dict(entity_config)\n-    for relation in relations_config:\n-        relations.append(RelationSchema.from_dict(relation))\n-\n-    return entities, relations, entity_path, edge_paths, dynamic_relations\n-\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent": "    ConfigSchema,\n    override_config_dict,\n)\n\n",
        "target_code_with_indent_exact_match": true,
        "source_code_with_indent": "    ConfigSchema,\n    EntitySchema,\n    RelationSchema,\n    override_config_dict,\n)\nfrom torchbiggraph.converters.dictionary import Dictionary\nfrom torchbiggraph.edgelist import EdgeList\nfrom torchbiggraph.entitylist import EntityList\nfrom torchbiggraph.graph_storages import (\n    AbstractEdgeAppender,\n    AbstractEdgeStorage,\n    AbstractEntityStorage,\n    AbstractRelationTypeStorage,\n    EDGE_STORAGES,\n    ENTITY_STORAGES,\n    RELATION_TYPE_STORAGES,\n)\n\n\ndef collect_relation_types(\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    rel_col: Optional[int],\n    relation_type_min_count: int,\n) -> Dictionary:\n\n    <IND>if dynamic_relations:\n        <IND>if rel_col is None:\n            <IND>raise RuntimeError(\"Need to specify rel_col in dynamic mode.\")\n        <DED>print(\"Looking up relation types in the edge files...\")\n        counter: Counter[str] = Counter()\n        for edgepath in edge_paths:\n            <IND>with edgepath.open(\"rt\") as tf:\n                <IND>for line_num, line in enumerate(tf, start=1):\n                    <IND>words = line.split()\n                    try:\n                        <IND>rel_word = words[rel_col]\n                    <DED>except IndexError:\n                        <IND>raise RuntimeError(\n                            f\"Line {line_num} of {edgepath} has only {len(words)} words\"\n                        ) from None\n                    <DED>counter[rel_word] += 1\n        <DED><DED><DED>print(f\"- Found {len(counter)} relation types\")\n        if relation_type_min_count > 0:\n            <IND>print(f\"- Removing the ones with fewer than {relation_type_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= relation_type_min_count})\n            print(f\"- Left with {len(counter)} relation types\")\n        <DED>print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n\n    <DED>else:\n        <IND>names = [rconfig.name for rconfig in relation_configs]\n        print(f\"Using the {len(names)} relation types given in the config\")\n\n    <DED>return Dictionary(names)\n\n\n<DED>def collect_entities_by_type(\n    relation_types: Dictionary,\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    edge_paths: List[Path],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n    entity_min_count: int,\n) -> Dict[str, Dictionary]:\n\n    <IND>counters: Dict[str, Counter[str]] = {}\n    for entity_name in entity_configs.keys():\n        <IND>counters[entity_name] = Counter()\n\n    <DED>print(\"Searching for the entities in the edge files...\")\n    for edgepath in edge_paths:\n        <IND>with edgepath.open(\"rt\") as tf:\n            <IND>for line_num, line in enumerate(tf, start=1):\n                <IND>words = line.split()\n                try:\n                    <IND>lhs_word = words[lhs_col]\n                    rhs_word = words[rhs_col]\n                    rel_word = words[rel_col] if rel_col is not None else None\n                <DED>except IndexError:\n                    <IND>raise RuntimeError(\n                        \"Line %d of %s has only %d words\"\n                        % (line_num, edgepath, len(words))) from None\n\n                <DED>if dynamic_relations or rel_col is None:\n                    <IND>rel_id = 0\n                <DED>else:\n                    <IND>try:\n                        <IND>rel_id = relation_types.get_id(rel_word)\n                    <DED>except KeyError:\n                        <IND>raise RuntimeError(\"Could not find relation type in config\")\n\n                <DED><DED>counters[relation_configs[rel_id].lhs][lhs_word] += 1\n                counters[relation_configs[rel_id].rhs][rhs_word] += 1\n\n    <DED><DED><DED>entities_by_type: Dict[str, Dictionary] = {}\n    for entity_name, counter in counters.items():\n        <IND>print(f\"Entity type {entity_name}:\")\n        print(f\"- Found {len(counter)} entities\")\n        if entity_min_count > 0:\n            <IND>print(f\"- Removing the ones with fewer than {entity_min_count} occurrences...\")\n            counter = Counter({k: c for k, c in counter.items()\n                               if c >= entity_min_count})\n            print(f\"- Left with {len(counter)} entities\")\n        <DED>print(\"- Shuffling them...\")\n        names = list(counter.keys())\n        random.shuffle(names)\n        entities_by_type[entity_name] = Dictionary(\n            names, num_parts=entity_configs[entity_name].num_partitions)\n\n    <DED>return entities_by_type\n\n\n<DED>def generate_entity_path_files(\n    entity_storage: AbstractEntityStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_type_storage: AbstractRelationTypeStorage,\n    relation_types: Dictionary,\n    dynamic_relations: bool,\n) -> None:\n    <IND>print(f\"Preparing counts and dictionaries for entities and relation types:\")\n    entity_storage.prepare()\n    relation_type_storage.prepare()\n\n    for entity_name, entities in entities_by_type.items():\n        <IND>for part in range(entities.num_parts):\n            <IND>print(f\"- Writing count of entity type {entity_name} \"\n                  f\"and partition {part}\")\n            entity_storage.save_count(entity_name, part, entities.part_size(part))\n            entity_storage.save_names(entity_name, part, entities.get_part_list(part))\n\n    <DED><DED>if dynamic_relations:\n        <IND>print(\"- Writing count of dynamic relations\")\n        relation_type_storage.save_count(relation_types.size())\n        relation_type_storage.save_names(relation_types.get_list())\n\n\n<DED><DED>def generate_edge_path_files(\n    edge_file_in: Path,\n    edge_path_out: Path,\n    edge_storage: AbstractEdgeStorage,\n    entities_by_type: Dict[str, Dictionary],\n    relation_types: Dictionary,\n    relation_configs: List[RelationSchema],\n    dynamic_relations: bool,\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int],\n) -> None:\n    <IND>print(f\"Preparing edge path {edge_path_out}, \"\n          f\"out of the edges found in {edge_file_in}\")\n    edge_storage.prepare()\n\n    num_lhs_parts = max(entities_by_type[rconfig.lhs].num_parts\n                        for rconfig in relation_configs)\n    num_rhs_parts = max(entities_by_type[rconfig.rhs].num_parts\n                        for rconfig in relation_configs)\n\n    print(f\"- Edges will be partitioned in {num_lhs_parts} x {num_rhs_parts} buckets.\")\n\n    processed = 0\n    skipped = 0\n\n    # We use an ExitStack in order to close the dynamically-created edge appenders.\n    with edge_file_in.open(\"rt\") as tf, ExitStack() as appender_stack:\n        <IND>appenders: Dict[Tuple[int, int], AbstractEdgeAppender] = {}\n        for line_num, line in enumerate(tf, start=1):\n            <IND>words = line.split()\n            try:\n                <IND>lhs_word = words[lhs_col]\n                rhs_word = words[rhs_col]\n                rel_word = words[rel_col] if rel_col is not None else None\n            <DED>except IndexError:\n                <IND>raise RuntimeError(\n                    f\"Line {line_num} of {edge_file_in} has only {len(words)} words\"\n                ) from None\n\n            <DED>if rel_col is None:\n                <IND>rel_id = 0\n            <DED>else:\n                <IND>try:\n                    <IND>rel_id = relation_types.get_id(rel_word)\n                <DED>except KeyError:\n                    # Ignore edges whose relation type is not known.\n                    <IND>skipped += 1\n                    continue\n\n            <DED><DED>if dynamic_relations:\n                <IND>lhs_type = relation_configs[0].lhs\n                rhs_type = relation_configs[0].rhs\n            <DED>else:\n                <IND>lhs_type = relation_configs[rel_id].lhs\n                rhs_type = relation_configs[rel_id].rhs\n\n            <DED>try:\n                <IND>lhs_part, lhs_offset =                    entities_by_type[lhs_type].get_partition(lhs_word)\n                rhs_part, rhs_offset =                    entities_by_type[rhs_type].get_partition(rhs_word)\n            <DED>except KeyError:\n                # Ignore edges whose entities are not known.\n                <IND>skipped += 1\n                continue\n\n            <DED>if (lhs_part, rhs_part) not in appenders:\n                <IND>appenders[lhs_part, rhs_part] = appender_stack.enter_context(\n                    edge_storage.save_edges_by_appending(lhs_part, rhs_part))\n            <DED>appenders[lhs_part, rhs_part].append_edges(EdgeList(\n                EntityList.from_tensor(torch.tensor([lhs_offset], dtype=torch.long)),\n                EntityList.from_tensor(torch.tensor([rhs_offset], dtype=torch.long)),\n                torch.tensor([rel_id], dtype=torch.long),\n            ))\n\n            processed = processed + 1\n            if processed % 100000 == 0:\n                <IND>print(f\"- Processed {processed} edges so far...\")\n\n    <DED><DED><DED>print(f\"- Processed {processed} edges in total\")\n    if skipped > 0:\n        <IND>print(f\"- Skipped {skipped} edges because their relation type or \"\n              f\"entities were unknown (either not given in the config or \"\n              f\"filtered out as too rare).\")\n\n\n<DED><DED>def convert_input_data(\n    entity_configs: Dict[str, EntitySchema],\n    relation_configs: List[RelationSchema],\n    entity_path: str,\n    edge_paths_out: List[str],\n    edge_paths_in: List[Path],\n    lhs_col: int,\n    rhs_col: int,\n    rel_col: Optional[int] = None,\n    entity_min_count: int = 1,\n    relation_type_min_count: int = 1,\n    dynamic_relations: bool = False,\n) -> None:\n    <IND>if len(edge_paths_in) != len(edge_paths_out):\n        <IND>raise ValueError(\n            f\"The edge paths passed as inputs ({edge_paths_in}) don't match \"\n            f\"the ones specified as outputs ({edge_paths_out})\")\n\n    <DED>entity_storage = ENTITY_STORAGES.make_instance(entity_path)\n    relation_type_storage = RELATION_TYPE_STORAGES.make_instance(entity_path)\n    edge_storages = [EDGE_STORAGES.make_instance(ep) for ep in edge_paths_out]\n\n    some_files_exists = []\n    some_files_exists.extend(\n        entity_storage.has_count(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    some_files_exists.extend(\n        entity_storage.has_names(entity_name, partition)\n        for entity_name, entity_config in entity_configs.items()\n        for partition in range(entity_config.num_partitions))\n    if dynamic_relations:\n        <IND>some_files_exists.append(relation_type_storage.has_count())\n        some_files_exists.append(relation_type_storage.has_names())\n    <DED>some_files_exists.extend(\n        edge_storage.has_edges(0, 0) for edge_storage in edge_storages)\n\n    if all(some_files_exists):\n        <IND>print(\"Found some files that indicate that the input data \"\n              \"has already been preprocessed, not doing it again.\")\n        all_paths = \", \".join(str(p) for p in [entity_path] + edge_paths_out)\n        print(f\"These files are in: {all_paths}\")\n        return\n\n    <DED>relation_types = collect_relation_types(\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        rel_col,\n        relation_type_min_count,\n    )\n\n    entities_by_type = collect_entities_by_type(\n        relation_types,\n        entity_configs,\n        relation_configs,\n        edge_paths_in,\n        dynamic_relations,\n        lhs_col,\n        rhs_col,\n        rel_col,\n        entity_min_count,\n    )\n\n    generate_entity_path_files(\n        entity_storage,\n        entities_by_type,\n        relation_type_storage,\n        relation_types,\n        dynamic_relations,\n    )\n\n    for edge_path_in, edge_path_out, edge_storage            in zip(edge_paths_in, edge_paths_out, edge_storages):\n        <IND>generate_edge_path_files(\n            edge_path_in,\n            edge_path_out,\n            edge_storage,\n            entities_by_type,\n            relation_types,\n            relation_configs,\n            dynamic_relations,\n            lhs_col,\n            rhs_col,\n            rel_col,\n        )\n\n\n<DED><DED>def parse_config_partial(\n    config_dict: Any,\n) -> Tuple[Dict[str, EntitySchema], List[RelationSchema], str, bool]:\n    <IND>entities_config = config_dict.get(\"entities\")\n    relations_config = config_dict.get(\"relations\")\n    entity_path = config_dict.get(\"entity_path\")\n    edge_paths = config_dict.get(\"edge_paths\")\n    dynamic_relations = config_dict.get(\"dynamic_relations\", False)\n    if not isinstance(entities_config, dict):\n        <IND>raise TypeError(\"Config entities is not of type dict\")\n    <DED>if any(not isinstance(k, str) for k in entities_config.keys()):\n        <IND>raise TypeError(\"Config entities has some keys that are not of type str\")\n    <DED>if not isinstance(relations_config, list):\n        <IND>raise TypeError(\"Config relations is not of type list\")\n    <DED>if not isinstance(entity_path, str):\n        <IND>raise TypeError(\"Config entity_path is not of type str\")\n    <DED>if not isinstance(edge_paths, list):\n        <IND>raise TypeError(\"Config edge_paths is not of type list\")\n    <DED>if any(not isinstance(p, str) for p in edge_paths):\n        <IND>raise TypeError(\"Config edge_paths has some items that are not of type str\")\n    <DED>if not isinstance(dynamic_relations, bool):\n        <IND>raise TypeError(\"Config dynamic_relations is not of type bool\")\n\n    <DED>entities = {}\n    relations = []\n    for entity, entity_config in entities_config.items():\n        <IND>entities[entity] = EntitySchema.from_dict(entity_config)\n    <DED>for relation in relations_config:\n        <IND>relations.append(RelationSchema.from_dict(relation))\n\n    <DED>return entities, relations, entity_path, edge_paths, dynamic_relations\n\n\n"
      }
    ]
  }
]