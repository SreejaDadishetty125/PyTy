[
  {
    "project": "RasaHQ/rasa",
    "commit": "d480c7676f7a9c0108233fefa4c0bb62f3035d4b",
    "filename": "rasa/core/featurizers/tracker_featurizers.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/core/featurizers/tracker_featurizers.py",
    "file_hunks_size": 9,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/core/featurizers/tracker_featurizers.py:1054:70 Incompatible parameter type [6]: Expected `List[int]` for 1st positional only parameter to call `list.append` but got `List[str]`.",
    "message": " Expected `List[int]` for 1st positional only parameter to call `list.append` but got `List[str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 1054,
    "warning_line": "                state_hash_to_label_list_instances[state_hash].append(label)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from tqdm import tqdm\nfrom typing import Tuple, List, Optional, Dict, Text, Union, Any, Iterator\nimport numpy as np\n",
        "source_code_len": 116,
        "target_code": "from tqdm import tqdm\nfrom typing import Tuple, List, Optional, Dict, Text, Union, Any, Iterator, Set\nimport numpy as np\n",
        "target_code_len": 121,
        "diff_format": "@@ -7,3 +7,3 @@\n from tqdm import tqdm\n-from typing import Tuple, List, Optional, Dict, Text, Union, Any, Iterator\n+from typing import Tuple, List, Optional, Dict, Text, Union, Any, Iterator, Set\n import numpy as np\n",
        "source_code_with_indent": "from tqdm import tqdm\nfrom typing import Tuple, List, Optional, Dict, Text, Union, Any, Iterator\nimport numpy as np\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from tqdm import tqdm\nfrom typing import Tuple, List, Optional, Dict, Text, Union, Any, Iterator, Set\nimport numpy as np\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    @staticmethod\n    def _hash_example(\n        tracker: DialogueStateTracker,\n        states: List[State],\n        labels: Optional[List[Text]] = None,\n    ) -> int:\n        \"\"\"Hashes states (and optionally label).\n",
        "source_code_len": 217,
        "target_code": "    @staticmethod\n    def _hash_example(states: List[State], labels: Optional[List[Text]] = None) -> int:\n        \"\"\"Hashes states (and optionally label).\n",
        "target_code_len": 155,
        "diff_format": "@@ -732,7 +732,3 @@\n     @staticmethod\n-    def _hash_example(\n-        tracker: DialogueStateTracker,\n-        states: List[State],\n-        labels: Optional[List[Text]] = None,\n-    ) -> int:\n+    def _hash_example(states: List[State], labels: Optional[List[Text]] = None) -> int:\n         \"\"\"Hashes states (and optionally label).\n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "    <DED>@staticmethod\n    def _hash_example(\n        tracker: DialogueStateTracker,\n        states: List[State],\n        labels: Optional[List[Text]] = None,\n    ) -> int:\n        <IND>",
        "target_code_with_indent": "    <DED>@staticmethod\n    def _hash_example(states: List[State], labels: Optional[List[Text]] = None) -> int:\n        <IND>"
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        frozen_states = tuple(\n            s if s is None else tracker.freeze_current_state(s) for s in states\n        )\n",
        "source_code_len": 121,
        "target_code": "        frozen_states = tuple(\n            s if s is None else DialogueStateTracker.freeze_current_state(s)\n            for s in states\n        )\n",
        "target_code_len": 146,
        "diff_format": "@@ -751,3 +746,4 @@\n         frozen_states = tuple(\n-            s if s is None else tracker.freeze_current_state(s) for s in states\n+            s if s is None else DialogueStateTracker.freeze_current_state(s)\n+            for s in states\n         )\n",
        "source_code_with_indent": "        frozen_states = tuple(\n            s if s is None else tracker.freeze_current_state(s) for s in states\n        )\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        frozen_states = tuple(\n            s if s is None else DialogueStateTracker.freeze_current_state(s)\n            for s in states\n        )\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "                if self.remove_duplicates:\n                    hashed = self._hash_example(tracker, states, label)\n                    if hashed in hashed_examples:\n",
        "source_code_len": 165,
        "target_code": "                if self.remove_duplicates:\n                    hashed = self._hash_example(states, label)\n                    if hashed in hashed_examples:\n",
        "target_code_len": 156,
        "diff_format": "@@ -805,3 +801,3 @@\n                 if self.remove_duplicates:\n-                    hashed = self._hash_example(tracker, states, label)\n+                    hashed = self._hash_example(states, label)\n                     if hashed in hashed_examples:\n",
        "source_code_with_indent": "                <IND>if self.remove_duplicates:\n                    <IND>hashed = self._hash_example(tracker, states, label)\n                    if hashed in hashed_examples:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "                <IND>if self.remove_duplicates:\n                    <IND>hashed = self._hash_example(states, label)\n                    if hashed in hashed_examples:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        example_states = []\n        example_labels = []\n        example_entities = []\n\n        # Store of example hashes for removing duplicate training examples.\n        hashed_examples = set()\n        # Mapping of example state hash to list of positive labels associated with\n        # the state. Note that each individual 'label' instance is a list of ints.\n        state_hash_to_label_list_instances: defaultdict[\n            int, List[List[int]]\n        ] = defaultdict(list)\n\n",
        "source_code_len": 482,
        "target_code": "        example_states = []\n        example_entities = []\n\n        # Store of example hashes (of both states and labels) for removing\n        # duplicate training examples.\n        hashed_examples = set()\n        # Mapping of example state hash to set of\n        # positive labels associated with the state.\n        state_hash_to_label_set: defaultdict[int, Set[Text]] = defaultdict(set)\n\n",
        "target_code_len": 389,
        "diff_format": "@@ -1015,12 +1011,10 @@\n         example_states = []\n-        example_labels = []\n         example_entities = []\n \n-        # Store of example hashes for removing duplicate training examples.\n+        # Store of example hashes (of both states and labels) for removing\n+        # duplicate training examples.\n         hashed_examples = set()\n-        # Mapping of example state hash to list of positive labels associated with\n-        # the state. Note that each individual 'label' instance is a list of ints.\n-        state_hash_to_label_list_instances: defaultdict[\n-            int, List[List[int]]\n-        ] = defaultdict(list)\n+        # Mapping of example state hash to set of\n+        # positive labels associated with the state.\n+        state_hash_to_label_set: defaultdict[int, Set[Text]] = defaultdict(set)\n \n",
        "source_code_with_indent": "        example_states = []\n        example_labels = []\n        example_entities = []\n\n        # Store of example hashes for removing duplicate training examples.\n        hashed_examples = set()\n        # Mapping of example state hash to list of positive labels associated with\n        # the state. Note that each individual 'label' instance is a list of ints.\n        state_hash_to_label_list_instances: defaultdict[\n            int, List[List[int]]\n        ] = defaultdict(list)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        example_states = []\n        example_entities = []\n\n        # Store of example hashes (of both states and labels) for removing\n        # duplicate training examples.\n        hashed_examples = set()\n        # Mapping of example state hash to set of\n        # positive labels associated with the state.\n        state_hash_to_label_set: defaultdict[int, Set[Text]] = defaultdict(set)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "                if self.remove_duplicates:\n                    hashed = self._hash_example(tracker, states, label)\n                    if hashed in hashed_examples:\n",
        "source_code_len": 165,
        "target_code": "                if self.remove_duplicates:\n                    hashed = self._hash_example(states, label)\n                    if hashed in hashed_examples:\n",
        "target_code_len": 156,
        "diff_format": "@@ -1046,3 +1040,3 @@\n                 if self.remove_duplicates:\n-                    hashed = self._hash_example(tracker, states, label)\n+                    hashed = self._hash_example(states, label)\n                     if hashed in hashed_examples:\n",
        "source_code_with_indent": "                <IND>if self.remove_duplicates:\n                    <IND>hashed = self._hash_example(tracker, states, label)\n                    if hashed in hashed_examples:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "                <IND>if self.remove_duplicates:\n                    <IND>hashed = self._hash_example(states, label)\n                    if hashed in hashed_examples:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "                # Store all positive labels associated with a training state.\n                state_hash = self._hash_example(tracker, states)\n                state_hash_to_label_list_instances[state_hash].append(label)\n\n                example_states.append(states)\n                example_labels.append(label)\n                example_entities.append(entities)\n\n                pbar.set_postfix({f\"# {self.LABEL_NAME}\": f\"{len(example_labels):d}\"})\n\n        self._remove_user_text_if_intent(example_states)\n\n        # Collect all positive intent labels for a given state hash and add\n        # the set back to the singleton labels.\n        for positive_label_list in state_hash_to_label_list_instances.values():\n            # Get the set of positive labels associated with each state hash.\n            positive_label_set = set([labels[0] for labels in positive_label_list])\n\n            for labels in positive_label_list:\n                # Extend the singletone `labels` with the `positive_label_set`.\n                # Note that we need to filter out the redundant label `labels[0]`\n                # from `positive_label_set` so as not to add it twice.\n                filtered_label_set = filter(\n                    lambda label: label != labels[0], positive_label_set\n                )\n                labels.extend(filtered_label_set)\n\n",
        "source_code_len": 1343,
        "target_code": "                # Store all positive labels associated with a training state.\n                state_hash = self._hash_example(states)\n\n                # Only add unique example states unless `remove_duplicates` is `False`.\n                if (\n                    not self.remove_duplicates\n                    or state_hash not in state_hash_to_label_set\n                ):\n                    example_states.append(states)\n                    example_entities.append(entities)\n\n                state_hash_to_label_set[state_hash].add(label[0])\n\n                pbar.set_postfix({f\"# {self.LABEL_NAME}\": f\"{len(example_states):d}\"})\n\n        # Collect positive labels for each state example.\n        example_labels = [\n            list(state_hash_to_label_set[self._hash_example(state)])\n            for state in example_states\n        ]\n\n        self._remove_user_text_if_intent(example_states)\n\n",
        "target_code_len": 898,
        "diff_format": "@@ -1052,27 +1046,23 @@\n                 # Store all positive labels associated with a training state.\n-                state_hash = self._hash_example(tracker, states)\n-                state_hash_to_label_list_instances[state_hash].append(label)\n-\n-                example_states.append(states)\n-                example_labels.append(label)\n-                example_entities.append(entities)\n-\n-                pbar.set_postfix({f\"# {self.LABEL_NAME}\": f\"{len(example_labels):d}\"})\n+                state_hash = self._hash_example(states)\n+\n+                # Only add unique example states unless `remove_duplicates` is `False`.\n+                if (\n+                    not self.remove_duplicates\n+                    or state_hash not in state_hash_to_label_set\n+                ):\n+                    example_states.append(states)\n+                    example_entities.append(entities)\n+\n+                state_hash_to_label_set[state_hash].add(label[0])\n+\n+                pbar.set_postfix({f\"# {self.LABEL_NAME}\": f\"{len(example_states):d}\"})\n+\n+        # Collect positive labels for each state example.\n+        example_labels = [\n+            list(state_hash_to_label_set[self._hash_example(state)])\n+            for state in example_states\n+        ]\n \n         self._remove_user_text_if_intent(example_states)\n-\n-        # Collect all positive intent labels for a given state hash and add\n-        # the set back to the singleton labels.\n-        for positive_label_list in state_hash_to_label_list_instances.values():\n-            # Get the set of positive labels associated with each state hash.\n-            positive_label_set = set([labels[0] for labels in positive_label_list])\n-\n-            for labels in positive_label_list:\n-                # Extend the singletone `labels` with the `positive_label_set`.\n-                # Note that we need to filter out the redundant label `labels[0]`\n-                # from `positive_label_set` so as not to add it twice.\n-                filtered_label_set = filter(\n-                    lambda label: label != labels[0], positive_label_set\n-                )\n-                labels.extend(filtered_label_set)\n \n",
        "source_code_with_indent": "                # Store all positive labels associated with a training state.\n                <DED>state_hash = self._hash_example(tracker, states)\n                state_hash_to_label_list_instances[state_hash].append(label)\n\n                example_states.append(states)\n                example_labels.append(label)\n                example_entities.append(entities)\n\n                pbar.set_postfix({f\"# {self.LABEL_NAME}\": f\"{len(example_labels):d}\"})\n\n        <DED><DED>self._remove_user_text_if_intent(example_states)\n\n        # Collect all positive intent labels for a given state hash and add\n        # the set back to the singleton labels.\n        for positive_label_list in state_hash_to_label_list_instances.values():\n            # Get the set of positive labels associated with each state hash.\n            <IND>positive_label_set = set([labels[0] for labels in positive_label_list])\n\n            for labels in positive_label_list:\n                # Extend the singletone `labels` with the `positive_label_set`.\n                # Note that we need to filter out the redundant label `labels[0]`\n                # from `positive_label_set` so as not to add it twice.\n                <IND>filtered_label_set = filter(\n                    lambda label: label != labels[0], positive_label_set\n                )\n                labels.extend(filtered_label_set)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "                # Store all positive labels associated with a training state.\n                <DED>state_hash = self._hash_example(states)\n\n                # Only add unique example states unless `remove_duplicates` is `False`.\n                if (\n                    not self.remove_duplicates\n                    or state_hash not in state_hash_to_label_set\n                ):\n                    <IND>example_states.append(states)\n                    example_entities.append(entities)\n\n                <DED>state_hash_to_label_set[state_hash].add(label[0])\n\n                pbar.set_postfix({f\"# {self.LABEL_NAME}\": f\"{len(example_states):d}\"})\n\n        # Collect positive labels for each state example.\n        <DED><DED>example_labels = [\n            list(state_hash_to_label_set[self._hash_example(state)])\n            for state in example_states\n        ]\n\n        self._remove_user_text_if_intent(example_states)\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  }
]