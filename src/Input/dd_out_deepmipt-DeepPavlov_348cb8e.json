[
  {
    "project": "deepmipt/DeepPavlov",
    "commit": "348cb8e8a0d0052417f57f2b923938e92b776ff9",
    "filename": "deeppavlov/core/commands/train.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/deepmipt-DeepPavlov/deeppavlov/core/commands/train.py",
    "file_hunks_size": 7,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "deeppavlov/core/commands/train.py:158:33 Incompatible parameter type [6]: Expected `typing.Iterable[Variable[_T1]]` for 1st positional only parameter to call `zip.__new__` but got `Union[List[str], bool]`.",
    "message": " Expected `typing.Iterable[Variable[_T1]]` for 1st positional only parameter to call `zip.__new__` but got `Union[List[str], bool]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 158,
    "warning_line": "    metrics_functions = list(zip(train_config['metrics'], get_metrics_by_names(train_config['metrics'])))",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef train_evaluate_model_from_config(config: [str, Path, dict], to_train: bool = True, to_validate: bool = True) -> None:\n    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        config = read_json(config)\n    set_deeppavlov_root(config)\n\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    dataset_config = config.get('dataset', None)\n",
        "source_code_len": 447,
        "target_code": "\ndef read_data_by_config(config: dict):\n    \"\"\"Read data by dataset_reader from specified config.\"\"\"\n    dataset_config = config.get('dataset', None)\n",
        "target_code_len": 150,
        "diff_format": "@@ -94,10 +94,4 @@\n \n-def train_evaluate_model_from_config(config: [str, Path, dict], to_train: bool = True, to_validate: bool = True) -> None:\n-    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n-    if isinstance(config, (str, Path)):\n-        config = read_json(config)\n-    set_deeppavlov_root(config)\n-\n-    import_packages(config.get('metadata', {}).get('imports', []))\n-\n+def read_data_by_config(config: dict):\n+    \"\"\"Read data by dataset_reader from specified config.\"\"\"\n     dataset_config = config.get('dataset', None)\n",
        "source_code_with_indent": "\n<DED>def train_evaluate_model_from_config(config: [str, Path, dict], to_train: bool = True, to_validate: bool = True) -> None:\n    <IND>\"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        <IND>config = read_json(config)\n    <DED>set_deeppavlov_root(config)\n\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    dataset_config = config.get('dataset', None)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def read_data_by_config(config: dict):\n    <IND>\"\"\"Read data by dataset_reader from specified config.\"\"\"\n    dataset_config = config.get('dataset', None)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    iterator_config = config['dataset_iterator']\n",
        "source_code_len": 50,
        "target_code": "\n    return data\n\n\ndef get_iterator_from_config(config: dict, data: dict):\n    \"\"\"Create iterator (from config) for specified data.\"\"\"\n    iterator_config = config['dataset_iterator']\n",
        "target_code_len": 184,
        "diff_format": "@@ -141,2 +135,7 @@\n \n+    return data\n+\n+\n+def get_iterator_from_config(config: dict, data: dict):\n+    \"\"\"Create iterator (from config) for specified data.\"\"\"\n     iterator_config = config['dataset_iterator']\n",
        "source_code_with_indent": "\n    <DED>iterator_config = config['dataset_iterator']\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>return data\n\n\n<DED>def get_iterator_from_config(config: dict, data: dict):\n    <IND>\"\"\"Create iterator (from config) for specified data.\"\"\"\n    iterator_config = config['dataset_iterator']\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "                                                                             data=data)\n\n",
        "source_code_len": 89,
        "target_code": "                                                                             data=data)\n    return iterator\n\n\ndef train_evaluate_model_from_config(config: [str, Path, dict], iterator=None,\n                                     to_train=True, to_validate=True) -> Dict[str, Dict[str, float]]:\n    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        config = read_json(config)\n    set_deeppavlov_root(config)\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    if iterator is None:\n        data = read_data_by_config(config)\n        iterator = get_iterator_from_config(config, data)\n\n",
        "target_code_len": 692,
        "diff_format": "@@ -144,2 +143,16 @@\n                                                                              data=data)\n+    return iterator\n+\n+\n+def train_evaluate_model_from_config(config: [str, Path, dict], iterator=None,\n+                                     to_train=True, to_validate=True) -> Dict[str, Dict[str, float]]:\n+    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n+    if isinstance(config, (str, Path)):\n+        config = read_json(config)\n+    set_deeppavlov_root(config)\n+    import_packages(config.get('metadata', {}).get('imports', []))\n+\n+    if iterator is None:\n+        data = read_data_by_config(config)\n+        iterator = get_iterator_from_config(config, data)\n \n",
        "source_code_with_indent": "                                                                             data=data)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "                                                                             data=data)\n    return iterator\n\n\n<DED>def train_evaluate_model_from_config(config: [str, Path, dict], iterator=None,\n                                     to_train=True, to_validate=True) -> Dict[str, Dict[str, float]]:\n    <IND>\"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        <IND>config = read_json(config)\n    <DED>set_deeppavlov_root(config)\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    if iterator is None:\n        <IND>data = read_data_by_config(config)\n        iterator = get_iterator_from_config(config, data)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    if train_config['validate_best'] or train_config['test_best']:\n",
        "source_code_len": 68,
        "target_code": "\n    res = {}\n\n    if train_config['validate_best'] or train_config['test_best']:\n",
        "target_code_len": 82,
        "diff_format": "@@ -173,2 +186,4 @@\n \n+    res = {}\n+\n     if train_config['validate_best'] or train_config['test_best']:\n",
        "source_code_with_indent": "\n    <DED>if train_config['validate_best'] or train_config['test_best']:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>res = {}\n\n    if train_config['validate_best'] or train_config['test_best']:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n            print(json.dumps(report, ensure_ascii=False))\n\n        model.destroy()\n\n",
        "source_code_len": 85,
        "target_code": "\n            res['test'] = report['test']['metrics']\n\n            print(json.dumps(report, ensure_ascii=False))\n        \n        model.destroy()\n\n    return res\n\n",
        "target_code_len": 162,
        "diff_format": "@@ -197,5 +214,9 @@\n \n+            res['test'] = report['test']['metrics']\n+\n             print(json.dumps(report, ensure_ascii=False))\n-\n+        \n         model.destroy()\n+\n+    return res\n \n",
        "source_code_with_indent": "\n            print(json.dumps(report, ensure_ascii=False))\n\n        <DED>model.destroy()\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n            res['test'] = report['test']['metrics']\n\n            print(json.dumps(report, ensure_ascii=False))\n        \n        <DED>model.destroy()\n\n    <DED>return res\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "deepmipt/DeepPavlov",
    "commit": "348cb8e8a0d0052417f57f2b923938e92b776ff9",
    "filename": "deeppavlov/core/commands/train.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/deepmipt-DeepPavlov/deeppavlov/core/commands/train.py",
    "file_hunks_size": 7,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "deeppavlov/core/commands/train.py:158:79 Incompatible parameter type [6]: Expected `List[typing.Any]` for 1st positional only parameter to call `get_metrics_by_names` but got `Union[List[str], bool]`.",
    "message": " Expected `List[typing.Any]` for 1st positional only parameter to call `get_metrics_by_names` but got `Union[List[str], bool]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 158,
    "warning_line": "    metrics_functions = list(zip(train_config['metrics'], get_metrics_by_names(train_config['metrics'])))",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef train_evaluate_model_from_config(config: [str, Path, dict], to_train: bool = True, to_validate: bool = True) -> None:\n    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        config = read_json(config)\n    set_deeppavlov_root(config)\n\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    dataset_config = config.get('dataset', None)\n",
        "source_code_len": 447,
        "target_code": "\ndef read_data_by_config(config: dict):\n    \"\"\"Read data by dataset_reader from specified config.\"\"\"\n    dataset_config = config.get('dataset', None)\n",
        "target_code_len": 150,
        "diff_format": "@@ -94,10 +94,4 @@\n \n-def train_evaluate_model_from_config(config: [str, Path, dict], to_train: bool = True, to_validate: bool = True) -> None:\n-    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n-    if isinstance(config, (str, Path)):\n-        config = read_json(config)\n-    set_deeppavlov_root(config)\n-\n-    import_packages(config.get('metadata', {}).get('imports', []))\n-\n+def read_data_by_config(config: dict):\n+    \"\"\"Read data by dataset_reader from specified config.\"\"\"\n     dataset_config = config.get('dataset', None)\n",
        "source_code_with_indent": "\n<DED>def train_evaluate_model_from_config(config: [str, Path, dict], to_train: bool = True, to_validate: bool = True) -> None:\n    <IND>\"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        <IND>config = read_json(config)\n    <DED>set_deeppavlov_root(config)\n\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    dataset_config = config.get('dataset', None)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def read_data_by_config(config: dict):\n    <IND>\"\"\"Read data by dataset_reader from specified config.\"\"\"\n    dataset_config = config.get('dataset', None)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    iterator_config = config['dataset_iterator']\n",
        "source_code_len": 50,
        "target_code": "\n    return data\n\n\ndef get_iterator_from_config(config: dict, data: dict):\n    \"\"\"Create iterator (from config) for specified data.\"\"\"\n    iterator_config = config['dataset_iterator']\n",
        "target_code_len": 184,
        "diff_format": "@@ -141,2 +135,7 @@\n \n+    return data\n+\n+\n+def get_iterator_from_config(config: dict, data: dict):\n+    \"\"\"Create iterator (from config) for specified data.\"\"\"\n     iterator_config = config['dataset_iterator']\n",
        "source_code_with_indent": "\n    <DED>iterator_config = config['dataset_iterator']\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>return data\n\n\n<DED>def get_iterator_from_config(config: dict, data: dict):\n    <IND>\"\"\"Create iterator (from config) for specified data.\"\"\"\n    iterator_config = config['dataset_iterator']\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "                                                                             data=data)\n\n",
        "source_code_len": 89,
        "target_code": "                                                                             data=data)\n    return iterator\n\n\ndef train_evaluate_model_from_config(config: [str, Path, dict], iterator=None,\n                                     to_train=True, to_validate=True) -> Dict[str, Dict[str, float]]:\n    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        config = read_json(config)\n    set_deeppavlov_root(config)\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    if iterator is None:\n        data = read_data_by_config(config)\n        iterator = get_iterator_from_config(config, data)\n\n",
        "target_code_len": 692,
        "diff_format": "@@ -144,2 +143,16 @@\n                                                                              data=data)\n+    return iterator\n+\n+\n+def train_evaluate_model_from_config(config: [str, Path, dict], iterator=None,\n+                                     to_train=True, to_validate=True) -> Dict[str, Dict[str, float]]:\n+    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n+    if isinstance(config, (str, Path)):\n+        config = read_json(config)\n+    set_deeppavlov_root(config)\n+    import_packages(config.get('metadata', {}).get('imports', []))\n+\n+    if iterator is None:\n+        data = read_data_by_config(config)\n+        iterator = get_iterator_from_config(config, data)\n \n",
        "source_code_with_indent": "                                                                             data=data)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "                                                                             data=data)\n    return iterator\n\n\n<DED>def train_evaluate_model_from_config(config: [str, Path, dict], iterator=None,\n                                     to_train=True, to_validate=True) -> Dict[str, Dict[str, float]]:\n    <IND>\"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        <IND>config = read_json(config)\n    <DED>set_deeppavlov_root(config)\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    if iterator is None:\n        <IND>data = read_data_by_config(config)\n        iterator = get_iterator_from_config(config, data)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    if train_config['validate_best'] or train_config['test_best']:\n",
        "source_code_len": 68,
        "target_code": "\n    res = {}\n\n    if train_config['validate_best'] or train_config['test_best']:\n",
        "target_code_len": 82,
        "diff_format": "@@ -173,2 +186,4 @@\n \n+    res = {}\n+\n     if train_config['validate_best'] or train_config['test_best']:\n",
        "source_code_with_indent": "\n    <DED>if train_config['validate_best'] or train_config['test_best']:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>res = {}\n\n    if train_config['validate_best'] or train_config['test_best']:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n            print(json.dumps(report, ensure_ascii=False))\n\n        model.destroy()\n\n",
        "source_code_len": 85,
        "target_code": "\n            res['test'] = report['test']['metrics']\n\n            print(json.dumps(report, ensure_ascii=False))\n        \n        model.destroy()\n\n    return res\n\n",
        "target_code_len": 162,
        "diff_format": "@@ -197,5 +214,9 @@\n \n+            res['test'] = report['test']['metrics']\n+\n             print(json.dumps(report, ensure_ascii=False))\n-\n+        \n         model.destroy()\n+\n+    return res\n \n",
        "source_code_with_indent": "\n            print(json.dumps(report, ensure_ascii=False))\n\n        <DED>model.destroy()\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n            res['test'] = report['test']['metrics']\n\n            print(json.dumps(report, ensure_ascii=False))\n        \n        <DED>model.destroy()\n\n    <DED>return res\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "deepmipt/DeepPavlov",
    "commit": "348cb8e8a0d0052417f57f2b923938e92b776ff9",
    "filename": "deeppavlov/core/commands/train.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/deepmipt-DeepPavlov/deeppavlov/core/commands/train.py",
    "file_hunks_size": 7,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "deeppavlov/core/commands/train.py:164:34 Incompatible parameter type [6]: Expected `DataLearningIterator` for 2nd positional only parameter to call `_train_batches` but got `Union[DataFittingIterator, DataLearningIterator]`.",
    "message": " Expected `DataLearningIterator` for 2nd positional only parameter to call `_train_batches` but got `Union[DataFittingIterator, DataLearningIterator]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 164,
    "warning_line": "            _train_batches(model, iterator, train_config, metrics_functions)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef train_evaluate_model_from_config(config: [str, Path, dict], to_train: bool = True, to_validate: bool = True) -> None:\n    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        config = read_json(config)\n    set_deeppavlov_root(config)\n\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    dataset_config = config.get('dataset', None)\n",
        "source_code_len": 447,
        "target_code": "\ndef read_data_by_config(config: dict):\n    \"\"\"Read data by dataset_reader from specified config.\"\"\"\n    dataset_config = config.get('dataset', None)\n",
        "target_code_len": 150,
        "diff_format": "@@ -94,10 +94,4 @@\n \n-def train_evaluate_model_from_config(config: [str, Path, dict], to_train: bool = True, to_validate: bool = True) -> None:\n-    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n-    if isinstance(config, (str, Path)):\n-        config = read_json(config)\n-    set_deeppavlov_root(config)\n-\n-    import_packages(config.get('metadata', {}).get('imports', []))\n-\n+def read_data_by_config(config: dict):\n+    \"\"\"Read data by dataset_reader from specified config.\"\"\"\n     dataset_config = config.get('dataset', None)\n",
        "source_code_with_indent": "\n<DED>def train_evaluate_model_from_config(config: [str, Path, dict], to_train: bool = True, to_validate: bool = True) -> None:\n    <IND>\"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        <IND>config = read_json(config)\n    <DED>set_deeppavlov_root(config)\n\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    dataset_config = config.get('dataset', None)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def read_data_by_config(config: dict):\n    <IND>\"\"\"Read data by dataset_reader from specified config.\"\"\"\n    dataset_config = config.get('dataset', None)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    iterator_config = config['dataset_iterator']\n",
        "source_code_len": 50,
        "target_code": "\n    return data\n\n\ndef get_iterator_from_config(config: dict, data: dict):\n    \"\"\"Create iterator (from config) for specified data.\"\"\"\n    iterator_config = config['dataset_iterator']\n",
        "target_code_len": 184,
        "diff_format": "@@ -141,2 +135,7 @@\n \n+    return data\n+\n+\n+def get_iterator_from_config(config: dict, data: dict):\n+    \"\"\"Create iterator (from config) for specified data.\"\"\"\n     iterator_config = config['dataset_iterator']\n",
        "source_code_with_indent": "\n    <DED>iterator_config = config['dataset_iterator']\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>return data\n\n\n<DED>def get_iterator_from_config(config: dict, data: dict):\n    <IND>\"\"\"Create iterator (from config) for specified data.\"\"\"\n    iterator_config = config['dataset_iterator']\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "                                                                             data=data)\n\n",
        "source_code_len": 89,
        "target_code": "                                                                             data=data)\n    return iterator\n\n\ndef train_evaluate_model_from_config(config: [str, Path, dict], iterator=None,\n                                     to_train=True, to_validate=True) -> Dict[str, Dict[str, float]]:\n    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        config = read_json(config)\n    set_deeppavlov_root(config)\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    if iterator is None:\n        data = read_data_by_config(config)\n        iterator = get_iterator_from_config(config, data)\n\n",
        "target_code_len": 692,
        "diff_format": "@@ -144,2 +143,16 @@\n                                                                              data=data)\n+    return iterator\n+\n+\n+def train_evaluate_model_from_config(config: [str, Path, dict], iterator=None,\n+                                     to_train=True, to_validate=True) -> Dict[str, Dict[str, float]]:\n+    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n+    if isinstance(config, (str, Path)):\n+        config = read_json(config)\n+    set_deeppavlov_root(config)\n+    import_packages(config.get('metadata', {}).get('imports', []))\n+\n+    if iterator is None:\n+        data = read_data_by_config(config)\n+        iterator = get_iterator_from_config(config, data)\n \n",
        "source_code_with_indent": "                                                                             data=data)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "                                                                             data=data)\n    return iterator\n\n\n<DED>def train_evaluate_model_from_config(config: [str, Path, dict], iterator=None,\n                                     to_train=True, to_validate=True) -> Dict[str, Dict[str, float]]:\n    <IND>\"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        <IND>config = read_json(config)\n    <DED>set_deeppavlov_root(config)\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    if iterator is None:\n        <IND>data = read_data_by_config(config)\n        iterator = get_iterator_from_config(config, data)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    if train_config['validate_best'] or train_config['test_best']:\n",
        "source_code_len": 68,
        "target_code": "\n    res = {}\n\n    if train_config['validate_best'] or train_config['test_best']:\n",
        "target_code_len": 82,
        "diff_format": "@@ -173,2 +186,4 @@\n \n+    res = {}\n+\n     if train_config['validate_best'] or train_config['test_best']:\n",
        "source_code_with_indent": "\n    <DED>if train_config['validate_best'] or train_config['test_best']:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>res = {}\n\n    if train_config['validate_best'] or train_config['test_best']:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n            print(json.dumps(report, ensure_ascii=False))\n\n        model.destroy()\n\n",
        "source_code_len": 85,
        "target_code": "\n            res['test'] = report['test']['metrics']\n\n            print(json.dumps(report, ensure_ascii=False))\n        \n        model.destroy()\n\n    return res\n\n",
        "target_code_len": 162,
        "diff_format": "@@ -197,5 +214,9 @@\n \n+            res['test'] = report['test']['metrics']\n+\n             print(json.dumps(report, ensure_ascii=False))\n-\n+        \n         model.destroy()\n+\n+    return res\n \n",
        "source_code_with_indent": "\n            print(json.dumps(report, ensure_ascii=False))\n\n        <DED>model.destroy()\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n            res['test'] = report['test']['metrics']\n\n            print(json.dumps(report, ensure_ascii=False))\n        \n        <DED>model.destroy()\n\n    <DED>return res\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "deepmipt/DeepPavlov",
    "commit": "348cb8e8a0d0052417f57f2b923938e92b776ff9",
    "filename": "deeppavlov/core/commands/train.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/deepmipt-DeepPavlov/deeppavlov/core/commands/train.py",
    "file_hunks_size": 7,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "deeppavlov/core/commands/train.py:166:32 Incompatible parameter type [6]: Expected `DataFittingIterator` for 2nd positional only parameter to call `_fit_batches` but got `Union[DataFittingIterator, DataLearningIterator]`.",
    "message": " Expected `DataFittingIterator` for 2nd positional only parameter to call `_fit_batches` but got `Union[DataFittingIterator, DataLearningIterator]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 166,
    "warning_line": "            _fit_batches(model, iterator, train_config)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef train_evaluate_model_from_config(config: [str, Path, dict], to_train: bool = True, to_validate: bool = True) -> None:\n    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        config = read_json(config)\n    set_deeppavlov_root(config)\n\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    dataset_config = config.get('dataset', None)\n",
        "source_code_len": 447,
        "target_code": "\ndef read_data_by_config(config: dict):\n    \"\"\"Read data by dataset_reader from specified config.\"\"\"\n    dataset_config = config.get('dataset', None)\n",
        "target_code_len": 150,
        "diff_format": "@@ -94,10 +94,4 @@\n \n-def train_evaluate_model_from_config(config: [str, Path, dict], to_train: bool = True, to_validate: bool = True) -> None:\n-    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n-    if isinstance(config, (str, Path)):\n-        config = read_json(config)\n-    set_deeppavlov_root(config)\n-\n-    import_packages(config.get('metadata', {}).get('imports', []))\n-\n+def read_data_by_config(config: dict):\n+    \"\"\"Read data by dataset_reader from specified config.\"\"\"\n     dataset_config = config.get('dataset', None)\n",
        "source_code_with_indent": "\n<DED>def train_evaluate_model_from_config(config: [str, Path, dict], to_train: bool = True, to_validate: bool = True) -> None:\n    <IND>\"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        <IND>config = read_json(config)\n    <DED>set_deeppavlov_root(config)\n\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    dataset_config = config.get('dataset', None)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def read_data_by_config(config: dict):\n    <IND>\"\"\"Read data by dataset_reader from specified config.\"\"\"\n    dataset_config = config.get('dataset', None)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    iterator_config = config['dataset_iterator']\n",
        "source_code_len": 50,
        "target_code": "\n    return data\n\n\ndef get_iterator_from_config(config: dict, data: dict):\n    \"\"\"Create iterator (from config) for specified data.\"\"\"\n    iterator_config = config['dataset_iterator']\n",
        "target_code_len": 184,
        "diff_format": "@@ -141,2 +135,7 @@\n \n+    return data\n+\n+\n+def get_iterator_from_config(config: dict, data: dict):\n+    \"\"\"Create iterator (from config) for specified data.\"\"\"\n     iterator_config = config['dataset_iterator']\n",
        "source_code_with_indent": "\n    <DED>iterator_config = config['dataset_iterator']\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>return data\n\n\n<DED>def get_iterator_from_config(config: dict, data: dict):\n    <IND>\"\"\"Create iterator (from config) for specified data.\"\"\"\n    iterator_config = config['dataset_iterator']\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "                                                                             data=data)\n\n",
        "source_code_len": 89,
        "target_code": "                                                                             data=data)\n    return iterator\n\n\ndef train_evaluate_model_from_config(config: [str, Path, dict], iterator=None,\n                                     to_train=True, to_validate=True) -> Dict[str, Dict[str, float]]:\n    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        config = read_json(config)\n    set_deeppavlov_root(config)\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    if iterator is None:\n        data = read_data_by_config(config)\n        iterator = get_iterator_from_config(config, data)\n\n",
        "target_code_len": 692,
        "diff_format": "@@ -144,2 +143,16 @@\n                                                                              data=data)\n+    return iterator\n+\n+\n+def train_evaluate_model_from_config(config: [str, Path, dict], iterator=None,\n+                                     to_train=True, to_validate=True) -> Dict[str, Dict[str, float]]:\n+    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n+    if isinstance(config, (str, Path)):\n+        config = read_json(config)\n+    set_deeppavlov_root(config)\n+    import_packages(config.get('metadata', {}).get('imports', []))\n+\n+    if iterator is None:\n+        data = read_data_by_config(config)\n+        iterator = get_iterator_from_config(config, data)\n \n",
        "source_code_with_indent": "                                                                             data=data)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "                                                                             data=data)\n    return iterator\n\n\n<DED>def train_evaluate_model_from_config(config: [str, Path, dict], iterator=None,\n                                     to_train=True, to_validate=True) -> Dict[str, Dict[str, float]]:\n    <IND>\"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        <IND>config = read_json(config)\n    <DED>set_deeppavlov_root(config)\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    if iterator is None:\n        <IND>data = read_data_by_config(config)\n        iterator = get_iterator_from_config(config, data)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    if train_config['validate_best'] or train_config['test_best']:\n",
        "source_code_len": 68,
        "target_code": "\n    res = {}\n\n    if train_config['validate_best'] or train_config['test_best']:\n",
        "target_code_len": 82,
        "diff_format": "@@ -173,2 +186,4 @@\n \n+    res = {}\n+\n     if train_config['validate_best'] or train_config['test_best']:\n",
        "source_code_with_indent": "\n    <DED>if train_config['validate_best'] or train_config['test_best']:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>res = {}\n\n    if train_config['validate_best'] or train_config['test_best']:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n            print(json.dumps(report, ensure_ascii=False))\n\n        model.destroy()\n\n",
        "source_code_len": 85,
        "target_code": "\n            res['test'] = report['test']['metrics']\n\n            print(json.dumps(report, ensure_ascii=False))\n        \n        model.destroy()\n\n    return res\n\n",
        "target_code_len": 162,
        "diff_format": "@@ -197,5 +214,9 @@\n \n+            res['test'] = report['test']['metrics']\n+\n             print(json.dumps(report, ensure_ascii=False))\n-\n+        \n         model.destroy()\n+\n+    return res\n \n",
        "source_code_with_indent": "\n            print(json.dumps(report, ensure_ascii=False))\n\n        <DED>model.destroy()\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n            res['test'] = report['test']['metrics']\n\n            print(json.dumps(report, ensure_ascii=False))\n        \n        <DED>model.destroy()\n\n    <DED>return res\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "deepmipt/DeepPavlov",
    "commit": "348cb8e8a0d0052417f57f2b923938e92b776ff9",
    "filename": "deeppavlov/core/commands/train.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/deepmipt-DeepPavlov/deeppavlov/core/commands/train.py",
    "file_hunks_size": 7,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "deeppavlov/core/commands/train.py:168:24 Incompatible parameter type [6]: Expected `DataLearningIterator` for 2nd positional only parameter to call `_fit` but got `Union[DataFittingIterator, DataLearningIterator]`.",
    "message": " Expected `DataLearningIterator` for 2nd positional only parameter to call `_fit` but got `Union[DataFittingIterator, DataLearningIterator]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 168,
    "warning_line": "            _fit(model, iterator, train_config)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef train_evaluate_model_from_config(config: [str, Path, dict], to_train: bool = True, to_validate: bool = True) -> None:\n    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        config = read_json(config)\n    set_deeppavlov_root(config)\n\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    dataset_config = config.get('dataset', None)\n",
        "source_code_len": 447,
        "target_code": "\ndef read_data_by_config(config: dict):\n    \"\"\"Read data by dataset_reader from specified config.\"\"\"\n    dataset_config = config.get('dataset', None)\n",
        "target_code_len": 150,
        "diff_format": "@@ -94,10 +94,4 @@\n \n-def train_evaluate_model_from_config(config: [str, Path, dict], to_train: bool = True, to_validate: bool = True) -> None:\n-    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n-    if isinstance(config, (str, Path)):\n-        config = read_json(config)\n-    set_deeppavlov_root(config)\n-\n-    import_packages(config.get('metadata', {}).get('imports', []))\n-\n+def read_data_by_config(config: dict):\n+    \"\"\"Read data by dataset_reader from specified config.\"\"\"\n     dataset_config = config.get('dataset', None)\n",
        "source_code_with_indent": "\n<DED>def train_evaluate_model_from_config(config: [str, Path, dict], to_train: bool = True, to_validate: bool = True) -> None:\n    <IND>\"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        <IND>config = read_json(config)\n    <DED>set_deeppavlov_root(config)\n\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    dataset_config = config.get('dataset', None)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def read_data_by_config(config: dict):\n    <IND>\"\"\"Read data by dataset_reader from specified config.\"\"\"\n    dataset_config = config.get('dataset', None)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    iterator_config = config['dataset_iterator']\n",
        "source_code_len": 50,
        "target_code": "\n    return data\n\n\ndef get_iterator_from_config(config: dict, data: dict):\n    \"\"\"Create iterator (from config) for specified data.\"\"\"\n    iterator_config = config['dataset_iterator']\n",
        "target_code_len": 184,
        "diff_format": "@@ -141,2 +135,7 @@\n \n+    return data\n+\n+\n+def get_iterator_from_config(config: dict, data: dict):\n+    \"\"\"Create iterator (from config) for specified data.\"\"\"\n     iterator_config = config['dataset_iterator']\n",
        "source_code_with_indent": "\n    <DED>iterator_config = config['dataset_iterator']\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>return data\n\n\n<DED>def get_iterator_from_config(config: dict, data: dict):\n    <IND>\"\"\"Create iterator (from config) for specified data.\"\"\"\n    iterator_config = config['dataset_iterator']\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "                                                                             data=data)\n\n",
        "source_code_len": 89,
        "target_code": "                                                                             data=data)\n    return iterator\n\n\ndef train_evaluate_model_from_config(config: [str, Path, dict], iterator=None,\n                                     to_train=True, to_validate=True) -> Dict[str, Dict[str, float]]:\n    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        config = read_json(config)\n    set_deeppavlov_root(config)\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    if iterator is None:\n        data = read_data_by_config(config)\n        iterator = get_iterator_from_config(config, data)\n\n",
        "target_code_len": 692,
        "diff_format": "@@ -144,2 +143,16 @@\n                                                                              data=data)\n+    return iterator\n+\n+\n+def train_evaluate_model_from_config(config: [str, Path, dict], iterator=None,\n+                                     to_train=True, to_validate=True) -> Dict[str, Dict[str, float]]:\n+    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n+    if isinstance(config, (str, Path)):\n+        config = read_json(config)\n+    set_deeppavlov_root(config)\n+    import_packages(config.get('metadata', {}).get('imports', []))\n+\n+    if iterator is None:\n+        data = read_data_by_config(config)\n+        iterator = get_iterator_from_config(config, data)\n \n",
        "source_code_with_indent": "                                                                             data=data)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "                                                                             data=data)\n    return iterator\n\n\n<DED>def train_evaluate_model_from_config(config: [str, Path, dict], iterator=None,\n                                     to_train=True, to_validate=True) -> Dict[str, Dict[str, float]]:\n    <IND>\"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        <IND>config = read_json(config)\n    <DED>set_deeppavlov_root(config)\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    if iterator is None:\n        <IND>data = read_data_by_config(config)\n        iterator = get_iterator_from_config(config, data)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    if train_config['validate_best'] or train_config['test_best']:\n",
        "source_code_len": 68,
        "target_code": "\n    res = {}\n\n    if train_config['validate_best'] or train_config['test_best']:\n",
        "target_code_len": 82,
        "diff_format": "@@ -173,2 +186,4 @@\n \n+    res = {}\n+\n     if train_config['validate_best'] or train_config['test_best']:\n",
        "source_code_with_indent": "\n    <DED>if train_config['validate_best'] or train_config['test_best']:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>res = {}\n\n    if train_config['validate_best'] or train_config['test_best']:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n            print(json.dumps(report, ensure_ascii=False))\n\n        model.destroy()\n\n",
        "source_code_len": 85,
        "target_code": "\n            res['test'] = report['test']['metrics']\n\n            print(json.dumps(report, ensure_ascii=False))\n        \n        model.destroy()\n\n    return res\n\n",
        "target_code_len": 162,
        "diff_format": "@@ -197,5 +214,9 @@\n \n+            res['test'] = report['test']['metrics']\n+\n             print(json.dumps(report, ensure_ascii=False))\n-\n+        \n         model.destroy()\n+\n+    return res\n \n",
        "source_code_with_indent": "\n            print(json.dumps(report, ensure_ascii=False))\n\n        <DED>model.destroy()\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n            res['test'] = report['test']['metrics']\n\n            print(json.dumps(report, ensure_ascii=False))\n        \n        <DED>model.destroy()\n\n    <DED>return res\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "deepmipt/DeepPavlov",
    "commit": "348cb8e8a0d0052417f57f2b923938e92b776ff9",
    "filename": "deeppavlov/core/commands/train.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/deepmipt-DeepPavlov/deeppavlov/core/commands/train.py",
    "file_hunks_size": 7,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "deeppavlov/core/commands/train.py:184:63 Incompatible parameter type [6]: Expected `DataLearningIterator` for 3rd positional only parameter to call `_test_model` but got `Union[DataFittingIterator, DataLearningIterator]`.",
    "message": " Expected `DataLearningIterator` for 3rd positional only parameter to call `_test_model` but got `Union[DataFittingIterator, DataLearningIterator]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 184,
    "warning_line": "                'valid': _test_model(model, metrics_functions, iterator,",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef train_evaluate_model_from_config(config: [str, Path, dict], to_train: bool = True, to_validate: bool = True) -> None:\n    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        config = read_json(config)\n    set_deeppavlov_root(config)\n\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    dataset_config = config.get('dataset', None)\n",
        "source_code_len": 447,
        "target_code": "\ndef read_data_by_config(config: dict):\n    \"\"\"Read data by dataset_reader from specified config.\"\"\"\n    dataset_config = config.get('dataset', None)\n",
        "target_code_len": 150,
        "diff_format": "@@ -94,10 +94,4 @@\n \n-def train_evaluate_model_from_config(config: [str, Path, dict], to_train: bool = True, to_validate: bool = True) -> None:\n-    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n-    if isinstance(config, (str, Path)):\n-        config = read_json(config)\n-    set_deeppavlov_root(config)\n-\n-    import_packages(config.get('metadata', {}).get('imports', []))\n-\n+def read_data_by_config(config: dict):\n+    \"\"\"Read data by dataset_reader from specified config.\"\"\"\n     dataset_config = config.get('dataset', None)\n",
        "source_code_with_indent": "\n<DED>def train_evaluate_model_from_config(config: [str, Path, dict], to_train: bool = True, to_validate: bool = True) -> None:\n    <IND>\"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        <IND>config = read_json(config)\n    <DED>set_deeppavlov_root(config)\n\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    dataset_config = config.get('dataset', None)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def read_data_by_config(config: dict):\n    <IND>\"\"\"Read data by dataset_reader from specified config.\"\"\"\n    dataset_config = config.get('dataset', None)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    iterator_config = config['dataset_iterator']\n",
        "source_code_len": 50,
        "target_code": "\n    return data\n\n\ndef get_iterator_from_config(config: dict, data: dict):\n    \"\"\"Create iterator (from config) for specified data.\"\"\"\n    iterator_config = config['dataset_iterator']\n",
        "target_code_len": 184,
        "diff_format": "@@ -141,2 +135,7 @@\n \n+    return data\n+\n+\n+def get_iterator_from_config(config: dict, data: dict):\n+    \"\"\"Create iterator (from config) for specified data.\"\"\"\n     iterator_config = config['dataset_iterator']\n",
        "source_code_with_indent": "\n    <DED>iterator_config = config['dataset_iterator']\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>return data\n\n\n<DED>def get_iterator_from_config(config: dict, data: dict):\n    <IND>\"\"\"Create iterator (from config) for specified data.\"\"\"\n    iterator_config = config['dataset_iterator']\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "                                                                             data=data)\n\n",
        "source_code_len": 89,
        "target_code": "                                                                             data=data)\n    return iterator\n\n\ndef train_evaluate_model_from_config(config: [str, Path, dict], iterator=None,\n                                     to_train=True, to_validate=True) -> Dict[str, Dict[str, float]]:\n    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        config = read_json(config)\n    set_deeppavlov_root(config)\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    if iterator is None:\n        data = read_data_by_config(config)\n        iterator = get_iterator_from_config(config, data)\n\n",
        "target_code_len": 692,
        "diff_format": "@@ -144,2 +143,16 @@\n                                                                              data=data)\n+    return iterator\n+\n+\n+def train_evaluate_model_from_config(config: [str, Path, dict], iterator=None,\n+                                     to_train=True, to_validate=True) -> Dict[str, Dict[str, float]]:\n+    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n+    if isinstance(config, (str, Path)):\n+        config = read_json(config)\n+    set_deeppavlov_root(config)\n+    import_packages(config.get('metadata', {}).get('imports', []))\n+\n+    if iterator is None:\n+        data = read_data_by_config(config)\n+        iterator = get_iterator_from_config(config, data)\n \n",
        "source_code_with_indent": "                                                                             data=data)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "                                                                             data=data)\n    return iterator\n\n\n<DED>def train_evaluate_model_from_config(config: [str, Path, dict], iterator=None,\n                                     to_train=True, to_validate=True) -> Dict[str, Dict[str, float]]:\n    <IND>\"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        <IND>config = read_json(config)\n    <DED>set_deeppavlov_root(config)\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    if iterator is None:\n        <IND>data = read_data_by_config(config)\n        iterator = get_iterator_from_config(config, data)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    if train_config['validate_best'] or train_config['test_best']:\n",
        "source_code_len": 68,
        "target_code": "\n    res = {}\n\n    if train_config['validate_best'] or train_config['test_best']:\n",
        "target_code_len": 82,
        "diff_format": "@@ -173,2 +186,4 @@\n \n+    res = {}\n+\n     if train_config['validate_best'] or train_config['test_best']:\n",
        "source_code_with_indent": "\n    <DED>if train_config['validate_best'] or train_config['test_best']:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>res = {}\n\n    if train_config['validate_best'] or train_config['test_best']:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n            print(json.dumps(report, ensure_ascii=False))\n\n        model.destroy()\n\n",
        "source_code_len": 85,
        "target_code": "\n            res['test'] = report['test']['metrics']\n\n            print(json.dumps(report, ensure_ascii=False))\n        \n        model.destroy()\n\n    return res\n\n",
        "target_code_len": 162,
        "diff_format": "@@ -197,5 +214,9 @@\n \n+            res['test'] = report['test']['metrics']\n+\n             print(json.dumps(report, ensure_ascii=False))\n-\n+        \n         model.destroy()\n+\n+    return res\n \n",
        "source_code_with_indent": "\n            print(json.dumps(report, ensure_ascii=False))\n\n        <DED>model.destroy()\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n            res['test'] = report['test']['metrics']\n\n            print(json.dumps(report, ensure_ascii=False))\n        \n        <DED>model.destroy()\n\n    <DED>return res\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "deepmipt/DeepPavlov",
    "commit": "348cb8e8a0d0052417f57f2b923938e92b776ff9",
    "filename": "deeppavlov/core/commands/train.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/deepmipt-DeepPavlov/deeppavlov/core/commands/train.py",
    "file_hunks_size": 7,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "deeppavlov/core/commands/train.py:193:62 Incompatible parameter type [6]: Expected `DataLearningIterator` for 3rd positional only parameter to call `_test_model` but got `Union[DataFittingIterator, DataLearningIterator]`.",
    "message": " Expected `DataLearningIterator` for 3rd positional only parameter to call `_test_model` but got `Union[DataFittingIterator, DataLearningIterator]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 193,
    "warning_line": "                'test': _test_model(model, metrics_functions, iterator,",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef train_evaluate_model_from_config(config: [str, Path, dict], to_train: bool = True, to_validate: bool = True) -> None:\n    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        config = read_json(config)\n    set_deeppavlov_root(config)\n\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    dataset_config = config.get('dataset', None)\n",
        "source_code_len": 447,
        "target_code": "\ndef read_data_by_config(config: dict):\n    \"\"\"Read data by dataset_reader from specified config.\"\"\"\n    dataset_config = config.get('dataset', None)\n",
        "target_code_len": 150,
        "diff_format": "@@ -94,10 +94,4 @@\n \n-def train_evaluate_model_from_config(config: [str, Path, dict], to_train: bool = True, to_validate: bool = True) -> None:\n-    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n-    if isinstance(config, (str, Path)):\n-        config = read_json(config)\n-    set_deeppavlov_root(config)\n-\n-    import_packages(config.get('metadata', {}).get('imports', []))\n-\n+def read_data_by_config(config: dict):\n+    \"\"\"Read data by dataset_reader from specified config.\"\"\"\n     dataset_config = config.get('dataset', None)\n",
        "source_code_with_indent": "\n<DED>def train_evaluate_model_from_config(config: [str, Path, dict], to_train: bool = True, to_validate: bool = True) -> None:\n    <IND>\"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        <IND>config = read_json(config)\n    <DED>set_deeppavlov_root(config)\n\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    dataset_config = config.get('dataset', None)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def read_data_by_config(config: dict):\n    <IND>\"\"\"Read data by dataset_reader from specified config.\"\"\"\n    dataset_config = config.get('dataset', None)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    iterator_config = config['dataset_iterator']\n",
        "source_code_len": 50,
        "target_code": "\n    return data\n\n\ndef get_iterator_from_config(config: dict, data: dict):\n    \"\"\"Create iterator (from config) for specified data.\"\"\"\n    iterator_config = config['dataset_iterator']\n",
        "target_code_len": 184,
        "diff_format": "@@ -141,2 +135,7 @@\n \n+    return data\n+\n+\n+def get_iterator_from_config(config: dict, data: dict):\n+    \"\"\"Create iterator (from config) for specified data.\"\"\"\n     iterator_config = config['dataset_iterator']\n",
        "source_code_with_indent": "\n    <DED>iterator_config = config['dataset_iterator']\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>return data\n\n\n<DED>def get_iterator_from_config(config: dict, data: dict):\n    <IND>\"\"\"Create iterator (from config) for specified data.\"\"\"\n    iterator_config = config['dataset_iterator']\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "                                                                             data=data)\n\n",
        "source_code_len": 89,
        "target_code": "                                                                             data=data)\n    return iterator\n\n\ndef train_evaluate_model_from_config(config: [str, Path, dict], iterator=None,\n                                     to_train=True, to_validate=True) -> Dict[str, Dict[str, float]]:\n    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        config = read_json(config)\n    set_deeppavlov_root(config)\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    if iterator is None:\n        data = read_data_by_config(config)\n        iterator = get_iterator_from_config(config, data)\n\n",
        "target_code_len": 692,
        "diff_format": "@@ -144,2 +143,16 @@\n                                                                              data=data)\n+    return iterator\n+\n+\n+def train_evaluate_model_from_config(config: [str, Path, dict], iterator=None,\n+                                     to_train=True, to_validate=True) -> Dict[str, Dict[str, float]]:\n+    \"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n+    if isinstance(config, (str, Path)):\n+        config = read_json(config)\n+    set_deeppavlov_root(config)\n+    import_packages(config.get('metadata', {}).get('imports', []))\n+\n+    if iterator is None:\n+        data = read_data_by_config(config)\n+        iterator = get_iterator_from_config(config, data)\n \n",
        "source_code_with_indent": "                                                                             data=data)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "                                                                             data=data)\n    return iterator\n\n\n<DED>def train_evaluate_model_from_config(config: [str, Path, dict], iterator=None,\n                                     to_train=True, to_validate=True) -> Dict[str, Dict[str, float]]:\n    <IND>\"\"\"Make training and evaluation of the model described in corresponding configuration file.\"\"\"\n    if isinstance(config, (str, Path)):\n        <IND>config = read_json(config)\n    <DED>set_deeppavlov_root(config)\n    import_packages(config.get('metadata', {}).get('imports', []))\n\n    if iterator is None:\n        <IND>data = read_data_by_config(config)\n        iterator = get_iterator_from_config(config, data)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    if train_config['validate_best'] or train_config['test_best']:\n",
        "source_code_len": 68,
        "target_code": "\n    res = {}\n\n    if train_config['validate_best'] or train_config['test_best']:\n",
        "target_code_len": 82,
        "diff_format": "@@ -173,2 +186,4 @@\n \n+    res = {}\n+\n     if train_config['validate_best'] or train_config['test_best']:\n",
        "source_code_with_indent": "\n    <DED>if train_config['validate_best'] or train_config['test_best']:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>res = {}\n\n    if train_config['validate_best'] or train_config['test_best']:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n            print(json.dumps(report, ensure_ascii=False))\n\n        model.destroy()\n\n",
        "source_code_len": 85,
        "target_code": "\n            res['test'] = report['test']['metrics']\n\n            print(json.dumps(report, ensure_ascii=False))\n        \n        model.destroy()\n\n    return res\n\n",
        "target_code_len": 162,
        "diff_format": "@@ -197,5 +214,9 @@\n \n+            res['test'] = report['test']['metrics']\n+\n             print(json.dumps(report, ensure_ascii=False))\n-\n+        \n         model.destroy()\n+\n+    return res\n \n",
        "source_code_with_indent": "\n            print(json.dumps(report, ensure_ascii=False))\n\n        <DED>model.destroy()\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n            res['test'] = report['test']['metrics']\n\n            print(json.dumps(report, ensure_ascii=False))\n        \n        <DED>model.destroy()\n\n    <DED>return res\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "deepmipt/DeepPavlov",
    "commit": "348cb8e8a0d0052417f57f2b923938e92b776ff9",
    "filename": "deeppavlov/core/commands/train.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/deepmipt-DeepPavlov/deeppavlov/core/commands/train.py",
    "file_hunks_size": 7,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "deeppavlov/core/commands/train.py:220:36 Incompatible parameter type [6]: Expected `Dict[typing.Any, typing.Any]` for 1st positional only parameter to call `prettify_metrics` but got `List[Tuple[str, typing.Any]]`.",
    "message": " Expected `Dict[typing.Any, typing.Any]` for 1st positional only parameter to call `prettify_metrics` but got `List[Tuple[str, typing.Any]]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 220,
    "warning_line": "        'metrics': prettify_metrics(metrics),",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef prettify_metrics(metrics: dict, precision: int = 4) -> OrderedDict:\n    \"\"\"Prettifies the dictionary of metrics.\"\"\"\n",
        "source_code_len": 121,
        "target_code": "\ndef prettify_metrics(metrics: List[Tuple[str, float]], precision: int = 4) -> OrderedDict:\n    \"\"\"Prettifies the dictionary of metrics.\"\"\"\n",
        "target_code_len": 140,
        "diff_format": "@@ -41,3 +41,3 @@\n \n-def prettify_metrics(metrics: dict, precision: int = 4) -> OrderedDict:\n+def prettify_metrics(metrics: List[Tuple[str, float]], precision: int = 4) -> OrderedDict:\n     \"\"\"Prettifies the dictionary of metrics.\"\"\"\n",
        "source_code_with_indent": "\ndef prettify_metrics(metrics: dict, precision: int = 4) -> OrderedDict:\n    <IND>\"\"\"Prettifies the dictionary of metrics.\"\"\"\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\ndef prettify_metrics(metrics: List[Tuple[str, float]], precision: int = 4) -> OrderedDict:\n    <IND>\"\"\"Prettifies the dictionary of metrics.\"\"\"\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "deepmipt/DeepPavlov",
    "commit": "348cb8e8a0d0052417f57f2b923938e92b776ff9",
    "filename": "deeppavlov/core/commands/train.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/deepmipt-DeepPavlov/deeppavlov/core/commands/train.py",
    "file_hunks_size": 7,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "deeppavlov/core/commands/train.py:345:52 Incompatible parameter type [6]: Expected `Dict[typing.Any, typing.Any]` for 1st positional only parameter to call `prettify_metrics` but got `List[Tuple[typing.Any, typing.Any]]`.",
    "message": " Expected `Dict[typing.Any, typing.Any]` for 1st positional only parameter to call `prettify_metrics` but got `List[Tuple[typing.Any, typing.Any]]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 345,
    "warning_line": "                        'metrics': prettify_metrics(metrics),",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef prettify_metrics(metrics: dict, precision: int = 4) -> OrderedDict:\n    \"\"\"Prettifies the dictionary of metrics.\"\"\"\n",
        "source_code_len": 121,
        "target_code": "\ndef prettify_metrics(metrics: List[Tuple[str, float]], precision: int = 4) -> OrderedDict:\n    \"\"\"Prettifies the dictionary of metrics.\"\"\"\n",
        "target_code_len": 140,
        "diff_format": "@@ -41,3 +41,3 @@\n \n-def prettify_metrics(metrics: dict, precision: int = 4) -> OrderedDict:\n+def prettify_metrics(metrics: List[Tuple[str, float]], precision: int = 4) -> OrderedDict:\n     \"\"\"Prettifies the dictionary of metrics.\"\"\"\n",
        "source_code_with_indent": "\ndef prettify_metrics(metrics: dict, precision: int = 4) -> OrderedDict:\n    <IND>\"\"\"Prettifies the dictionary of metrics.\"\"\"\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\ndef prettify_metrics(metrics: List[Tuple[str, float]], precision: int = 4) -> OrderedDict:\n    <IND>\"\"\"Prettifies the dictionary of metrics.\"\"\"\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "deepmipt/DeepPavlov",
    "commit": "348cb8e8a0d0052417f57f2b923938e92b776ff9",
    "filename": "deeppavlov/core/commands/train.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/deepmipt-DeepPavlov/deeppavlov/core/commands/train.py",
    "file_hunks_size": 7,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "deeppavlov/core/commands/train.py:410:48 Incompatible parameter type [6]: Expected `Dict[typing.Any, typing.Any]` for 1st positional only parameter to call `prettify_metrics` but got `List[Tuple[typing.Any, typing.Any]]`.",
    "message": " Expected `Dict[typing.Any, typing.Any]` for 1st positional only parameter to call `prettify_metrics` but got `List[Tuple[typing.Any, typing.Any]]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 410,
    "warning_line": "                    'metrics': prettify_metrics(metrics),",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef prettify_metrics(metrics: dict, precision: int = 4) -> OrderedDict:\n    \"\"\"Prettifies the dictionary of metrics.\"\"\"\n",
        "source_code_len": 121,
        "target_code": "\ndef prettify_metrics(metrics: List[Tuple[str, float]], precision: int = 4) -> OrderedDict:\n    \"\"\"Prettifies the dictionary of metrics.\"\"\"\n",
        "target_code_len": 140,
        "diff_format": "@@ -41,3 +41,3 @@\n \n-def prettify_metrics(metrics: dict, precision: int = 4) -> OrderedDict:\n+def prettify_metrics(metrics: List[Tuple[str, float]], precision: int = 4) -> OrderedDict:\n     \"\"\"Prettifies the dictionary of metrics.\"\"\"\n",
        "source_code_with_indent": "\ndef prettify_metrics(metrics: dict, precision: int = 4) -> OrderedDict:\n    <IND>\"\"\"Prettifies the dictionary of metrics.\"\"\"\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\ndef prettify_metrics(metrics: List[Tuple[str, float]], precision: int = 4) -> OrderedDict:\n    <IND>\"\"\"Prettifies the dictionary of metrics.\"\"\"\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  }
]