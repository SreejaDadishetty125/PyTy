[
  {
    "project": "allenai/allennlp",
    "commit": "85b2c2d2b9fa8bbaa3335d889c610e46d253e6cc",
    "filename": "allennlp/data/dataset_readers/semantic_role_labeling.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/dataset_readers/semantic_role_labeling.py",
    "file_hunks_size": 5,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/dataset_readers/semantic_role_labeling.py:240:51 Unsupported operand [58]: `+` is not supported for operand types `str` and `Optional[str]`.",
    "message": " `+` is not supported for operand types `str` and `Optional[str]`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 240,
    "warning_line": "                                bio_label = \"I-\" + current_span_label[annotation_index]",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from allennlp.data.tokenizers import Token\n\n",
        "source_code_len": 44,
        "target_code": "from allennlp.data.tokenizers import Token\nfrom allennlp.data.dataset_readers.dataset_utils import Ontonotes\n\n\n",
        "target_code_len": 111,
        "diff_format": "@@ -17,2 +14,4 @@\n from allennlp.data.tokenizers import Token\n+from allennlp.data.dataset_readers.dataset_utils import Ontonotes\n+\n \n",
        "source_code_with_indent": "from allennlp.data.tokenizers import Token\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from allennlp.data.tokenizers import Token\nfrom allennlp.data.dataset_readers.dataset_utils import Ontonotes\n\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        file_path = cached_path(file_path)\n\n        instances = []\n\n        sentence: List[str] = []\n        verbal_predicates: List[int] = []\n        predicate_argument_labels: List[List[str]] = []\n        current_span_label: List[Optional[str]] = []\n\n        logger.info(\"Reading SRL instances from dataset files at: %s\", file_path)\n        for root, _, files in tqdm.tqdm(list(os.walk(file_path))):\n            for data_file in files:\n                # These are a relic of the dataset pre-processing. Every file will be duplicated\n                # - one file called filename.gold_skel and one generated from the preprocessing\n                # called filename.gold_conll.\n                if not data_file.endswith(\"gold_conll\"):\n                    continue\n                with codecs.open(os.path.join(root, data_file), 'r', encoding='utf8') as open_file:\n                    for line in open_file:\n                        line = line.strip()\n                        if line == '' or line.startswith(\"#\"):\n\n                            # Conll format data begins and ends with lines containing a hash,\n                            # which may or may not occur after an empty line. To deal with this\n                            # we check if the sentence is empty or not and if it is, we just skip\n                            # adding instances, because there aren't any to add.\n                            if not sentence:\n                                continue\n                            instances.extend(self._process_sentence(sentence,\n                                                                    verbal_predicates,\n                                                                    predicate_argument_labels))\n                            # Reset everything for the next sentence.\n                            sentence = []\n                            verbal_predicates = []\n                            predicate_argument_labels = []\n                            current_span_label = []\n                            continue\n\n                        conll_components = line.split()\n                        word = conll_components[3]\n\n                        sentence.append(word)\n                        word_index = len(sentence) - 1\n                        if word_index == 0:\n                            # We're starting a new sentence. Here we set up a list of lists\n                            # for the BIO labels for the annotation for each verb and create\n                            # a temporary 'current_span_label' list for each annotation which\n                            # we will use to keep track of whether we are beginning, inside of,\n                            # or outside a particular span.\n                            predicate_argument_labels = [[] for _ in conll_components[11:-1]]\n                            current_span_label = [None for _ in conll_components[11:-1]]\n\n                        num_annotations = len(predicate_argument_labels)\n                        is_verbal_predicate = False\n                        # Iterate over all verb annotations for the current sentence.\n                        for annotation_index in range(num_annotations):\n                            annotation = conll_components[11 + annotation_index]\n                            label = annotation.strip(\"()*\")\n\n                            if \"(\" in annotation:\n                                # Entering into a span for a particular semantic role label.\n                                # We append the label and set the current span for this annotation.\n                                bio_label = \"B-\" + label\n                                predicate_argument_labels[annotation_index].append(bio_label)\n                                current_span_label[annotation_index] = label\n\n                            elif current_span_label[annotation_index] is not None:\n                                # If there's no '(' token, but the current_span_label is not None,\n                                # then we are inside a span.\n                                bio_label = \"I-\" + current_span_label[annotation_index]\n                                predicate_argument_labels[annotation_index].append(bio_label)\n                            else:\n                                # We're outside a span.\n                                predicate_argument_labels[annotation_index].append(\"O\")\n\n                            # Exiting a span, so we reset the current span label for this annotation.\n                            if \")\" in annotation:\n                                current_span_label[annotation_index] = None\n                            # If any annotation contains this word as a verb predicate,\n                            # we need to record its index. This also has the side effect\n                            # of ordering the verbal predicates by their location in the\n                            # sentence, automatically aligning them with the annotations.\n                            if \"(V\" in annotation:\n                                is_verbal_predicate = True\n\n                        if is_verbal_predicate:\n                            verbal_predicates.append(word_index)\n\n",
        "source_code_len": 5224,
        "target_code": "        file_path = cached_path(file_path)\n        instances = []\n        ontonotes_reader = Ontonotes()\n        logger.info(\"Reading SRL instances from dataset files at: %s\", file_path)\n\n        for sentence in ontonotes_reader.dataset_iterator(file_path):\n            tokens = [Token(t) for t in sentence.words]\n            if not sentence.srl_frames:\n                # Sentence contains no predicates.\n                tags = [\"O\" for _ in tokens]\n                verb_label = [0 for _ in tokens]\n                instances.append(self.text_to_instance(tokens, verb_label, tags))\n            else:\n                for tags in sentence.srl_frames.values():\n                    verb_indicator = [1 if label[-2:] == \"-V\" else 0 for label in tags]\n                    instances.append(self.text_to_instance(tokens, verb_indicator, tags))\n\n",
        "target_code_len": 836,
        "diff_format": "@@ -171,88 +52,17 @@\n         file_path = cached_path(file_path)\n+        instances = []\n+        ontonotes_reader = Ontonotes()\n+        logger.info(\"Reading SRL instances from dataset files at: %s\", file_path)\n \n-        instances = []\n-\n-        sentence: List[str] = []\n-        verbal_predicates: List[int] = []\n-        predicate_argument_labels: List[List[str]] = []\n-        current_span_label: List[Optional[str]] = []\n-\n-        logger.info(\"Reading SRL instances from dataset files at: %s\", file_path)\n-        for root, _, files in tqdm.tqdm(list(os.walk(file_path))):\n-            for data_file in files:\n-                # These are a relic of the dataset pre-processing. Every file will be duplicated\n-                # - one file called filename.gold_skel and one generated from the preprocessing\n-                # called filename.gold_conll.\n-                if not data_file.endswith(\"gold_conll\"):\n-                    continue\n-                with codecs.open(os.path.join(root, data_file), 'r', encoding='utf8') as open_file:\n-                    for line in open_file:\n-                        line = line.strip()\n-                        if line == '' or line.startswith(\"#\"):\n-\n-                            # Conll format data begins and ends with lines containing a hash,\n-                            # which may or may not occur after an empty line. To deal with this\n-                            # we check if the sentence is empty or not and if it is, we just skip\n-                            # adding instances, because there aren't any to add.\n-                            if not sentence:\n-                                continue\n-                            instances.extend(self._process_sentence(sentence,\n-                                                                    verbal_predicates,\n-                                                                    predicate_argument_labels))\n-                            # Reset everything for the next sentence.\n-                            sentence = []\n-                            verbal_predicates = []\n-                            predicate_argument_labels = []\n-                            current_span_label = []\n-                            continue\n-\n-                        conll_components = line.split()\n-                        word = conll_components[3]\n-\n-                        sentence.append(word)\n-                        word_index = len(sentence) - 1\n-                        if word_index == 0:\n-                            # We're starting a new sentence. Here we set up a list of lists\n-                            # for the BIO labels for the annotation for each verb and create\n-                            # a temporary 'current_span_label' list for each annotation which\n-                            # we will use to keep track of whether we are beginning, inside of,\n-                            # or outside a particular span.\n-                            predicate_argument_labels = [[] for _ in conll_components[11:-1]]\n-                            current_span_label = [None for _ in conll_components[11:-1]]\n-\n-                        num_annotations = len(predicate_argument_labels)\n-                        is_verbal_predicate = False\n-                        # Iterate over all verb annotations for the current sentence.\n-                        for annotation_index in range(num_annotations):\n-                            annotation = conll_components[11 + annotation_index]\n-                            label = annotation.strip(\"()*\")\n-\n-                            if \"(\" in annotation:\n-                                # Entering into a span for a particular semantic role label.\n-                                # We append the label and set the current span for this annotation.\n-                                bio_label = \"B-\" + label\n-                                predicate_argument_labels[annotation_index].append(bio_label)\n-                                current_span_label[annotation_index] = label\n-\n-                            elif current_span_label[annotation_index] is not None:\n-                                # If there's no '(' token, but the current_span_label is not None,\n-                                # then we are inside a span.\n-                                bio_label = \"I-\" + current_span_label[annotation_index]\n-                                predicate_argument_labels[annotation_index].append(bio_label)\n-                            else:\n-                                # We're outside a span.\n-                                predicate_argument_labels[annotation_index].append(\"O\")\n-\n-                            # Exiting a span, so we reset the current span label for this annotation.\n-                            if \")\" in annotation:\n-                                current_span_label[annotation_index] = None\n-                            # If any annotation contains this word as a verb predicate,\n-                            # we need to record its index. This also has the side effect\n-                            # of ordering the verbal predicates by their location in the\n-                            # sentence, automatically aligning them with the annotations.\n-                            if \"(V\" in annotation:\n-                                is_verbal_predicate = True\n-\n-                        if is_verbal_predicate:\n-                            verbal_predicates.append(word_index)\n+        for sentence in ontonotes_reader.dataset_iterator(file_path):\n+            tokens = [Token(t) for t in sentence.words]\n+            if not sentence.srl_frames:\n+                # Sentence contains no predicates.\n+                tags = [\"O\" for _ in tokens]\n+                verb_label = [0 for _ in tokens]\n+                instances.append(self.text_to_instance(tokens, verb_label, tags))\n+            else:\n+                for tags in sentence.srl_frames.values():\n+                    verb_indicator = [1 if label[-2:] == \"-V\" else 0 for label in tags]\n+                    instances.append(self.text_to_instance(tokens, verb_indicator, tags))\n \n",
        "source_code_with_indent": "        <IND>file_path = cached_path(file_path)\n\n        instances = []\n\n        sentence: List[str] = []\n        verbal_predicates: List[int] = []\n        predicate_argument_labels: List[List[str]] = []\n        current_span_label: List[Optional[str]] = []\n\n        logger.info(\"Reading SRL instances from dataset files at: %s\", file_path)\n        for root, _, files in tqdm.tqdm(list(os.walk(file_path))):\n            <IND>for data_file in files:\n                # These are a relic of the dataset pre-processing. Every file will be duplicated\n                # - one file called filename.gold_skel and one generated from the preprocessing\n                # called filename.gold_conll.\n                <IND>if not data_file.endswith(\"gold_conll\"):\n                    <IND>continue\n                <DED>with codecs.open(os.path.join(root, data_file), 'r', encoding='utf8') as open_file:\n                    <IND>for line in open_file:\n                        <IND>line = line.strip()\n                        if line == '' or line.startswith(\"#\"):\n\n                            # Conll format data begins and ends with lines containing a hash,\n                            # which may or may not occur after an empty line. To deal with this\n                            # we check if the sentence is empty or not and if it is, we just skip\n                            # adding instances, because there aren't any to add.\n                            <IND>if not sentence:\n                                <IND>continue\n                            <DED>instances.extend(self._process_sentence(sentence,\n                                                                    verbal_predicates,\n                                                                    predicate_argument_labels))\n                            # Reset everything for the next sentence.\n                            sentence = []\n                            verbal_predicates = []\n                            predicate_argument_labels = []\n                            current_span_label = []\n                            continue\n\n                        <DED>conll_components = line.split()\n                        word = conll_components[3]\n\n                        sentence.append(word)\n                        word_index = len(sentence) - 1\n                        if word_index == 0:\n                            # We're starting a new sentence. Here we set up a list of lists\n                            # for the BIO labels for the annotation for each verb and create\n                            # a temporary 'current_span_label' list for each annotation which\n                            # we will use to keep track of whether we are beginning, inside of,\n                            # or outside a particular span.\n                            <IND>predicate_argument_labels = [[] for _ in conll_components[11:-1]]\n                            current_span_label = [None for _ in conll_components[11:-1]]\n\n                        <DED>num_annotations = len(predicate_argument_labels)\n                        is_verbal_predicate = False\n                        # Iterate over all verb annotations for the current sentence.\n                        for annotation_index in range(num_annotations):\n                            <IND>annotation = conll_components[11 + annotation_index]\n                            label = annotation.strip(\"()*\")\n\n                            if \"(\" in annotation:\n                                # Entering into a span for a particular semantic role label.\n                                # We append the label and set the current span for this annotation.\n                                <IND>bio_label = \"B-\" + label\n                                predicate_argument_labels[annotation_index].append(bio_label)\n                                current_span_label[annotation_index] = label\n\n                            <DED>elif current_span_label[annotation_index] is not None:\n                                # If there's no '(' token, but the current_span_label is not None,\n                                # then we are inside a span.\n                                <IND>bio_label = \"I-\" + current_span_label[annotation_index]\n                                predicate_argument_labels[annotation_index].append(bio_label)\n                            <DED>else:\n                                # We're outside a span.\n                                <IND>predicate_argument_labels[annotation_index].append(\"O\")\n\n                            # Exiting a span, so we reset the current span label for this annotation.\n                            <DED>if \")\" in annotation:\n                                <IND>current_span_label[annotation_index] = None\n                            # If any annotation contains this word as a verb predicate,\n                            # we need to record its index. This also has the side effect\n                            # of ordering the verbal predicates by their location in the\n                            # sentence, automatically aligning them with the annotations.\n                            <DED>if \"(V\" in annotation:\n                                <IND>is_verbal_predicate = True\n\n                        <DED><DED>if is_verbal_predicate:\n                            <IND>verbal_predicates.append(word_index)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        <IND>file_path = cached_path(file_path)\n        instances = []\n        ontonotes_reader = Ontonotes()\n        logger.info(\"Reading SRL instances from dataset files at: %s\", file_path)\n\n        for sentence in ontonotes_reader.dataset_iterator(file_path):\n            <IND>tokens = [Token(t) for t in sentence.words]\n            if not sentence.srl_frames:\n                # Sentence contains no predicates.\n                <IND>tags = [\"O\" for _ in tokens]\n                verb_label = [0 for _ in tokens]\n                instances.append(self.text_to_instance(tokens, verb_label, tags))\n            <DED>else:\n                <IND>for tags in sentence.srl_frames.values():\n                    <IND>verb_indicator = [1 if label[-2:] == \"-V\" else 0 for label in tags]\n                    instances.append(self.text_to_instance(tokens, verb_indicator, tags))\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  }
]