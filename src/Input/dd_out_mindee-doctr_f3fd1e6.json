[
  {
    "project": "mindee/doctr",
    "commit": "f3fd1e612cb2163dc590dbb9cd36e94bf4d347f3",
    "filename": "doctr/models/detection/differentiable_binarization.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/mindee-doctr/doctr/models/detection/differentiable_binarization/base.py",
    "file_hunks_size": 6,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "doctr/models/detection/differentiable_binarization.py:256:29 Call error [29]: `FeaturePyramidNetwork` is not a function.",
    "message": " `FeaturePyramidNetwork` is not a function.",
    "rule_id": "Call error [29]",
    "warning_line_no": 256,
    "warning_line": "        output_shape = tuple(self.fpn(_inputs).shape)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    _children_names: List[str] = ['feat_extractor', 'fpn', 'probability_head', 'threshold_head', 'postprocessor']\n\n    def __init__(\n        self,\n        feature_extractor: IntermediateLayerGetter,\n        fpn_channels: int = 128,\n        rotated_bbox: bool = False,\n        cfg: Optional[Dict[str, Any]] = None,\n    ) -> None:\n\n        super().__init__(cfg=cfg)\n\n        self.shrink_ratio = 0.4\n        self.thresh_min = 0.3\n        self.thresh_max = 0.7\n        self.min_size_box = 3\n\n        self.feat_extractor = feature_extractor\n        self.rotated_bbox = rotated_bbox\n\n        self.fpn = FeaturePyramidNetwork(channels=fpn_channels)\n        # Initialize kernels\n        _inputs = [layers.Input(shape=in_shape[1:]) for in_shape in self.feat_extractor.output_shape]\n        output_shape = tuple(self.fpn(_inputs).shape)\n\n        self.probability_head = keras.Sequential(\n            [\n                *conv_sequence(64, 'relu', True, kernel_size=3, input_shape=output_shape[1:]),\n                layers.Conv2DTranspose(64, 2, strides=2, use_bias=False, kernel_initializer='he_normal'),\n                layers.BatchNormalization(),\n                layers.Activation('relu'),\n                layers.Conv2DTranspose(1, 2, strides=2, kernel_initializer='he_normal'),\n            ]\n        )\n        self.threshold_head = keras.Sequential(\n            [\n                *conv_sequence(64, 'relu', True, kernel_size=3, input_shape=output_shape[1:]),\n                layers.Conv2DTranspose(64, 2, strides=2, use_bias=False, kernel_initializer='he_normal'),\n                layers.BatchNormalization(),\n                layers.Activation('relu'),\n                layers.Conv2DTranspose(1, 2, strides=2, kernel_initializer='he_normal'),\n            ]\n        )\n\n        self.postprocessor = DBPostProcessor(rotated_bbox=rotated_bbox)\n\n",
        "source_code_len": 1833,
        "target_code": "\n    shrink_ratio = 0.4\n    thresh_min = 0.3\n    thresh_max = 0.7\n    min_size_box = 3\n    rotated_bbox: bool = False\n\n",
        "target_code_len": 119,
        "diff_format": "@@ -232,47 +148,7 @@\n \n-    _children_names: List[str] = ['feat_extractor', 'fpn', 'probability_head', 'threshold_head', 'postprocessor']\n-\n-    def __init__(\n-        self,\n-        feature_extractor: IntermediateLayerGetter,\n-        fpn_channels: int = 128,\n-        rotated_bbox: bool = False,\n-        cfg: Optional[Dict[str, Any]] = None,\n-    ) -> None:\n-\n-        super().__init__(cfg=cfg)\n-\n-        self.shrink_ratio = 0.4\n-        self.thresh_min = 0.3\n-        self.thresh_max = 0.7\n-        self.min_size_box = 3\n-\n-        self.feat_extractor = feature_extractor\n-        self.rotated_bbox = rotated_bbox\n-\n-        self.fpn = FeaturePyramidNetwork(channels=fpn_channels)\n-        # Initialize kernels\n-        _inputs = [layers.Input(shape=in_shape[1:]) for in_shape in self.feat_extractor.output_shape]\n-        output_shape = tuple(self.fpn(_inputs).shape)\n-\n-        self.probability_head = keras.Sequential(\n-            [\n-                *conv_sequence(64, 'relu', True, kernel_size=3, input_shape=output_shape[1:]),\n-                layers.Conv2DTranspose(64, 2, strides=2, use_bias=False, kernel_initializer='he_normal'),\n-                layers.BatchNormalization(),\n-                layers.Activation('relu'),\n-                layers.Conv2DTranspose(1, 2, strides=2, kernel_initializer='he_normal'),\n-            ]\n-        )\n-        self.threshold_head = keras.Sequential(\n-            [\n-                *conv_sequence(64, 'relu', True, kernel_size=3, input_shape=output_shape[1:]),\n-                layers.Conv2DTranspose(64, 2, strides=2, use_bias=False, kernel_initializer='he_normal'),\n-                layers.BatchNormalization(),\n-                layers.Activation('relu'),\n-                layers.Conv2DTranspose(1, 2, strides=2, kernel_initializer='he_normal'),\n-            ]\n-        )\n-\n-        self.postprocessor = DBPostProcessor(rotated_bbox=rotated_bbox)\n+    shrink_ratio = 0.4\n+    thresh_min = 0.3\n+    thresh_max = 0.7\n+    min_size_box = 3\n+    rotated_bbox: bool = False\n \n",
        "source_code_with_indent": "\n    _children_names: List[str] = ['feat_extractor', 'fpn', 'probability_head', 'threshold_head', 'postprocessor']\n\n    def __init__(\n        self,\n        feature_extractor: IntermediateLayerGetter,\n        fpn_channels: int = 128,\n        rotated_bbox: bool = False,\n        cfg: Optional[Dict[str, Any]] = None,\n    ) -> None:\n\n        <IND>super().__init__(cfg=cfg)\n\n        self.shrink_ratio = 0.4\n        self.thresh_min = 0.3\n        self.thresh_max = 0.7\n        self.min_size_box = 3\n\n        self.feat_extractor = feature_extractor\n        self.rotated_bbox = rotated_bbox\n\n        self.fpn = FeaturePyramidNetwork(channels=fpn_channels)\n        # Initialize kernels\n        _inputs = [layers.Input(shape=in_shape[1:]) for in_shape in self.feat_extractor.output_shape]\n        output_shape = tuple(self.fpn(_inputs).shape)\n\n        self.probability_head = keras.Sequential(\n            [\n                *conv_sequence(64, 'relu', True, kernel_size=3, input_shape=output_shape[1:]),\n                layers.Conv2DTranspose(64, 2, strides=2, use_bias=False, kernel_initializer='he_normal'),\n                layers.BatchNormalization(),\n                layers.Activation('relu'),\n                layers.Conv2DTranspose(1, 2, strides=2, kernel_initializer='he_normal'),\n            ]\n        )\n        self.threshold_head = keras.Sequential(\n            [\n                *conv_sequence(64, 'relu', True, kernel_size=3, input_shape=output_shape[1:]),\n                layers.Conv2DTranspose(64, 2, strides=2, use_bias=False, kernel_initializer='he_normal'),\n                layers.BatchNormalization(),\n                layers.Activation('relu'),\n                layers.Conv2DTranspose(1, 2, strides=2, kernel_initializer='he_normal'),\n            ]\n        )\n\n        self.postprocessor = DBPostProcessor(rotated_bbox=rotated_bbox)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    shrink_ratio = 0.4\n    thresh_min = 0.3\n    thresh_max = 0.7\n    min_size_box = 3\n    rotated_bbox: bool = False\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n        seg_target = tf.convert_to_tensor(seg_target, dtype=tf.float32)\n        seg_mask = tf.convert_to_tensor(seg_mask, dtype=tf.bool)\n        thresh_target = tf.convert_to_tensor(thresh_target, dtype=tf.float32)\n        thresh_mask = tf.convert_to_tensor(thresh_mask, dtype=tf.bool)\n\n        return seg_target, seg_mask, thresh_target, thresh_mask\n\n    def compute_loss(\n        self,\n        out_map: tf.Tensor,\n        thresh_map: tf.Tensor,\n        target: List[Dict[str, Any]]\n    ) -> tf.Tensor:\n        \"\"\"Compute a batch of gts, masks, thresh_gts, thresh_masks from a list of boxes\n        and a list of masks for each image. From there it computes the loss with the model output\n\n        Args:\n            out_map: output feature map of the model of shape (N, H, W, C)\n            thresh_map: threshold map of shape (N, H, W, C)\n            target: list of dictionary where each dict has a `boxes` and a `flags` entry\n\n        Returns:\n            A loss tensor\n        \"\"\"\n\n        prob_map = tf.math.sigmoid(tf.squeeze(out_map, axis=[-1]))\n        thresh_map = tf.math.sigmoid(tf.squeeze(thresh_map, axis=[-1]))\n\n        seg_target, seg_mask, thresh_target, thresh_mask = self.compute_target(target, out_map.shape[:3])\n\n        # Compute balanced BCE loss for proba_map\n        bce_scale = 5.\n        bce_loss = tf.keras.losses.binary_crossentropy(seg_target[..., None], out_map, from_logits=True)[seg_mask]\n\n        neg_target = 1 - seg_target[seg_mask]\n        positive_count = tf.math.reduce_sum(seg_target[seg_mask])\n        negative_count = tf.math.reduce_min([tf.math.reduce_sum(neg_target), 3. * positive_count])\n        negative_loss = bce_loss * neg_target\n        negative_loss, _ = tf.nn.top_k(negative_loss, tf.cast(negative_count, tf.int32))\n        sum_losses = tf.math.reduce_sum(bce_loss * seg_target[seg_mask]) + tf.math.reduce_sum(negative_loss)\n        balanced_bce_loss = sum_losses / (positive_count + negative_count + 1e-6)\n\n        # Compute dice loss for approxbin_map\n        bin_map = 1 / (1 + tf.exp(-50. * (prob_map[seg_mask] - thresh_map[seg_mask])))\n\n        bce_min = tf.math.reduce_min(bce_loss)\n        weights = (bce_loss - bce_min) / (tf.math.reduce_max(bce_loss) - bce_min) + 1.\n        inter = tf.math.reduce_sum(bin_map * seg_target[seg_mask] * weights)\n        union = tf.math.reduce_sum(bin_map) + tf.math.reduce_sum(seg_target[seg_mask]) + 1e-8\n        dice_loss = 1 - 2.0 * inter / union\n\n        # Compute l1 loss for thresh_map\n        l1_scale = 10.\n        if tf.reduce_any(thresh_mask):\n            l1_loss = tf.math.reduce_mean(tf.math.abs(thresh_map[thresh_mask] - thresh_target[thresh_mask]))\n        else:\n            l1_loss = tf.constant(0.)\n\n        return l1_scale * l1_loss + bce_scale * balanced_bce_loss + dice_loss\n\n    def call(\n        self,\n        x: tf.Tensor,\n        target: Optional[List[Dict[str, Any]]] = None,\n        return_model_output: bool = False,\n        return_boxes: bool = False,\n        **kwargs: Any,\n    ) -> Dict[str, Any]:\n\n        feat_maps = self.feat_extractor(x, **kwargs)\n        feat_concat = self.fpn(feat_maps, **kwargs)\n        logits = self.probability_head(feat_concat, **kwargs)\n\n        out: Dict[str, tf.Tensor] = {}\n        if return_model_output or target is None or return_boxes:\n            prob_map = tf.math.sigmoid(logits)\n\n        if return_model_output:\n            out[\"out_map\"] = prob_map\n\n        if target is None or return_boxes:\n            # Post-process boxes\n            out[\"preds\"] = self.postprocessor(prob_map)\n\n        if target is not None:\n            thresh_map = self.threshold_head(feat_concat, **kwargs)\n            loss = self.compute_loss(logits, thresh_map, target)\n            out['loss'] = loss\n\n        return out\n\n\ndef _db_resnet(arch: str, pretrained: bool, input_shape: Tuple[int, int, int] = None, **kwargs: Any) -> DBNet:\n\n    # Patch the config\n    _cfg = deepcopy(default_cfgs[arch])\n    _cfg['input_shape'] = input_shape or _cfg['input_shape']\n    _cfg['fpn_channels'] = kwargs.get('fpn_channels', _cfg['fpn_channels'])\n    _cfg['rotated_bbox'] = kwargs.get('rotated_bbox', _cfg['rotated_bbox'])\n\n    # Feature extractor\n    resnet = tf.keras.applications.__dict__[_cfg['backbone']](\n        include_top=False,\n        weights=None,\n        input_shape=_cfg['input_shape'],\n        pooling=None,\n    )\n\n    feat_extractor = IntermediateLayerGetter(\n        resnet,\n        _cfg['fpn_layers'],\n    )\n\n    kwargs['fpn_channels'] = _cfg['fpn_channels']\n    kwargs['rotated_bbox'] = _cfg['rotated_bbox']\n\n    # Build the model\n    model = DBNet(feat_extractor, cfg=_cfg, **kwargs)\n    # Load pretrained parameters\n    if pretrained:\n        load_pretrained_params(model, _cfg['url'])\n\n    return model\n\n\ndef db_resnet50(pretrained: bool = False, **kwargs: Any) -> DBNet:\n    \"\"\"DBNet as described in `\"Real-time Scene Text Detection with Differentiable Binarization\"\n    <https://arxiv.org/pdf/1911.08947.pdf>`_, using a ResNet-50 backbone.\n\n    Example::\n        >>> import tensorflow as tf\n        >>> from doctr.models import db_resnet50\n        >>> model = db_resnet50(pretrained=True)\n        >>> input_tensor = tf.random.uniform(shape=[1, 1024, 1024, 3], maxval=1, dtype=tf.float32)\n        >>> out = model(input_tensor)\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on our text detection dataset\n\n    Returns:\n        text detection architecture\n    \"\"\"\n\n    return _db_resnet('db_resnet50', pretrained, **kwargs)\n",
        "source_code_len": 5502,
        "target_code": "\n        seg_target = seg_target.astype(np.float32)\n        seg_mask = seg_mask.astype(bool)\n        thresh_target = thresh_target.astype(np.float32)\n        thresh_mask = thresh_mask.astype(bool)\n\n        return seg_target, seg_mask, thresh_target, thresh_mask\n",
        "target_code_len": 262,
        "diff_format": "@@ -445,145 +321,7 @@\n \n-        seg_target = tf.convert_to_tensor(seg_target, dtype=tf.float32)\n-        seg_mask = tf.convert_to_tensor(seg_mask, dtype=tf.bool)\n-        thresh_target = tf.convert_to_tensor(thresh_target, dtype=tf.float32)\n-        thresh_mask = tf.convert_to_tensor(thresh_mask, dtype=tf.bool)\n+        seg_target = seg_target.astype(np.float32)\n+        seg_mask = seg_mask.astype(bool)\n+        thresh_target = thresh_target.astype(np.float32)\n+        thresh_mask = thresh_mask.astype(bool)\n \n         return seg_target, seg_mask, thresh_target, thresh_mask\n-\n-    def compute_loss(\n-        self,\n-        out_map: tf.Tensor,\n-        thresh_map: tf.Tensor,\n-        target: List[Dict[str, Any]]\n-    ) -> tf.Tensor:\n-        \"\"\"Compute a batch of gts, masks, thresh_gts, thresh_masks from a list of boxes\n-        and a list of masks for each image. From there it computes the loss with the model output\n-\n-        Args:\n-            out_map: output feature map of the model of shape (N, H, W, C)\n-            thresh_map: threshold map of shape (N, H, W, C)\n-            target: list of dictionary where each dict has a `boxes` and a `flags` entry\n-\n-        Returns:\n-            A loss tensor\n-        \"\"\"\n-\n-        prob_map = tf.math.sigmoid(tf.squeeze(out_map, axis=[-1]))\n-        thresh_map = tf.math.sigmoid(tf.squeeze(thresh_map, axis=[-1]))\n-\n-        seg_target, seg_mask, thresh_target, thresh_mask = self.compute_target(target, out_map.shape[:3])\n-\n-        # Compute balanced BCE loss for proba_map\n-        bce_scale = 5.\n-        bce_loss = tf.keras.losses.binary_crossentropy(seg_target[..., None], out_map, from_logits=True)[seg_mask]\n-\n-        neg_target = 1 - seg_target[seg_mask]\n-        positive_count = tf.math.reduce_sum(seg_target[seg_mask])\n-        negative_count = tf.math.reduce_min([tf.math.reduce_sum(neg_target), 3. * positive_count])\n-        negative_loss = bce_loss * neg_target\n-        negative_loss, _ = tf.nn.top_k(negative_loss, tf.cast(negative_count, tf.int32))\n-        sum_losses = tf.math.reduce_sum(bce_loss * seg_target[seg_mask]) + tf.math.reduce_sum(negative_loss)\n-        balanced_bce_loss = sum_losses / (positive_count + negative_count + 1e-6)\n-\n-        # Compute dice loss for approxbin_map\n-        bin_map = 1 / (1 + tf.exp(-50. * (prob_map[seg_mask] - thresh_map[seg_mask])))\n-\n-        bce_min = tf.math.reduce_min(bce_loss)\n-        weights = (bce_loss - bce_min) / (tf.math.reduce_max(bce_loss) - bce_min) + 1.\n-        inter = tf.math.reduce_sum(bin_map * seg_target[seg_mask] * weights)\n-        union = tf.math.reduce_sum(bin_map) + tf.math.reduce_sum(seg_target[seg_mask]) + 1e-8\n-        dice_loss = 1 - 2.0 * inter / union\n-\n-        # Compute l1 loss for thresh_map\n-        l1_scale = 10.\n-        if tf.reduce_any(thresh_mask):\n-            l1_loss = tf.math.reduce_mean(tf.math.abs(thresh_map[thresh_mask] - thresh_target[thresh_mask]))\n-        else:\n-            l1_loss = tf.constant(0.)\n-\n-        return l1_scale * l1_loss + bce_scale * balanced_bce_loss + dice_loss\n-\n-    def call(\n-        self,\n-        x: tf.Tensor,\n-        target: Optional[List[Dict[str, Any]]] = None,\n-        return_model_output: bool = False,\n-        return_boxes: bool = False,\n-        **kwargs: Any,\n-    ) -> Dict[str, Any]:\n-\n-        feat_maps = self.feat_extractor(x, **kwargs)\n-        feat_concat = self.fpn(feat_maps, **kwargs)\n-        logits = self.probability_head(feat_concat, **kwargs)\n-\n-        out: Dict[str, tf.Tensor] = {}\n-        if return_model_output or target is None or return_boxes:\n-            prob_map = tf.math.sigmoid(logits)\n-\n-        if return_model_output:\n-            out[\"out_map\"] = prob_map\n-\n-        if target is None or return_boxes:\n-            # Post-process boxes\n-            out[\"preds\"] = self.postprocessor(prob_map)\n-\n-        if target is not None:\n-            thresh_map = self.threshold_head(feat_concat, **kwargs)\n-            loss = self.compute_loss(logits, thresh_map, target)\n-            out['loss'] = loss\n-\n-        return out\n-\n-\n-def _db_resnet(arch: str, pretrained: bool, input_shape: Tuple[int, int, int] = None, **kwargs: Any) -> DBNet:\n-\n-    # Patch the config\n-    _cfg = deepcopy(default_cfgs[arch])\n-    _cfg['input_shape'] = input_shape or _cfg['input_shape']\n-    _cfg['fpn_channels'] = kwargs.get('fpn_channels', _cfg['fpn_channels'])\n-    _cfg['rotated_bbox'] = kwargs.get('rotated_bbox', _cfg['rotated_bbox'])\n-\n-    # Feature extractor\n-    resnet = tf.keras.applications.__dict__[_cfg['backbone']](\n-        include_top=False,\n-        weights=None,\n-        input_shape=_cfg['input_shape'],\n-        pooling=None,\n-    )\n-\n-    feat_extractor = IntermediateLayerGetter(\n-        resnet,\n-        _cfg['fpn_layers'],\n-    )\n-\n-    kwargs['fpn_channels'] = _cfg['fpn_channels']\n-    kwargs['rotated_bbox'] = _cfg['rotated_bbox']\n-\n-    # Build the model\n-    model = DBNet(feat_extractor, cfg=_cfg, **kwargs)\n-    # Load pretrained parameters\n-    if pretrained:\n-        load_pretrained_params(model, _cfg['url'])\n-\n-    return model\n-\n-\n-def db_resnet50(pretrained: bool = False, **kwargs: Any) -> DBNet:\n-    \"\"\"DBNet as described in `\"Real-time Scene Text Detection with Differentiable Binarization\"\n-    <https://arxiv.org/pdf/1911.08947.pdf>`_, using a ResNet-50 backbone.\n-\n-    Example::\n-        >>> import tensorflow as tf\n-        >>> from doctr.models import db_resnet50\n-        >>> model = db_resnet50(pretrained=True)\n-        >>> input_tensor = tf.random.uniform(shape=[1, 1024, 1024, 3], maxval=1, dtype=tf.float32)\n-        >>> out = model(input_tensor)\n-\n-    Args:\n-        pretrained (bool): If True, returns a model pre-trained on our text detection dataset\n-\n-    Returns:\n-        text detection architecture\n-    \"\"\"\n-\n-    return _db_resnet('db_resnet50', pretrained, **kwargs)\n",
        "source_code_with_indent": "\n        seg_target = tf.convert_to_tensor(seg_target, dtype=tf.float32)\n        seg_mask = tf.convert_to_tensor(seg_mask, dtype=tf.bool)\n        thresh_target = tf.convert_to_tensor(thresh_target, dtype=tf.float32)\n        thresh_mask = tf.convert_to_tensor(thresh_mask, dtype=tf.bool)\n\n        return seg_target, seg_mask, thresh_target, thresh_mask\n\n    <DED>def compute_loss(\n        self,\n        out_map: tf.Tensor,\n        thresh_map: tf.Tensor,\n        target: List[Dict[str, Any]]\n    ) -> tf.Tensor:\n        <IND>\"\"\"Compute a batch of gts, masks, thresh_gts, thresh_masks from a list of boxes\n        and a list of masks for each image. From there it computes the loss with the model output\n\n        Args:\n            out_map: output feature map of the model of shape (N, H, W, C)\n            thresh_map: threshold map of shape (N, H, W, C)\n            target: list of dictionary where each dict has a `boxes` and a `flags` entry\n\n        Returns:\n            A loss tensor\n        \"\"\"\n\n        prob_map = tf.math.sigmoid(tf.squeeze(out_map, axis=[-1]))\n        thresh_map = tf.math.sigmoid(tf.squeeze(thresh_map, axis=[-1]))\n\n        seg_target, seg_mask, thresh_target, thresh_mask = self.compute_target(target, out_map.shape[:3])\n\n        # Compute balanced BCE loss for proba_map\n        bce_scale = 5.\n        bce_loss = tf.keras.losses.binary_crossentropy(seg_target[..., None], out_map, from_logits=True)[seg_mask]\n\n        neg_target = 1 - seg_target[seg_mask]\n        positive_count = tf.math.reduce_sum(seg_target[seg_mask])\n        negative_count = tf.math.reduce_min([tf.math.reduce_sum(neg_target), 3. * positive_count])\n        negative_loss = bce_loss * neg_target\n        negative_loss, _ = tf.nn.top_k(negative_loss, tf.cast(negative_count, tf.int32))\n        sum_losses = tf.math.reduce_sum(bce_loss * seg_target[seg_mask]) + tf.math.reduce_sum(negative_loss)\n        balanced_bce_loss = sum_losses / (positive_count + negative_count + 1e-6)\n\n        # Compute dice loss for approxbin_map\n        bin_map = 1 / (1 + tf.exp(-50. * (prob_map[seg_mask] - thresh_map[seg_mask])))\n\n        bce_min = tf.math.reduce_min(bce_loss)\n        weights = (bce_loss - bce_min) / (tf.math.reduce_max(bce_loss) - bce_min) + 1.\n        inter = tf.math.reduce_sum(bin_map * seg_target[seg_mask] * weights)\n        union = tf.math.reduce_sum(bin_map) + tf.math.reduce_sum(seg_target[seg_mask]) + 1e-8\n        dice_loss = 1 - 2.0 * inter / union\n\n        # Compute l1 loss for thresh_map\n        l1_scale = 10.\n        if tf.reduce_any(thresh_mask):\n            <IND>l1_loss = tf.math.reduce_mean(tf.math.abs(thresh_map[thresh_mask] - thresh_target[thresh_mask]))\n        <DED>else:\n            <IND>l1_loss = tf.constant(0.)\n\n        <DED>return l1_scale * l1_loss + bce_scale * balanced_bce_loss + dice_loss\n\n    <DED>def call(\n        self,\n        x: tf.Tensor,\n        target: Optional[List[Dict[str, Any]]] = None,\n        return_model_output: bool = False,\n        return_boxes: bool = False,\n        **kwargs: Any,\n    ) -> Dict[str, Any]:\n\n        <IND>feat_maps = self.feat_extractor(x, **kwargs)\n        feat_concat = self.fpn(feat_maps, **kwargs)\n        logits = self.probability_head(feat_concat, **kwargs)\n\n        out: Dict[str, tf.Tensor] = {}\n        if return_model_output or target is None or return_boxes:\n            <IND>prob_map = tf.math.sigmoid(logits)\n\n        <DED>if return_model_output:\n            <IND>out[\"out_map\"] = prob_map\n\n        <DED>if target is None or return_boxes:\n            # Post-process boxes\n            <IND>out[\"preds\"] = self.postprocessor(prob_map)\n\n        <DED>if target is not None:\n            <IND>thresh_map = self.threshold_head(feat_concat, **kwargs)\n            loss = self.compute_loss(logits, thresh_map, target)\n            out['loss'] = loss\n\n        <DED>return out\n\n\n<DED><DED>def _db_resnet(arch: str, pretrained: bool, input_shape: Tuple[int, int, int] = None, **kwargs: Any) -> DBNet:\n\n    # Patch the config\n    <IND>_cfg = deepcopy(default_cfgs[arch])\n    _cfg['input_shape'] = input_shape or _cfg['input_shape']\n    _cfg['fpn_channels'] = kwargs.get('fpn_channels', _cfg['fpn_channels'])\n    _cfg['rotated_bbox'] = kwargs.get('rotated_bbox', _cfg['rotated_bbox'])\n\n    # Feature extractor\n    resnet = tf.keras.applications.__dict__[_cfg['backbone']](\n        include_top=False,\n        weights=None,\n        input_shape=_cfg['input_shape'],\n        pooling=None,\n    )\n\n    feat_extractor = IntermediateLayerGetter(\n        resnet,\n        _cfg['fpn_layers'],\n    )\n\n    kwargs['fpn_channels'] = _cfg['fpn_channels']\n    kwargs['rotated_bbox'] = _cfg['rotated_bbox']\n\n    # Build the model\n    model = DBNet(feat_extractor, cfg=_cfg, **kwargs)\n    # Load pretrained parameters\n    if pretrained:\n        <IND>load_pretrained_params(model, _cfg['url'])\n\n    <DED>return model\n\n\n<DED>def db_resnet50(pretrained: bool = False, **kwargs: Any) -> DBNet:\n    <IND>\"\"\"DBNet as described in `\"Real-time Scene Text Detection with Differentiable Binarization\"\n    <https://arxiv.org/pdf/1911.08947.pdf>`_, using a ResNet-50 backbone.\n\n    Example::\n        >>> import tensorflow as tf\n        >>> from doctr.models import db_resnet50\n        >>> model = db_resnet50(pretrained=True)\n        >>> input_tensor = tf.random.uniform(shape=[1, 1024, 1024, 3], maxval=1, dtype=tf.float32)\n        >>> out = model(input_tensor)\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on our text detection dataset\n\n    Returns:\n        text detection architecture\n    \"\"\"\n\n    return _db_resnet('db_resnet50', pretrained, **kwargs)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n        seg_target = seg_target.astype(np.float32)\n        seg_mask = seg_mask.astype(bool)\n        thresh_target = thresh_target.astype(np.float32)\n        thresh_mask = thresh_mask.astype(bool)\n\n        return seg_target, seg_mask, thresh_target, thresh_mask\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "mindee/doctr",
    "commit": "f3fd1e612cb2163dc590dbb9cd36e94bf4d347f3",
    "filename": "doctr/models/detection/differentiable_binarization.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/mindee-doctr/doctr/models/detection/differentiable_binarization/base.py",
    "file_hunks_size": 6,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "doctr/models/detection/differentiable_binarization.py:515:20 Call error [29]: `IntermediateLayerGetter` is not a function.",
    "message": " `IntermediateLayerGetter` is not a function.",
    "rule_id": "Call error [29]",
    "warning_line_no": 515,
    "warning_line": "        feat_maps = self.feat_extractor(x, **kwargs)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n        seg_target = tf.convert_to_tensor(seg_target, dtype=tf.float32)\n        seg_mask = tf.convert_to_tensor(seg_mask, dtype=tf.bool)\n        thresh_target = tf.convert_to_tensor(thresh_target, dtype=tf.float32)\n        thresh_mask = tf.convert_to_tensor(thresh_mask, dtype=tf.bool)\n\n        return seg_target, seg_mask, thresh_target, thresh_mask\n\n    def compute_loss(\n        self,\n        out_map: tf.Tensor,\n        thresh_map: tf.Tensor,\n        target: List[Dict[str, Any]]\n    ) -> tf.Tensor:\n        \"\"\"Compute a batch of gts, masks, thresh_gts, thresh_masks from a list of boxes\n        and a list of masks for each image. From there it computes the loss with the model output\n\n        Args:\n            out_map: output feature map of the model of shape (N, H, W, C)\n            thresh_map: threshold map of shape (N, H, W, C)\n            target: list of dictionary where each dict has a `boxes` and a `flags` entry\n\n        Returns:\n            A loss tensor\n        \"\"\"\n\n        prob_map = tf.math.sigmoid(tf.squeeze(out_map, axis=[-1]))\n        thresh_map = tf.math.sigmoid(tf.squeeze(thresh_map, axis=[-1]))\n\n        seg_target, seg_mask, thresh_target, thresh_mask = self.compute_target(target, out_map.shape[:3])\n\n        # Compute balanced BCE loss for proba_map\n        bce_scale = 5.\n        bce_loss = tf.keras.losses.binary_crossentropy(seg_target[..., None], out_map, from_logits=True)[seg_mask]\n\n        neg_target = 1 - seg_target[seg_mask]\n        positive_count = tf.math.reduce_sum(seg_target[seg_mask])\n        negative_count = tf.math.reduce_min([tf.math.reduce_sum(neg_target), 3. * positive_count])\n        negative_loss = bce_loss * neg_target\n        negative_loss, _ = tf.nn.top_k(negative_loss, tf.cast(negative_count, tf.int32))\n        sum_losses = tf.math.reduce_sum(bce_loss * seg_target[seg_mask]) + tf.math.reduce_sum(negative_loss)\n        balanced_bce_loss = sum_losses / (positive_count + negative_count + 1e-6)\n\n        # Compute dice loss for approxbin_map\n        bin_map = 1 / (1 + tf.exp(-50. * (prob_map[seg_mask] - thresh_map[seg_mask])))\n\n        bce_min = tf.math.reduce_min(bce_loss)\n        weights = (bce_loss - bce_min) / (tf.math.reduce_max(bce_loss) - bce_min) + 1.\n        inter = tf.math.reduce_sum(bin_map * seg_target[seg_mask] * weights)\n        union = tf.math.reduce_sum(bin_map) + tf.math.reduce_sum(seg_target[seg_mask]) + 1e-8\n        dice_loss = 1 - 2.0 * inter / union\n\n        # Compute l1 loss for thresh_map\n        l1_scale = 10.\n        if tf.reduce_any(thresh_mask):\n            l1_loss = tf.math.reduce_mean(tf.math.abs(thresh_map[thresh_mask] - thresh_target[thresh_mask]))\n        else:\n            l1_loss = tf.constant(0.)\n\n        return l1_scale * l1_loss + bce_scale * balanced_bce_loss + dice_loss\n\n    def call(\n        self,\n        x: tf.Tensor,\n        target: Optional[List[Dict[str, Any]]] = None,\n        return_model_output: bool = False,\n        return_boxes: bool = False,\n        **kwargs: Any,\n    ) -> Dict[str, Any]:\n\n        feat_maps = self.feat_extractor(x, **kwargs)\n        feat_concat = self.fpn(feat_maps, **kwargs)\n        logits = self.probability_head(feat_concat, **kwargs)\n\n        out: Dict[str, tf.Tensor] = {}\n        if return_model_output or target is None or return_boxes:\n            prob_map = tf.math.sigmoid(logits)\n\n        if return_model_output:\n            out[\"out_map\"] = prob_map\n\n        if target is None or return_boxes:\n            # Post-process boxes\n            out[\"preds\"] = self.postprocessor(prob_map)\n\n        if target is not None:\n            thresh_map = self.threshold_head(feat_concat, **kwargs)\n            loss = self.compute_loss(logits, thresh_map, target)\n            out['loss'] = loss\n\n        return out\n\n\ndef _db_resnet(arch: str, pretrained: bool, input_shape: Tuple[int, int, int] = None, **kwargs: Any) -> DBNet:\n\n    # Patch the config\n    _cfg = deepcopy(default_cfgs[arch])\n    _cfg['input_shape'] = input_shape or _cfg['input_shape']\n    _cfg['fpn_channels'] = kwargs.get('fpn_channels', _cfg['fpn_channels'])\n    _cfg['rotated_bbox'] = kwargs.get('rotated_bbox', _cfg['rotated_bbox'])\n\n    # Feature extractor\n    resnet = tf.keras.applications.__dict__[_cfg['backbone']](\n        include_top=False,\n        weights=None,\n        input_shape=_cfg['input_shape'],\n        pooling=None,\n    )\n\n    feat_extractor = IntermediateLayerGetter(\n        resnet,\n        _cfg['fpn_layers'],\n    )\n\n    kwargs['fpn_channels'] = _cfg['fpn_channels']\n    kwargs['rotated_bbox'] = _cfg['rotated_bbox']\n\n    # Build the model\n    model = DBNet(feat_extractor, cfg=_cfg, **kwargs)\n    # Load pretrained parameters\n    if pretrained:\n        load_pretrained_params(model, _cfg['url'])\n\n    return model\n\n\ndef db_resnet50(pretrained: bool = False, **kwargs: Any) -> DBNet:\n    \"\"\"DBNet as described in `\"Real-time Scene Text Detection with Differentiable Binarization\"\n    <https://arxiv.org/pdf/1911.08947.pdf>`_, using a ResNet-50 backbone.\n\n    Example::\n        >>> import tensorflow as tf\n        >>> from doctr.models import db_resnet50\n        >>> model = db_resnet50(pretrained=True)\n        >>> input_tensor = tf.random.uniform(shape=[1, 1024, 1024, 3], maxval=1, dtype=tf.float32)\n        >>> out = model(input_tensor)\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on our text detection dataset\n\n    Returns:\n        text detection architecture\n    \"\"\"\n\n    return _db_resnet('db_resnet50', pretrained, **kwargs)\n",
        "source_code_len": 5502,
        "target_code": "\n        seg_target = seg_target.astype(np.float32)\n        seg_mask = seg_mask.astype(bool)\n        thresh_target = thresh_target.astype(np.float32)\n        thresh_mask = thresh_mask.astype(bool)\n\n        return seg_target, seg_mask, thresh_target, thresh_mask\n",
        "target_code_len": 262,
        "diff_format": "@@ -445,145 +321,7 @@\n \n-        seg_target = tf.convert_to_tensor(seg_target, dtype=tf.float32)\n-        seg_mask = tf.convert_to_tensor(seg_mask, dtype=tf.bool)\n-        thresh_target = tf.convert_to_tensor(thresh_target, dtype=tf.float32)\n-        thresh_mask = tf.convert_to_tensor(thresh_mask, dtype=tf.bool)\n+        seg_target = seg_target.astype(np.float32)\n+        seg_mask = seg_mask.astype(bool)\n+        thresh_target = thresh_target.astype(np.float32)\n+        thresh_mask = thresh_mask.astype(bool)\n \n         return seg_target, seg_mask, thresh_target, thresh_mask\n-\n-    def compute_loss(\n-        self,\n-        out_map: tf.Tensor,\n-        thresh_map: tf.Tensor,\n-        target: List[Dict[str, Any]]\n-    ) -> tf.Tensor:\n-        \"\"\"Compute a batch of gts, masks, thresh_gts, thresh_masks from a list of boxes\n-        and a list of masks for each image. From there it computes the loss with the model output\n-\n-        Args:\n-            out_map: output feature map of the model of shape (N, H, W, C)\n-            thresh_map: threshold map of shape (N, H, W, C)\n-            target: list of dictionary where each dict has a `boxes` and a `flags` entry\n-\n-        Returns:\n-            A loss tensor\n-        \"\"\"\n-\n-        prob_map = tf.math.sigmoid(tf.squeeze(out_map, axis=[-1]))\n-        thresh_map = tf.math.sigmoid(tf.squeeze(thresh_map, axis=[-1]))\n-\n-        seg_target, seg_mask, thresh_target, thresh_mask = self.compute_target(target, out_map.shape[:3])\n-\n-        # Compute balanced BCE loss for proba_map\n-        bce_scale = 5.\n-        bce_loss = tf.keras.losses.binary_crossentropy(seg_target[..., None], out_map, from_logits=True)[seg_mask]\n-\n-        neg_target = 1 - seg_target[seg_mask]\n-        positive_count = tf.math.reduce_sum(seg_target[seg_mask])\n-        negative_count = tf.math.reduce_min([tf.math.reduce_sum(neg_target), 3. * positive_count])\n-        negative_loss = bce_loss * neg_target\n-        negative_loss, _ = tf.nn.top_k(negative_loss, tf.cast(negative_count, tf.int32))\n-        sum_losses = tf.math.reduce_sum(bce_loss * seg_target[seg_mask]) + tf.math.reduce_sum(negative_loss)\n-        balanced_bce_loss = sum_losses / (positive_count + negative_count + 1e-6)\n-\n-        # Compute dice loss for approxbin_map\n-        bin_map = 1 / (1 + tf.exp(-50. * (prob_map[seg_mask] - thresh_map[seg_mask])))\n-\n-        bce_min = tf.math.reduce_min(bce_loss)\n-        weights = (bce_loss - bce_min) / (tf.math.reduce_max(bce_loss) - bce_min) + 1.\n-        inter = tf.math.reduce_sum(bin_map * seg_target[seg_mask] * weights)\n-        union = tf.math.reduce_sum(bin_map) + tf.math.reduce_sum(seg_target[seg_mask]) + 1e-8\n-        dice_loss = 1 - 2.0 * inter / union\n-\n-        # Compute l1 loss for thresh_map\n-        l1_scale = 10.\n-        if tf.reduce_any(thresh_mask):\n-            l1_loss = tf.math.reduce_mean(tf.math.abs(thresh_map[thresh_mask] - thresh_target[thresh_mask]))\n-        else:\n-            l1_loss = tf.constant(0.)\n-\n-        return l1_scale * l1_loss + bce_scale * balanced_bce_loss + dice_loss\n-\n-    def call(\n-        self,\n-        x: tf.Tensor,\n-        target: Optional[List[Dict[str, Any]]] = None,\n-        return_model_output: bool = False,\n-        return_boxes: bool = False,\n-        **kwargs: Any,\n-    ) -> Dict[str, Any]:\n-\n-        feat_maps = self.feat_extractor(x, **kwargs)\n-        feat_concat = self.fpn(feat_maps, **kwargs)\n-        logits = self.probability_head(feat_concat, **kwargs)\n-\n-        out: Dict[str, tf.Tensor] = {}\n-        if return_model_output or target is None or return_boxes:\n-            prob_map = tf.math.sigmoid(logits)\n-\n-        if return_model_output:\n-            out[\"out_map\"] = prob_map\n-\n-        if target is None or return_boxes:\n-            # Post-process boxes\n-            out[\"preds\"] = self.postprocessor(prob_map)\n-\n-        if target is not None:\n-            thresh_map = self.threshold_head(feat_concat, **kwargs)\n-            loss = self.compute_loss(logits, thresh_map, target)\n-            out['loss'] = loss\n-\n-        return out\n-\n-\n-def _db_resnet(arch: str, pretrained: bool, input_shape: Tuple[int, int, int] = None, **kwargs: Any) -> DBNet:\n-\n-    # Patch the config\n-    _cfg = deepcopy(default_cfgs[arch])\n-    _cfg['input_shape'] = input_shape or _cfg['input_shape']\n-    _cfg['fpn_channels'] = kwargs.get('fpn_channels', _cfg['fpn_channels'])\n-    _cfg['rotated_bbox'] = kwargs.get('rotated_bbox', _cfg['rotated_bbox'])\n-\n-    # Feature extractor\n-    resnet = tf.keras.applications.__dict__[_cfg['backbone']](\n-        include_top=False,\n-        weights=None,\n-        input_shape=_cfg['input_shape'],\n-        pooling=None,\n-    )\n-\n-    feat_extractor = IntermediateLayerGetter(\n-        resnet,\n-        _cfg['fpn_layers'],\n-    )\n-\n-    kwargs['fpn_channels'] = _cfg['fpn_channels']\n-    kwargs['rotated_bbox'] = _cfg['rotated_bbox']\n-\n-    # Build the model\n-    model = DBNet(feat_extractor, cfg=_cfg, **kwargs)\n-    # Load pretrained parameters\n-    if pretrained:\n-        load_pretrained_params(model, _cfg['url'])\n-\n-    return model\n-\n-\n-def db_resnet50(pretrained: bool = False, **kwargs: Any) -> DBNet:\n-    \"\"\"DBNet as described in `\"Real-time Scene Text Detection with Differentiable Binarization\"\n-    <https://arxiv.org/pdf/1911.08947.pdf>`_, using a ResNet-50 backbone.\n-\n-    Example::\n-        >>> import tensorflow as tf\n-        >>> from doctr.models import db_resnet50\n-        >>> model = db_resnet50(pretrained=True)\n-        >>> input_tensor = tf.random.uniform(shape=[1, 1024, 1024, 3], maxval=1, dtype=tf.float32)\n-        >>> out = model(input_tensor)\n-\n-    Args:\n-        pretrained (bool): If True, returns a model pre-trained on our text detection dataset\n-\n-    Returns:\n-        text detection architecture\n-    \"\"\"\n-\n-    return _db_resnet('db_resnet50', pretrained, **kwargs)\n",
        "source_code_with_indent": "\n        seg_target = tf.convert_to_tensor(seg_target, dtype=tf.float32)\n        seg_mask = tf.convert_to_tensor(seg_mask, dtype=tf.bool)\n        thresh_target = tf.convert_to_tensor(thresh_target, dtype=tf.float32)\n        thresh_mask = tf.convert_to_tensor(thresh_mask, dtype=tf.bool)\n\n        return seg_target, seg_mask, thresh_target, thresh_mask\n\n    <DED>def compute_loss(\n        self,\n        out_map: tf.Tensor,\n        thresh_map: tf.Tensor,\n        target: List[Dict[str, Any]]\n    ) -> tf.Tensor:\n        <IND>\"\"\"Compute a batch of gts, masks, thresh_gts, thresh_masks from a list of boxes\n        and a list of masks for each image. From there it computes the loss with the model output\n\n        Args:\n            out_map: output feature map of the model of shape (N, H, W, C)\n            thresh_map: threshold map of shape (N, H, W, C)\n            target: list of dictionary where each dict has a `boxes` and a `flags` entry\n\n        Returns:\n            A loss tensor\n        \"\"\"\n\n        prob_map = tf.math.sigmoid(tf.squeeze(out_map, axis=[-1]))\n        thresh_map = tf.math.sigmoid(tf.squeeze(thresh_map, axis=[-1]))\n\n        seg_target, seg_mask, thresh_target, thresh_mask = self.compute_target(target, out_map.shape[:3])\n\n        # Compute balanced BCE loss for proba_map\n        bce_scale = 5.\n        bce_loss = tf.keras.losses.binary_crossentropy(seg_target[..., None], out_map, from_logits=True)[seg_mask]\n\n        neg_target = 1 - seg_target[seg_mask]\n        positive_count = tf.math.reduce_sum(seg_target[seg_mask])\n        negative_count = tf.math.reduce_min([tf.math.reduce_sum(neg_target), 3. * positive_count])\n        negative_loss = bce_loss * neg_target\n        negative_loss, _ = tf.nn.top_k(negative_loss, tf.cast(negative_count, tf.int32))\n        sum_losses = tf.math.reduce_sum(bce_loss * seg_target[seg_mask]) + tf.math.reduce_sum(negative_loss)\n        balanced_bce_loss = sum_losses / (positive_count + negative_count + 1e-6)\n\n        # Compute dice loss for approxbin_map\n        bin_map = 1 / (1 + tf.exp(-50. * (prob_map[seg_mask] - thresh_map[seg_mask])))\n\n        bce_min = tf.math.reduce_min(bce_loss)\n        weights = (bce_loss - bce_min) / (tf.math.reduce_max(bce_loss) - bce_min) + 1.\n        inter = tf.math.reduce_sum(bin_map * seg_target[seg_mask] * weights)\n        union = tf.math.reduce_sum(bin_map) + tf.math.reduce_sum(seg_target[seg_mask]) + 1e-8\n        dice_loss = 1 - 2.0 * inter / union\n\n        # Compute l1 loss for thresh_map\n        l1_scale = 10.\n        if tf.reduce_any(thresh_mask):\n            <IND>l1_loss = tf.math.reduce_mean(tf.math.abs(thresh_map[thresh_mask] - thresh_target[thresh_mask]))\n        <DED>else:\n            <IND>l1_loss = tf.constant(0.)\n\n        <DED>return l1_scale * l1_loss + bce_scale * balanced_bce_loss + dice_loss\n\n    <DED>def call(\n        self,\n        x: tf.Tensor,\n        target: Optional[List[Dict[str, Any]]] = None,\n        return_model_output: bool = False,\n        return_boxes: bool = False,\n        **kwargs: Any,\n    ) -> Dict[str, Any]:\n\n        <IND>feat_maps = self.feat_extractor(x, **kwargs)\n        feat_concat = self.fpn(feat_maps, **kwargs)\n        logits = self.probability_head(feat_concat, **kwargs)\n\n        out: Dict[str, tf.Tensor] = {}\n        if return_model_output or target is None or return_boxes:\n            <IND>prob_map = tf.math.sigmoid(logits)\n\n        <DED>if return_model_output:\n            <IND>out[\"out_map\"] = prob_map\n\n        <DED>if target is None or return_boxes:\n            # Post-process boxes\n            <IND>out[\"preds\"] = self.postprocessor(prob_map)\n\n        <DED>if target is not None:\n            <IND>thresh_map = self.threshold_head(feat_concat, **kwargs)\n            loss = self.compute_loss(logits, thresh_map, target)\n            out['loss'] = loss\n\n        <DED>return out\n\n\n<DED><DED>def _db_resnet(arch: str, pretrained: bool, input_shape: Tuple[int, int, int] = None, **kwargs: Any) -> DBNet:\n\n    # Patch the config\n    <IND>_cfg = deepcopy(default_cfgs[arch])\n    _cfg['input_shape'] = input_shape or _cfg['input_shape']\n    _cfg['fpn_channels'] = kwargs.get('fpn_channels', _cfg['fpn_channels'])\n    _cfg['rotated_bbox'] = kwargs.get('rotated_bbox', _cfg['rotated_bbox'])\n\n    # Feature extractor\n    resnet = tf.keras.applications.__dict__[_cfg['backbone']](\n        include_top=False,\n        weights=None,\n        input_shape=_cfg['input_shape'],\n        pooling=None,\n    )\n\n    feat_extractor = IntermediateLayerGetter(\n        resnet,\n        _cfg['fpn_layers'],\n    )\n\n    kwargs['fpn_channels'] = _cfg['fpn_channels']\n    kwargs['rotated_bbox'] = _cfg['rotated_bbox']\n\n    # Build the model\n    model = DBNet(feat_extractor, cfg=_cfg, **kwargs)\n    # Load pretrained parameters\n    if pretrained:\n        <IND>load_pretrained_params(model, _cfg['url'])\n\n    <DED>return model\n\n\n<DED>def db_resnet50(pretrained: bool = False, **kwargs: Any) -> DBNet:\n    <IND>\"\"\"DBNet as described in `\"Real-time Scene Text Detection with Differentiable Binarization\"\n    <https://arxiv.org/pdf/1911.08947.pdf>`_, using a ResNet-50 backbone.\n\n    Example::\n        >>> import tensorflow as tf\n        >>> from doctr.models import db_resnet50\n        >>> model = db_resnet50(pretrained=True)\n        >>> input_tensor = tf.random.uniform(shape=[1, 1024, 1024, 3], maxval=1, dtype=tf.float32)\n        >>> out = model(input_tensor)\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on our text detection dataset\n\n    Returns:\n        text detection architecture\n    \"\"\"\n\n    return _db_resnet('db_resnet50', pretrained, **kwargs)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n        seg_target = seg_target.astype(np.float32)\n        seg_mask = seg_mask.astype(bool)\n        thresh_target = thresh_target.astype(np.float32)\n        thresh_mask = thresh_mask.astype(bool)\n\n        return seg_target, seg_mask, thresh_target, thresh_mask\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "mindee/doctr",
    "commit": "f3fd1e612cb2163dc590dbb9cd36e94bf4d347f3",
    "filename": "doctr/models/detection/differentiable_binarization.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/mindee-doctr/doctr/models/detection/differentiable_binarization/base.py",
    "file_hunks_size": 6,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "doctr/models/detection/differentiable_binarization.py:516:22 Call error [29]: `FeaturePyramidNetwork` is not a function.",
    "message": " `FeaturePyramidNetwork` is not a function.",
    "rule_id": "Call error [29]",
    "warning_line_no": 516,
    "warning_line": "        feat_concat = self.fpn(feat_maps, **kwargs)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n        seg_target = tf.convert_to_tensor(seg_target, dtype=tf.float32)\n        seg_mask = tf.convert_to_tensor(seg_mask, dtype=tf.bool)\n        thresh_target = tf.convert_to_tensor(thresh_target, dtype=tf.float32)\n        thresh_mask = tf.convert_to_tensor(thresh_mask, dtype=tf.bool)\n\n        return seg_target, seg_mask, thresh_target, thresh_mask\n\n    def compute_loss(\n        self,\n        out_map: tf.Tensor,\n        thresh_map: tf.Tensor,\n        target: List[Dict[str, Any]]\n    ) -> tf.Tensor:\n        \"\"\"Compute a batch of gts, masks, thresh_gts, thresh_masks from a list of boxes\n        and a list of masks for each image. From there it computes the loss with the model output\n\n        Args:\n            out_map: output feature map of the model of shape (N, H, W, C)\n            thresh_map: threshold map of shape (N, H, W, C)\n            target: list of dictionary where each dict has a `boxes` and a `flags` entry\n\n        Returns:\n            A loss tensor\n        \"\"\"\n\n        prob_map = tf.math.sigmoid(tf.squeeze(out_map, axis=[-1]))\n        thresh_map = tf.math.sigmoid(tf.squeeze(thresh_map, axis=[-1]))\n\n        seg_target, seg_mask, thresh_target, thresh_mask = self.compute_target(target, out_map.shape[:3])\n\n        # Compute balanced BCE loss for proba_map\n        bce_scale = 5.\n        bce_loss = tf.keras.losses.binary_crossentropy(seg_target[..., None], out_map, from_logits=True)[seg_mask]\n\n        neg_target = 1 - seg_target[seg_mask]\n        positive_count = tf.math.reduce_sum(seg_target[seg_mask])\n        negative_count = tf.math.reduce_min([tf.math.reduce_sum(neg_target), 3. * positive_count])\n        negative_loss = bce_loss * neg_target\n        negative_loss, _ = tf.nn.top_k(negative_loss, tf.cast(negative_count, tf.int32))\n        sum_losses = tf.math.reduce_sum(bce_loss * seg_target[seg_mask]) + tf.math.reduce_sum(negative_loss)\n        balanced_bce_loss = sum_losses / (positive_count + negative_count + 1e-6)\n\n        # Compute dice loss for approxbin_map\n        bin_map = 1 / (1 + tf.exp(-50. * (prob_map[seg_mask] - thresh_map[seg_mask])))\n\n        bce_min = tf.math.reduce_min(bce_loss)\n        weights = (bce_loss - bce_min) / (tf.math.reduce_max(bce_loss) - bce_min) + 1.\n        inter = tf.math.reduce_sum(bin_map * seg_target[seg_mask] * weights)\n        union = tf.math.reduce_sum(bin_map) + tf.math.reduce_sum(seg_target[seg_mask]) + 1e-8\n        dice_loss = 1 - 2.0 * inter / union\n\n        # Compute l1 loss for thresh_map\n        l1_scale = 10.\n        if tf.reduce_any(thresh_mask):\n            l1_loss = tf.math.reduce_mean(tf.math.abs(thresh_map[thresh_mask] - thresh_target[thresh_mask]))\n        else:\n            l1_loss = tf.constant(0.)\n\n        return l1_scale * l1_loss + bce_scale * balanced_bce_loss + dice_loss\n\n    def call(\n        self,\n        x: tf.Tensor,\n        target: Optional[List[Dict[str, Any]]] = None,\n        return_model_output: bool = False,\n        return_boxes: bool = False,\n        **kwargs: Any,\n    ) -> Dict[str, Any]:\n\n        feat_maps = self.feat_extractor(x, **kwargs)\n        feat_concat = self.fpn(feat_maps, **kwargs)\n        logits = self.probability_head(feat_concat, **kwargs)\n\n        out: Dict[str, tf.Tensor] = {}\n        if return_model_output or target is None or return_boxes:\n            prob_map = tf.math.sigmoid(logits)\n\n        if return_model_output:\n            out[\"out_map\"] = prob_map\n\n        if target is None or return_boxes:\n            # Post-process boxes\n            out[\"preds\"] = self.postprocessor(prob_map)\n\n        if target is not None:\n            thresh_map = self.threshold_head(feat_concat, **kwargs)\n            loss = self.compute_loss(logits, thresh_map, target)\n            out['loss'] = loss\n\n        return out\n\n\ndef _db_resnet(arch: str, pretrained: bool, input_shape: Tuple[int, int, int] = None, **kwargs: Any) -> DBNet:\n\n    # Patch the config\n    _cfg = deepcopy(default_cfgs[arch])\n    _cfg['input_shape'] = input_shape or _cfg['input_shape']\n    _cfg['fpn_channels'] = kwargs.get('fpn_channels', _cfg['fpn_channels'])\n    _cfg['rotated_bbox'] = kwargs.get('rotated_bbox', _cfg['rotated_bbox'])\n\n    # Feature extractor\n    resnet = tf.keras.applications.__dict__[_cfg['backbone']](\n        include_top=False,\n        weights=None,\n        input_shape=_cfg['input_shape'],\n        pooling=None,\n    )\n\n    feat_extractor = IntermediateLayerGetter(\n        resnet,\n        _cfg['fpn_layers'],\n    )\n\n    kwargs['fpn_channels'] = _cfg['fpn_channels']\n    kwargs['rotated_bbox'] = _cfg['rotated_bbox']\n\n    # Build the model\n    model = DBNet(feat_extractor, cfg=_cfg, **kwargs)\n    # Load pretrained parameters\n    if pretrained:\n        load_pretrained_params(model, _cfg['url'])\n\n    return model\n\n\ndef db_resnet50(pretrained: bool = False, **kwargs: Any) -> DBNet:\n    \"\"\"DBNet as described in `\"Real-time Scene Text Detection with Differentiable Binarization\"\n    <https://arxiv.org/pdf/1911.08947.pdf>`_, using a ResNet-50 backbone.\n\n    Example::\n        >>> import tensorflow as tf\n        >>> from doctr.models import db_resnet50\n        >>> model = db_resnet50(pretrained=True)\n        >>> input_tensor = tf.random.uniform(shape=[1, 1024, 1024, 3], maxval=1, dtype=tf.float32)\n        >>> out = model(input_tensor)\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on our text detection dataset\n\n    Returns:\n        text detection architecture\n    \"\"\"\n\n    return _db_resnet('db_resnet50', pretrained, **kwargs)\n",
        "source_code_len": 5502,
        "target_code": "\n        seg_target = seg_target.astype(np.float32)\n        seg_mask = seg_mask.astype(bool)\n        thresh_target = thresh_target.astype(np.float32)\n        thresh_mask = thresh_mask.astype(bool)\n\n        return seg_target, seg_mask, thresh_target, thresh_mask\n",
        "target_code_len": 262,
        "diff_format": "@@ -445,145 +321,7 @@\n \n-        seg_target = tf.convert_to_tensor(seg_target, dtype=tf.float32)\n-        seg_mask = tf.convert_to_tensor(seg_mask, dtype=tf.bool)\n-        thresh_target = tf.convert_to_tensor(thresh_target, dtype=tf.float32)\n-        thresh_mask = tf.convert_to_tensor(thresh_mask, dtype=tf.bool)\n+        seg_target = seg_target.astype(np.float32)\n+        seg_mask = seg_mask.astype(bool)\n+        thresh_target = thresh_target.astype(np.float32)\n+        thresh_mask = thresh_mask.astype(bool)\n \n         return seg_target, seg_mask, thresh_target, thresh_mask\n-\n-    def compute_loss(\n-        self,\n-        out_map: tf.Tensor,\n-        thresh_map: tf.Tensor,\n-        target: List[Dict[str, Any]]\n-    ) -> tf.Tensor:\n-        \"\"\"Compute a batch of gts, masks, thresh_gts, thresh_masks from a list of boxes\n-        and a list of masks for each image. From there it computes the loss with the model output\n-\n-        Args:\n-            out_map: output feature map of the model of shape (N, H, W, C)\n-            thresh_map: threshold map of shape (N, H, W, C)\n-            target: list of dictionary where each dict has a `boxes` and a `flags` entry\n-\n-        Returns:\n-            A loss tensor\n-        \"\"\"\n-\n-        prob_map = tf.math.sigmoid(tf.squeeze(out_map, axis=[-1]))\n-        thresh_map = tf.math.sigmoid(tf.squeeze(thresh_map, axis=[-1]))\n-\n-        seg_target, seg_mask, thresh_target, thresh_mask = self.compute_target(target, out_map.shape[:3])\n-\n-        # Compute balanced BCE loss for proba_map\n-        bce_scale = 5.\n-        bce_loss = tf.keras.losses.binary_crossentropy(seg_target[..., None], out_map, from_logits=True)[seg_mask]\n-\n-        neg_target = 1 - seg_target[seg_mask]\n-        positive_count = tf.math.reduce_sum(seg_target[seg_mask])\n-        negative_count = tf.math.reduce_min([tf.math.reduce_sum(neg_target), 3. * positive_count])\n-        negative_loss = bce_loss * neg_target\n-        negative_loss, _ = tf.nn.top_k(negative_loss, tf.cast(negative_count, tf.int32))\n-        sum_losses = tf.math.reduce_sum(bce_loss * seg_target[seg_mask]) + tf.math.reduce_sum(negative_loss)\n-        balanced_bce_loss = sum_losses / (positive_count + negative_count + 1e-6)\n-\n-        # Compute dice loss for approxbin_map\n-        bin_map = 1 / (1 + tf.exp(-50. * (prob_map[seg_mask] - thresh_map[seg_mask])))\n-\n-        bce_min = tf.math.reduce_min(bce_loss)\n-        weights = (bce_loss - bce_min) / (tf.math.reduce_max(bce_loss) - bce_min) + 1.\n-        inter = tf.math.reduce_sum(bin_map * seg_target[seg_mask] * weights)\n-        union = tf.math.reduce_sum(bin_map) + tf.math.reduce_sum(seg_target[seg_mask]) + 1e-8\n-        dice_loss = 1 - 2.0 * inter / union\n-\n-        # Compute l1 loss for thresh_map\n-        l1_scale = 10.\n-        if tf.reduce_any(thresh_mask):\n-            l1_loss = tf.math.reduce_mean(tf.math.abs(thresh_map[thresh_mask] - thresh_target[thresh_mask]))\n-        else:\n-            l1_loss = tf.constant(0.)\n-\n-        return l1_scale * l1_loss + bce_scale * balanced_bce_loss + dice_loss\n-\n-    def call(\n-        self,\n-        x: tf.Tensor,\n-        target: Optional[List[Dict[str, Any]]] = None,\n-        return_model_output: bool = False,\n-        return_boxes: bool = False,\n-        **kwargs: Any,\n-    ) -> Dict[str, Any]:\n-\n-        feat_maps = self.feat_extractor(x, **kwargs)\n-        feat_concat = self.fpn(feat_maps, **kwargs)\n-        logits = self.probability_head(feat_concat, **kwargs)\n-\n-        out: Dict[str, tf.Tensor] = {}\n-        if return_model_output or target is None or return_boxes:\n-            prob_map = tf.math.sigmoid(logits)\n-\n-        if return_model_output:\n-            out[\"out_map\"] = prob_map\n-\n-        if target is None or return_boxes:\n-            # Post-process boxes\n-            out[\"preds\"] = self.postprocessor(prob_map)\n-\n-        if target is not None:\n-            thresh_map = self.threshold_head(feat_concat, **kwargs)\n-            loss = self.compute_loss(logits, thresh_map, target)\n-            out['loss'] = loss\n-\n-        return out\n-\n-\n-def _db_resnet(arch: str, pretrained: bool, input_shape: Tuple[int, int, int] = None, **kwargs: Any) -> DBNet:\n-\n-    # Patch the config\n-    _cfg = deepcopy(default_cfgs[arch])\n-    _cfg['input_shape'] = input_shape or _cfg['input_shape']\n-    _cfg['fpn_channels'] = kwargs.get('fpn_channels', _cfg['fpn_channels'])\n-    _cfg['rotated_bbox'] = kwargs.get('rotated_bbox', _cfg['rotated_bbox'])\n-\n-    # Feature extractor\n-    resnet = tf.keras.applications.__dict__[_cfg['backbone']](\n-        include_top=False,\n-        weights=None,\n-        input_shape=_cfg['input_shape'],\n-        pooling=None,\n-    )\n-\n-    feat_extractor = IntermediateLayerGetter(\n-        resnet,\n-        _cfg['fpn_layers'],\n-    )\n-\n-    kwargs['fpn_channels'] = _cfg['fpn_channels']\n-    kwargs['rotated_bbox'] = _cfg['rotated_bbox']\n-\n-    # Build the model\n-    model = DBNet(feat_extractor, cfg=_cfg, **kwargs)\n-    # Load pretrained parameters\n-    if pretrained:\n-        load_pretrained_params(model, _cfg['url'])\n-\n-    return model\n-\n-\n-def db_resnet50(pretrained: bool = False, **kwargs: Any) -> DBNet:\n-    \"\"\"DBNet as described in `\"Real-time Scene Text Detection with Differentiable Binarization\"\n-    <https://arxiv.org/pdf/1911.08947.pdf>`_, using a ResNet-50 backbone.\n-\n-    Example::\n-        >>> import tensorflow as tf\n-        >>> from doctr.models import db_resnet50\n-        >>> model = db_resnet50(pretrained=True)\n-        >>> input_tensor = tf.random.uniform(shape=[1, 1024, 1024, 3], maxval=1, dtype=tf.float32)\n-        >>> out = model(input_tensor)\n-\n-    Args:\n-        pretrained (bool): If True, returns a model pre-trained on our text detection dataset\n-\n-    Returns:\n-        text detection architecture\n-    \"\"\"\n-\n-    return _db_resnet('db_resnet50', pretrained, **kwargs)\n",
        "source_code_with_indent": "\n        seg_target = tf.convert_to_tensor(seg_target, dtype=tf.float32)\n        seg_mask = tf.convert_to_tensor(seg_mask, dtype=tf.bool)\n        thresh_target = tf.convert_to_tensor(thresh_target, dtype=tf.float32)\n        thresh_mask = tf.convert_to_tensor(thresh_mask, dtype=tf.bool)\n\n        return seg_target, seg_mask, thresh_target, thresh_mask\n\n    <DED>def compute_loss(\n        self,\n        out_map: tf.Tensor,\n        thresh_map: tf.Tensor,\n        target: List[Dict[str, Any]]\n    ) -> tf.Tensor:\n        <IND>\"\"\"Compute a batch of gts, masks, thresh_gts, thresh_masks from a list of boxes\n        and a list of masks for each image. From there it computes the loss with the model output\n\n        Args:\n            out_map: output feature map of the model of shape (N, H, W, C)\n            thresh_map: threshold map of shape (N, H, W, C)\n            target: list of dictionary where each dict has a `boxes` and a `flags` entry\n\n        Returns:\n            A loss tensor\n        \"\"\"\n\n        prob_map = tf.math.sigmoid(tf.squeeze(out_map, axis=[-1]))\n        thresh_map = tf.math.sigmoid(tf.squeeze(thresh_map, axis=[-1]))\n\n        seg_target, seg_mask, thresh_target, thresh_mask = self.compute_target(target, out_map.shape[:3])\n\n        # Compute balanced BCE loss for proba_map\n        bce_scale = 5.\n        bce_loss = tf.keras.losses.binary_crossentropy(seg_target[..., None], out_map, from_logits=True)[seg_mask]\n\n        neg_target = 1 - seg_target[seg_mask]\n        positive_count = tf.math.reduce_sum(seg_target[seg_mask])\n        negative_count = tf.math.reduce_min([tf.math.reduce_sum(neg_target), 3. * positive_count])\n        negative_loss = bce_loss * neg_target\n        negative_loss, _ = tf.nn.top_k(negative_loss, tf.cast(negative_count, tf.int32))\n        sum_losses = tf.math.reduce_sum(bce_loss * seg_target[seg_mask]) + tf.math.reduce_sum(negative_loss)\n        balanced_bce_loss = sum_losses / (positive_count + negative_count + 1e-6)\n\n        # Compute dice loss for approxbin_map\n        bin_map = 1 / (1 + tf.exp(-50. * (prob_map[seg_mask] - thresh_map[seg_mask])))\n\n        bce_min = tf.math.reduce_min(bce_loss)\n        weights = (bce_loss - bce_min) / (tf.math.reduce_max(bce_loss) - bce_min) + 1.\n        inter = tf.math.reduce_sum(bin_map * seg_target[seg_mask] * weights)\n        union = tf.math.reduce_sum(bin_map) + tf.math.reduce_sum(seg_target[seg_mask]) + 1e-8\n        dice_loss = 1 - 2.0 * inter / union\n\n        # Compute l1 loss for thresh_map\n        l1_scale = 10.\n        if tf.reduce_any(thresh_mask):\n            <IND>l1_loss = tf.math.reduce_mean(tf.math.abs(thresh_map[thresh_mask] - thresh_target[thresh_mask]))\n        <DED>else:\n            <IND>l1_loss = tf.constant(0.)\n\n        <DED>return l1_scale * l1_loss + bce_scale * balanced_bce_loss + dice_loss\n\n    <DED>def call(\n        self,\n        x: tf.Tensor,\n        target: Optional[List[Dict[str, Any]]] = None,\n        return_model_output: bool = False,\n        return_boxes: bool = False,\n        **kwargs: Any,\n    ) -> Dict[str, Any]:\n\n        <IND>feat_maps = self.feat_extractor(x, **kwargs)\n        feat_concat = self.fpn(feat_maps, **kwargs)\n        logits = self.probability_head(feat_concat, **kwargs)\n\n        out: Dict[str, tf.Tensor] = {}\n        if return_model_output or target is None or return_boxes:\n            <IND>prob_map = tf.math.sigmoid(logits)\n\n        <DED>if return_model_output:\n            <IND>out[\"out_map\"] = prob_map\n\n        <DED>if target is None or return_boxes:\n            # Post-process boxes\n            <IND>out[\"preds\"] = self.postprocessor(prob_map)\n\n        <DED>if target is not None:\n            <IND>thresh_map = self.threshold_head(feat_concat, **kwargs)\n            loss = self.compute_loss(logits, thresh_map, target)\n            out['loss'] = loss\n\n        <DED>return out\n\n\n<DED><DED>def _db_resnet(arch: str, pretrained: bool, input_shape: Tuple[int, int, int] = None, **kwargs: Any) -> DBNet:\n\n    # Patch the config\n    <IND>_cfg = deepcopy(default_cfgs[arch])\n    _cfg['input_shape'] = input_shape or _cfg['input_shape']\n    _cfg['fpn_channels'] = kwargs.get('fpn_channels', _cfg['fpn_channels'])\n    _cfg['rotated_bbox'] = kwargs.get('rotated_bbox', _cfg['rotated_bbox'])\n\n    # Feature extractor\n    resnet = tf.keras.applications.__dict__[_cfg['backbone']](\n        include_top=False,\n        weights=None,\n        input_shape=_cfg['input_shape'],\n        pooling=None,\n    )\n\n    feat_extractor = IntermediateLayerGetter(\n        resnet,\n        _cfg['fpn_layers'],\n    )\n\n    kwargs['fpn_channels'] = _cfg['fpn_channels']\n    kwargs['rotated_bbox'] = _cfg['rotated_bbox']\n\n    # Build the model\n    model = DBNet(feat_extractor, cfg=_cfg, **kwargs)\n    # Load pretrained parameters\n    if pretrained:\n        <IND>load_pretrained_params(model, _cfg['url'])\n\n    <DED>return model\n\n\n<DED>def db_resnet50(pretrained: bool = False, **kwargs: Any) -> DBNet:\n    <IND>\"\"\"DBNet as described in `\"Real-time Scene Text Detection with Differentiable Binarization\"\n    <https://arxiv.org/pdf/1911.08947.pdf>`_, using a ResNet-50 backbone.\n\n    Example::\n        >>> import tensorflow as tf\n        >>> from doctr.models import db_resnet50\n        >>> model = db_resnet50(pretrained=True)\n        >>> input_tensor = tf.random.uniform(shape=[1, 1024, 1024, 3], maxval=1, dtype=tf.float32)\n        >>> out = model(input_tensor)\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on our text detection dataset\n\n    Returns:\n        text detection architecture\n    \"\"\"\n\n    return _db_resnet('db_resnet50', pretrained, **kwargs)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n        seg_target = seg_target.astype(np.float32)\n        seg_mask = seg_mask.astype(bool)\n        thresh_target = thresh_target.astype(np.float32)\n        thresh_mask = thresh_mask.astype(bool)\n\n        return seg_target, seg_mask, thresh_target, thresh_mask\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "mindee/doctr",
    "commit": "f3fd1e612cb2163dc590dbb9cd36e94bf4d347f3",
    "filename": "doctr/models/detection/differentiable_binarization.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/mindee-doctr/doctr/models/detection/differentiable_binarization/base.py",
    "file_hunks_size": 6,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "doctr/models/detection/differentiable_binarization.py:538:44 Incompatible variable type [9]: Unable to unpack `None`, expected a tuple.",
    "message": " Unable to unpack `None`, expected a tuple.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 538,
    "warning_line": "def _db_resnet(arch: str, pretrained: bool, input_shape: Tuple[int, int, int] = None, **kwargs: Any) -> DBNet:",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n        seg_target = tf.convert_to_tensor(seg_target, dtype=tf.float32)\n        seg_mask = tf.convert_to_tensor(seg_mask, dtype=tf.bool)\n        thresh_target = tf.convert_to_tensor(thresh_target, dtype=tf.float32)\n        thresh_mask = tf.convert_to_tensor(thresh_mask, dtype=tf.bool)\n\n        return seg_target, seg_mask, thresh_target, thresh_mask\n\n    def compute_loss(\n        self,\n        out_map: tf.Tensor,\n        thresh_map: tf.Tensor,\n        target: List[Dict[str, Any]]\n    ) -> tf.Tensor:\n        \"\"\"Compute a batch of gts, masks, thresh_gts, thresh_masks from a list of boxes\n        and a list of masks for each image. From there it computes the loss with the model output\n\n        Args:\n            out_map: output feature map of the model of shape (N, H, W, C)\n            thresh_map: threshold map of shape (N, H, W, C)\n            target: list of dictionary where each dict has a `boxes` and a `flags` entry\n\n        Returns:\n            A loss tensor\n        \"\"\"\n\n        prob_map = tf.math.sigmoid(tf.squeeze(out_map, axis=[-1]))\n        thresh_map = tf.math.sigmoid(tf.squeeze(thresh_map, axis=[-1]))\n\n        seg_target, seg_mask, thresh_target, thresh_mask = self.compute_target(target, out_map.shape[:3])\n\n        # Compute balanced BCE loss for proba_map\n        bce_scale = 5.\n        bce_loss = tf.keras.losses.binary_crossentropy(seg_target[..., None], out_map, from_logits=True)[seg_mask]\n\n        neg_target = 1 - seg_target[seg_mask]\n        positive_count = tf.math.reduce_sum(seg_target[seg_mask])\n        negative_count = tf.math.reduce_min([tf.math.reduce_sum(neg_target), 3. * positive_count])\n        negative_loss = bce_loss * neg_target\n        negative_loss, _ = tf.nn.top_k(negative_loss, tf.cast(negative_count, tf.int32))\n        sum_losses = tf.math.reduce_sum(bce_loss * seg_target[seg_mask]) + tf.math.reduce_sum(negative_loss)\n        balanced_bce_loss = sum_losses / (positive_count + negative_count + 1e-6)\n\n        # Compute dice loss for approxbin_map\n        bin_map = 1 / (1 + tf.exp(-50. * (prob_map[seg_mask] - thresh_map[seg_mask])))\n\n        bce_min = tf.math.reduce_min(bce_loss)\n        weights = (bce_loss - bce_min) / (tf.math.reduce_max(bce_loss) - bce_min) + 1.\n        inter = tf.math.reduce_sum(bin_map * seg_target[seg_mask] * weights)\n        union = tf.math.reduce_sum(bin_map) + tf.math.reduce_sum(seg_target[seg_mask]) + 1e-8\n        dice_loss = 1 - 2.0 * inter / union\n\n        # Compute l1 loss for thresh_map\n        l1_scale = 10.\n        if tf.reduce_any(thresh_mask):\n            l1_loss = tf.math.reduce_mean(tf.math.abs(thresh_map[thresh_mask] - thresh_target[thresh_mask]))\n        else:\n            l1_loss = tf.constant(0.)\n\n        return l1_scale * l1_loss + bce_scale * balanced_bce_loss + dice_loss\n\n    def call(\n        self,\n        x: tf.Tensor,\n        target: Optional[List[Dict[str, Any]]] = None,\n        return_model_output: bool = False,\n        return_boxes: bool = False,\n        **kwargs: Any,\n    ) -> Dict[str, Any]:\n\n        feat_maps = self.feat_extractor(x, **kwargs)\n        feat_concat = self.fpn(feat_maps, **kwargs)\n        logits = self.probability_head(feat_concat, **kwargs)\n\n        out: Dict[str, tf.Tensor] = {}\n        if return_model_output or target is None or return_boxes:\n            prob_map = tf.math.sigmoid(logits)\n\n        if return_model_output:\n            out[\"out_map\"] = prob_map\n\n        if target is None or return_boxes:\n            # Post-process boxes\n            out[\"preds\"] = self.postprocessor(prob_map)\n\n        if target is not None:\n            thresh_map = self.threshold_head(feat_concat, **kwargs)\n            loss = self.compute_loss(logits, thresh_map, target)\n            out['loss'] = loss\n\n        return out\n\n\ndef _db_resnet(arch: str, pretrained: bool, input_shape: Tuple[int, int, int] = None, **kwargs: Any) -> DBNet:\n\n    # Patch the config\n    _cfg = deepcopy(default_cfgs[arch])\n    _cfg['input_shape'] = input_shape or _cfg['input_shape']\n    _cfg['fpn_channels'] = kwargs.get('fpn_channels', _cfg['fpn_channels'])\n    _cfg['rotated_bbox'] = kwargs.get('rotated_bbox', _cfg['rotated_bbox'])\n\n    # Feature extractor\n    resnet = tf.keras.applications.__dict__[_cfg['backbone']](\n        include_top=False,\n        weights=None,\n        input_shape=_cfg['input_shape'],\n        pooling=None,\n    )\n\n    feat_extractor = IntermediateLayerGetter(\n        resnet,\n        _cfg['fpn_layers'],\n    )\n\n    kwargs['fpn_channels'] = _cfg['fpn_channels']\n    kwargs['rotated_bbox'] = _cfg['rotated_bbox']\n\n    # Build the model\n    model = DBNet(feat_extractor, cfg=_cfg, **kwargs)\n    # Load pretrained parameters\n    if pretrained:\n        load_pretrained_params(model, _cfg['url'])\n\n    return model\n\n\ndef db_resnet50(pretrained: bool = False, **kwargs: Any) -> DBNet:\n    \"\"\"DBNet as described in `\"Real-time Scene Text Detection with Differentiable Binarization\"\n    <https://arxiv.org/pdf/1911.08947.pdf>`_, using a ResNet-50 backbone.\n\n    Example::\n        >>> import tensorflow as tf\n        >>> from doctr.models import db_resnet50\n        >>> model = db_resnet50(pretrained=True)\n        >>> input_tensor = tf.random.uniform(shape=[1, 1024, 1024, 3], maxval=1, dtype=tf.float32)\n        >>> out = model(input_tensor)\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on our text detection dataset\n\n    Returns:\n        text detection architecture\n    \"\"\"\n\n    return _db_resnet('db_resnet50', pretrained, **kwargs)\n",
        "source_code_len": 5502,
        "target_code": "\n        seg_target = seg_target.astype(np.float32)\n        seg_mask = seg_mask.astype(bool)\n        thresh_target = thresh_target.astype(np.float32)\n        thresh_mask = thresh_mask.astype(bool)\n\n        return seg_target, seg_mask, thresh_target, thresh_mask\n",
        "target_code_len": 262,
        "diff_format": "@@ -445,145 +321,7 @@\n \n-        seg_target = tf.convert_to_tensor(seg_target, dtype=tf.float32)\n-        seg_mask = tf.convert_to_tensor(seg_mask, dtype=tf.bool)\n-        thresh_target = tf.convert_to_tensor(thresh_target, dtype=tf.float32)\n-        thresh_mask = tf.convert_to_tensor(thresh_mask, dtype=tf.bool)\n+        seg_target = seg_target.astype(np.float32)\n+        seg_mask = seg_mask.astype(bool)\n+        thresh_target = thresh_target.astype(np.float32)\n+        thresh_mask = thresh_mask.astype(bool)\n \n         return seg_target, seg_mask, thresh_target, thresh_mask\n-\n-    def compute_loss(\n-        self,\n-        out_map: tf.Tensor,\n-        thresh_map: tf.Tensor,\n-        target: List[Dict[str, Any]]\n-    ) -> tf.Tensor:\n-        \"\"\"Compute a batch of gts, masks, thresh_gts, thresh_masks from a list of boxes\n-        and a list of masks for each image. From there it computes the loss with the model output\n-\n-        Args:\n-            out_map: output feature map of the model of shape (N, H, W, C)\n-            thresh_map: threshold map of shape (N, H, W, C)\n-            target: list of dictionary where each dict has a `boxes` and a `flags` entry\n-\n-        Returns:\n-            A loss tensor\n-        \"\"\"\n-\n-        prob_map = tf.math.sigmoid(tf.squeeze(out_map, axis=[-1]))\n-        thresh_map = tf.math.sigmoid(tf.squeeze(thresh_map, axis=[-1]))\n-\n-        seg_target, seg_mask, thresh_target, thresh_mask = self.compute_target(target, out_map.shape[:3])\n-\n-        # Compute balanced BCE loss for proba_map\n-        bce_scale = 5.\n-        bce_loss = tf.keras.losses.binary_crossentropy(seg_target[..., None], out_map, from_logits=True)[seg_mask]\n-\n-        neg_target = 1 - seg_target[seg_mask]\n-        positive_count = tf.math.reduce_sum(seg_target[seg_mask])\n-        negative_count = tf.math.reduce_min([tf.math.reduce_sum(neg_target), 3. * positive_count])\n-        negative_loss = bce_loss * neg_target\n-        negative_loss, _ = tf.nn.top_k(negative_loss, tf.cast(negative_count, tf.int32))\n-        sum_losses = tf.math.reduce_sum(bce_loss * seg_target[seg_mask]) + tf.math.reduce_sum(negative_loss)\n-        balanced_bce_loss = sum_losses / (positive_count + negative_count + 1e-6)\n-\n-        # Compute dice loss for approxbin_map\n-        bin_map = 1 / (1 + tf.exp(-50. * (prob_map[seg_mask] - thresh_map[seg_mask])))\n-\n-        bce_min = tf.math.reduce_min(bce_loss)\n-        weights = (bce_loss - bce_min) / (tf.math.reduce_max(bce_loss) - bce_min) + 1.\n-        inter = tf.math.reduce_sum(bin_map * seg_target[seg_mask] * weights)\n-        union = tf.math.reduce_sum(bin_map) + tf.math.reduce_sum(seg_target[seg_mask]) + 1e-8\n-        dice_loss = 1 - 2.0 * inter / union\n-\n-        # Compute l1 loss for thresh_map\n-        l1_scale = 10.\n-        if tf.reduce_any(thresh_mask):\n-            l1_loss = tf.math.reduce_mean(tf.math.abs(thresh_map[thresh_mask] - thresh_target[thresh_mask]))\n-        else:\n-            l1_loss = tf.constant(0.)\n-\n-        return l1_scale * l1_loss + bce_scale * balanced_bce_loss + dice_loss\n-\n-    def call(\n-        self,\n-        x: tf.Tensor,\n-        target: Optional[List[Dict[str, Any]]] = None,\n-        return_model_output: bool = False,\n-        return_boxes: bool = False,\n-        **kwargs: Any,\n-    ) -> Dict[str, Any]:\n-\n-        feat_maps = self.feat_extractor(x, **kwargs)\n-        feat_concat = self.fpn(feat_maps, **kwargs)\n-        logits = self.probability_head(feat_concat, **kwargs)\n-\n-        out: Dict[str, tf.Tensor] = {}\n-        if return_model_output or target is None or return_boxes:\n-            prob_map = tf.math.sigmoid(logits)\n-\n-        if return_model_output:\n-            out[\"out_map\"] = prob_map\n-\n-        if target is None or return_boxes:\n-            # Post-process boxes\n-            out[\"preds\"] = self.postprocessor(prob_map)\n-\n-        if target is not None:\n-            thresh_map = self.threshold_head(feat_concat, **kwargs)\n-            loss = self.compute_loss(logits, thresh_map, target)\n-            out['loss'] = loss\n-\n-        return out\n-\n-\n-def _db_resnet(arch: str, pretrained: bool, input_shape: Tuple[int, int, int] = None, **kwargs: Any) -> DBNet:\n-\n-    # Patch the config\n-    _cfg = deepcopy(default_cfgs[arch])\n-    _cfg['input_shape'] = input_shape or _cfg['input_shape']\n-    _cfg['fpn_channels'] = kwargs.get('fpn_channels', _cfg['fpn_channels'])\n-    _cfg['rotated_bbox'] = kwargs.get('rotated_bbox', _cfg['rotated_bbox'])\n-\n-    # Feature extractor\n-    resnet = tf.keras.applications.__dict__[_cfg['backbone']](\n-        include_top=False,\n-        weights=None,\n-        input_shape=_cfg['input_shape'],\n-        pooling=None,\n-    )\n-\n-    feat_extractor = IntermediateLayerGetter(\n-        resnet,\n-        _cfg['fpn_layers'],\n-    )\n-\n-    kwargs['fpn_channels'] = _cfg['fpn_channels']\n-    kwargs['rotated_bbox'] = _cfg['rotated_bbox']\n-\n-    # Build the model\n-    model = DBNet(feat_extractor, cfg=_cfg, **kwargs)\n-    # Load pretrained parameters\n-    if pretrained:\n-        load_pretrained_params(model, _cfg['url'])\n-\n-    return model\n-\n-\n-def db_resnet50(pretrained: bool = False, **kwargs: Any) -> DBNet:\n-    \"\"\"DBNet as described in `\"Real-time Scene Text Detection with Differentiable Binarization\"\n-    <https://arxiv.org/pdf/1911.08947.pdf>`_, using a ResNet-50 backbone.\n-\n-    Example::\n-        >>> import tensorflow as tf\n-        >>> from doctr.models import db_resnet50\n-        >>> model = db_resnet50(pretrained=True)\n-        >>> input_tensor = tf.random.uniform(shape=[1, 1024, 1024, 3], maxval=1, dtype=tf.float32)\n-        >>> out = model(input_tensor)\n-\n-    Args:\n-        pretrained (bool): If True, returns a model pre-trained on our text detection dataset\n-\n-    Returns:\n-        text detection architecture\n-    \"\"\"\n-\n-    return _db_resnet('db_resnet50', pretrained, **kwargs)\n",
        "source_code_with_indent": "\n        seg_target = tf.convert_to_tensor(seg_target, dtype=tf.float32)\n        seg_mask = tf.convert_to_tensor(seg_mask, dtype=tf.bool)\n        thresh_target = tf.convert_to_tensor(thresh_target, dtype=tf.float32)\n        thresh_mask = tf.convert_to_tensor(thresh_mask, dtype=tf.bool)\n\n        return seg_target, seg_mask, thresh_target, thresh_mask\n\n    <DED>def compute_loss(\n        self,\n        out_map: tf.Tensor,\n        thresh_map: tf.Tensor,\n        target: List[Dict[str, Any]]\n    ) -> tf.Tensor:\n        <IND>\"\"\"Compute a batch of gts, masks, thresh_gts, thresh_masks from a list of boxes\n        and a list of masks for each image. From there it computes the loss with the model output\n\n        Args:\n            out_map: output feature map of the model of shape (N, H, W, C)\n            thresh_map: threshold map of shape (N, H, W, C)\n            target: list of dictionary where each dict has a `boxes` and a `flags` entry\n\n        Returns:\n            A loss tensor\n        \"\"\"\n\n        prob_map = tf.math.sigmoid(tf.squeeze(out_map, axis=[-1]))\n        thresh_map = tf.math.sigmoid(tf.squeeze(thresh_map, axis=[-1]))\n\n        seg_target, seg_mask, thresh_target, thresh_mask = self.compute_target(target, out_map.shape[:3])\n\n        # Compute balanced BCE loss for proba_map\n        bce_scale = 5.\n        bce_loss = tf.keras.losses.binary_crossentropy(seg_target[..., None], out_map, from_logits=True)[seg_mask]\n\n        neg_target = 1 - seg_target[seg_mask]\n        positive_count = tf.math.reduce_sum(seg_target[seg_mask])\n        negative_count = tf.math.reduce_min([tf.math.reduce_sum(neg_target), 3. * positive_count])\n        negative_loss = bce_loss * neg_target\n        negative_loss, _ = tf.nn.top_k(negative_loss, tf.cast(negative_count, tf.int32))\n        sum_losses = tf.math.reduce_sum(bce_loss * seg_target[seg_mask]) + tf.math.reduce_sum(negative_loss)\n        balanced_bce_loss = sum_losses / (positive_count + negative_count + 1e-6)\n\n        # Compute dice loss for approxbin_map\n        bin_map = 1 / (1 + tf.exp(-50. * (prob_map[seg_mask] - thresh_map[seg_mask])))\n\n        bce_min = tf.math.reduce_min(bce_loss)\n        weights = (bce_loss - bce_min) / (tf.math.reduce_max(bce_loss) - bce_min) + 1.\n        inter = tf.math.reduce_sum(bin_map * seg_target[seg_mask] * weights)\n        union = tf.math.reduce_sum(bin_map) + tf.math.reduce_sum(seg_target[seg_mask]) + 1e-8\n        dice_loss = 1 - 2.0 * inter / union\n\n        # Compute l1 loss for thresh_map\n        l1_scale = 10.\n        if tf.reduce_any(thresh_mask):\n            <IND>l1_loss = tf.math.reduce_mean(tf.math.abs(thresh_map[thresh_mask] - thresh_target[thresh_mask]))\n        <DED>else:\n            <IND>l1_loss = tf.constant(0.)\n\n        <DED>return l1_scale * l1_loss + bce_scale * balanced_bce_loss + dice_loss\n\n    <DED>def call(\n        self,\n        x: tf.Tensor,\n        target: Optional[List[Dict[str, Any]]] = None,\n        return_model_output: bool = False,\n        return_boxes: bool = False,\n        **kwargs: Any,\n    ) -> Dict[str, Any]:\n\n        <IND>feat_maps = self.feat_extractor(x, **kwargs)\n        feat_concat = self.fpn(feat_maps, **kwargs)\n        logits = self.probability_head(feat_concat, **kwargs)\n\n        out: Dict[str, tf.Tensor] = {}\n        if return_model_output or target is None or return_boxes:\n            <IND>prob_map = tf.math.sigmoid(logits)\n\n        <DED>if return_model_output:\n            <IND>out[\"out_map\"] = prob_map\n\n        <DED>if target is None or return_boxes:\n            # Post-process boxes\n            <IND>out[\"preds\"] = self.postprocessor(prob_map)\n\n        <DED>if target is not None:\n            <IND>thresh_map = self.threshold_head(feat_concat, **kwargs)\n            loss = self.compute_loss(logits, thresh_map, target)\n            out['loss'] = loss\n\n        <DED>return out\n\n\n<DED><DED>def _db_resnet(arch: str, pretrained: bool, input_shape: Tuple[int, int, int] = None, **kwargs: Any) -> DBNet:\n\n    # Patch the config\n    <IND>_cfg = deepcopy(default_cfgs[arch])\n    _cfg['input_shape'] = input_shape or _cfg['input_shape']\n    _cfg['fpn_channels'] = kwargs.get('fpn_channels', _cfg['fpn_channels'])\n    _cfg['rotated_bbox'] = kwargs.get('rotated_bbox', _cfg['rotated_bbox'])\n\n    # Feature extractor\n    resnet = tf.keras.applications.__dict__[_cfg['backbone']](\n        include_top=False,\n        weights=None,\n        input_shape=_cfg['input_shape'],\n        pooling=None,\n    )\n\n    feat_extractor = IntermediateLayerGetter(\n        resnet,\n        _cfg['fpn_layers'],\n    )\n\n    kwargs['fpn_channels'] = _cfg['fpn_channels']\n    kwargs['rotated_bbox'] = _cfg['rotated_bbox']\n\n    # Build the model\n    model = DBNet(feat_extractor, cfg=_cfg, **kwargs)\n    # Load pretrained parameters\n    if pretrained:\n        <IND>load_pretrained_params(model, _cfg['url'])\n\n    <DED>return model\n\n\n<DED>def db_resnet50(pretrained: bool = False, **kwargs: Any) -> DBNet:\n    <IND>\"\"\"DBNet as described in `\"Real-time Scene Text Detection with Differentiable Binarization\"\n    <https://arxiv.org/pdf/1911.08947.pdf>`_, using a ResNet-50 backbone.\n\n    Example::\n        >>> import tensorflow as tf\n        >>> from doctr.models import db_resnet50\n        >>> model = db_resnet50(pretrained=True)\n        >>> input_tensor = tf.random.uniform(shape=[1, 1024, 1024, 3], maxval=1, dtype=tf.float32)\n        >>> out = model(input_tensor)\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on our text detection dataset\n\n    Returns:\n        text detection architecture\n    \"\"\"\n\n    return _db_resnet('db_resnet50', pretrained, **kwargs)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n        seg_target = seg_target.astype(np.float32)\n        seg_mask = seg_mask.astype(bool)\n        thresh_target = thresh_target.astype(np.float32)\n        thresh_mask = thresh_mask.astype(bool)\n\n        return seg_target, seg_mask, thresh_target, thresh_mask\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "mindee/doctr",
    "commit": "f3fd1e612cb2163dc590dbb9cd36e94bf4d347f3",
    "filename": "doctr/models/detection/differentiable_binarization_pt.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/mindee-doctr/doctr/models/detection/differentiable_binarization/pytorch.py",
    "file_hunks_size": 12,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "doctr/models/detection/differentiable_binarization_pt.py:139:22 Call error [29]: `FeaturePyramidNetwork` is not a function.",
    "message": " `FeaturePyramidNetwork` is not a function.",
    "rule_id": "Call error [29]",
    "warning_line_no": 139,
    "warning_line": "        feat_concat = self.fpn(feats)"
  },
  {
    "project": "mindee/doctr",
    "commit": "f3fd1e612cb2163dc590dbb9cd36e94bf4d347f3",
    "filename": "doctr/models/detection/linknet.py",
    "min_patch_found": false,
    "full_warning_msg": "doctr/models/detection/linknet.py:155:14 Call error [29]: `doctr.models.backbones.resnet.ResnetStage` is not a function.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/mindee-doctr/doctr/models/detection/linknet.py'",
    "dd_fail": true
  },
  {
    "project": "mindee/doctr",
    "commit": "f3fd1e612cb2163dc590dbb9cd36e94bf4d347f3",
    "filename": "doctr/models/detection/linknet.py",
    "min_patch_found": false,
    "full_warning_msg": "doctr/models/detection/linknet.py:156:14 Call error [29]: `doctr.models.backbones.resnet.ResnetStage` is not a function.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/mindee-doctr/doctr/models/detection/linknet.py'",
    "dd_fail": true
  },
  {
    "project": "mindee/doctr",
    "commit": "f3fd1e612cb2163dc590dbb9cd36e94bf4d347f3",
    "filename": "doctr/models/detection/linknet.py",
    "min_patch_found": false,
    "full_warning_msg": "doctr/models/detection/linknet.py:157:14 Call error [29]: `doctr.models.backbones.resnet.ResnetStage` is not a function.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/mindee-doctr/doctr/models/detection/linknet.py'",
    "dd_fail": true
  },
  {
    "project": "mindee/doctr",
    "commit": "f3fd1e612cb2163dc590dbb9cd36e94bf4d347f3",
    "filename": "doctr/models/detection/linknet.py",
    "min_patch_found": false,
    "full_warning_msg": "doctr/models/detection/linknet.py:158:14 Call error [29]: `doctr.models.backbones.resnet.ResnetStage` is not a function.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/mindee-doctr/doctr/models/detection/linknet.py'",
    "dd_fail": true
  },
  {
    "project": "mindee/doctr",
    "commit": "f3fd1e612cb2163dc590dbb9cd36e94bf4d347f3",
    "filename": "doctr/models/detection/linknet.py",
    "min_patch_found": false,
    "full_warning_msg": "doctr/models/detection/linknet.py:348:17 Call error [29]: `LinkNetFPN` is not a function.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/mindee-doctr/doctr/models/detection/linknet.py'",
    "dd_fail": true
  },
  {
    "project": "mindee/doctr",
    "commit": "f3fd1e612cb2163dc590dbb9cd36e94bf4d347f3",
    "filename": "doctr/models/detection/linknet.py",
    "min_patch_found": false,
    "full_warning_msg": "doctr/models/detection/linknet.py:368:42 Incompatible variable type [9]: Unable to unpack `None`, expected a tuple.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/mindee-doctr/doctr/models/detection/linknet.py'",
    "dd_fail": true
  }
]