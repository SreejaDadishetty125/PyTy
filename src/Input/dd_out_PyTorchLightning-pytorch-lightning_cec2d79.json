[
  {
    "project": "PyTorchLightning/pytorch-lightning",
    "commit": "cec2d7946b9da07289025e27e57597538d2c50ec",
    "filename": "pytorch_lightning/accelerators/accelerator.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/PyTorchLightning-pytorch-lightning/pytorch_lightning/accelerators/accelerator.py",
    "file_hunks_size": 4,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": true,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "pytorch_lightning/accelerators/accelerator.py:91:8 Incompatible return type [7]: Expected `pl.core.lightning.LightningModule` but got `Optional[pl.core.lightning.LightningModule]`.",
    "message": " Expected `pl.core.lightning.LightningModule` but got `Optional[pl.core.lightning.LightningModule]`.",
    "rule_id": "Incompatible return type [7]",
    "warning_line_no": 91,
    "warning_line": "        return self.training_type_plugin.lightning_module",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "        \"\"\"\n        self.training_type_plugin.setup(trainer)\n\n    @property\n    def model(self) -> Module:\n        \"\"\"Returns the model.\n\n        This can also be a wrapped LightningModule. For retrieving the pure LightningModule use\n        :attr:`Accelerator.lightning_module`\n        \"\"\"\n        return self.training_type_plugin.model\n\n    @model.setter\n    def model(self, new_model: Module) -> None:\n        self.training_type_plugin.model = new_model\n\n    @property\n    def lightning_module(self) -> \"pl.LightningModule\":\n        \"\"\"Returns the pure LightningModule.\n\n        To get the potentially wrapped model use :attr:`Accelerator.model`\n        \"\"\"\n        return self.training_type_plugin.lightning_module\n\n    @property\n    def root_device(self) -> torch.device:\n        \"\"\"Returns the root device.\"\"\"\n        return self.training_type_plugin.root_device\n\n    def teardown(self) -> None:\n        \"\"\"This method is called to teardown the training process.\n\n        It is the right place to release memory and free other resources.\n        \"\"\"\n        self.training_type_plugin.teardown()\n\n",
        "source_code_len": 1102,
        "target_code": "        \"\"\"\n\n",
        "target_code_len": 13,
        "diff_format": "@@ -69,36 +45,2 @@\n         \"\"\"\n-        self.training_type_plugin.setup(trainer)\n-\n-    @property\n-    def model(self) -> Module:\n-        \"\"\"Returns the model.\n-\n-        This can also be a wrapped LightningModule. For retrieving the pure LightningModule use\n-        :attr:`Accelerator.lightning_module`\n-        \"\"\"\n-        return self.training_type_plugin.model\n-\n-    @model.setter\n-    def model(self, new_model: Module) -> None:\n-        self.training_type_plugin.model = new_model\n-\n-    @property\n-    def lightning_module(self) -> \"pl.LightningModule\":\n-        \"\"\"Returns the pure LightningModule.\n-\n-        To get the potentially wrapped model use :attr:`Accelerator.model`\n-        \"\"\"\n-        return self.training_type_plugin.lightning_module\n-\n-    @property\n-    def root_device(self) -> torch.device:\n-        \"\"\"Returns the root device.\"\"\"\n-        return self.training_type_plugin.root_device\n-\n-    def teardown(self) -> None:\n-        \"\"\"This method is called to teardown the training process.\n-\n-        It is the right place to release memory and free other resources.\n-        \"\"\"\n-        self.training_type_plugin.teardown()\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "\n        self.training_type_plugin.setup(trainer)\n\n    <DED>@property\n    def model(self) -> Module:\n        <IND>\"\"\"Returns the model.\n\n        This can also be a wrapped LightningModule. For retrieving the pure LightningModule use\n        :attr:`Accelerator.lightning_module`\n        \"\"\"\n        return self.training_type_plugin.model\n\n    <DED>@model.setter\n    def model(self, new_model: Module) -> None:\n        <IND>self.training_type_plugin.model = new_model\n\n    <DED>@property\n    def lightning_module(self) -> \"pl.LightningModule\":\n        <IND>\"\"\"Returns the pure LightningModule.\n\n        To get the potentially wrapped model use :attr:`Accelerator.model`\n        \"\"\"\n        return self.training_type_plugin.lightning_module\n\n    <DED>@property\n    def root_device(self) -> torch.device:\n        <IND>\"\"\"Returns the root device.\"\"\"\n        return self.training_type_plugin.root_device\n\n    <DED>def teardown(self) -> None:\n        <IND>\"\"\"This method is called to teardown the training process.\n\n        It is the right place to release memory and free other resources.\n        \"\"\"\n        self.training_type_plugin.teardown()\n\n",
        "target_code_with_indent": "\n\n"
      }
    ]
  }
]