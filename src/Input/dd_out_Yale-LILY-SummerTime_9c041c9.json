[
  {
    "project": "Yale-LILY/SummerTime",
    "commit": "9c041c93d622f4f63d5b87d62e86a2f650c038e8",
    "filename": "pipeline/__init__.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/Yale-LILY-SummerTime/pipeline/__init__.py",
    "file_hunks_size": 6,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "pipeline/__init__.py:17:27 Incompatible parameter type [6]: Expected `typing.Iterator[Variable[_T]]` for 1st positional only parameter to call `next` but got `List[dataset.st_dataset.SummInstance]`.",
    "message": " Expected `typing.Iterator[Variable[_T]]` for 1st positional only parameter to call `next` but got `List[dataset.st_dataset.SummInstance]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 17,
    "warning_line": "        subset.append(next(dataset.train_set))",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from dataset.st_dataset import SummDataset\n\n",
        "source_code_len": 44,
        "target_code": "from dataset.st_dataset import SummDataset\nfrom dataset.non_huggingface_datasets import ScisummnetDataset\n\n",
        "target_code_len": 107,
        "diff_format": "@@ -5,2 +5,3 @@\n from dataset.st_dataset import SummDataset\n+from dataset.non_huggingface_datasets import ScisummnetDataset\n \n",
        "source_code_with_indent": "from dataset.st_dataset import SummDataset\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from dataset.st_dataset import SummDataset\nfrom dataset.non_huggingface_datasets import ScisummnetDataset\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    for i in range(size):\n        subset.append(next(dataset.train_set))\n\n    src = list(map(lambda x: \" \".join(x.source) if dataset.is_dialogue_based or dataset.is_multi_document else x.source, subset))\n\n",
        "source_code_len": 205,
        "target_code": "    for i in range(size):\n        subset.append(next(iter(dataset.train_set)))\n\n    src = list(map(lambda x: \" \".join(x.source) if dataset.is_dialogue_based or dataset.is_multi_document else x.source[0] if isinstance(dataset, ScisummnetDataset) else x.source, subset))\n\n",
        "target_code_len": 270,
        "diff_format": "@@ -16,5 +17,5 @@\n     for i in range(size):\n-        subset.append(next(dataset.train_set))\n+        subset.append(next(iter(dataset.train_set)))\n \n-    src = list(map(lambda x: \" \".join(x.source) if dataset.is_dialogue_based or dataset.is_multi_document else x.source, subset))\n+    src = list(map(lambda x: \" \".join(x.source) if dataset.is_dialogue_based or dataset.is_multi_document else x.source[0] if isinstance(dataset, ScisummnetDataset) else x.source, subset))\n \n",
        "source_code_with_indent": "    for i in range(size):\n        <IND>subset.append(next(dataset.train_set))\n\n    <DED>src = list(map(lambda x: \" \".join(x.source) if dataset.is_dialogue_based or dataset.is_multi_document else x.source, subset))\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    for i in range(size):\n        <IND>subset.append(next(iter(dataset.train_set)))\n\n    <DED>src = list(map(lambda x: \" \".join(x.source) if dataset.is_dialogue_based or dataset.is_multi_document else x.source[0] if isinstance(dataset, ScisummnetDataset) else x.source, subset))\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  }
]