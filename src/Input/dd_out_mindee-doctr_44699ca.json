[
  {
    "project": "mindee/doctr",
    "commit": "44699caa16b7d3796babc929e7c0038ae3cda8e1",
    "filename": "doctr/models/recognition/master.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/mindee-doctr/doctr/models/recognition/master.py",
    "file_hunks_size": 5,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "doctr/models/recognition/master.py:203:61 Incompatible parameter type [6]: Expected `Tuple[int, int, int]` for 2nd parameter `input_shape` to call `MAGCResnet.__init__` but got `typing.Tuple[typing.Any, ...]`.",
    "message": " Expected `Tuple[int, int, int]` for 2nd parameter `input_shape` to call `MAGCResnet.__init__` but got `typing.Tuple[typing.Any, ...]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 203,
    "warning_line": "        self.feature_extractor = MAGCResnet(headers=headers, input_shape=input_shape)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        max_length: int = 50,\n        input_shape: tuple = (48, 160, 3),\n        cfg: Optional[Dict[str, Any]] = None,\n",
        "source_code_len": 119,
        "target_code": "        max_length: int = 50,\n        input_shape: Tuple[int, int, int] = (48, 160, 3),\n        cfg: Optional[Dict[str, Any]] = None,\n",
        "target_code_len": 134,
        "diff_format": "@@ -194,3 +194,3 @@\n         max_length: int = 50,\n-        input_shape: tuple = (48, 160, 3),\n+        input_shape: Tuple[int, int, int] = (48, 160, 3),\n         cfg: Optional[Dict[str, Any]] = None,\n",
        "source_code_with_indent": "        max_length: int = 50,\n        input_shape: tuple = (48, 160, 3),\n        cfg: Optional[Dict[str, Any]] = None,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        max_length: int = 50,\n        input_shape: Tuple[int, int, int] = (48, 160, 3),\n        cfg: Optional[Dict[str, Any]] = None,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "mindee/doctr",
    "commit": "44699caa16b7d3796babc929e7c0038ae3cda8e1",
    "filename": "doctr/models/recognition/master.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/mindee-doctr/doctr/models/recognition/master.py",
    "file_hunks_size": 5,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "doctr/models/recognition/master.py:259:4 Inconsistent override [14]: `doctr.models.recognition.master.MASTER.call` overrides method defined in `RecognitionModel` inconsistently. Could not find parameter `target` in overriding signature.",
    "message": " `doctr.models.recognition.master.MASTER.call` overrides method defined in `RecognitionModel` inconsistently. Could not find parameter `target` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 259,
    "warning_line": "    def call(",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        self,\n        inputs: tf.Tensor,\n        labels: Optional[List[str]] = None,\n        return_model_output: bool = False,\n        return_preds: bool = False,\n        **kwargs\n    ) -> Dict[str, Any]:\n",
        "source_code_len": 206,
        "target_code": "        self,\n        x: tf.Tensor,\n        target: Optional[List[str]] = None,\n        return_model_output: bool = False,\n        return_preds: bool = False,\n        **kwargs: Any,\n    ) -> Dict[str, Any]:\n",
        "target_code_len": 207,
        "diff_format": "@@ -260,7 +260,7 @@\n         self,\n-        inputs: tf.Tensor,\n-        labels: Optional[List[str]] = None,\n+        x: tf.Tensor,\n+        target: Optional[List[str]] = None,\n         return_model_output: bool = False,\n         return_preds: bool = False,\n-        **kwargs\n+        **kwargs: Any,\n     ) -> Dict[str, Any]:\n",
        "source_code_with_indent": "        self,\n        inputs: tf.Tensor,\n        labels: Optional[List[str]] = None,\n        return_model_output: bool = False,\n        return_preds: bool = False,\n        **kwargs\n    ) -> Dict[str, Any]:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        self,\n        x: tf.Tensor,\n        target: Optional[List[str]] = None,\n        return_model_output: bool = False,\n        return_preds: bool = False,\n        **kwargs: Any,\n    ) -> Dict[str, Any]:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        # Encode\n        feature = self.feature_extractor(inputs, **kwargs)\n        b, h, w, c = (tf.shape(feature)[i] for i in range(4))\n",
        "source_code_len": 138,
        "target_code": "        # Encode\n        feature = self.feature_extractor(x, **kwargs)\n        b, h, w, c = (tf.shape(feature)[i] for i in range(4))\n",
        "target_code_len": 133,
        "diff_format": "@@ -279,3 +279,3 @@\n         # Encode\n-        feature = self.feature_extractor(inputs, **kwargs)\n+        feature = self.feature_extractor(x, **kwargs)\n         b, h, w, c = (tf.shape(feature)[i] for i in range(4))\n",
        "source_code_with_indent": "        # Encode\n        feature = self.feature_extractor(inputs, **kwargs)\n        b, h, w, c = (tf.shape(feature)[i] for i in range(4))\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        # Encode\n        feature = self.feature_extractor(x, **kwargs)\n        b, h, w, c = (tf.shape(feature)[i] for i in range(4))\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n        if labels is not None:\n            # Compute target: tensor of gts and sequence lengths\n            gt, seq_len = self.compute_target(labels)\n            tgt_mask = self.make_mask(gt)\n",
        "source_code_len": 193,
        "target_code": "\n        if target is not None:\n            # Compute target: tensor of gts and sequence lengths\n            gt, seq_len = self.compute_target(target)\n            tgt_mask = self.make_mask(gt)\n",
        "target_code_len": 193,
        "diff_format": "@@ -286,5 +286,5 @@\n \n-        if labels is not None:\n+        if target is not None:\n             # Compute target: tensor of gts and sequence lengths\n-            gt, seq_len = self.compute_target(labels)\n+            gt, seq_len = self.compute_target(target)\n             tgt_mask = self.make_mask(gt)\n",
        "source_code_with_indent": "\n        if labels is not None:\n            # Compute target: tensor of gts and sequence lengths\n            <IND>gt, seq_len = self.compute_target(labels)\n            tgt_mask = self.make_mask(gt)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n        if target is not None:\n            # Compute target: tensor of gts and sequence lengths\n            <IND>gt, seq_len = self.compute_target(target)\n            tgt_mask = self.make_mask(gt)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "mindee/doctr",
    "commit": "44699caa16b7d3796babc929e7c0038ae3cda8e1",
    "filename": "doctr/models/recognition/master.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/mindee-doctr/doctr/models/recognition/master.py",
    "file_hunks_size": 5,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "doctr/models/recognition/master.py:259:4 Inconsistent override [14]: `doctr.models.recognition.master.MASTER.call` overrides method defined in `RecognitionModel` inconsistently. Could not find parameter `x` in overriding signature.",
    "message": " `doctr.models.recognition.master.MASTER.call` overrides method defined in `RecognitionModel` inconsistently. Could not find parameter `x` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 259,
    "warning_line": "    def call(",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        self,\n        inputs: tf.Tensor,\n        labels: Optional[List[str]] = None,\n        return_model_output: bool = False,\n        return_preds: bool = False,\n        **kwargs\n    ) -> Dict[str, Any]:\n",
        "source_code_len": 206,
        "target_code": "        self,\n        x: tf.Tensor,\n        target: Optional[List[str]] = None,\n        return_model_output: bool = False,\n        return_preds: bool = False,\n        **kwargs: Any,\n    ) -> Dict[str, Any]:\n",
        "target_code_len": 207,
        "diff_format": "@@ -260,7 +260,7 @@\n         self,\n-        inputs: tf.Tensor,\n-        labels: Optional[List[str]] = None,\n+        x: tf.Tensor,\n+        target: Optional[List[str]] = None,\n         return_model_output: bool = False,\n         return_preds: bool = False,\n-        **kwargs\n+        **kwargs: Any,\n     ) -> Dict[str, Any]:\n",
        "source_code_with_indent": "        self,\n        inputs: tf.Tensor,\n        labels: Optional[List[str]] = None,\n        return_model_output: bool = False,\n        return_preds: bool = False,\n        **kwargs\n    ) -> Dict[str, Any]:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        self,\n        x: tf.Tensor,\n        target: Optional[List[str]] = None,\n        return_model_output: bool = False,\n        return_preds: bool = False,\n        **kwargs: Any,\n    ) -> Dict[str, Any]:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        # Encode\n        feature = self.feature_extractor(inputs, **kwargs)\n        b, h, w, c = (tf.shape(feature)[i] for i in range(4))\n",
        "source_code_len": 138,
        "target_code": "        # Encode\n        feature = self.feature_extractor(x, **kwargs)\n        b, h, w, c = (tf.shape(feature)[i] for i in range(4))\n",
        "target_code_len": 133,
        "diff_format": "@@ -279,3 +279,3 @@\n         # Encode\n-        feature = self.feature_extractor(inputs, **kwargs)\n+        feature = self.feature_extractor(x, **kwargs)\n         b, h, w, c = (tf.shape(feature)[i] for i in range(4))\n",
        "source_code_with_indent": "        # Encode\n        feature = self.feature_extractor(inputs, **kwargs)\n        b, h, w, c = (tf.shape(feature)[i] for i in range(4))\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        # Encode\n        feature = self.feature_extractor(x, **kwargs)\n        b, h, w, c = (tf.shape(feature)[i] for i in range(4))\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n        if labels is not None:\n            # Compute target: tensor of gts and sequence lengths\n            gt, seq_len = self.compute_target(labels)\n            tgt_mask = self.make_mask(gt)\n",
        "source_code_len": 193,
        "target_code": "\n        if target is not None:\n            # Compute target: tensor of gts and sequence lengths\n            gt, seq_len = self.compute_target(target)\n            tgt_mask = self.make_mask(gt)\n",
        "target_code_len": 193,
        "diff_format": "@@ -286,5 +286,5 @@\n \n-        if labels is not None:\n+        if target is not None:\n             # Compute target: tensor of gts and sequence lengths\n-            gt, seq_len = self.compute_target(labels)\n+            gt, seq_len = self.compute_target(target)\n             tgt_mask = self.make_mask(gt)\n",
        "source_code_with_indent": "\n        if labels is not None:\n            # Compute target: tensor of gts and sequence lengths\n            <IND>gt, seq_len = self.compute_target(labels)\n            tgt_mask = self.make_mask(gt)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n        if target is not None:\n            # Compute target: tensor of gts and sequence lengths\n            <IND>gt, seq_len = self.compute_target(target)\n            tgt_mask = self.make_mask(gt)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  }
]