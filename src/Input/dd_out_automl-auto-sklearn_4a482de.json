[
  {
    "project": "automl/auto-sklearn",
    "commit": "4a482de8b30cfff6a79d7749577a707c1467d4f7",
    "filename": "autosklearn/data/feature_validator.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/automl-auto-sklearn/autosklearn/data/feature_validator.py",
    "file_hunks_size": 22,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "autosklearn/data/feature_validator.py:112:19 Incompatible parameter type [6]: Expected `typing.Sized` for 1st positional only parameter to call `len` but got `typing.Optional[typing.List[str]]`.",
    "message": " Expected `typing.Sized` for 1st positional only parameter to call `len` but got `typing.Optional[typing.List[str]]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 112,
    "warning_line": "            if len(self.feat_type) != np.shape(X_train)[1]:",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import pandas as pd\nfrom pandas.api.types import is_numeric_dtype\n\n",
        "source_code_len": 67,
        "target_code": "import pandas as pd\nfrom pandas.api.types import is_numeric_dtype, is_sparse\n\n",
        "target_code_len": 78,
        "diff_format": "@@ -7,3 +6,3 @@\n import pandas as pd\n-from pandas.api.types import is_numeric_dtype\n+from pandas.api.types import is_numeric_dtype, is_sparse\n \n",
        "source_code_with_indent": "import pandas as pd\nfrom pandas.api.types import is_numeric_dtype\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "import pandas as pd\nfrom pandas.api.types import is_numeric_dtype, is_sparse\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        # If a dataframe was provided, we populate\n        # this attribute with the column types from the dataframe\n        # That is, this attribute contains whether autosklearn\n        # should treat a column as categorical or numerical\n        # During fit, if the user provided feat_types, the user\n        # constrain is honored. If not, this attribute is used.\n        self.feat_type = feat_type  # type: typing.Optional[typing.List[str]]\n\n",
        "source_code_len": 447,
        "target_code": "        # If a dataframe was provided, we populate\n        # this attribute with a mapping from column to {numerical | categorical}\n        self.feat_type: typing.Optional[\n            typing.Dict[typing.Union[str, int], str]\n        ] = None\n        if feat_type is not None:\n            if isinstance(feat_type, dict):\n                self.feat_type = feat_type\n            elif not isinstance(feat_type, list):\n                raise ValueError(\"Auto-Sklearn expects a list of categorical/\"\n                                 \"numerical feature types, yet a\"\n                                 \" {} was provided\".format(type(feat_type)))\n            else:\n\n                # Convert to a dictionary which will be passed to the ColumnTransformer\n                # Column Transformer supports strings or integer indexes\n                self.feat_type = {i: feat for i, feat in enumerate(feat_type)}\n\n",
        "target_code_len": 896,
        "diff_format": "@@ -56,8 +56,18 @@\n         # If a dataframe was provided, we populate\n-        # this attribute with the column types from the dataframe\n-        # That is, this attribute contains whether autosklearn\n-        # should treat a column as categorical or numerical\n-        # During fit, if the user provided feat_types, the user\n-        # constrain is honored. If not, this attribute is used.\n-        self.feat_type = feat_type  # type: typing.Optional[typing.List[str]]\n+        # this attribute with a mapping from column to {numerical | categorical}\n+        self.feat_type: typing.Optional[\n+            typing.Dict[typing.Union[str, int], str]\n+        ] = None\n+        if feat_type is not None:\n+            if isinstance(feat_type, dict):\n+                self.feat_type = feat_type\n+            elif not isinstance(feat_type, list):\n+                raise ValueError(\"Auto-Sklearn expects a list of categorical/\"\n+                                 \"numerical feature types, yet a\"\n+                                 \" {} was provided\".format(type(feat_type)))\n+            else:\n+\n+                # Convert to a dictionary which will be passed to the ColumnTransformer\n+                # Column Transformer supports strings or integer indexes\n+                self.feat_type = {i: feat for i, feat in enumerate(feat_type)}\n \n",
        "source_code_with_indent": "        # If a dataframe was provided, we populate\n        # this attribute with the column types from the dataframe\n        # That is, this attribute contains whether autosklearn\n        # should treat a column as categorical or numerical\n        # During fit, if the user provided feat_types, the user\n        # constrain is honored. If not, this attribute is used.\n        <IND>self.feat_type = feat_type  # type: typing.Optional[typing.List[str]]\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        # If a dataframe was provided, we populate\n        # this attribute with a mapping from column to {numerical | categorical}\n        <IND>self.feat_type: typing.Optional[\n            typing.Dict[typing.Union[str, int], str]\n        ] = None\n        if feat_type is not None:\n            <IND>if isinstance(feat_type, dict):\n                <IND>self.feat_type = feat_type\n            <DED>elif not isinstance(feat_type, list):\n                <IND>raise ValueError(\"Auto-Sklearn expects a list of categorical/\"\n                                 \"numerical feature types, yet a\"\n                                 \" {} was provided\".format(type(feat_type)))\n            <DED>else:\n\n                # Convert to a dictionary which will be passed to the ColumnTransformer\n                # Column Transformer supports strings or integer indexes\n                <IND>self.feat_type = {i: feat for i, feat in enumerate(feat_type)}\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        self.data_type = None  # type: typing.Optional[type]\n        self.dtypes = []  # type: typing.List[str]\n        self.column_order = []  # type: typing.List[str]\n\n        self.encoder = None  # type: typing.Optional[BaseEstimator]\n        self.enc_columns = []  # type: typing.List[str]\n\n",
        "source_code_len": 295,
        "target_code": "        self.data_type = None  # type: typing.Optional[type]\n        self.dtypes = {}  # type: typing.Dict[str, str]\n\n",
        "target_code_len": 118,
        "diff_format": "@@ -65,7 +75,3 @@\n         self.data_type = None  # type: typing.Optional[type]\n-        self.dtypes = []  # type: typing.List[str]\n-        self.column_order = []  # type: typing.List[str]\n-\n-        self.encoder = None  # type: typing.Optional[BaseEstimator]\n-        self.enc_columns = []  # type: typing.List[str]\n+        self.dtypes = {}  # type: typing.Dict[str, str]\n \n",
        "source_code_with_indent": "        self.data_type = None  # type: typing.Optional[type]\n        self.dtypes = []  # type: typing.List[str]\n        self.column_order = []  # type: typing.List[str]\n\n        self.encoder = None  # type: typing.Optional[BaseEstimator]\n        self.enc_columns = []  # type: typing.List[str]\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        <DED><DED>self.data_type = None  # type: typing.Optional[type]\n        self.dtypes = {}  # type: typing.Dict[str, str]\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "                                 \"/api/pandas.DataFrame.astype.html\")\n            # Some checks if self.feat_type is provided\n            if len(self.feat_type) != np.shape(X_train)[1]:\n                raise ValueError('Array feat_type does not have same number of '\n                                 'variables as X has features. %d vs %d.' %\n                                 (len(self.feat_type), np.shape(X_train)[1]))\n            if not all([isinstance(f, str) for f in self.feat_type]):\n                raise ValueError('Array feat_type must only contain strings.')\n\n            for ft in self.feat_type:\n                if ft.lower() not in ['categorical', 'numerical']:\n                    raise ValueError('Only `Categorical` and `Numerical` are '\n                                     'valid feature types, you passed `%s`' % ft)\n\n        self._check_data(X_train)\n\n",
        "source_code_len": 873,
        "target_code": "                                 \"/api/pandas.DataFrame.astype.html\")\n            else:\n                self.feat_type = self.get_feat_type_from_columns(X_train)\n        else:\n            # Numpy array was provided\n            if self.feat_type is None:\n                # Assume numerical columns if a numpy array has no feature types\n                self.feat_type = {i: 'numerical' for i in range(np.shape(X_train)[1])}\n            else:\n                # Check The feat type provided\n                if len(self.feat_type) != np.shape(X_train)[1]:\n                    raise ValueError('Array feat_type does not have same number of '\n                                     'variables as X has features. %d vs %d.' %\n                                     (len(self.feat_type), np.shape(X_train)[1]))\n                if not all([isinstance(f, str) for f in self.feat_type.values()]):\n                    raise ValueError(\"feat_type must only contain strings: {}\".format(\n                        list(self.feat_type.values()),\n                    ))\n\n                for ft in self.feat_type.values():\n                    if ft.lower() not in ['categorical', 'numerical']:\n                        raise ValueError('Only `Categorical` and `Numerical` are '\n                                         'valid feature types, you passed `%s`' % ft)\n\n",
        "target_code_len": 1339,
        "diff_format": "@@ -110,16 +118,24 @@\n                                  \"/api/pandas.DataFrame.astype.html\")\n-            # Some checks if self.feat_type is provided\n-            if len(self.feat_type) != np.shape(X_train)[1]:\n-                raise ValueError('Array feat_type does not have same number of '\n-                                 'variables as X has features. %d vs %d.' %\n-                                 (len(self.feat_type), np.shape(X_train)[1]))\n-            if not all([isinstance(f, str) for f in self.feat_type]):\n-                raise ValueError('Array feat_type must only contain strings.')\n-\n-            for ft in self.feat_type:\n-                if ft.lower() not in ['categorical', 'numerical']:\n-                    raise ValueError('Only `Categorical` and `Numerical` are '\n-                                     'valid feature types, you passed `%s`' % ft)\n-\n-        self._check_data(X_train)\n+            else:\n+                self.feat_type = self.get_feat_type_from_columns(X_train)\n+        else:\n+            # Numpy array was provided\n+            if self.feat_type is None:\n+                # Assume numerical columns if a numpy array has no feature types\n+                self.feat_type = {i: 'numerical' for i in range(np.shape(X_train)[1])}\n+            else:\n+                # Check The feat type provided\n+                if len(self.feat_type) != np.shape(X_train)[1]:\n+                    raise ValueError('Array feat_type does not have same number of '\n+                                     'variables as X has features. %d vs %d.' %\n+                                     (len(self.feat_type), np.shape(X_train)[1]))\n+                if not all([isinstance(f, str) for f in self.feat_type.values()]):\n+                    raise ValueError(\"feat_type must only contain strings: {}\".format(\n+                        list(self.feat_type.values()),\n+                    ))\n+\n+                for ft in self.feat_type.values():\n+                    if ft.lower() not in ['categorical', 'numerical']:\n+                        raise ValueError('Only `Categorical` and `Numerical` are '\n+                                         'valid feature types, you passed `%s`' % ft)\n \n",
        "source_code_with_indent": "                                 \"/api/pandas.DataFrame.astype.html\")\n            # Some checks if self.feat_type is provided\n            <DED>if len(self.feat_type) != np.shape(X_train)[1]:\n                <IND>raise ValueError('Array feat_type does not have same number of '\n                                 'variables as X has features. %d vs %d.' %\n                                 (len(self.feat_type), np.shape(X_train)[1]))\n            <DED>if not all([isinstance(f, str) for f in self.feat_type]):\n                <IND>raise ValueError('Array feat_type must only contain strings.')\n\n            <DED>for ft in self.feat_type:\n                <IND>if ft.lower() not in ['categorical', 'numerical']:\n                    <IND>raise ValueError('Only `Categorical` and `Numerical` are '\n                                     'valid feature types, you passed `%s`' % ft)\n\n        <DED><DED><DED>self._check_data(X_train)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "                                 \"/api/pandas.DataFrame.astype.html\")\n            <DED>else:\n                <IND>self.feat_type = self.get_feat_type_from_columns(X_train)\n        <DED><DED>else:\n            # Numpy array was provided\n            <IND>if self.feat_type is None:\n                # Assume numerical columns if a numpy array has no feature types\n                <IND>self.feat_type = {i: 'numerical' for i in range(np.shape(X_train)[1])}\n            <DED>else:\n                # Check The feat type provided\n                <IND>if len(self.feat_type) != np.shape(X_train)[1]:\n                    <IND>raise ValueError('Array feat_type does not have same number of '\n                                     'variables as X has features. %d vs %d.' %\n                                     (len(self.feat_type), np.shape(X_train)[1]))\n                <DED>if not all([isinstance(f, str) for f in self.feat_type.values()]):\n                    <IND>raise ValueError(\"feat_type must only contain strings: {}\".format(\n                        list(self.feat_type.values()),\n                    ))\n\n                <DED>for ft in self.feat_type.values():\n                    <IND>if ft.lower() not in ['categorical', 'numerical']:\n                        <IND>raise ValueError('Only `Categorical` and `Numerical` are '\n                                         'valid feature types, you passed `%s`' % ft)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "\n        # Fit on the training data\n        self._fit(X_train)\n\n        self._is_fitted = True\n",
        "source_code_len": 95,
        "target_code": "\n        self._is_fitted = True\n",
        "target_code_len": 32,
        "diff_format": "@@ -135,5 +151,2 @@\n \n-        # Fit on the training data\n-        self._fit(X_train)\n-\n         self._is_fitted = True\n",
        "source_code_with_indent": "\n        # Fit on the training data\n        <DED><DED>self._fit(X_train)\n\n        self._is_fitted = True\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n        <DED><DED>self._is_fitted = True\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    def _fit(\n        self,\n        X: SUPPORTED_FEAT_TYPES,\n    ) -> BaseEstimator:\n        \"\"\"\n        In case input data is a pandas DataFrame, this utility encodes the user provided\n        features (from categorical for example) to a numerical value that further stages\n        will be able to use\n\n",
        "source_code_len": 305,
        "target_code": "\n    def transform(\n        self,\n        X: SUPPORTED_FEAT_TYPES,\n    ) -> np.ndarray:\n        \"\"\"\n        Validates and fit a categorical encoder (if needed) to the features.\n        The supported data types are List, numpy arrays and pandas DataFrames.\n\n        Parameters\n        ----------\n            X_train: SUPPORTED_FEAT_TYPES\n                A set of features, whose categorical features are going to be\n                transformed\n\n        Return\n        ------\n            np.ndarray:\n                The transformed array\n        \"\"\"\n        if not self._is_fitted:\n            raise NotFittedError(\"Cannot call transform on a validator that is not fitted\")\n\n        # If a list was provided, it will be converted to pandas\n        if isinstance(X, list):\n            X, _ = self.list_to_dataframe(X)\n\n        # Check the data here so we catch problems on new test data\n        self._check_data(X)\n\n        # Sparse related transformations\n        # Not all sparse format support index sorting\n        if scipy.sparse.issparse(X):\n            if not isinstance(X, scipy.sparse.csr_matrix):\n                self.logger.warning(f\"Sparse data provided is of type {type(X)} \"\n                                    \"yet Auto-Sklearn only support csr_matrix. Auto-sklearn \"\n                                    \"will convert the provided data to the csr_matrix format.\")\n                X = X.tocsr(copy=False)\n            if hasattr(X, 'sort_indices'):\n                X.sort_indices()\n        return X\n\n    def _check_data(\n        self,\n        X: SUPPORTED_FEAT_TYPES,\n    ) -> None:\n        \"\"\"\n        Feature dimensionality and data type checks\n\n",
        "target_code_len": 1658,
        "diff_format": "@@ -142,10 +155,49 @@\n \n-    def _fit(\n+    def transform(\n         self,\n         X: SUPPORTED_FEAT_TYPES,\n-    ) -> BaseEstimator:\n-        \"\"\"\n-        In case input data is a pandas DataFrame, this utility encodes the user provided\n-        features (from categorical for example) to a numerical value that further stages\n-        will be able to use\n+    ) -> np.ndarray:\n+        \"\"\"\n+        Validates and fit a categorical encoder (if needed) to the features.\n+        The supported data types are List, numpy arrays and pandas DataFrames.\n+\n+        Parameters\n+        ----------\n+            X_train: SUPPORTED_FEAT_TYPES\n+                A set of features, whose categorical features are going to be\n+                transformed\n+\n+        Return\n+        ------\n+            np.ndarray:\n+                The transformed array\n+        \"\"\"\n+        if not self._is_fitted:\n+            raise NotFittedError(\"Cannot call transform on a validator that is not fitted\")\n+\n+        # If a list was provided, it will be converted to pandas\n+        if isinstance(X, list):\n+            X, _ = self.list_to_dataframe(X)\n+\n+        # Check the data here so we catch problems on new test data\n+        self._check_data(X)\n+\n+        # Sparse related transformations\n+        # Not all sparse format support index sorting\n+        if scipy.sparse.issparse(X):\n+            if not isinstance(X, scipy.sparse.csr_matrix):\n+                self.logger.warning(f\"Sparse data provided is of type {type(X)} \"\n+                                    \"yet Auto-Sklearn only support csr_matrix. Auto-sklearn \"\n+                                    \"will convert the provided data to the csr_matrix format.\")\n+                X = X.tocsr(copy=False)\n+            if hasattr(X, 'sort_indices'):\n+                X.sort_indices()\n+        return X\n+\n+    def _check_data(\n+        self,\n+        X: SUPPORTED_FEAT_TYPES,\n+    ) -> None:\n+        \"\"\"\n+        Feature dimensionality and data type checks\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "\n    <DED>def _fit(\n        self,\n        X: SUPPORTED_FEAT_TYPES,\n    ) -> BaseEstimator:\n        <IND>",
        "target_code_with_indent": "\n    <DED>def transform(\n        self,\n        X: SUPPORTED_FEAT_TYPES,\n    ) -> np.ndarray:\n        <IND>\"\"\"\n        Validates and fit a categorical encoder (if needed) to the features.\n        The supported data types are List, numpy arrays and pandas DataFrames.\n\n        Parameters\n        ----------\n            X_train: SUPPORTED_FEAT_TYPES\n                A set of features, whose categorical features are going to be\n                transformed\n\n        Return\n        ------\n            np.ndarray:\n                The transformed array\n        \"\"\"\n        if not self._is_fitted:\n            <IND>raise NotFittedError(\"Cannot call transform on a validator that is not fitted\")\n\n        # If a list was provided, it will be converted to pandas\n        <DED>if isinstance(X, list):\n            <IND>X, _ = self.list_to_dataframe(X)\n\n        # Check the data here so we catch problems on new test data\n        <DED>self._check_data(X)\n\n        # Sparse related transformations\n        # Not all sparse format support index sorting\n        if scipy.sparse.issparse(X):\n            <IND>if not isinstance(X, scipy.sparse.csr_matrix):\n                <IND>self.logger.warning(f\"Sparse data provided is of type {type(X)} \"\n                                    \"yet Auto-Sklearn only support csr_matrix. Auto-sklearn \"\n                                    \"will convert the provided data to the csr_matrix format.\")\n                X = X.tocsr(copy=False)\n            <DED>if hasattr(X, 'sort_indices'):\n                <IND>X.sort_indices()\n        <DED><DED>return X\n\n    <DED>def _check_data(\n        self,\n        X: SUPPORTED_FEAT_TYPES,\n    ) -> None:\n        <IND>"
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        \"\"\"\n        if hasattr(X, \"iloc\") and not scipy.sparse.issparse(X):\n            X = typing.cast(pd.DataFrame, X)\n            # Treat a column with all instances a NaN as numerical\n            # This will prevent doing encoding to a categorical column made completely\n            # out of nan values -- which will trigger a fail, as encoding is not supported\n            # with nan values.\n            # Columns that are completely made of NaN values are provided to the pipeline\n            # so that later stages decide how to handle them\n            if np.any(pd.isnull(X)):\n                for column in X.columns:\n                    if X[column].isna().all():\n                        X[column] = pd.to_numeric(X[column])\n\n            self.enc_columns, self.feat_type = self._get_columns_to_encode(X)\n\n            if len(self.enc_columns) > 0:\n\n                self.encoder = make_column_transformer(\n                    (preprocessing.OrdinalEncoder(\n                        handle_unknown='use_encoded_value',\n                        unknown_value=-1,\n                    ), self.enc_columns),\n                    remainder=\"passthrough\"\n                )\n\n                # Mypy redefinition\n                assert self.encoder is not None\n                self.encoder.fit(X)\n\n                # The column transformer reoders the feature types - we therefore need to change\n                # it as well\n                def comparator(cmp1: str, cmp2: str) -> int:\n                    if (\n                        cmp1 == 'categorical' and cmp2 == 'categorical'\n                        or cmp1 == 'numerical' and cmp2 == 'numerical'\n                    ):\n                        return 0\n                    elif cmp1 == 'categorical' and cmp2 == 'numerical':\n                        return -1\n                    elif cmp1 == 'numerical' and cmp2 == 'categorical':\n                        return 1\n                    else:\n                        raise ValueError((cmp1, cmp2))\n                self.feat_type = sorted(\n                    self.feat_type,\n                    key=functools.cmp_to_key(comparator)\n                )\n        return self\n\n    def transform(\n        self,\n        X: SUPPORTED_FEAT_TYPES,\n    ) -> np.ndarray:\n        \"\"\"\n        Validates and fit a categorical encoder (if needed) to the features.\n        The supported data types are List, numpy arrays and pandas DataFrames.\n\n        Parameters\n        ----------\n            X_train: SUPPORTED_FEAT_TYPES\n                A set of features, whose categorical features are going to be\n                transformed\n\n        Return\n        ------\n            np.ndarray:\n                The transformed array\n        \"\"\"\n        if not self._is_fitted:\n            raise NotFittedError(\"Cannot call transform on a validator that is not fitted\")\n\n        # If a list was provided, it will be converted to pandas\n        if isinstance(X, list):\n            X, _ = self.list_to_dataframe(X)\n\n        if hasattr(X, \"iloc\") and not scipy.sparse.issparse(X):\n            X = typing.cast(pd.DataFrame, X)\n            if np.any(pd.isnull(X)):\n                for column in X.columns:\n                    if X[column].isna().all():\n                        X[column] = pd.to_numeric(X[column])\n\n        # Check the data here so we catch problems on new test data\n        self._check_data(X)\n\n        # Pandas related transformations\n        if hasattr(X, \"iloc\") and self.encoder is not None:\n            if np.any(pd.isnull(X)):\n                # After above check it means that if there is a NaN\n                # the whole column must be NaN\n                # Make sure it is numerical and let the pipeline handle it\n                for column in X.columns:\n                    if X[column].isna().all():\n                        X[column] = pd.to_numeric(X[column])\n            X = self.encoder.transform(X)\n\n        # Sparse related transformations\n        # Not all sparse format support index sorting\n        if scipy.sparse.issparse(X) and hasattr(X, 'sort_indices'):\n            X.sort_indices()\n\n        return sklearn.utils.check_array(\n            X,\n            force_all_finite=False,\n            accept_sparse='csr'\n        )\n\n    def _check_data(\n        self,\n        X: SUPPORTED_FEAT_TYPES,\n    ) -> None:\n        \"\"\"\n        Feature dimensionality and data type checks\n\n        Parameters\n        ----------\n            X: SUPPORTED_FEAT_TYPES\n                A set of features that are going to be validated (type and dimensionality\n                checks) and a encoder fitted in the case the data needs encoding\n        \"\"\"\n\n",
        "source_code_len": 4631,
        "target_code": "        \"\"\"\n\n        # We consider columns that are all nan in a pandas frame as category\n        if hasattr(X, 'columns'):\n            for column in typing.cast(pd.DataFrame, X).columns:\n                if X[column].isna().all():\n                    X[column] = X[column].astype('category')\n\n",
        "target_code_len": 293,
        "diff_format": "@@ -157,122 +209,8 @@\n         \"\"\"\n-        if hasattr(X, \"iloc\") and not scipy.sparse.issparse(X):\n-            X = typing.cast(pd.DataFrame, X)\n-            # Treat a column with all instances a NaN as numerical\n-            # This will prevent doing encoding to a categorical column made completely\n-            # out of nan values -- which will trigger a fail, as encoding is not supported\n-            # with nan values.\n-            # Columns that are completely made of NaN values are provided to the pipeline\n-            # so that later stages decide how to handle them\n-            if np.any(pd.isnull(X)):\n-                for column in X.columns:\n-                    if X[column].isna().all():\n-                        X[column] = pd.to_numeric(X[column])\n-\n-            self.enc_columns, self.feat_type = self._get_columns_to_encode(X)\n-\n-            if len(self.enc_columns) > 0:\n-\n-                self.encoder = make_column_transformer(\n-                    (preprocessing.OrdinalEncoder(\n-                        handle_unknown='use_encoded_value',\n-                        unknown_value=-1,\n-                    ), self.enc_columns),\n-                    remainder=\"passthrough\"\n-                )\n-\n-                # Mypy redefinition\n-                assert self.encoder is not None\n-                self.encoder.fit(X)\n-\n-                # The column transformer reoders the feature types - we therefore need to change\n-                # it as well\n-                def comparator(cmp1: str, cmp2: str) -> int:\n-                    if (\n-                        cmp1 == 'categorical' and cmp2 == 'categorical'\n-                        or cmp1 == 'numerical' and cmp2 == 'numerical'\n-                    ):\n-                        return 0\n-                    elif cmp1 == 'categorical' and cmp2 == 'numerical':\n-                        return -1\n-                    elif cmp1 == 'numerical' and cmp2 == 'categorical':\n-                        return 1\n-                    else:\n-                        raise ValueError((cmp1, cmp2))\n-                self.feat_type = sorted(\n-                    self.feat_type,\n-                    key=functools.cmp_to_key(comparator)\n-                )\n-        return self\n-\n-    def transform(\n-        self,\n-        X: SUPPORTED_FEAT_TYPES,\n-    ) -> np.ndarray:\n-        \"\"\"\n-        Validates and fit a categorical encoder (if needed) to the features.\n-        The supported data types are List, numpy arrays and pandas DataFrames.\n-\n-        Parameters\n-        ----------\n-            X_train: SUPPORTED_FEAT_TYPES\n-                A set of features, whose categorical features are going to be\n-                transformed\n-\n-        Return\n-        ------\n-            np.ndarray:\n-                The transformed array\n-        \"\"\"\n-        if not self._is_fitted:\n-            raise NotFittedError(\"Cannot call transform on a validator that is not fitted\")\n-\n-        # If a list was provided, it will be converted to pandas\n-        if isinstance(X, list):\n-            X, _ = self.list_to_dataframe(X)\n-\n-        if hasattr(X, \"iloc\") and not scipy.sparse.issparse(X):\n-            X = typing.cast(pd.DataFrame, X)\n-            if np.any(pd.isnull(X)):\n-                for column in X.columns:\n-                    if X[column].isna().all():\n-                        X[column] = pd.to_numeric(X[column])\n-\n-        # Check the data here so we catch problems on new test data\n-        self._check_data(X)\n-\n-        # Pandas related transformations\n-        if hasattr(X, \"iloc\") and self.encoder is not None:\n-            if np.any(pd.isnull(X)):\n-                # After above check it means that if there is a NaN\n-                # the whole column must be NaN\n-                # Make sure it is numerical and let the pipeline handle it\n-                for column in X.columns:\n-                    if X[column].isna().all():\n-                        X[column] = pd.to_numeric(X[column])\n-            X = self.encoder.transform(X)\n-\n-        # Sparse related transformations\n-        # Not all sparse format support index sorting\n-        if scipy.sparse.issparse(X) and hasattr(X, 'sort_indices'):\n-            X.sort_indices()\n-\n-        return sklearn.utils.check_array(\n-            X,\n-            force_all_finite=False,\n-            accept_sparse='csr'\n-        )\n-\n-    def _check_data(\n-        self,\n-        X: SUPPORTED_FEAT_TYPES,\n-    ) -> None:\n-        \"\"\"\n-        Feature dimensionality and data type checks\n-\n-        Parameters\n-        ----------\n-            X: SUPPORTED_FEAT_TYPES\n-                A set of features that are going to be validated (type and dimensionality\n-                checks) and a encoder fitted in the case the data needs encoding\n-        \"\"\"\n+\n+        # We consider columns that are all nan in a pandas frame as category\n+        if hasattr(X, 'columns'):\n+            for column in typing.cast(pd.DataFrame, X).columns:\n+                if X[column].isna().all():\n+                    X[column] = X[column].astype('category')\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "\n        if hasattr(X, \"iloc\") and not scipy.sparse.issparse(X):\n            <IND>X = typing.cast(pd.DataFrame, X)\n            # Treat a column with all instances a NaN as numerical\n            # This will prevent doing encoding to a categorical column made completely\n            # out of nan values -- which will trigger a fail, as encoding is not supported\n            # with nan values.\n            # Columns that are completely made of NaN values are provided to the pipeline\n            # so that later stages decide how to handle them\n            if np.any(pd.isnull(X)):\n                <IND>for column in X.columns:\n                    <IND>if X[column].isna().all():\n                        <IND>X[column] = pd.to_numeric(X[column])\n\n            <DED><DED><DED>self.enc_columns, self.feat_type = self._get_columns_to_encode(X)\n\n            if len(self.enc_columns) > 0:\n\n                <IND>self.encoder = make_column_transformer(\n                    (preprocessing.OrdinalEncoder(\n                        handle_unknown='use_encoded_value',\n                        unknown_value=-1,\n                    ), self.enc_columns),\n                    remainder=\"passthrough\"\n                )\n\n                # Mypy redefinition\n                assert self.encoder is not None\n                self.encoder.fit(X)\n\n                # The column transformer reoders the feature types - we therefore need to change\n                # it as well\n                def comparator(cmp1: str, cmp2: str) -> int:\n                    <IND>if (\n                        cmp1 == 'categorical' and cmp2 == 'categorical'\n                        or cmp1 == 'numerical' and cmp2 == 'numerical'\n                    ):\n                        <IND>return 0\n                    <DED>elif cmp1 == 'categorical' and cmp2 == 'numerical':\n                        <IND>return -1\n                    <DED>elif cmp1 == 'numerical' and cmp2 == 'categorical':\n                        <IND>return 1\n                    <DED>else:\n                        <IND>raise ValueError((cmp1, cmp2))\n                <DED><DED>self.feat_type = sorted(\n                    self.feat_type,\n                    key=functools.cmp_to_key(comparator)\n                )\n        <DED><DED>return self\n\n    <DED>def transform(\n        self,\n        X: SUPPORTED_FEAT_TYPES,\n    ) -> np.ndarray:\n        <IND>\"\"\"\n        Validates and fit a categorical encoder (if needed) to the features.\n        The supported data types are List, numpy arrays and pandas DataFrames.\n\n        Parameters\n        ----------\n            X_train: SUPPORTED_FEAT_TYPES\n                A set of features, whose categorical features are going to be\n                transformed\n\n        Return\n        ------\n            np.ndarray:\n                The transformed array\n        \"\"\"\n        if not self._is_fitted:\n            <IND>raise NotFittedError(\"Cannot call transform on a validator that is not fitted\")\n\n        # If a list was provided, it will be converted to pandas\n        <DED>if isinstance(X, list):\n            <IND>X, _ = self.list_to_dataframe(X)\n\n        <DED>if hasattr(X, \"iloc\") and not scipy.sparse.issparse(X):\n            <IND>X = typing.cast(pd.DataFrame, X)\n            if np.any(pd.isnull(X)):\n                <IND>for column in X.columns:\n                    <IND>if X[column].isna().all():\n                        <IND>X[column] = pd.to_numeric(X[column])\n\n        # Check the data here so we catch problems on new test data\n        <DED><DED><DED><DED>self._check_data(X)\n\n        # Pandas related transformations\n        if hasattr(X, \"iloc\") and self.encoder is not None:\n            <IND>if np.any(pd.isnull(X)):\n                # After above check it means that if there is a NaN\n                # the whole column must be NaN\n                # Make sure it is numerical and let the pipeline handle it\n                <IND>for column in X.columns:\n                    <IND>if X[column].isna().all():\n                        <IND>X[column] = pd.to_numeric(X[column])\n            <DED><DED><DED>X = self.encoder.transform(X)\n\n        # Sparse related transformations\n        # Not all sparse format support index sorting\n        <DED>if scipy.sparse.issparse(X) and hasattr(X, 'sort_indices'):\n            <IND>X.sort_indices()\n\n        <DED>return sklearn.utils.check_array(\n            X,\n            force_all_finite=False,\n            accept_sparse='csr'\n        )\n\n    <DED>def _check_data(\n        self,\n        X: SUPPORTED_FEAT_TYPES,\n    ) -> None:\n        <IND>\"\"\"\n        Feature dimensionality and data type checks\n\n        Parameters\n        ----------\n            X: SUPPORTED_FEAT_TYPES\n                A set of features that are going to be validated (type and dimensionality\n                checks) and a encoder fitted in the case the data needs encoding\n        \"\"\"\n\n",
        "target_code_with_indent": "\n\n        # We consider columns that are all nan in a pandas frame as category\n        if hasattr(X, 'columns'):\n            <IND>for column in typing.cast(pd.DataFrame, X).columns:\n                <IND>if X[column].isna().all():\n                    <IND>X[column] = X[column].astype('category')\n\n"
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n            # Define the column to be encoded here as the feature validator is fitted once\n            # per estimator\n            enc_columns, _ = self._get_columns_to_encode(X)\n\n            if len(enc_columns) > 0:\n                if np.any(pd.isnull(\n                    X[enc_columns].dropna(  # type: ignore[call-overload]\n                        axis='columns', how='all')\n                )):\n                    # Ignore all NaN columns, and if still a NaN\n                    # Error out\n                    raise ValueError(\"Categorical features in a dataframe cannot contain \"\n                                     \"missing/NaN values. The OrdinalEncoder used by \"\n                                     \"Auto-sklearn cannot handle this yet (due to a \"\n                                     \"limitation on scikit-learn being addressed via: \"\n                                     \"https://github.com/scikit-learn/scikit-learn/issues/17123)\"\n                                     )\n            column_order = [column for column in X.columns]\n            if len(self.column_order) > 0:\n                if self.column_order != column_order:\n                    raise ValueError(\"Changing the column order of the features after fit() is \"\n                                     \"not supported. Fit() method was called with \"\n                                     \"{} whereas the new features have {} as type\".format(\n                                        self.column_order,\n                                        column_order,\n                                     ))\n            else:\n                self.column_order = column_order\n            dtypes = [dtype.name for dtype in X.dtypes]\n            if len(self.dtypes) > 0:\n                if self.dtypes != dtypes:\n                    raise ValueError(\"Changing the dtype of the features after fit() is \"\n                                     \"not supported. Fit() method was called with \"\n                                     \"{} whereas the new features have {} as type\".format(\n                                        self.dtypes,\n                                        dtypes,\n                                     ))\n            else:\n",
        "source_code_len": 2194,
        "target_code": "\n            dtypes = {col: X[col].dtype.name.lower() for col in X.columns}\n            if len(self.dtypes) > 0:\n                if self.dtypes != dtypes:\n                    # To support list, we need to support object inference.\n                    # In extreme cases, the train column might be all integer,\n                    # and the test column might be float.\n                    self.logger.warning(\"Changing the dtype of the features after fit() is \"\n                                        \"not recommended. Fit() method was called with \"\n                                        \"{} whereas the new features have {} as type\".format(\n                                            self.dtypes,\n                                            dtypes,\n                                        ))\n            else:\n",
        "target_code_len": 814,
        "diff_format": "@@ -312,39 +251,14 @@\n \n-            # Define the column to be encoded here as the feature validator is fitted once\n-            # per estimator\n-            enc_columns, _ = self._get_columns_to_encode(X)\n-\n-            if len(enc_columns) > 0:\n-                if np.any(pd.isnull(\n-                    X[enc_columns].dropna(  # type: ignore[call-overload]\n-                        axis='columns', how='all')\n-                )):\n-                    # Ignore all NaN columns, and if still a NaN\n-                    # Error out\n-                    raise ValueError(\"Categorical features in a dataframe cannot contain \"\n-                                     \"missing/NaN values. The OrdinalEncoder used by \"\n-                                     \"Auto-sklearn cannot handle this yet (due to a \"\n-                                     \"limitation on scikit-learn being addressed via: \"\n-                                     \"https://github.com/scikit-learn/scikit-learn/issues/17123)\"\n-                                     )\n-            column_order = [column for column in X.columns]\n-            if len(self.column_order) > 0:\n-                if self.column_order != column_order:\n-                    raise ValueError(\"Changing the column order of the features after fit() is \"\n-                                     \"not supported. Fit() method was called with \"\n-                                     \"{} whereas the new features have {} as type\".format(\n-                                        self.column_order,\n-                                        column_order,\n-                                     ))\n-            else:\n-                self.column_order = column_order\n-            dtypes = [dtype.name for dtype in X.dtypes]\n+            dtypes = {col: X[col].dtype.name.lower() for col in X.columns}\n             if len(self.dtypes) > 0:\n                 if self.dtypes != dtypes:\n-                    raise ValueError(\"Changing the dtype of the features after fit() is \"\n-                                     \"not supported. Fit() method was called with \"\n-                                     \"{} whereas the new features have {} as type\".format(\n-                                        self.dtypes,\n-                                        dtypes,\n-                                     ))\n+                    # To support list, we need to support object inference.\n+                    # In extreme cases, the train column might be all integer,\n+                    # and the test column might be float.\n+                    self.logger.warning(\"Changing the dtype of the features after fit() is \"\n+                                        \"not recommended. Fit() method was called with \"\n+                                        \"{} whereas the new features have {} as type\".format(\n+                                            self.dtypes,\n+                                            dtypes,\n+                                        ))\n             else:\n",
        "source_code_with_indent": "\n            # Define the column to be encoded here as the feature validator is fitted once\n            # per estimator\n            enc_columns, _ = self._get_columns_to_encode(X)\n\n            if len(enc_columns) > 0:\n                <IND>if np.any(pd.isnull(\n                    X[enc_columns].dropna(  # type: ignore[call-overload]\n                        axis='columns', how='all')\n                )):\n                    # Ignore all NaN columns, and if still a NaN\n                    # Error out\n                    <IND>raise ValueError(\"Categorical features in a dataframe cannot contain \"\n                                     \"missing/NaN values. The OrdinalEncoder used by \"\n                                     \"Auto-sklearn cannot handle this yet (due to a \"\n                                     \"limitation on scikit-learn being addressed via: \"\n                                     \"https://github.com/scikit-learn/scikit-learn/issues/17123)\"\n                                     )\n            <DED><DED>column_order = [column for column in X.columns]\n            if len(self.column_order) > 0:\n                <IND>if self.column_order != column_order:\n                    <IND>raise ValueError(\"Changing the column order of the features after fit() is \"\n                                     \"not supported. Fit() method was called with \"\n                                     \"{} whereas the new features have {} as type\".format(\n                                        self.column_order,\n                                        column_order,\n                                     ))\n            <DED><DED>else:\n                <IND>self.column_order = column_order\n            <DED>dtypes = [dtype.name for dtype in X.dtypes]\n            if len(self.dtypes) > 0:\n                <IND>if self.dtypes != dtypes:\n                    <IND>raise ValueError(\"Changing the dtype of the features after fit() is \"\n                                     \"not supported. Fit() method was called with \"\n                                     \"{} whereas the new features have {} as type\".format(\n                                        self.dtypes,\n                                        dtypes,\n                                     ))\n            <DED><DED>else:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n            dtypes = {col: X[col].dtype.name.lower() for col in X.columns}\n            if len(self.dtypes) > 0:\n                <IND>if self.dtypes != dtypes:\n                    # To support list, we need to support object inference.\n                    # In extreme cases, the train column might be all integer,\n                    # and the test column might be float.\n                    <IND>self.logger.warning(\"Changing the dtype of the features after fit() is \"\n                                        \"not recommended. Fit() method was called with \"\n                                        \"{} whereas the new features have {} as type\".format(\n                                            self.dtypes,\n                                            dtypes,\n                                        ))\n            <DED><DED>else:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    def _get_columns_to_encode(\n        self,\n        X: pd.DataFrame,\n    ) -> typing.Tuple[typing.List[str], typing.List[str]]:\n        \"\"\"\n        Return the columns to be encoded from a pandas dataframe\n\n",
        "source_code_len": 209,
        "target_code": "\n    def get_feat_type_from_columns(\n        self,\n        X: pd.DataFrame,\n    ) -> typing.Dict[typing.Union[str, int], str]:\n        \"\"\"\n        Returns a dictionary that maps pandas dataframe columns to a feature type.\n        This feature type can be categorical or numerical\n\n",
        "target_code_len": 281,
        "diff_format": "@@ -352,8 +266,9 @@\n \n-    def _get_columns_to_encode(\n+    def get_feat_type_from_columns(\n         self,\n         X: pd.DataFrame,\n-    ) -> typing.Tuple[typing.List[str], typing.List[str]]:\n-        \"\"\"\n-        Return the columns to be encoded from a pandas dataframe\n+    ) -> typing.Dict[typing.Union[str, int], str]:\n+        \"\"\"\n+        Returns a dictionary that maps pandas dataframe columns to a feature type.\n+        This feature type can be categorical or numerical\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "\n    <DED><DED><DED>def _get_columns_to_encode(\n        self,\n        X: pd.DataFrame,\n    ) -> typing.Tuple[typing.List[str], typing.List[str]]:\n        <IND>",
        "target_code_with_indent": "\n    <DED><DED><DED>def get_feat_type_from_columns(\n        self,\n        X: pd.DataFrame,\n    ) -> typing.Dict[typing.Union[str, int], str]:\n        <IND>"
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        -------\n            enc_columns:\n                Columns to encode, if any\n            feat_type:\n                Type of each column numerical/categorical\n        \"\"\"\n        # Register if a column needs encoding\n        enc_columns = []\n\n        # Also, register the feature types for the estimator\n        feat_type = []\n\n",
        "source_code_len": 333,
        "target_code": "        -------\n            feat_type:\n                dictionary with column to feature type mapping\n        \"\"\"\n\n        # Also, register the feature types for the estimator\n        feat_type = {}\n\n",
        "target_code_len": 200,
        "diff_format": "@@ -366,12 +281,8 @@\n         -------\n-            enc_columns:\n-                Columns to encode, if any\n             feat_type:\n-                Type of each column numerical/categorical\n-        \"\"\"\n-        # Register if a column needs encoding\n-        enc_columns = []\n+                dictionary with column to feature type mapping\n+        \"\"\"\n \n         # Also, register the feature types for the estimator\n-        feat_type = []\n+        feat_type = {}\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "\n        # Register if a column needs encoding\n        enc_columns = []\n\n        # Also, register the feature types for the estimator\n        feat_type = []\n\n",
        "target_code_with_indent": "\n\n        # Also, register the feature types for the estimator\n        feat_type = {}\n\n"
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        for i, column in enumerate(X.columns):\n            if X[column].dtype.name in ['category', 'bool']:\n\n                enc_columns.append(column)\n                feat_type.append('categorical')\n            # Move away from np.issubdtype as it causes\n",
        "source_code_len": 256,
        "target_code": "        for i, column in enumerate(X.columns):\n            if is_sparse(X[column]):\n                raise ValueError(\"Auto-sklearn does not yet support sparse pandas Series.\"\n                                 f\" Please convert {column} to a dense format.\")\n            elif X[column].dtype.name in ['category', 'bool']:\n\n                feat_type[column] = 'categorical'\n            # Move away from np.issubdtype as it causes\n",
        "target_code_len": 426,
        "diff_format": "@@ -379,6 +290,8 @@\n         for i, column in enumerate(X.columns):\n-            if X[column].dtype.name in ['category', 'bool']:\n-\n-                enc_columns.append(column)\n-                feat_type.append('categorical')\n+            if is_sparse(X[column]):\n+                raise ValueError(\"Auto-sklearn does not yet support sparse pandas Series.\"\n+                                 f\" Please convert {column} to a dense format.\")\n+            elif X[column].dtype.name in ['category', 'bool']:\n+\n+                feat_type[column] = 'categorical'\n             # Move away from np.issubdtype as it causes\n",
        "source_code_with_indent": "        for i, column in enumerate(X.columns):\n            <IND>if X[column].dtype.name in ['category', 'bool']:\n\n                <IND>enc_columns.append(column)\n                feat_type.append('categorical')\n            # Move away from np.issubdtype as it causes\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        for i, column in enumerate(X.columns):\n            <IND>if is_sparse(X[column]):\n                <IND>raise ValueError(\"Auto-sklearn does not yet support sparse pandas Series.\"\n                                 f\" Please convert {column} to a dense format.\")\n            <DED>elif X[column].dtype.name in ['category', 'bool']:\n\n                <IND>feat_type[column] = 'categorical'\n            # Move away from np.issubdtype as it causes\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "            else:\n                feat_type.append('numerical')\n        return enc_columns, feat_type\n\n",
        "source_code_len": 103,
        "target_code": "            else:\n                feat_type[column] = 'numerical'\n        return feat_type\n\n",
        "target_code_len": 92,
        "diff_format": "@@ -421,4 +334,4 @@\n             else:\n-                feat_type.append('numerical')\n-        return enc_columns, feat_type\n+                feat_type[column] = 'numerical'\n+        return feat_type\n \n",
        "source_code_with_indent": "            <DED><DED>else:\n                <IND>feat_type.append('numerical')\n        <DED><DED>return enc_columns, feat_type\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "            <DED><DED>else:\n                <IND>feat_type[column] = 'numerical'\n        <DED><DED>return feat_type\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "automl/auto-sklearn",
    "commit": "4a482de8b30cfff6a79d7749577a707c1467d4f7",
    "filename": "autosklearn/data/feature_validator.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/automl-auto-sklearn/autosklearn/data/feature_validator.py",
    "file_hunks_size": 22,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "autosklearn/data/feature_validator.py:115:38 Incompatible parameter type [6]: Expected `typing.Sized` for 1st positional only parameter to call `len` but got `typing.Optional[typing.List[str]]`.",
    "message": " Expected `typing.Sized` for 1st positional only parameter to call `len` but got `typing.Optional[typing.List[str]]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 115,
    "warning_line": "                                 (len(self.feat_type), np.shape(X_train)[1]))",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import pandas as pd\nfrom pandas.api.types import is_numeric_dtype\n\n",
        "source_code_len": 67,
        "target_code": "import pandas as pd\nfrom pandas.api.types import is_numeric_dtype, is_sparse\n\n",
        "target_code_len": 78,
        "diff_format": "@@ -7,3 +6,3 @@\n import pandas as pd\n-from pandas.api.types import is_numeric_dtype\n+from pandas.api.types import is_numeric_dtype, is_sparse\n \n",
        "source_code_with_indent": "import pandas as pd\nfrom pandas.api.types import is_numeric_dtype\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "import pandas as pd\nfrom pandas.api.types import is_numeric_dtype, is_sparse\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        # If a dataframe was provided, we populate\n        # this attribute with the column types from the dataframe\n        # That is, this attribute contains whether autosklearn\n        # should treat a column as categorical or numerical\n        # During fit, if the user provided feat_types, the user\n        # constrain is honored. If not, this attribute is used.\n        self.feat_type = feat_type  # type: typing.Optional[typing.List[str]]\n\n",
        "source_code_len": 447,
        "target_code": "        # If a dataframe was provided, we populate\n        # this attribute with a mapping from column to {numerical | categorical}\n        self.feat_type: typing.Optional[\n            typing.Dict[typing.Union[str, int], str]\n        ] = None\n        if feat_type is not None:\n            if isinstance(feat_type, dict):\n                self.feat_type = feat_type\n            elif not isinstance(feat_type, list):\n                raise ValueError(\"Auto-Sklearn expects a list of categorical/\"\n                                 \"numerical feature types, yet a\"\n                                 \" {} was provided\".format(type(feat_type)))\n            else:\n\n                # Convert to a dictionary which will be passed to the ColumnTransformer\n                # Column Transformer supports strings or integer indexes\n                self.feat_type = {i: feat for i, feat in enumerate(feat_type)}\n\n",
        "target_code_len": 896,
        "diff_format": "@@ -56,8 +56,18 @@\n         # If a dataframe was provided, we populate\n-        # this attribute with the column types from the dataframe\n-        # That is, this attribute contains whether autosklearn\n-        # should treat a column as categorical or numerical\n-        # During fit, if the user provided feat_types, the user\n-        # constrain is honored. If not, this attribute is used.\n-        self.feat_type = feat_type  # type: typing.Optional[typing.List[str]]\n+        # this attribute with a mapping from column to {numerical | categorical}\n+        self.feat_type: typing.Optional[\n+            typing.Dict[typing.Union[str, int], str]\n+        ] = None\n+        if feat_type is not None:\n+            if isinstance(feat_type, dict):\n+                self.feat_type = feat_type\n+            elif not isinstance(feat_type, list):\n+                raise ValueError(\"Auto-Sklearn expects a list of categorical/\"\n+                                 \"numerical feature types, yet a\"\n+                                 \" {} was provided\".format(type(feat_type)))\n+            else:\n+\n+                # Convert to a dictionary which will be passed to the ColumnTransformer\n+                # Column Transformer supports strings or integer indexes\n+                self.feat_type = {i: feat for i, feat in enumerate(feat_type)}\n \n",
        "source_code_with_indent": "        # If a dataframe was provided, we populate\n        # this attribute with the column types from the dataframe\n        # That is, this attribute contains whether autosklearn\n        # should treat a column as categorical or numerical\n        # During fit, if the user provided feat_types, the user\n        # constrain is honored. If not, this attribute is used.\n        <IND>self.feat_type = feat_type  # type: typing.Optional[typing.List[str]]\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        # If a dataframe was provided, we populate\n        # this attribute with a mapping from column to {numerical | categorical}\n        <IND>self.feat_type: typing.Optional[\n            typing.Dict[typing.Union[str, int], str]\n        ] = None\n        if feat_type is not None:\n            <IND>if isinstance(feat_type, dict):\n                <IND>self.feat_type = feat_type\n            <DED>elif not isinstance(feat_type, list):\n                <IND>raise ValueError(\"Auto-Sklearn expects a list of categorical/\"\n                                 \"numerical feature types, yet a\"\n                                 \" {} was provided\".format(type(feat_type)))\n            <DED>else:\n\n                # Convert to a dictionary which will be passed to the ColumnTransformer\n                # Column Transformer supports strings or integer indexes\n                <IND>self.feat_type = {i: feat for i, feat in enumerate(feat_type)}\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        self.data_type = None  # type: typing.Optional[type]\n        self.dtypes = []  # type: typing.List[str]\n        self.column_order = []  # type: typing.List[str]\n\n        self.encoder = None  # type: typing.Optional[BaseEstimator]\n        self.enc_columns = []  # type: typing.List[str]\n\n",
        "source_code_len": 295,
        "target_code": "        self.data_type = None  # type: typing.Optional[type]\n        self.dtypes = {}  # type: typing.Dict[str, str]\n\n",
        "target_code_len": 118,
        "diff_format": "@@ -65,7 +75,3 @@\n         self.data_type = None  # type: typing.Optional[type]\n-        self.dtypes = []  # type: typing.List[str]\n-        self.column_order = []  # type: typing.List[str]\n-\n-        self.encoder = None  # type: typing.Optional[BaseEstimator]\n-        self.enc_columns = []  # type: typing.List[str]\n+        self.dtypes = {}  # type: typing.Dict[str, str]\n \n",
        "source_code_with_indent": "        self.data_type = None  # type: typing.Optional[type]\n        self.dtypes = []  # type: typing.List[str]\n        self.column_order = []  # type: typing.List[str]\n\n        self.encoder = None  # type: typing.Optional[BaseEstimator]\n        self.enc_columns = []  # type: typing.List[str]\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        <DED><DED>self.data_type = None  # type: typing.Optional[type]\n        self.dtypes = {}  # type: typing.Dict[str, str]\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "                                 \"/api/pandas.DataFrame.astype.html\")\n            # Some checks if self.feat_type is provided\n            if len(self.feat_type) != np.shape(X_train)[1]:\n                raise ValueError('Array feat_type does not have same number of '\n                                 'variables as X has features. %d vs %d.' %\n                                 (len(self.feat_type), np.shape(X_train)[1]))\n            if not all([isinstance(f, str) for f in self.feat_type]):\n                raise ValueError('Array feat_type must only contain strings.')\n\n            for ft in self.feat_type:\n                if ft.lower() not in ['categorical', 'numerical']:\n                    raise ValueError('Only `Categorical` and `Numerical` are '\n                                     'valid feature types, you passed `%s`' % ft)\n\n        self._check_data(X_train)\n\n",
        "source_code_len": 873,
        "target_code": "                                 \"/api/pandas.DataFrame.astype.html\")\n            else:\n                self.feat_type = self.get_feat_type_from_columns(X_train)\n        else:\n            # Numpy array was provided\n            if self.feat_type is None:\n                # Assume numerical columns if a numpy array has no feature types\n                self.feat_type = {i: 'numerical' for i in range(np.shape(X_train)[1])}\n            else:\n                # Check The feat type provided\n                if len(self.feat_type) != np.shape(X_train)[1]:\n                    raise ValueError('Array feat_type does not have same number of '\n                                     'variables as X has features. %d vs %d.' %\n                                     (len(self.feat_type), np.shape(X_train)[1]))\n                if not all([isinstance(f, str) for f in self.feat_type.values()]):\n                    raise ValueError(\"feat_type must only contain strings: {}\".format(\n                        list(self.feat_type.values()),\n                    ))\n\n                for ft in self.feat_type.values():\n                    if ft.lower() not in ['categorical', 'numerical']:\n                        raise ValueError('Only `Categorical` and `Numerical` are '\n                                         'valid feature types, you passed `%s`' % ft)\n\n",
        "target_code_len": 1339,
        "diff_format": "@@ -110,16 +118,24 @@\n                                  \"/api/pandas.DataFrame.astype.html\")\n-            # Some checks if self.feat_type is provided\n-            if len(self.feat_type) != np.shape(X_train)[1]:\n-                raise ValueError('Array feat_type does not have same number of '\n-                                 'variables as X has features. %d vs %d.' %\n-                                 (len(self.feat_type), np.shape(X_train)[1]))\n-            if not all([isinstance(f, str) for f in self.feat_type]):\n-                raise ValueError('Array feat_type must only contain strings.')\n-\n-            for ft in self.feat_type:\n-                if ft.lower() not in ['categorical', 'numerical']:\n-                    raise ValueError('Only `Categorical` and `Numerical` are '\n-                                     'valid feature types, you passed `%s`' % ft)\n-\n-        self._check_data(X_train)\n+            else:\n+                self.feat_type = self.get_feat_type_from_columns(X_train)\n+        else:\n+            # Numpy array was provided\n+            if self.feat_type is None:\n+                # Assume numerical columns if a numpy array has no feature types\n+                self.feat_type = {i: 'numerical' for i in range(np.shape(X_train)[1])}\n+            else:\n+                # Check The feat type provided\n+                if len(self.feat_type) != np.shape(X_train)[1]:\n+                    raise ValueError('Array feat_type does not have same number of '\n+                                     'variables as X has features. %d vs %d.' %\n+                                     (len(self.feat_type), np.shape(X_train)[1]))\n+                if not all([isinstance(f, str) for f in self.feat_type.values()]):\n+                    raise ValueError(\"feat_type must only contain strings: {}\".format(\n+                        list(self.feat_type.values()),\n+                    ))\n+\n+                for ft in self.feat_type.values():\n+                    if ft.lower() not in ['categorical', 'numerical']:\n+                        raise ValueError('Only `Categorical` and `Numerical` are '\n+                                         'valid feature types, you passed `%s`' % ft)\n \n",
        "source_code_with_indent": "                                 \"/api/pandas.DataFrame.astype.html\")\n            # Some checks if self.feat_type is provided\n            <DED>if len(self.feat_type) != np.shape(X_train)[1]:\n                <IND>raise ValueError('Array feat_type does not have same number of '\n                                 'variables as X has features. %d vs %d.' %\n                                 (len(self.feat_type), np.shape(X_train)[1]))\n            <DED>if not all([isinstance(f, str) for f in self.feat_type]):\n                <IND>raise ValueError('Array feat_type must only contain strings.')\n\n            <DED>for ft in self.feat_type:\n                <IND>if ft.lower() not in ['categorical', 'numerical']:\n                    <IND>raise ValueError('Only `Categorical` and `Numerical` are '\n                                     'valid feature types, you passed `%s`' % ft)\n\n        <DED><DED><DED>self._check_data(X_train)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "                                 \"/api/pandas.DataFrame.astype.html\")\n            <DED>else:\n                <IND>self.feat_type = self.get_feat_type_from_columns(X_train)\n        <DED><DED>else:\n            # Numpy array was provided\n            <IND>if self.feat_type is None:\n                # Assume numerical columns if a numpy array has no feature types\n                <IND>self.feat_type = {i: 'numerical' for i in range(np.shape(X_train)[1])}\n            <DED>else:\n                # Check The feat type provided\n                <IND>if len(self.feat_type) != np.shape(X_train)[1]:\n                    <IND>raise ValueError('Array feat_type does not have same number of '\n                                     'variables as X has features. %d vs %d.' %\n                                     (len(self.feat_type), np.shape(X_train)[1]))\n                <DED>if not all([isinstance(f, str) for f in self.feat_type.values()]):\n                    <IND>raise ValueError(\"feat_type must only contain strings: {}\".format(\n                        list(self.feat_type.values()),\n                    ))\n\n                <DED>for ft in self.feat_type.values():\n                    <IND>if ft.lower() not in ['categorical', 'numerical']:\n                        <IND>raise ValueError('Only `Categorical` and `Numerical` are '\n                                         'valid feature types, you passed `%s`' % ft)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "\n        # Fit on the training data\n        self._fit(X_train)\n\n        self._is_fitted = True\n",
        "source_code_len": 95,
        "target_code": "\n        self._is_fitted = True\n",
        "target_code_len": 32,
        "diff_format": "@@ -135,5 +151,2 @@\n \n-        # Fit on the training data\n-        self._fit(X_train)\n-\n         self._is_fitted = True\n",
        "source_code_with_indent": "\n        # Fit on the training data\n        <DED><DED>self._fit(X_train)\n\n        self._is_fitted = True\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n        <DED><DED>self._is_fitted = True\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    def _fit(\n        self,\n        X: SUPPORTED_FEAT_TYPES,\n    ) -> BaseEstimator:\n        \"\"\"\n        In case input data is a pandas DataFrame, this utility encodes the user provided\n        features (from categorical for example) to a numerical value that further stages\n        will be able to use\n\n",
        "source_code_len": 305,
        "target_code": "\n    def transform(\n        self,\n        X: SUPPORTED_FEAT_TYPES,\n    ) -> np.ndarray:\n        \"\"\"\n        Validates and fit a categorical encoder (if needed) to the features.\n        The supported data types are List, numpy arrays and pandas DataFrames.\n\n        Parameters\n        ----------\n            X_train: SUPPORTED_FEAT_TYPES\n                A set of features, whose categorical features are going to be\n                transformed\n\n        Return\n        ------\n            np.ndarray:\n                The transformed array\n        \"\"\"\n        if not self._is_fitted:\n            raise NotFittedError(\"Cannot call transform on a validator that is not fitted\")\n\n        # If a list was provided, it will be converted to pandas\n        if isinstance(X, list):\n            X, _ = self.list_to_dataframe(X)\n\n        # Check the data here so we catch problems on new test data\n        self._check_data(X)\n\n        # Sparse related transformations\n        # Not all sparse format support index sorting\n        if scipy.sparse.issparse(X):\n            if not isinstance(X, scipy.sparse.csr_matrix):\n                self.logger.warning(f\"Sparse data provided is of type {type(X)} \"\n                                    \"yet Auto-Sklearn only support csr_matrix. Auto-sklearn \"\n                                    \"will convert the provided data to the csr_matrix format.\")\n                X = X.tocsr(copy=False)\n            if hasattr(X, 'sort_indices'):\n                X.sort_indices()\n        return X\n\n    def _check_data(\n        self,\n        X: SUPPORTED_FEAT_TYPES,\n    ) -> None:\n        \"\"\"\n        Feature dimensionality and data type checks\n\n",
        "target_code_len": 1658,
        "diff_format": "@@ -142,10 +155,49 @@\n \n-    def _fit(\n+    def transform(\n         self,\n         X: SUPPORTED_FEAT_TYPES,\n-    ) -> BaseEstimator:\n-        \"\"\"\n-        In case input data is a pandas DataFrame, this utility encodes the user provided\n-        features (from categorical for example) to a numerical value that further stages\n-        will be able to use\n+    ) -> np.ndarray:\n+        \"\"\"\n+        Validates and fit a categorical encoder (if needed) to the features.\n+        The supported data types are List, numpy arrays and pandas DataFrames.\n+\n+        Parameters\n+        ----------\n+            X_train: SUPPORTED_FEAT_TYPES\n+                A set of features, whose categorical features are going to be\n+                transformed\n+\n+        Return\n+        ------\n+            np.ndarray:\n+                The transformed array\n+        \"\"\"\n+        if not self._is_fitted:\n+            raise NotFittedError(\"Cannot call transform on a validator that is not fitted\")\n+\n+        # If a list was provided, it will be converted to pandas\n+        if isinstance(X, list):\n+            X, _ = self.list_to_dataframe(X)\n+\n+        # Check the data here so we catch problems on new test data\n+        self._check_data(X)\n+\n+        # Sparse related transformations\n+        # Not all sparse format support index sorting\n+        if scipy.sparse.issparse(X):\n+            if not isinstance(X, scipy.sparse.csr_matrix):\n+                self.logger.warning(f\"Sparse data provided is of type {type(X)} \"\n+                                    \"yet Auto-Sklearn only support csr_matrix. Auto-sklearn \"\n+                                    \"will convert the provided data to the csr_matrix format.\")\n+                X = X.tocsr(copy=False)\n+            if hasattr(X, 'sort_indices'):\n+                X.sort_indices()\n+        return X\n+\n+    def _check_data(\n+        self,\n+        X: SUPPORTED_FEAT_TYPES,\n+    ) -> None:\n+        \"\"\"\n+        Feature dimensionality and data type checks\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "\n    <DED>def _fit(\n        self,\n        X: SUPPORTED_FEAT_TYPES,\n    ) -> BaseEstimator:\n        <IND>",
        "target_code_with_indent": "\n    <DED>def transform(\n        self,\n        X: SUPPORTED_FEAT_TYPES,\n    ) -> np.ndarray:\n        <IND>\"\"\"\n        Validates and fit a categorical encoder (if needed) to the features.\n        The supported data types are List, numpy arrays and pandas DataFrames.\n\n        Parameters\n        ----------\n            X_train: SUPPORTED_FEAT_TYPES\n                A set of features, whose categorical features are going to be\n                transformed\n\n        Return\n        ------\n            np.ndarray:\n                The transformed array\n        \"\"\"\n        if not self._is_fitted:\n            <IND>raise NotFittedError(\"Cannot call transform on a validator that is not fitted\")\n\n        # If a list was provided, it will be converted to pandas\n        <DED>if isinstance(X, list):\n            <IND>X, _ = self.list_to_dataframe(X)\n\n        # Check the data here so we catch problems on new test data\n        <DED>self._check_data(X)\n\n        # Sparse related transformations\n        # Not all sparse format support index sorting\n        if scipy.sparse.issparse(X):\n            <IND>if not isinstance(X, scipy.sparse.csr_matrix):\n                <IND>self.logger.warning(f\"Sparse data provided is of type {type(X)} \"\n                                    \"yet Auto-Sklearn only support csr_matrix. Auto-sklearn \"\n                                    \"will convert the provided data to the csr_matrix format.\")\n                X = X.tocsr(copy=False)\n            <DED>if hasattr(X, 'sort_indices'):\n                <IND>X.sort_indices()\n        <DED><DED>return X\n\n    <DED>def _check_data(\n        self,\n        X: SUPPORTED_FEAT_TYPES,\n    ) -> None:\n        <IND>"
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        \"\"\"\n        if hasattr(X, \"iloc\") and not scipy.sparse.issparse(X):\n            X = typing.cast(pd.DataFrame, X)\n            # Treat a column with all instances a NaN as numerical\n            # This will prevent doing encoding to a categorical column made completely\n            # out of nan values -- which will trigger a fail, as encoding is not supported\n            # with nan values.\n            # Columns that are completely made of NaN values are provided to the pipeline\n            # so that later stages decide how to handle them\n            if np.any(pd.isnull(X)):\n                for column in X.columns:\n                    if X[column].isna().all():\n                        X[column] = pd.to_numeric(X[column])\n\n            self.enc_columns, self.feat_type = self._get_columns_to_encode(X)\n\n            if len(self.enc_columns) > 0:\n\n                self.encoder = make_column_transformer(\n                    (preprocessing.OrdinalEncoder(\n                        handle_unknown='use_encoded_value',\n                        unknown_value=-1,\n                    ), self.enc_columns),\n                    remainder=\"passthrough\"\n                )\n\n                # Mypy redefinition\n                assert self.encoder is not None\n                self.encoder.fit(X)\n\n                # The column transformer reoders the feature types - we therefore need to change\n                # it as well\n                def comparator(cmp1: str, cmp2: str) -> int:\n                    if (\n                        cmp1 == 'categorical' and cmp2 == 'categorical'\n                        or cmp1 == 'numerical' and cmp2 == 'numerical'\n                    ):\n                        return 0\n                    elif cmp1 == 'categorical' and cmp2 == 'numerical':\n                        return -1\n                    elif cmp1 == 'numerical' and cmp2 == 'categorical':\n                        return 1\n                    else:\n                        raise ValueError((cmp1, cmp2))\n                self.feat_type = sorted(\n                    self.feat_type,\n                    key=functools.cmp_to_key(comparator)\n                )\n        return self\n\n    def transform(\n        self,\n        X: SUPPORTED_FEAT_TYPES,\n    ) -> np.ndarray:\n        \"\"\"\n        Validates and fit a categorical encoder (if needed) to the features.\n        The supported data types are List, numpy arrays and pandas DataFrames.\n\n        Parameters\n        ----------\n            X_train: SUPPORTED_FEAT_TYPES\n                A set of features, whose categorical features are going to be\n                transformed\n\n        Return\n        ------\n            np.ndarray:\n                The transformed array\n        \"\"\"\n        if not self._is_fitted:\n            raise NotFittedError(\"Cannot call transform on a validator that is not fitted\")\n\n        # If a list was provided, it will be converted to pandas\n        if isinstance(X, list):\n            X, _ = self.list_to_dataframe(X)\n\n        if hasattr(X, \"iloc\") and not scipy.sparse.issparse(X):\n            X = typing.cast(pd.DataFrame, X)\n            if np.any(pd.isnull(X)):\n                for column in X.columns:\n                    if X[column].isna().all():\n                        X[column] = pd.to_numeric(X[column])\n\n        # Check the data here so we catch problems on new test data\n        self._check_data(X)\n\n        # Pandas related transformations\n        if hasattr(X, \"iloc\") and self.encoder is not None:\n            if np.any(pd.isnull(X)):\n                # After above check it means that if there is a NaN\n                # the whole column must be NaN\n                # Make sure it is numerical and let the pipeline handle it\n                for column in X.columns:\n                    if X[column].isna().all():\n                        X[column] = pd.to_numeric(X[column])\n            X = self.encoder.transform(X)\n\n        # Sparse related transformations\n        # Not all sparse format support index sorting\n        if scipy.sparse.issparse(X) and hasattr(X, 'sort_indices'):\n            X.sort_indices()\n\n        return sklearn.utils.check_array(\n            X,\n            force_all_finite=False,\n            accept_sparse='csr'\n        )\n\n    def _check_data(\n        self,\n        X: SUPPORTED_FEAT_TYPES,\n    ) -> None:\n        \"\"\"\n        Feature dimensionality and data type checks\n\n        Parameters\n        ----------\n            X: SUPPORTED_FEAT_TYPES\n                A set of features that are going to be validated (type and dimensionality\n                checks) and a encoder fitted in the case the data needs encoding\n        \"\"\"\n\n",
        "source_code_len": 4631,
        "target_code": "        \"\"\"\n\n        # We consider columns that are all nan in a pandas frame as category\n        if hasattr(X, 'columns'):\n            for column in typing.cast(pd.DataFrame, X).columns:\n                if X[column].isna().all():\n                    X[column] = X[column].astype('category')\n\n",
        "target_code_len": 293,
        "diff_format": "@@ -157,122 +209,8 @@\n         \"\"\"\n-        if hasattr(X, \"iloc\") and not scipy.sparse.issparse(X):\n-            X = typing.cast(pd.DataFrame, X)\n-            # Treat a column with all instances a NaN as numerical\n-            # This will prevent doing encoding to a categorical column made completely\n-            # out of nan values -- which will trigger a fail, as encoding is not supported\n-            # with nan values.\n-            # Columns that are completely made of NaN values are provided to the pipeline\n-            # so that later stages decide how to handle them\n-            if np.any(pd.isnull(X)):\n-                for column in X.columns:\n-                    if X[column].isna().all():\n-                        X[column] = pd.to_numeric(X[column])\n-\n-            self.enc_columns, self.feat_type = self._get_columns_to_encode(X)\n-\n-            if len(self.enc_columns) > 0:\n-\n-                self.encoder = make_column_transformer(\n-                    (preprocessing.OrdinalEncoder(\n-                        handle_unknown='use_encoded_value',\n-                        unknown_value=-1,\n-                    ), self.enc_columns),\n-                    remainder=\"passthrough\"\n-                )\n-\n-                # Mypy redefinition\n-                assert self.encoder is not None\n-                self.encoder.fit(X)\n-\n-                # The column transformer reoders the feature types - we therefore need to change\n-                # it as well\n-                def comparator(cmp1: str, cmp2: str) -> int:\n-                    if (\n-                        cmp1 == 'categorical' and cmp2 == 'categorical'\n-                        or cmp1 == 'numerical' and cmp2 == 'numerical'\n-                    ):\n-                        return 0\n-                    elif cmp1 == 'categorical' and cmp2 == 'numerical':\n-                        return -1\n-                    elif cmp1 == 'numerical' and cmp2 == 'categorical':\n-                        return 1\n-                    else:\n-                        raise ValueError((cmp1, cmp2))\n-                self.feat_type = sorted(\n-                    self.feat_type,\n-                    key=functools.cmp_to_key(comparator)\n-                )\n-        return self\n-\n-    def transform(\n-        self,\n-        X: SUPPORTED_FEAT_TYPES,\n-    ) -> np.ndarray:\n-        \"\"\"\n-        Validates and fit a categorical encoder (if needed) to the features.\n-        The supported data types are List, numpy arrays and pandas DataFrames.\n-\n-        Parameters\n-        ----------\n-            X_train: SUPPORTED_FEAT_TYPES\n-                A set of features, whose categorical features are going to be\n-                transformed\n-\n-        Return\n-        ------\n-            np.ndarray:\n-                The transformed array\n-        \"\"\"\n-        if not self._is_fitted:\n-            raise NotFittedError(\"Cannot call transform on a validator that is not fitted\")\n-\n-        # If a list was provided, it will be converted to pandas\n-        if isinstance(X, list):\n-            X, _ = self.list_to_dataframe(X)\n-\n-        if hasattr(X, \"iloc\") and not scipy.sparse.issparse(X):\n-            X = typing.cast(pd.DataFrame, X)\n-            if np.any(pd.isnull(X)):\n-                for column in X.columns:\n-                    if X[column].isna().all():\n-                        X[column] = pd.to_numeric(X[column])\n-\n-        # Check the data here so we catch problems on new test data\n-        self._check_data(X)\n-\n-        # Pandas related transformations\n-        if hasattr(X, \"iloc\") and self.encoder is not None:\n-            if np.any(pd.isnull(X)):\n-                # After above check it means that if there is a NaN\n-                # the whole column must be NaN\n-                # Make sure it is numerical and let the pipeline handle it\n-                for column in X.columns:\n-                    if X[column].isna().all():\n-                        X[column] = pd.to_numeric(X[column])\n-            X = self.encoder.transform(X)\n-\n-        # Sparse related transformations\n-        # Not all sparse format support index sorting\n-        if scipy.sparse.issparse(X) and hasattr(X, 'sort_indices'):\n-            X.sort_indices()\n-\n-        return sklearn.utils.check_array(\n-            X,\n-            force_all_finite=False,\n-            accept_sparse='csr'\n-        )\n-\n-    def _check_data(\n-        self,\n-        X: SUPPORTED_FEAT_TYPES,\n-    ) -> None:\n-        \"\"\"\n-        Feature dimensionality and data type checks\n-\n-        Parameters\n-        ----------\n-            X: SUPPORTED_FEAT_TYPES\n-                A set of features that are going to be validated (type and dimensionality\n-                checks) and a encoder fitted in the case the data needs encoding\n-        \"\"\"\n+\n+        # We consider columns that are all nan in a pandas frame as category\n+        if hasattr(X, 'columns'):\n+            for column in typing.cast(pd.DataFrame, X).columns:\n+                if X[column].isna().all():\n+                    X[column] = X[column].astype('category')\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "\n        if hasattr(X, \"iloc\") and not scipy.sparse.issparse(X):\n            <IND>X = typing.cast(pd.DataFrame, X)\n            # Treat a column with all instances a NaN as numerical\n            # This will prevent doing encoding to a categorical column made completely\n            # out of nan values -- which will trigger a fail, as encoding is not supported\n            # with nan values.\n            # Columns that are completely made of NaN values are provided to the pipeline\n            # so that later stages decide how to handle them\n            if np.any(pd.isnull(X)):\n                <IND>for column in X.columns:\n                    <IND>if X[column].isna().all():\n                        <IND>X[column] = pd.to_numeric(X[column])\n\n            <DED><DED><DED>self.enc_columns, self.feat_type = self._get_columns_to_encode(X)\n\n            if len(self.enc_columns) > 0:\n\n                <IND>self.encoder = make_column_transformer(\n                    (preprocessing.OrdinalEncoder(\n                        handle_unknown='use_encoded_value',\n                        unknown_value=-1,\n                    ), self.enc_columns),\n                    remainder=\"passthrough\"\n                )\n\n                # Mypy redefinition\n                assert self.encoder is not None\n                self.encoder.fit(X)\n\n                # The column transformer reoders the feature types - we therefore need to change\n                # it as well\n                def comparator(cmp1: str, cmp2: str) -> int:\n                    <IND>if (\n                        cmp1 == 'categorical' and cmp2 == 'categorical'\n                        or cmp1 == 'numerical' and cmp2 == 'numerical'\n                    ):\n                        <IND>return 0\n                    <DED>elif cmp1 == 'categorical' and cmp2 == 'numerical':\n                        <IND>return -1\n                    <DED>elif cmp1 == 'numerical' and cmp2 == 'categorical':\n                        <IND>return 1\n                    <DED>else:\n                        <IND>raise ValueError((cmp1, cmp2))\n                <DED><DED>self.feat_type = sorted(\n                    self.feat_type,\n                    key=functools.cmp_to_key(comparator)\n                )\n        <DED><DED>return self\n\n    <DED>def transform(\n        self,\n        X: SUPPORTED_FEAT_TYPES,\n    ) -> np.ndarray:\n        <IND>\"\"\"\n        Validates and fit a categorical encoder (if needed) to the features.\n        The supported data types are List, numpy arrays and pandas DataFrames.\n\n        Parameters\n        ----------\n            X_train: SUPPORTED_FEAT_TYPES\n                A set of features, whose categorical features are going to be\n                transformed\n\n        Return\n        ------\n            np.ndarray:\n                The transformed array\n        \"\"\"\n        if not self._is_fitted:\n            <IND>raise NotFittedError(\"Cannot call transform on a validator that is not fitted\")\n\n        # If a list was provided, it will be converted to pandas\n        <DED>if isinstance(X, list):\n            <IND>X, _ = self.list_to_dataframe(X)\n\n        <DED>if hasattr(X, \"iloc\") and not scipy.sparse.issparse(X):\n            <IND>X = typing.cast(pd.DataFrame, X)\n            if np.any(pd.isnull(X)):\n                <IND>for column in X.columns:\n                    <IND>if X[column].isna().all():\n                        <IND>X[column] = pd.to_numeric(X[column])\n\n        # Check the data here so we catch problems on new test data\n        <DED><DED><DED><DED>self._check_data(X)\n\n        # Pandas related transformations\n        if hasattr(X, \"iloc\") and self.encoder is not None:\n            <IND>if np.any(pd.isnull(X)):\n                # After above check it means that if there is a NaN\n                # the whole column must be NaN\n                # Make sure it is numerical and let the pipeline handle it\n                <IND>for column in X.columns:\n                    <IND>if X[column].isna().all():\n                        <IND>X[column] = pd.to_numeric(X[column])\n            <DED><DED><DED>X = self.encoder.transform(X)\n\n        # Sparse related transformations\n        # Not all sparse format support index sorting\n        <DED>if scipy.sparse.issparse(X) and hasattr(X, 'sort_indices'):\n            <IND>X.sort_indices()\n\n        <DED>return sklearn.utils.check_array(\n            X,\n            force_all_finite=False,\n            accept_sparse='csr'\n        )\n\n    <DED>def _check_data(\n        self,\n        X: SUPPORTED_FEAT_TYPES,\n    ) -> None:\n        <IND>\"\"\"\n        Feature dimensionality and data type checks\n\n        Parameters\n        ----------\n            X: SUPPORTED_FEAT_TYPES\n                A set of features that are going to be validated (type and dimensionality\n                checks) and a encoder fitted in the case the data needs encoding\n        \"\"\"\n\n",
        "target_code_with_indent": "\n\n        # We consider columns that are all nan in a pandas frame as category\n        if hasattr(X, 'columns'):\n            <IND>for column in typing.cast(pd.DataFrame, X).columns:\n                <IND>if X[column].isna().all():\n                    <IND>X[column] = X[column].astype('category')\n\n"
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n            # Define the column to be encoded here as the feature validator is fitted once\n            # per estimator\n            enc_columns, _ = self._get_columns_to_encode(X)\n\n            if len(enc_columns) > 0:\n                if np.any(pd.isnull(\n                    X[enc_columns].dropna(  # type: ignore[call-overload]\n                        axis='columns', how='all')\n                )):\n                    # Ignore all NaN columns, and if still a NaN\n                    # Error out\n                    raise ValueError(\"Categorical features in a dataframe cannot contain \"\n                                     \"missing/NaN values. The OrdinalEncoder used by \"\n                                     \"Auto-sklearn cannot handle this yet (due to a \"\n                                     \"limitation on scikit-learn being addressed via: \"\n                                     \"https://github.com/scikit-learn/scikit-learn/issues/17123)\"\n                                     )\n            column_order = [column for column in X.columns]\n            if len(self.column_order) > 0:\n                if self.column_order != column_order:\n                    raise ValueError(\"Changing the column order of the features after fit() is \"\n                                     \"not supported. Fit() method was called with \"\n                                     \"{} whereas the new features have {} as type\".format(\n                                        self.column_order,\n                                        column_order,\n                                     ))\n            else:\n                self.column_order = column_order\n            dtypes = [dtype.name for dtype in X.dtypes]\n            if len(self.dtypes) > 0:\n                if self.dtypes != dtypes:\n                    raise ValueError(\"Changing the dtype of the features after fit() is \"\n                                     \"not supported. Fit() method was called with \"\n                                     \"{} whereas the new features have {} as type\".format(\n                                        self.dtypes,\n                                        dtypes,\n                                     ))\n            else:\n",
        "source_code_len": 2194,
        "target_code": "\n            dtypes = {col: X[col].dtype.name.lower() for col in X.columns}\n            if len(self.dtypes) > 0:\n                if self.dtypes != dtypes:\n                    # To support list, we need to support object inference.\n                    # In extreme cases, the train column might be all integer,\n                    # and the test column might be float.\n                    self.logger.warning(\"Changing the dtype of the features after fit() is \"\n                                        \"not recommended. Fit() method was called with \"\n                                        \"{} whereas the new features have {} as type\".format(\n                                            self.dtypes,\n                                            dtypes,\n                                        ))\n            else:\n",
        "target_code_len": 814,
        "diff_format": "@@ -312,39 +251,14 @@\n \n-            # Define the column to be encoded here as the feature validator is fitted once\n-            # per estimator\n-            enc_columns, _ = self._get_columns_to_encode(X)\n-\n-            if len(enc_columns) > 0:\n-                if np.any(pd.isnull(\n-                    X[enc_columns].dropna(  # type: ignore[call-overload]\n-                        axis='columns', how='all')\n-                )):\n-                    # Ignore all NaN columns, and if still a NaN\n-                    # Error out\n-                    raise ValueError(\"Categorical features in a dataframe cannot contain \"\n-                                     \"missing/NaN values. The OrdinalEncoder used by \"\n-                                     \"Auto-sklearn cannot handle this yet (due to a \"\n-                                     \"limitation on scikit-learn being addressed via: \"\n-                                     \"https://github.com/scikit-learn/scikit-learn/issues/17123)\"\n-                                     )\n-            column_order = [column for column in X.columns]\n-            if len(self.column_order) > 0:\n-                if self.column_order != column_order:\n-                    raise ValueError(\"Changing the column order of the features after fit() is \"\n-                                     \"not supported. Fit() method was called with \"\n-                                     \"{} whereas the new features have {} as type\".format(\n-                                        self.column_order,\n-                                        column_order,\n-                                     ))\n-            else:\n-                self.column_order = column_order\n-            dtypes = [dtype.name for dtype in X.dtypes]\n+            dtypes = {col: X[col].dtype.name.lower() for col in X.columns}\n             if len(self.dtypes) > 0:\n                 if self.dtypes != dtypes:\n-                    raise ValueError(\"Changing the dtype of the features after fit() is \"\n-                                     \"not supported. Fit() method was called with \"\n-                                     \"{} whereas the new features have {} as type\".format(\n-                                        self.dtypes,\n-                                        dtypes,\n-                                     ))\n+                    # To support list, we need to support object inference.\n+                    # In extreme cases, the train column might be all integer,\n+                    # and the test column might be float.\n+                    self.logger.warning(\"Changing the dtype of the features after fit() is \"\n+                                        \"not recommended. Fit() method was called with \"\n+                                        \"{} whereas the new features have {} as type\".format(\n+                                            self.dtypes,\n+                                            dtypes,\n+                                        ))\n             else:\n",
        "source_code_with_indent": "\n            # Define the column to be encoded here as the feature validator is fitted once\n            # per estimator\n            enc_columns, _ = self._get_columns_to_encode(X)\n\n            if len(enc_columns) > 0:\n                <IND>if np.any(pd.isnull(\n                    X[enc_columns].dropna(  # type: ignore[call-overload]\n                        axis='columns', how='all')\n                )):\n                    # Ignore all NaN columns, and if still a NaN\n                    # Error out\n                    <IND>raise ValueError(\"Categorical features in a dataframe cannot contain \"\n                                     \"missing/NaN values. The OrdinalEncoder used by \"\n                                     \"Auto-sklearn cannot handle this yet (due to a \"\n                                     \"limitation on scikit-learn being addressed via: \"\n                                     \"https://github.com/scikit-learn/scikit-learn/issues/17123)\"\n                                     )\n            <DED><DED>column_order = [column for column in X.columns]\n            if len(self.column_order) > 0:\n                <IND>if self.column_order != column_order:\n                    <IND>raise ValueError(\"Changing the column order of the features after fit() is \"\n                                     \"not supported. Fit() method was called with \"\n                                     \"{} whereas the new features have {} as type\".format(\n                                        self.column_order,\n                                        column_order,\n                                     ))\n            <DED><DED>else:\n                <IND>self.column_order = column_order\n            <DED>dtypes = [dtype.name for dtype in X.dtypes]\n            if len(self.dtypes) > 0:\n                <IND>if self.dtypes != dtypes:\n                    <IND>raise ValueError(\"Changing the dtype of the features after fit() is \"\n                                     \"not supported. Fit() method was called with \"\n                                     \"{} whereas the new features have {} as type\".format(\n                                        self.dtypes,\n                                        dtypes,\n                                     ))\n            <DED><DED>else:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n            dtypes = {col: X[col].dtype.name.lower() for col in X.columns}\n            if len(self.dtypes) > 0:\n                <IND>if self.dtypes != dtypes:\n                    # To support list, we need to support object inference.\n                    # In extreme cases, the train column might be all integer,\n                    # and the test column might be float.\n                    <IND>self.logger.warning(\"Changing the dtype of the features after fit() is \"\n                                        \"not recommended. Fit() method was called with \"\n                                        \"{} whereas the new features have {} as type\".format(\n                                            self.dtypes,\n                                            dtypes,\n                                        ))\n            <DED><DED>else:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    def _get_columns_to_encode(\n        self,\n        X: pd.DataFrame,\n    ) -> typing.Tuple[typing.List[str], typing.List[str]]:\n        \"\"\"\n        Return the columns to be encoded from a pandas dataframe\n\n",
        "source_code_len": 209,
        "target_code": "\n    def get_feat_type_from_columns(\n        self,\n        X: pd.DataFrame,\n    ) -> typing.Dict[typing.Union[str, int], str]:\n        \"\"\"\n        Returns a dictionary that maps pandas dataframe columns to a feature type.\n        This feature type can be categorical or numerical\n\n",
        "target_code_len": 281,
        "diff_format": "@@ -352,8 +266,9 @@\n \n-    def _get_columns_to_encode(\n+    def get_feat_type_from_columns(\n         self,\n         X: pd.DataFrame,\n-    ) -> typing.Tuple[typing.List[str], typing.List[str]]:\n-        \"\"\"\n-        Return the columns to be encoded from a pandas dataframe\n+    ) -> typing.Dict[typing.Union[str, int], str]:\n+        \"\"\"\n+        Returns a dictionary that maps pandas dataframe columns to a feature type.\n+        This feature type can be categorical or numerical\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "\n    <DED><DED><DED>def _get_columns_to_encode(\n        self,\n        X: pd.DataFrame,\n    ) -> typing.Tuple[typing.List[str], typing.List[str]]:\n        <IND>",
        "target_code_with_indent": "\n    <DED><DED><DED>def get_feat_type_from_columns(\n        self,\n        X: pd.DataFrame,\n    ) -> typing.Dict[typing.Union[str, int], str]:\n        <IND>"
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        -------\n            enc_columns:\n                Columns to encode, if any\n            feat_type:\n                Type of each column numerical/categorical\n        \"\"\"\n        # Register if a column needs encoding\n        enc_columns = []\n\n        # Also, register the feature types for the estimator\n        feat_type = []\n\n",
        "source_code_len": 333,
        "target_code": "        -------\n            feat_type:\n                dictionary with column to feature type mapping\n        \"\"\"\n\n        # Also, register the feature types for the estimator\n        feat_type = {}\n\n",
        "target_code_len": 200,
        "diff_format": "@@ -366,12 +281,8 @@\n         -------\n-            enc_columns:\n-                Columns to encode, if any\n             feat_type:\n-                Type of each column numerical/categorical\n-        \"\"\"\n-        # Register if a column needs encoding\n-        enc_columns = []\n+                dictionary with column to feature type mapping\n+        \"\"\"\n \n         # Also, register the feature types for the estimator\n-        feat_type = []\n+        feat_type = {}\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "\n        # Register if a column needs encoding\n        enc_columns = []\n\n        # Also, register the feature types for the estimator\n        feat_type = []\n\n",
        "target_code_with_indent": "\n\n        # Also, register the feature types for the estimator\n        feat_type = {}\n\n"
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        for i, column in enumerate(X.columns):\n            if X[column].dtype.name in ['category', 'bool']:\n\n                enc_columns.append(column)\n                feat_type.append('categorical')\n            # Move away from np.issubdtype as it causes\n",
        "source_code_len": 256,
        "target_code": "        for i, column in enumerate(X.columns):\n            if is_sparse(X[column]):\n                raise ValueError(\"Auto-sklearn does not yet support sparse pandas Series.\"\n                                 f\" Please convert {column} to a dense format.\")\n            elif X[column].dtype.name in ['category', 'bool']:\n\n                feat_type[column] = 'categorical'\n            # Move away from np.issubdtype as it causes\n",
        "target_code_len": 426,
        "diff_format": "@@ -379,6 +290,8 @@\n         for i, column in enumerate(X.columns):\n-            if X[column].dtype.name in ['category', 'bool']:\n-\n-                enc_columns.append(column)\n-                feat_type.append('categorical')\n+            if is_sparse(X[column]):\n+                raise ValueError(\"Auto-sklearn does not yet support sparse pandas Series.\"\n+                                 f\" Please convert {column} to a dense format.\")\n+            elif X[column].dtype.name in ['category', 'bool']:\n+\n+                feat_type[column] = 'categorical'\n             # Move away from np.issubdtype as it causes\n",
        "source_code_with_indent": "        for i, column in enumerate(X.columns):\n            <IND>if X[column].dtype.name in ['category', 'bool']:\n\n                <IND>enc_columns.append(column)\n                feat_type.append('categorical')\n            # Move away from np.issubdtype as it causes\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        for i, column in enumerate(X.columns):\n            <IND>if is_sparse(X[column]):\n                <IND>raise ValueError(\"Auto-sklearn does not yet support sparse pandas Series.\"\n                                 f\" Please convert {column} to a dense format.\")\n            <DED>elif X[column].dtype.name in ['category', 'bool']:\n\n                <IND>feat_type[column] = 'categorical'\n            # Move away from np.issubdtype as it causes\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "            else:\n                feat_type.append('numerical')\n        return enc_columns, feat_type\n\n",
        "source_code_len": 103,
        "target_code": "            else:\n                feat_type[column] = 'numerical'\n        return feat_type\n\n",
        "target_code_len": 92,
        "diff_format": "@@ -421,4 +334,4 @@\n             else:\n-                feat_type.append('numerical')\n-        return enc_columns, feat_type\n+                feat_type[column] = 'numerical'\n+        return feat_type\n \n",
        "source_code_with_indent": "            <DED><DED>else:\n                <IND>feat_type.append('numerical')\n        <DED><DED>return enc_columns, feat_type\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "            <DED><DED>else:\n                <IND>feat_type[column] = 'numerical'\n        <DED><DED>return feat_type\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "automl/auto-sklearn",
    "commit": "4a482de8b30cfff6a79d7749577a707c1467d4f7",
    "filename": "autosklearn/data/feature_validator.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/automl-auto-sklearn/autosklearn/data/feature_validator.py",
    "file_hunks_size": 22,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "autosklearn/data/feature_validator.py:202:20 Incompatible parameter type [6]: Expected `typing.Iterable[Variable[_T]]` for 1st positional only parameter to call `sorted` but got `typing.Optional[typing.List[str]]`.",
    "message": " Expected `typing.Iterable[Variable[_T]]` for 1st positional only parameter to call `sorted` but got `typing.Optional[typing.List[str]]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 202,
    "warning_line": "                    self.feat_type,"
  }
]