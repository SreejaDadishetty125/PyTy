[
  {
    "project": "kornia/kornia",
    "commit": "6a4fa82792bddc6126eaf944956f49f0a0cb7ca7",
    "filename": "kornia/filters/blur.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/kornia-kornia/kornia/filters/blur.py",
    "file_hunks_size": 4,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "kornia/filters/blur.py:78:11 Call error [29]: `BoxBlur` is not a function.",
    "message": " `BoxBlur` is not a function.",
    "rule_id": "Call error [29]",
    "warning_line_no": 78,
    "warning_line": "    return BoxBlur(kernel_size, border_type, normalized)(input)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import kornia\nfrom kornia.filters.kernels import get_box_kernel2d\nfrom kornia.filters.kernels import normalize_kernel2d\n\n",
        "source_code_len": 121,
        "target_code": "import kornia\nfrom kornia.filters.kernels import (\n    get_box_kernel2d, normalize_kernel2d\n)\n\n\ndef box_blur(input: torch.Tensor,\n             kernel_size: Tuple[int, int],\n             border_type: str = 'reflect',\n             normalized: bool = True) -> torch.Tensor:\n    r\"\"\"Blurs an image using the box filter.\n\n    The function smooths an image using the kernel:\n\n    .. math::\n        K = \\frac{1}{\\text{kernel_size}_x * \\text{kernel_size}_y}\n        \\begin{bmatrix}\n            1 & 1 & 1 & \\cdots & 1 & 1 \\\\\n            1 & 1 & 1 & \\cdots & 1 & 1 \\\\\n            \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n            1 & 1 & 1 & \\cdots & 1 & 1 \\\\\n        \\end{bmatrix}\n\n    Args:\n        image (torch.Tensor): the image to blur with shape :math:`(B,C,H,W)`.\n        kernel_size (Tuple[int, int]): the blurring kernel size.\n        border_type (str): the padding mode to be applied before convolving.\n          The expected modes are: ``'constant'``, ``'reflect'``,\n          ``'replicate'`` or ``'circular'``. Default: ``'reflect'``.\n        normalized (bool): if True, L1 norm of the kernel is set to 1.\n\n    Returns:\n        torch.Tensor: the blurred tensor with shape :math:`(B,C,H,W)`.\n\n    Example:\n        >>> input = torch.rand(2, 4, 5, 7)\n        >>> output = box_blur(input, (3, 3))  # 2x4x5x7\n        >>> output.shape\n        torch.Size([2, 4, 5, 7])\n    \"\"\"\n    kernel: torch.Tensor = get_box_kernel2d(kernel_size)\n    if normalized:\n        kernel = normalize_kernel2d(kernel)\n    return kornia.filter2D(input, kernel, border_type)\n\n",
        "target_code_len": 1565,
        "diff_format": "@@ -6,4 +6,45 @@\n import kornia\n-from kornia.filters.kernels import get_box_kernel2d\n-from kornia.filters.kernels import normalize_kernel2d\n+from kornia.filters.kernels import (\n+    get_box_kernel2d, normalize_kernel2d\n+)\n+\n+\n+def box_blur(input: torch.Tensor,\n+             kernel_size: Tuple[int, int],\n+             border_type: str = 'reflect',\n+             normalized: bool = True) -> torch.Tensor:\n+    r\"\"\"Blurs an image using the box filter.\n+\n+    The function smooths an image using the kernel:\n+\n+    .. math::\n+        K = \\frac{1}{\\text{kernel_size}_x * \\text{kernel_size}_y}\n+        \\begin{bmatrix}\n+            1 & 1 & 1 & \\cdots & 1 & 1 \\\\\n+            1 & 1 & 1 & \\cdots & 1 & 1 \\\\\n+            \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n+            1 & 1 & 1 & \\cdots & 1 & 1 \\\\\n+        \\end{bmatrix}\n+\n+    Args:\n+        image (torch.Tensor): the image to blur with shape :math:`(B,C,H,W)`.\n+        kernel_size (Tuple[int, int]): the blurring kernel size.\n+        border_type (str): the padding mode to be applied before convolving.\n+          The expected modes are: ``'constant'``, ``'reflect'``,\n+          ``'replicate'`` or ``'circular'``. Default: ``'reflect'``.\n+        normalized (bool): if True, L1 norm of the kernel is set to 1.\n+\n+    Returns:\n+        torch.Tensor: the blurred tensor with shape :math:`(B,C,H,W)`.\n+\n+    Example:\n+        >>> input = torch.rand(2, 4, 5, 7)\n+        >>> output = box_blur(input, (3, 3))  # 2x4x5x7\n+        >>> output.shape\n+        torch.Size([2, 4, 5, 7])\n+    \"\"\"\n+    kernel: torch.Tensor = get_box_kernel2d(kernel_size)\n+    if normalized:\n+        kernel = normalize_kernel2d(kernel)\n+    return kornia.filter2D(input, kernel, border_type)\n \n",
        "source_code_with_indent": "import kornia\nfrom kornia.filters.kernels import get_box_kernel2d\nfrom kornia.filters.kernels import normalize_kernel2d\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "import kornia\nfrom kornia.filters.kernels import (\n    get_box_kernel2d, normalize_kernel2d\n)\n\n\ndef box_blur(input: torch.Tensor,\n             kernel_size: Tuple[int, int],\n             border_type: str = 'reflect',\n             normalized: bool = True) -> torch.Tensor:\n    <IND>r\"\"\"Blurs an image using the box filter.\n\n    The function smooths an image using the kernel:\n\n    .. math::\n        K = \\frac{1}{\\text{kernel_size}_x * \\text{kernel_size}_y}\n        \\begin{bmatrix}\n            1 & 1 & 1 & \\cdots & 1 & 1 \\\\\n            1 & 1 & 1 & \\cdots & 1 & 1 \\\\\n            \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n            1 & 1 & 1 & \\cdots & 1 & 1 \\\\\n        \\end{bmatrix}\n\n    Args:\n        image (torch.Tensor): the image to blur with shape :math:`(B,C,H,W)`.\n        kernel_size (Tuple[int, int]): the blurring kernel size.\n        border_type (str): the padding mode to be applied before convolving.\n          The expected modes are: ``'constant'``, ``'reflect'``,\n          ``'replicate'`` or ``'circular'``. Default: ``'reflect'``.\n        normalized (bool): if True, L1 norm of the kernel is set to 1.\n\n    Returns:\n        torch.Tensor: the blurred tensor with shape :math:`(B,C,H,W)`.\n\n    Example:\n        >>> input = torch.rand(2, 4, 5, 7)\n        >>> output = box_blur(input, (3, 3))  # 2x4x5x7\n        >>> output.shape\n        torch.Size([2, 4, 5, 7])\n    \"\"\"\n    kernel: torch.Tensor = get_box_kernel2d(kernel_size)\n    if normalized:\n        <IND>kernel = normalize_kernel2d(kernel)\n    <DED>return kornia.filter2D(input, kernel, border_type)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    def forward(self, input: torch.Tensor):  # type: ignore\n        return kornia.filter2D(input, self.kernel, self.border_type)\n\n\n# functiona api\n# TODO: In terms of functional API, there should not be any initialization of an nn.Module.\n#       This logic is reversed.\n\ndef box_blur(input: torch.Tensor,\n             kernel_size: Tuple[int, int],\n             border_type: str = 'reflect',\n             normalized: bool = True) -> torch.Tensor:\n    r\"\"\"Blurs an image using the box filter.\n\n    See :class:`~kornia.filters.BoxBlur` for details.\n    \"\"\"\n    return BoxBlur(kernel_size, border_type, normalized)(input)\n",
        "source_code_len": 620,
        "target_code": "\n    def forward(self, input: torch.Tensor) -> torch.Tensor:\n        return box_blur(input, self.kernel_size, self.border_type, self.normalized)\n",
        "target_code_len": 145,
        "diff_format": "@@ -61,18 +101,3 @@\n \n-    def forward(self, input: torch.Tensor):  # type: ignore\n-        return kornia.filter2D(input, self.kernel, self.border_type)\n-\n-\n-# functiona api\n-# TODO: In terms of functional API, there should not be any initialization of an nn.Module.\n-#       This logic is reversed.\n-\n-def box_blur(input: torch.Tensor,\n-             kernel_size: Tuple[int, int],\n-             border_type: str = 'reflect',\n-             normalized: bool = True) -> torch.Tensor:\n-    r\"\"\"Blurs an image using the box filter.\n-\n-    See :class:`~kornia.filters.BoxBlur` for details.\n-    \"\"\"\n-    return BoxBlur(kernel_size, border_type, normalized)(input)\n+    def forward(self, input: torch.Tensor) -> torch.Tensor:\n+        return box_blur(input, self.kernel_size, self.border_type, self.normalized)\n",
        "source_code_with_indent": "\n    <DED>def forward(self, input: torch.Tensor):  # type: ignore\n        <IND>return kornia.filter2D(input, self.kernel, self.border_type)\n\n\n# functiona api\n# TODO: In terms of functional API, there should not be any initialization of an nn.Module.\n#       This logic is reversed.\n\n<DED><DED>def box_blur(input: torch.Tensor,\n             kernel_size: Tuple[int, int],\n             border_type: str = 'reflect',\n             normalized: bool = True) -> torch.Tensor:\n    <IND>r\"\"\"Blurs an image using the box filter.\n\n    See :class:`~kornia.filters.BoxBlur` for details.\n    \"\"\"\n    return BoxBlur(kernel_size, border_type, normalized)(input)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>def forward(self, input: torch.Tensor) -> torch.Tensor:\n        <IND>return box_blur(input, self.kernel_size, self.border_type, self.normalized)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "kornia/kornia",
    "commit": "6a4fa82792bddc6126eaf944956f49f0a0cb7ca7",
    "filename": "kornia/filters/gaussian.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/kornia-kornia/kornia/filters/gaussian.py",
    "file_hunks_size": 4,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "kornia/filters/gaussian.py:74:11 Call error [29]: `GaussianBlur2d` is not a function.",
    "message": " `GaussianBlur2d` is not a function.",
    "rule_id": "Call error [29]",
    "warning_line_no": 74,
    "warning_line": "    return GaussianBlur2d(kernel_size, sigma, border_type)(input)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from kornia.filters.kernels import get_gaussian_kernel2d\n\n",
        "source_code_len": 58,
        "target_code": "from kornia.filters.kernels import get_gaussian_kernel2d\n\n\ndef gaussian_blur2d(\n        input: torch.Tensor,\n        kernel_size: Tuple[int, int],\n        sigma: Tuple[float, float],\n        border_type: str = 'reflect') -> torch.Tensor:\n    r\"\"\"Creates an operator that blurs a tensor using a Gaussian filter.\n\n    The operator smooths the given tensor with a gaussian kernel by convolving\n    it to each channel. It supports batched operation.\n\n    Arguments:\n        input (torch.Tensor): the input tensor with shape :math:`(B,C,H,W)`.\n        kernel_size (Tuple[int, int]): the size of the kernel.\n        sigma (Tuple[float, float]): the standard deviation of the kernel.\n        border_type (str): the padding mode to be applied before convolving.\n          The expected modes are: ``'constant'``, ``'reflect'``,\n          ``'replicate'`` or ``'circular'``. Default: ``'reflect'``.\n\n    Returns:\n        torch.Tensor: the blurred tensor with shape :math:`(B, C, H, W)`.\n\n    Examples:\n        >>> input = torch.rand(2, 4, 5, 5)\n        >>> output = gaussian_blur2d(input, (3, 3), (1.5, 1.5))\n        >>> output.shape\n        torch.Size([2, 4, 5, 5])\n    \"\"\"\n    kernel: torch.Tensor = torch.unsqueeze(\n        get_gaussian_kernel2d(kernel_size, sigma), dim=0)\n\n    return kornia.filter2D(input, kernel, border_type)\n\n",
        "target_code_len": 1323,
        "diff_format": "@@ -7,2 +7,35 @@\n from kornia.filters.kernels import get_gaussian_kernel2d\n+\n+\n+def gaussian_blur2d(\n+        input: torch.Tensor,\n+        kernel_size: Tuple[int, int],\n+        sigma: Tuple[float, float],\n+        border_type: str = 'reflect') -> torch.Tensor:\n+    r\"\"\"Creates an operator that blurs a tensor using a Gaussian filter.\n+\n+    The operator smooths the given tensor with a gaussian kernel by convolving\n+    it to each channel. It supports batched operation.\n+\n+    Arguments:\n+        input (torch.Tensor): the input tensor with shape :math:`(B,C,H,W)`.\n+        kernel_size (Tuple[int, int]): the size of the kernel.\n+        sigma (Tuple[float, float]): the standard deviation of the kernel.\n+        border_type (str): the padding mode to be applied before convolving.\n+          The expected modes are: ``'constant'``, ``'reflect'``,\n+          ``'replicate'`` or ``'circular'``. Default: ``'reflect'``.\n+\n+    Returns:\n+        torch.Tensor: the blurred tensor with shape :math:`(B, C, H, W)`.\n+\n+    Examples:\n+        >>> input = torch.rand(2, 4, 5, 5)\n+        >>> output = gaussian_blur2d(input, (3, 3), (1.5, 1.5))\n+        >>> output.shape\n+        torch.Size([2, 4, 5, 5])\n+    \"\"\"\n+    kernel: torch.Tensor = torch.unsqueeze(\n+        get_gaussian_kernel2d(kernel_size, sigma), dim=0)\n+\n+    return kornia.filter2D(input, kernel, border_type)\n \n",
        "source_code_with_indent": "from kornia.filters.kernels import get_gaussian_kernel2d\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from kornia.filters.kernels import get_gaussian_kernel2d\n\n\ndef gaussian_blur2d(\n        input: torch.Tensor,\n        kernel_size: Tuple[int, int],\n        sigma: Tuple[float, float],\n        border_type: str = 'reflect') -> torch.Tensor:\n    <IND>r\"\"\"Creates an operator that blurs a tensor using a Gaussian filter.\n\n    The operator smooths the given tensor with a gaussian kernel by convolving\n    it to each channel. It supports batched operation.\n\n    Arguments:\n        input (torch.Tensor): the input tensor with shape :math:`(B,C,H,W)`.\n        kernel_size (Tuple[int, int]): the size of the kernel.\n        sigma (Tuple[float, float]): the standard deviation of the kernel.\n        border_type (str): the padding mode to be applied before convolving.\n          The expected modes are: ``'constant'``, ``'reflect'``,\n          ``'replicate'`` or ``'circular'``. Default: ``'reflect'``.\n\n    Returns:\n        torch.Tensor: the blurred tensor with shape :math:`(B, C, H, W)`.\n\n    Examples:\n        >>> input = torch.rand(2, 4, 5, 5)\n        >>> output = gaussian_blur2d(input, (3, 3), (1.5, 1.5))\n        >>> output.shape\n        torch.Size([2, 4, 5, 5])\n    \"\"\"\n    kernel: torch.Tensor = torch.unsqueeze(\n        get_gaussian_kernel2d(kernel_size, sigma), dim=0)\n\n    return kornia.filter2D(input, kernel, border_type)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    def forward(self, x: torch.Tensor):  # type: ignore\n        return kornia.filter2D(x, self.kernel, self.border_type)\n\n\n######################\n# functional interface\n######################\n# TODO: In terms of functional API, there should not be any initialization of an nn.Module.\n#       This logic is reversed.\n\ndef gaussian_blur2d(\n        input: torch.Tensor,\n        kernel_size: Tuple[int, int],\n        sigma: Tuple[float, float],\n        border_type: str = 'reflect') -> torch.Tensor:\n    r\"\"\"Function that blurs a tensor using a Gaussian filter.\n\n    See :class:`~kornia.filters.GaussianBlur` for details.\n    \"\"\"\n    return GaussianBlur2d(kernel_size, sigma, border_type)(input)\n",
        "source_code_len": 693,
        "target_code": "\n    def forward(self, input: torch.Tensor) -> torch.Tensor:\n        return gaussian_blur2d(input, self.kernel_size, self.sigma, self.border_type)\n",
        "target_code_len": 147,
        "diff_format": "@@ -54,21 +85,3 @@\n \n-    def forward(self, x: torch.Tensor):  # type: ignore\n-        return kornia.filter2D(x, self.kernel, self.border_type)\n-\n-\n-######################\n-# functional interface\n-######################\n-# TODO: In terms of functional API, there should not be any initialization of an nn.Module.\n-#       This logic is reversed.\n-\n-def gaussian_blur2d(\n-        input: torch.Tensor,\n-        kernel_size: Tuple[int, int],\n-        sigma: Tuple[float, float],\n-        border_type: str = 'reflect') -> torch.Tensor:\n-    r\"\"\"Function that blurs a tensor using a Gaussian filter.\n-\n-    See :class:`~kornia.filters.GaussianBlur` for details.\n-    \"\"\"\n-    return GaussianBlur2d(kernel_size, sigma, border_type)(input)\n+    def forward(self, input: torch.Tensor) -> torch.Tensor:\n+        return gaussian_blur2d(input, self.kernel_size, self.sigma, self.border_type)\n",
        "source_code_with_indent": "\n    <DED>def forward(self, x: torch.Tensor):  # type: ignore\n        <IND>return kornia.filter2D(x, self.kernel, self.border_type)\n\n\n######################\n# functional interface\n######################\n# TODO: In terms of functional API, there should not be any initialization of an nn.Module.\n#       This logic is reversed.\n\n<DED><DED>def gaussian_blur2d(\n        input: torch.Tensor,\n        kernel_size: Tuple[int, int],\n        sigma: Tuple[float, float],\n        border_type: str = 'reflect') -> torch.Tensor:\n    <IND>r\"\"\"Function that blurs a tensor using a Gaussian filter.\n\n    See :class:`~kornia.filters.GaussianBlur` for details.\n    \"\"\"\n    return GaussianBlur2d(kernel_size, sigma, border_type)(input)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>def forward(self, input: torch.Tensor) -> torch.Tensor:\n        <IND>return gaussian_blur2d(input, self.kernel_size, self.sigma, self.border_type)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "kornia/kornia",
    "commit": "6a4fa82792bddc6126eaf944956f49f0a0cb7ca7",
    "filename": "kornia/filters/laplacian.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/kornia-kornia/kornia/filters/laplacian.py",
    "file_hunks_size": 5,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "kornia/filters/laplacian.py:75:11 Call error [29]: `Laplacian` is not a function.",
    "message": " `Laplacian` is not a function.",
    "rule_id": "Call error [29]",
    "warning_line_no": 75,
    "warning_line": "    return Laplacian(kernel_size, border_type, normalized)(input)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from kornia.filters.kernels import normalize_kernel2d\n\n",
        "source_code_len": 55,
        "target_code": "from kornia.filters.kernels import normalize_kernel2d\n\n\ndef laplacian(\n        input: torch.Tensor,\n        kernel_size: int,\n        border_type: str = 'reflect',\n        normalized: bool = True) -> torch.Tensor:\n    r\"\"\"Creates an operator that returns a tensor using a Laplacian filter.\n\n    The operator smooths the given tensor with a laplacian kernel by convolving\n    it to each channel. It supports batched operation.\n\n    Arguments:\n        input (torch.Tensor): the input image tensor with shape :math:`(B, C, H, W)`.\n        kernel_size (int): the size of the kernel.\n        border_type (str): the padding mode to be applied before convolving.\n          The expected modes are: ``'constant'``, ``'reflect'``,\n          ``'replicate'`` or ``'circular'``. Default: ``'reflect'``.\n        normalized (bool): if True, L1 norm of the kernel is set to 1.\n\n    Return:\n        torch.Tensor: the blurred image with shape :math:`(B, C, H, W)`.\n\n    Examples:\n        >>> input = torch.rand(2, 4, 5, 5)\n        >>> output = laplacian(input, 3)\n        >>> output.shape\n        torch.Size([2, 4, 5, 5])\n    \"\"\"\n    kernel: torch.Tensor = torch.unsqueeze(\n        get_laplacian_kernel2d(kernel_size), dim=0)\n\n    if normalized:\n        kernel = normalize_kernel2d(kernel)\n\n    return kornia.filter2D(input, kernel, border_type)\n\n",
        "target_code_len": 1329,
        "diff_format": "@@ -8,2 +8,38 @@\n from kornia.filters.kernels import normalize_kernel2d\n+\n+\n+def laplacian(\n+        input: torch.Tensor,\n+        kernel_size: int,\n+        border_type: str = 'reflect',\n+        normalized: bool = True) -> torch.Tensor:\n+    r\"\"\"Creates an operator that returns a tensor using a Laplacian filter.\n+\n+    The operator smooths the given tensor with a laplacian kernel by convolving\n+    it to each channel. It supports batched operation.\n+\n+    Arguments:\n+        input (torch.Tensor): the input image tensor with shape :math:`(B, C, H, W)`.\n+        kernel_size (int): the size of the kernel.\n+        border_type (str): the padding mode to be applied before convolving.\n+          The expected modes are: ``'constant'``, ``'reflect'``,\n+          ``'replicate'`` or ``'circular'``. Default: ``'reflect'``.\n+        normalized (bool): if True, L1 norm of the kernel is set to 1.\n+\n+    Return:\n+        torch.Tensor: the blurred image with shape :math:`(B, C, H, W)`.\n+\n+    Examples:\n+        >>> input = torch.rand(2, 4, 5, 5)\n+        >>> output = laplacian(input, 3)\n+        >>> output.shape\n+        torch.Size([2, 4, 5, 5])\n+    \"\"\"\n+    kernel: torch.Tensor = torch.unsqueeze(\n+        get_laplacian_kernel2d(kernel_size), dim=0)\n+\n+    if normalized:\n+        kernel = normalize_kernel2d(kernel)\n+\n+    return kornia.filter2D(input, kernel, border_type)\n \n",
        "source_code_with_indent": "from kornia.filters.kernels import normalize_kernel2d\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from kornia.filters.kernels import normalize_kernel2d\n\n\ndef laplacian(\n        input: torch.Tensor,\n        kernel_size: int,\n        border_type: str = 'reflect',\n        normalized: bool = True) -> torch.Tensor:\n    <IND>r\"\"\"Creates an operator that returns a tensor using a Laplacian filter.\n\n    The operator smooths the given tensor with a laplacian kernel by convolving\n    it to each channel. It supports batched operation.\n\n    Arguments:\n        input (torch.Tensor): the input image tensor with shape :math:`(B, C, H, W)`.\n        kernel_size (int): the size of the kernel.\n        border_type (str): the padding mode to be applied before convolving.\n          The expected modes are: ``'constant'``, ``'reflect'``,\n          ``'replicate'`` or ``'circular'``. Default: ``'reflect'``.\n        normalized (bool): if True, L1 norm of the kernel is set to 1.\n\n    Return:\n        torch.Tensor: the blurred image with shape :math:`(B, C, H, W)`.\n\n    Examples:\n        >>> input = torch.rand(2, 4, 5, 5)\n        >>> output = laplacian(input, 3)\n        >>> output.shape\n        torch.Size([2, 4, 5, 5])\n    \"\"\"\n    kernel: torch.Tensor = torch.unsqueeze(\n        get_laplacian_kernel2d(kernel_size), dim=0)\n\n    if normalized:\n        <IND>kernel = normalize_kernel2d(kernel)\n\n    <DED>return kornia.filter2D(input, kernel, border_type)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    def forward(self, input: torch.Tensor):  # type: ignore\n        return kornia.filter2D(input, self.kernel, self.border_type)\n\n\n######################\n# functional interface\n######################\n# TODO: In terms of functional API, there should not be any initialization of an nn.Module.\n#       This logic is reversed.\n\ndef laplacian(\n        input: torch.Tensor,\n        kernel_size: int,\n        border_type: str = 'reflect',\n        normalized: bool = True) -> torch.Tensor:\n    r\"\"\"Function that returns a tensor using a Laplacian filter.\n\n    See :class:`~kornia.filters.Laplacian` for details.\n    \"\"\"\n    return Laplacian(kernel_size, border_type, normalized)(input)\n",
        "source_code_len": 680,
        "target_code": "\n    def forward(self, input: torch.Tensor) -> torch.Tensor:\n        return laplacian(input, self.kernel_size, self.border_type, self.normalized)\n",
        "target_code_len": 146,
        "diff_format": "@@ -55,21 +85,3 @@\n \n-    def forward(self, input: torch.Tensor):  # type: ignore\n-        return kornia.filter2D(input, self.kernel, self.border_type)\n-\n-\n-######################\n-# functional interface\n-######################\n-# TODO: In terms of functional API, there should not be any initialization of an nn.Module.\n-#       This logic is reversed.\n-\n-def laplacian(\n-        input: torch.Tensor,\n-        kernel_size: int,\n-        border_type: str = 'reflect',\n-        normalized: bool = True) -> torch.Tensor:\n-    r\"\"\"Function that returns a tensor using a Laplacian filter.\n-\n-    See :class:`~kornia.filters.Laplacian` for details.\n-    \"\"\"\n-    return Laplacian(kernel_size, border_type, normalized)(input)\n+    def forward(self, input: torch.Tensor) -> torch.Tensor:\n+        return laplacian(input, self.kernel_size, self.border_type, self.normalized)\n",
        "source_code_with_indent": "\n    <DED>def forward(self, input: torch.Tensor):  # type: ignore\n        <IND>return kornia.filter2D(input, self.kernel, self.border_type)\n\n\n######################\n# functional interface\n######################\n# TODO: In terms of functional API, there should not be any initialization of an nn.Module.\n#       This logic is reversed.\n\n<DED><DED>def laplacian(\n        input: torch.Tensor,\n        kernel_size: int,\n        border_type: str = 'reflect',\n        normalized: bool = True) -> torch.Tensor:\n    <IND>r\"\"\"Function that returns a tensor using a Laplacian filter.\n\n    See :class:`~kornia.filters.Laplacian` for details.\n    \"\"\"\n    return Laplacian(kernel_size, border_type, normalized)(input)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>def forward(self, input: torch.Tensor) -> torch.Tensor:\n        <IND>return laplacian(input, self.kernel_size, self.border_type, self.normalized)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "kornia/kornia",
    "commit": "6a4fa82792bddc6126eaf944956f49f0a0cb7ca7",
    "filename": "kornia/filters/median.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/kornia-kornia/kornia/filters/median.py",
    "file_hunks_size": 5,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "kornia/filters/median.py:68:11 Call error [29]: `MedianBlur` is not a function.",
    "message": " `MedianBlur` is not a function.",
    "rule_id": "Call error [29]",
    "warning_line_no": 68,
    "warning_line": "    return MedianBlur(kernel_size)(input)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from typing import Tuple\n\n",
        "source_code_len": 26,
        "target_code": "from typing import List, Tuple\n\n",
        "target_code_len": 32,
        "diff_format": "@@ -1,2 +1,2 @@\n-from typing import Tuple\n+from typing import List, Tuple\n \n",
        "source_code_with_indent": "from typing import Tuple\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from typing import List, Tuple\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    r\"\"\"Utility function that computes zero padding tuple.\"\"\"\n    computed: Tuple[int, ...] = tuple([(k - 1) // 2 for k in kernel_size])\n    return computed[0], computed[1]\n\n",
        "source_code_len": 174,
        "target_code": "    r\"\"\"Utility function that computes zero padding tuple.\"\"\"\n    computed: List[int] = [(k - 1) // 2 for k in kernel_size]\n    return computed[0], computed[1]\n\n\ndef median_blur(input: torch.Tensor,\n                kernel_size: Tuple[int, int]) -> torch.Tensor:\n    r\"\"\"Blurs an image using the median filter.\n\n    Args:\n        input (torch.Tensor): the input image with shape :math:`(B,C,H,W)`.\n        kernel_size (Tuple[int, int]): the blurring kernel size.\n\n    Returns:\n        torch.Tensor: the blurred input tensor with shape :math:`(B,C,H,W)`.\n\n    Example:\n        >>> input = torch.rand(2, 4, 5, 7)\n        >>> output = median_blur(input, (3, 3))\n        >>> output.shape\n        torch.Size([2, 4, 5, 7])\n    \"\"\"\n    if not isinstance(input, torch.Tensor):\n        raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n                        .format(type(input)))\n\n    if not len(input.shape) == 4:\n        raise ValueError(\"Invalid input shape, we expect BxCxHxW. Got: {}\"\n                         .format(input.shape))\n\n    padding: Tuple[int, int] = _compute_zero_padding(kernel_size)\n\n    # prepare kernel\n    kernel: torch.Tensor = get_binary_kernel2d(kernel_size).to(input)\n    b, c, h, w = input.shape\n\n    # map the local window to single vector\n    features: torch.Tensor = F.conv2d(\n        input.reshape(b * c, 1, h, w), kernel, padding=padding, stride=1)\n    features = features.view(b, c, -1, h, w)  # BxCx(K_h * K_w)xHxW\n\n    # compute the median along the feature axis\n    median: torch.Tensor = torch.median(features, dim=2)[0]\n\n    return median\n\n",
        "target_code_len": 1581,
        "diff_format": "@@ -10,4 +11,46 @@\n     r\"\"\"Utility function that computes zero padding tuple.\"\"\"\n-    computed: Tuple[int, ...] = tuple([(k - 1) // 2 for k in kernel_size])\n+    computed: List[int] = [(k - 1) // 2 for k in kernel_size]\n     return computed[0], computed[1]\n+\n+\n+def median_blur(input: torch.Tensor,\n+                kernel_size: Tuple[int, int]) -> torch.Tensor:\n+    r\"\"\"Blurs an image using the median filter.\n+\n+    Args:\n+        input (torch.Tensor): the input image with shape :math:`(B,C,H,W)`.\n+        kernel_size (Tuple[int, int]): the blurring kernel size.\n+\n+    Returns:\n+        torch.Tensor: the blurred input tensor with shape :math:`(B,C,H,W)`.\n+\n+    Example:\n+        >>> input = torch.rand(2, 4, 5, 7)\n+        >>> output = median_blur(input, (3, 3))\n+        >>> output.shape\n+        torch.Size([2, 4, 5, 7])\n+    \"\"\"\n+    if not isinstance(input, torch.Tensor):\n+        raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n+                        .format(type(input)))\n+\n+    if not len(input.shape) == 4:\n+        raise ValueError(\"Invalid input shape, we expect BxCxHxW. Got: {}\"\n+                         .format(input.shape))\n+\n+    padding: Tuple[int, int] = _compute_zero_padding(kernel_size)\n+\n+    # prepare kernel\n+    kernel: torch.Tensor = get_binary_kernel2d(kernel_size).to(input)\n+    b, c, h, w = input.shape\n+\n+    # map the local window to single vector\n+    features: torch.Tensor = F.conv2d(\n+        input.reshape(b * c, 1, h, w), kernel, padding=padding, stride=1)\n+    features = features.view(b, c, -1, h, w)  # BxCx(K_h * K_w)xHxW\n+\n+    # compute the median along the feature axis\n+    median: torch.Tensor = torch.median(features, dim=2)[0]\n+\n+    return median\n \n",
        "source_code_with_indent": "    <IND>r\"\"\"Utility function that computes zero padding tuple.\"\"\"\n    computed: Tuple[int, ...] = tuple([(k - 1) // 2 for k in kernel_size])\n    return computed[0], computed[1]\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <IND>r\"\"\"Utility function that computes zero padding tuple.\"\"\"\n    computed: List[int] = [(k - 1) // 2 for k in kernel_size]\n    return computed[0], computed[1]\n\n\n<DED>def median_blur(input: torch.Tensor,\n                kernel_size: Tuple[int, int]) -> torch.Tensor:\n    <IND>r\"\"\"Blurs an image using the median filter.\n\n    Args:\n        input (torch.Tensor): the input image with shape :math:`(B,C,H,W)`.\n        kernel_size (Tuple[int, int]): the blurring kernel size.\n\n    Returns:\n        torch.Tensor: the blurred input tensor with shape :math:`(B,C,H,W)`.\n\n    Example:\n        >>> input = torch.rand(2, 4, 5, 7)\n        >>> output = median_blur(input, (3, 3))\n        >>> output.shape\n        torch.Size([2, 4, 5, 7])\n    \"\"\"\n    if not isinstance(input, torch.Tensor):\n        <IND>raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n                        .format(type(input)))\n\n    <DED>if not len(input.shape) == 4:\n        <IND>raise ValueError(\"Invalid input shape, we expect BxCxHxW. Got: {}\"\n                         .format(input.shape))\n\n    <DED>padding: Tuple[int, int] = _compute_zero_padding(kernel_size)\n\n    # prepare kernel\n    kernel: torch.Tensor = get_binary_kernel2d(kernel_size).to(input)\n    b, c, h, w = input.shape\n\n    # map the local window to single vector\n    features: torch.Tensor = F.conv2d(\n        input.reshape(b * c, 1, h, w), kernel, padding=padding, stride=1)\n    features = features.view(b, c, -1, h, w)  # BxCx(K_h * K_w)xHxW\n\n    # compute the median along the feature axis\n    median: torch.Tensor = torch.median(features, dim=2)[0]\n\n    return median\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        super(MedianBlur, self).__init__()\n        self.kernel: torch.Tensor = get_binary_kernel2d(kernel_size)\n        self.padding: Tuple[int, int] = _compute_zero_padding(kernel_size)\n\n    def forward(self, input: torch.Tensor):  # type: ignore\n        if not torch.is_tensor(input):\n            raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n                            .format(type(input)))\n        if not len(input.shape) == 4:\n            raise ValueError(\"Invalid input shape, we expect BxCxHxW. Got: {}\"\n                             .format(input.shape))\n        # prepare kernel\n        b, c, h, w = input.shape\n        kernel: torch.Tensor = self.kernel.to(input.device).to(input.dtype)\n        # map the local window to single vector\n        features: torch.Tensor = F.conv2d(\n            input.reshape(b * c, 1, h, w), kernel, padding=self.padding, stride=1)\n        features = features.view(b, c, -1, h, w)  # BxCx(K_h * K_w)xHxW\n\n        # compute the median along the feature axis\n        median: torch.Tensor = torch.median(features, dim=2)[0]\n        return median\n\n\n# functiona api\n\n\ndef median_blur(input: torch.Tensor,\n                kernel_size: Tuple[int, int]) -> torch.Tensor:\n    r\"\"\"Blurs an image using the median filter.\n\n    See :class:`~kornia.filters.MedianBlur` for details.\n    \"\"\"\n    return MedianBlur(kernel_size)(input)\n",
        "source_code_len": 1371,
        "target_code": "        super(MedianBlur, self).__init__()\n        self.kernel_size: Tuple[int, int] = kernel_size\n\n    def forward(self, input: torch.Tensor) -> torch.Tensor:\n        return median_blur(input, self.kernel_size)\n",
        "target_code_len": 212,
        "diff_format": "@@ -35,34 +80,5 @@\n         super(MedianBlur, self).__init__()\n-        self.kernel: torch.Tensor = get_binary_kernel2d(kernel_size)\n-        self.padding: Tuple[int, int] = _compute_zero_padding(kernel_size)\n+        self.kernel_size: Tuple[int, int] = kernel_size\n \n-    def forward(self, input: torch.Tensor):  # type: ignore\n-        if not torch.is_tensor(input):\n-            raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n-                            .format(type(input)))\n-        if not len(input.shape) == 4:\n-            raise ValueError(\"Invalid input shape, we expect BxCxHxW. Got: {}\"\n-                             .format(input.shape))\n-        # prepare kernel\n-        b, c, h, w = input.shape\n-        kernel: torch.Tensor = self.kernel.to(input.device).to(input.dtype)\n-        # map the local window to single vector\n-        features: torch.Tensor = F.conv2d(\n-            input.reshape(b * c, 1, h, w), kernel, padding=self.padding, stride=1)\n-        features = features.view(b, c, -1, h, w)  # BxCx(K_h * K_w)xHxW\n-\n-        # compute the median along the feature axis\n-        median: torch.Tensor = torch.median(features, dim=2)[0]\n-        return median\n-\n-\n-# functiona api\n-\n-\n-def median_blur(input: torch.Tensor,\n-                kernel_size: Tuple[int, int]) -> torch.Tensor:\n-    r\"\"\"Blurs an image using the median filter.\n-\n-    See :class:`~kornia.filters.MedianBlur` for details.\n-    \"\"\"\n-    return MedianBlur(kernel_size)(input)\n+    def forward(self, input: torch.Tensor) -> torch.Tensor:\n+        return median_blur(input, self.kernel_size)\n",
        "source_code_with_indent": "        <IND>super(MedianBlur, self).__init__()\n        self.kernel: torch.Tensor = get_binary_kernel2d(kernel_size)\n        self.padding: Tuple[int, int] = _compute_zero_padding(kernel_size)\n\n    <DED>def forward(self, input: torch.Tensor):  # type: ignore\n        <IND>if not torch.is_tensor(input):\n            <IND>raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n                            .format(type(input)))\n        <DED>if not len(input.shape) == 4:\n            <IND>raise ValueError(\"Invalid input shape, we expect BxCxHxW. Got: {}\"\n                             .format(input.shape))\n        # prepare kernel\n        <DED>b, c, h, w = input.shape\n        kernel: torch.Tensor = self.kernel.to(input.device).to(input.dtype)\n        # map the local window to single vector\n        features: torch.Tensor = F.conv2d(\n            input.reshape(b * c, 1, h, w), kernel, padding=self.padding, stride=1)\n        features = features.view(b, c, -1, h, w)  # BxCx(K_h * K_w)xHxW\n\n        # compute the median along the feature axis\n        median: torch.Tensor = torch.median(features, dim=2)[0]\n        return median\n\n\n# functiona api\n\n\n<DED><DED>def median_blur(input: torch.Tensor,\n                kernel_size: Tuple[int, int]) -> torch.Tensor:\n    <IND>r\"\"\"Blurs an image using the median filter.\n\n    See :class:`~kornia.filters.MedianBlur` for details.\n    \"\"\"\n    return MedianBlur(kernel_size)(input)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        <IND>super(MedianBlur, self).__init__()\n        self.kernel_size: Tuple[int, int] = kernel_size\n\n    <DED>def forward(self, input: torch.Tensor) -> torch.Tensor:\n        <IND>return median_blur(input, self.kernel_size)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "kornia/kornia",
    "commit": "6a4fa82792bddc6126eaf944956f49f0a0cb7ca7",
    "filename": "kornia/filters/sobel.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/kornia-kornia/kornia/filters/sobel.py",
    "file_hunks_size": 10,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "kornia/filters/sobel.py:185:11 Call error [29]: `SpatialGradient` is not a function.",
    "message": " `SpatialGradient` is not a function.",
    "rule_id": "Call error [29]",
    "warning_line_no": 185,
    "warning_line": "    return SpatialGradient(mode, order, normalized)(input)"
  },
  {
    "project": "kornia/kornia",
    "commit": "6a4fa82792bddc6126eaf944956f49f0a0cb7ca7",
    "filename": "kornia/filters/sobel.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/kornia-kornia/kornia/filters/sobel.py",
    "file_hunks_size": 10,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "kornia/filters/sobel.py:196:11 Call error [29]: `SpatialGradient3d` is not a function.",
    "message": " `SpatialGradient3d` is not a function.",
    "rule_id": "Call error [29]",
    "warning_line_no": 196,
    "warning_line": "    return SpatialGradient3d(mode, order)(input)"
  },
  {
    "project": "kornia/kornia",
    "commit": "6a4fa82792bddc6126eaf944956f49f0a0cb7ca7",
    "filename": "kornia/filters/sobel.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/kornia-kornia/kornia/filters/sobel.py",
    "file_hunks_size": 10,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "kornia/filters/sobel.py:204:11 Call error [29]: `Sobel` is not a function.",
    "message": " `Sobel` is not a function.",
    "rule_id": "Call error [29]",
    "warning_line_no": 204,
    "warning_line": "    return Sobel(normalized, eps)(input)"
  }
]