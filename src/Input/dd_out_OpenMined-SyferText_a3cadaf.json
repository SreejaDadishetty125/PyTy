[
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/__init__.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/__init__.py",
    "file_hunks_size": 1,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "syfertext/__init__.py:43:8 Incompatible return type [7]: Expected `Language` but got `None`.",
    "message": " Expected `Language` but got `None`.",
    "rule_id": "Incompatible return type [7]",
    "warning_line_no": 43,
    "warning_line": "        return",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import syft\nfrom syft.serde.msgpack.serde import msgpack_global_state\nfrom syft.workers.base import BaseWorker\nimport torch\nimport dill\nimport os\nfrom pathlib import Path\n\n# Get a torch hook\nHOOK = syft.TorchHook(torch)\n\n# Set the local worker\nLOCAL_WORKER = HOOK.local_worker\n\nfrom .language import Language\nfrom .pipeline import SubPipeline\nfrom .pipeline import Pipeline\nfrom .pipeline.pointers.pipeline_pointer import PipelinePointer\nfrom .pointers.state_pointer import StatePointer\nfrom .utils import search_resource, create_state_query\n\nfrom typing import Set\nfrom typing import Union\n\n\ndef load(pipeline_name: str) -> Language:\n    \"\"\"Searches for `pipeline_name` on PyGrid and loads it as a Language object.\n\n    Args:\n        pipeline_name (str): The name of the pipeline to search for  on PyGrid.\n\n    Returns:\n        a an object of the Language class, representing the requested pipeline.\n    \"\"\"\n\n    # Search for the pipeline\n    result = search_resource(query=pipeline_name, local_worker=LOCAL_WORKER)\n\n    pipeline = None\n\n    # If no pipeline is found, return\n    if not result:\n        return\n\n    # If a pipeline is found get either its pointer if it is remote\n    # or the pipeline itself if it is local\n    elif isinstance(result, PipelinePointer):\n\n        # The ID of the worker on which the pipeline is deployed\n        deployed_on = result.location.id\n\n        # Get a copy of the pipeline using its pointer\n        pipeline = result.get_copy()\n\n        # Save the pipeline to local storage\n        save(pipeline_name=pipeline_name, pipeline=pipeline, destination=\"local\")\n\n    elif isinstance(result, Pipeline):\n\n        # In this case, the Pipeline object is found on the local worker\n        # which is a virtual worker by default as of the current PySyft version\n        # 0.2.9. We do not consider that it is officially deployed.\n        deployed_on = None\n\n        # Get the pipeline object\n        pipeline = result\n\n    elif isinstance(result, tuple):\n\n        # In this case we get a simplified pipeline object,\n        # from the stored cache which is a tuple.\n        # The following code details it back to a pipeline object.\n\n        pipeline = Pipeline.detail(worker=LOCAL_WORKER, pipeline_simple=result)\n\n        # Since we found the model in local storage, deployed_on = None\n\n        deployed_on = None\n\n    # Instantiate a Language object\n    nlp = Language(\n        pipeline_name, owner=LOCAL_WORKER, tags=pipeline.tags, description=pipeline.description\n    )\n\n    # Set the `deployed_on` property\n    nlp.deployed_on = deployed_on\n\n    # Load the pipeline into the Language object\n    nlp.load_pipeline(template=pipeline.template, states_info=pipeline.states_info)\n\n    return nlp\n\n\ndef create(pipeline_name, tags: Set[str] = None, description: str = None):\n    \"\"\"Creates a new Language object. This function is used when a new pipeline\n    is constructed from local files.\n\n\n    Args:\n        pipeline_name (str): The name of the pipeline to create.\n        tags (set): A set of str that help search for the pipeline across workers.\n        description (str): A str that describes the Language object.\n\n\n    Returns:\n        a an object of the Language class, representing the created pipeline.\n    \"\"\"\n\n    # TODO: The create method should first search over pygrid to make sure no other\n    #      model has the same name\n\n    # Instantiate a Language object\n    nlp = Language(\n        pipeline_name=pipeline_name, owner=LOCAL_WORKER, tags=tags, description=description\n    )\n\n    return nlp\n\n\n# Set the default owners of some classes\n# SubPipeline.owner = LOCAL_WORKER\n\n\ndef save(pipeline_name: str, pipeline: \"Pipeline\", destination: Union[\"local\"] = \"local\") -> None:\n    \"\"\"Saves the pipeline and it's states to storage\n\n    Args:\n        pipeline_name (str): The name of the pipeline.\n        pipeline (Pipeline): The pipeline object itself\n        destination (Union): The location where to save that object, currently storage on local machine is implemented.\n\n    \"\"\"\n\n    # Path to the home/SyferText/cache/<pipeline_name> directory\n    data_path = os.path.join(str(Path.home()), \"SyferText\", \"cache\", pipeline_name)\n\n    # Creating a new directory if home/SyferText/cache/<pipeline_name> does not exist\n    if not os.path.exists(data_path):\n        os.makedirs(data_path, exist_ok=True)\n\n    # Making a target at the file\n    target = str(\"/{}.pkl\".format(pipeline_name))\n\n    # Opening cache file\n    pipeline_cache = open(data_path + target, \"wb\")\n\n    # Dumping data\n    dill.dump(pipeline.simplify(worker=LOCAL_WORKER, pipeline=pipeline), pipeline_cache)\n\n    # Loading states\n    for state in pipeline.states_info:\n        # Searching on state\n        state_id = create_state_query(pipeline_name=pipeline_name, state_name=state)\n\n        result = search_resource(query=state_id, local_worker=LOCAL_WORKER)\n\n        if isinstance(result, StatePointer):\n            # State target\n\n            # Since : is a reserved character for naming files, replacing with - instead\n            # Splitting tokens to get the name of the pipeline for the name of the pipeline directory\n\n            file_name = state_id.replace(\":\", \"-\")\n\n            target = str(\"/{}.pkl\".format(file_name))\n\n            state_obj = result.get_copy()\n\n            state_cache = open(data_path + target, \"wb\")\n\n            dill.dump(state_obj.simplify(worker=LOCAL_WORKER, state=state_obj), state_cache)\n\n    pipeline_cache.close()\n",
        "source_code_len": 5464,
        "target_code": "__version__ = \"0.2.0\"\n",
        "target_code_len": 22,
        "diff_format": "@@ -1,173 +1,1 @@\n-import syft\n-from syft.serde.msgpack.serde import msgpack_global_state\n-from syft.workers.base import BaseWorker\n-import torch\n-import dill\n-import os\n-from pathlib import Path\n-\n-# Get a torch hook\n-HOOK = syft.TorchHook(torch)\n-\n-# Set the local worker\n-LOCAL_WORKER = HOOK.local_worker\n-\n-from .language import Language\n-from .pipeline import SubPipeline\n-from .pipeline import Pipeline\n-from .pipeline.pointers.pipeline_pointer import PipelinePointer\n-from .pointers.state_pointer import StatePointer\n-from .utils import search_resource, create_state_query\n-\n-from typing import Set\n-from typing import Union\n-\n-\n-def load(pipeline_name: str) -> Language:\n-    \"\"\"Searches for `pipeline_name` on PyGrid and loads it as a Language object.\n-\n-    Args:\n-        pipeline_name (str): The name of the pipeline to search for  on PyGrid.\n-\n-    Returns:\n-        a an object of the Language class, representing the requested pipeline.\n-    \"\"\"\n-\n-    # Search for the pipeline\n-    result = search_resource(query=pipeline_name, local_worker=LOCAL_WORKER)\n-\n-    pipeline = None\n-\n-    # If no pipeline is found, return\n-    if not result:\n-        return\n-\n-    # If a pipeline is found get either its pointer if it is remote\n-    # or the pipeline itself if it is local\n-    elif isinstance(result, PipelinePointer):\n-\n-        # The ID of the worker on which the pipeline is deployed\n-        deployed_on = result.location.id\n-\n-        # Get a copy of the pipeline using its pointer\n-        pipeline = result.get_copy()\n-\n-        # Save the pipeline to local storage\n-        save(pipeline_name=pipeline_name, pipeline=pipeline, destination=\"local\")\n-\n-    elif isinstance(result, Pipeline):\n-\n-        # In this case, the Pipeline object is found on the local worker\n-        # which is a virtual worker by default as of the current PySyft version\n-        # 0.2.9. We do not consider that it is officially deployed.\n-        deployed_on = None\n-\n-        # Get the pipeline object\n-        pipeline = result\n-\n-    elif isinstance(result, tuple):\n-\n-        # In this case we get a simplified pipeline object,\n-        # from the stored cache which is a tuple.\n-        # The following code details it back to a pipeline object.\n-\n-        pipeline = Pipeline.detail(worker=LOCAL_WORKER, pipeline_simple=result)\n-\n-        # Since we found the model in local storage, deployed_on = None\n-\n-        deployed_on = None\n-\n-    # Instantiate a Language object\n-    nlp = Language(\n-        pipeline_name, owner=LOCAL_WORKER, tags=pipeline.tags, description=pipeline.description\n-    )\n-\n-    # Set the `deployed_on` property\n-    nlp.deployed_on = deployed_on\n-\n-    # Load the pipeline into the Language object\n-    nlp.load_pipeline(template=pipeline.template, states_info=pipeline.states_info)\n-\n-    return nlp\n-\n-\n-def create(pipeline_name, tags: Set[str] = None, description: str = None):\n-    \"\"\"Creates a new Language object. This function is used when a new pipeline\n-    is constructed from local files.\n-\n-\n-    Args:\n-        pipeline_name (str): The name of the pipeline to create.\n-        tags (set): A set of str that help search for the pipeline across workers.\n-        description (str): A str that describes the Language object.\n-\n-\n-    Returns:\n-        a an object of the Language class, representing the created pipeline.\n-    \"\"\"\n-\n-    # TODO: The create method should first search over pygrid to make sure no other\n-    #      model has the same name\n-\n-    # Instantiate a Language object\n-    nlp = Language(\n-        pipeline_name=pipeline_name, owner=LOCAL_WORKER, tags=tags, description=description\n-    )\n-\n-    return nlp\n-\n-\n-# Set the default owners of some classes\n-# SubPipeline.owner = LOCAL_WORKER\n-\n-\n-def save(pipeline_name: str, pipeline: \"Pipeline\", destination: Union[\"local\"] = \"local\") -> None:\n-    \"\"\"Saves the pipeline and it's states to storage\n-\n-    Args:\n-        pipeline_name (str): The name of the pipeline.\n-        pipeline (Pipeline): The pipeline object itself\n-        destination (Union): The location where to save that object, currently storage on local machine is implemented.\n-\n-    \"\"\"\n-\n-    # Path to the home/SyferText/cache/<pipeline_name> directory\n-    data_path = os.path.join(str(Path.home()), \"SyferText\", \"cache\", pipeline_name)\n-\n-    # Creating a new directory if home/SyferText/cache/<pipeline_name> does not exist\n-    if not os.path.exists(data_path):\n-        os.makedirs(data_path, exist_ok=True)\n-\n-    # Making a target at the file\n-    target = str(\"/{}.pkl\".format(pipeline_name))\n-\n-    # Opening cache file\n-    pipeline_cache = open(data_path + target, \"wb\")\n-\n-    # Dumping data\n-    dill.dump(pipeline.simplify(worker=LOCAL_WORKER, pipeline=pipeline), pipeline_cache)\n-\n-    # Loading states\n-    for state in pipeline.states_info:\n-        # Searching on state\n-        state_id = create_state_query(pipeline_name=pipeline_name, state_name=state)\n-\n-        result = search_resource(query=state_id, local_worker=LOCAL_WORKER)\n-\n-        if isinstance(result, StatePointer):\n-            # State target\n-\n-            # Since : is a reserved character for naming files, replacing with - instead\n-            # Splitting tokens to get the name of the pipeline for the name of the pipeline directory\n-\n-            file_name = state_id.replace(\":\", \"-\")\n-\n-            target = str(\"/{}.pkl\".format(file_name))\n-\n-            state_obj = result.get_copy()\n-\n-            state_cache = open(data_path + target, \"wb\")\n-\n-            dill.dump(state_obj.simplify(worker=LOCAL_WORKER, state=state_obj), state_cache)\n-\n-    pipeline_cache.close()\n+__version__ = \"0.2.0\"\n",
        "source_code_with_indent": "import syft\nfrom syft.serde.msgpack.serde import msgpack_global_state\nfrom syft.workers.base import BaseWorker\nimport torch\nimport dill\nimport os\nfrom pathlib import Path\n\n# Get a torch hook\nHOOK = syft.TorchHook(torch)\n\n# Set the local worker\nLOCAL_WORKER = HOOK.local_worker\n\nfrom .language import Language\nfrom .pipeline import SubPipeline\nfrom .pipeline import Pipeline\nfrom .pipeline.pointers.pipeline_pointer import PipelinePointer\nfrom .pointers.state_pointer import StatePointer\nfrom .utils import search_resource, create_state_query\n\nfrom typing import Set\nfrom typing import Union\n\n\ndef load(pipeline_name: str) -> Language:\n    <IND>\"\"\"Searches for `pipeline_name` on PyGrid and loads it as a Language object.\n\n    Args:\n        pipeline_name (str): The name of the pipeline to search for  on PyGrid.\n\n    Returns:\n        a an object of the Language class, representing the requested pipeline.\n    \"\"\"\n\n    # Search for the pipeline\n    result = search_resource(query=pipeline_name, local_worker=LOCAL_WORKER)\n\n    pipeline = None\n\n    # If no pipeline is found, return\n    if not result:\n        <IND>return\n\n    # If a pipeline is found get either its pointer if it is remote\n    # or the pipeline itself if it is local\n    <DED>elif isinstance(result, PipelinePointer):\n\n        # The ID of the worker on which the pipeline is deployed\n        <IND>deployed_on = result.location.id\n\n        # Get a copy of the pipeline using its pointer\n        pipeline = result.get_copy()\n\n        # Save the pipeline to local storage\n        save(pipeline_name=pipeline_name, pipeline=pipeline, destination=\"local\")\n\n    <DED>elif isinstance(result, Pipeline):\n\n        # In this case, the Pipeline object is found on the local worker\n        # which is a virtual worker by default as of the current PySyft version\n        # 0.2.9. We do not consider that it is officially deployed.\n        <IND>deployed_on = None\n\n        # Get the pipeline object\n        pipeline = result\n\n    <DED>elif isinstance(result, tuple):\n\n        # In this case we get a simplified pipeline object,\n        # from the stored cache which is a tuple.\n        # The following code details it back to a pipeline object.\n\n        <IND>pipeline = Pipeline.detail(worker=LOCAL_WORKER, pipeline_simple=result)\n\n        # Since we found the model in local storage, deployed_on = None\n\n        deployed_on = None\n\n    # Instantiate a Language object\n    <DED>nlp = Language(\n        pipeline_name, owner=LOCAL_WORKER, tags=pipeline.tags, description=pipeline.description\n    )\n\n    # Set the `deployed_on` property\n    nlp.deployed_on = deployed_on\n\n    # Load the pipeline into the Language object\n    nlp.load_pipeline(template=pipeline.template, states_info=pipeline.states_info)\n\n    return nlp\n\n\n<DED>def create(pipeline_name, tags: Set[str] = None, description: str = None):\n    <IND>\"\"\"Creates a new Language object. This function is used when a new pipeline\n    is constructed from local files.\n\n\n    Args:\n        pipeline_name (str): The name of the pipeline to create.\n        tags (set): A set of str that help search for the pipeline across workers.\n        description (str): A str that describes the Language object.\n\n\n    Returns:\n        a an object of the Language class, representing the created pipeline.\n    \"\"\"\n\n    # TODO: The create method should first search over pygrid to make sure no other\n    #      model has the same name\n\n    # Instantiate a Language object\n    nlp = Language(\n        pipeline_name=pipeline_name, owner=LOCAL_WORKER, tags=tags, description=description\n    )\n\n    return nlp\n\n\n# Set the default owners of some classes\n# SubPipeline.owner = LOCAL_WORKER\n\n\n<DED>def save(pipeline_name: str, pipeline: \"Pipeline\", destination: Union[\"local\"] = \"local\") -> None:\n    <IND>\"\"\"Saves the pipeline and it's states to storage\n\n    Args:\n        pipeline_name (str): The name of the pipeline.\n        pipeline (Pipeline): The pipeline object itself\n        destination (Union): The location where to save that object, currently storage on local machine is implemented.\n\n    \"\"\"\n\n    # Path to the home/SyferText/cache/<pipeline_name> directory\n    data_path = os.path.join(str(Path.home()), \"SyferText\", \"cache\", pipeline_name)\n\n    # Creating a new directory if home/SyferText/cache/<pipeline_name> does not exist\n    if not os.path.exists(data_path):\n        <IND>os.makedirs(data_path, exist_ok=True)\n\n    # Making a target at the file\n    <DED>target = str(\"/{}.pkl\".format(pipeline_name))\n\n    # Opening cache file\n    pipeline_cache = open(data_path + target, \"wb\")\n\n    # Dumping data\n    dill.dump(pipeline.simplify(worker=LOCAL_WORKER, pipeline=pipeline), pipeline_cache)\n\n    # Loading states\n    for state in pipeline.states_info:\n        # Searching on state\n        <IND>state_id = create_state_query(pipeline_name=pipeline_name, state_name=state)\n\n        result = search_resource(query=state_id, local_worker=LOCAL_WORKER)\n\n        if isinstance(result, StatePointer):\n            # State target\n\n            # Since : is a reserved character for naming files, replacing with - instead\n            # Splitting tokens to get the name of the pipeline for the name of the pipeline directory\n\n            <IND>file_name = state_id.replace(\":\", \"-\")\n\n            target = str(\"/{}.pkl\".format(file_name))\n\n            state_obj = result.get_copy()\n\n            state_cache = open(data_path + target, \"wb\")\n\n            dill.dump(state_obj.simplify(worker=LOCAL_WORKER, state=state_obj), state_cache)\n\n    <DED><DED>pipeline_cache.close()\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "__version__ = \"0.2.0\"\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/__init__.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/__init__.py",
    "file_hunks_size": 1,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "syfertext/__init__.py:74:56 Incompatible parameter type [6]: Expected `typing.Tuple[object]` for 2nd parameter `pipeline_simple` to call `pipeline.pipeline.Pipeline.detail` but got `typing.Tuple[typing.Any, ...]`.",
    "message": " Expected `typing.Tuple[object]` for 2nd parameter `pipeline_simple` to call `pipeline.pipeline.Pipeline.detail` but got `typing.Tuple[typing.Any, ...]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 74,
    "warning_line": "        pipeline = Pipeline.detail(worker=LOCAL_WORKER, pipeline_simple=result)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import syft\nfrom syft.serde.msgpack.serde import msgpack_global_state\nfrom syft.workers.base import BaseWorker\nimport torch\nimport dill\nimport os\nfrom pathlib import Path\n\n# Get a torch hook\nHOOK = syft.TorchHook(torch)\n\n# Set the local worker\nLOCAL_WORKER = HOOK.local_worker\n\nfrom .language import Language\nfrom .pipeline import SubPipeline\nfrom .pipeline import Pipeline\nfrom .pipeline.pointers.pipeline_pointer import PipelinePointer\nfrom .pointers.state_pointer import StatePointer\nfrom .utils import search_resource, create_state_query\n\nfrom typing import Set\nfrom typing import Union\n\n\ndef load(pipeline_name: str) -> Language:\n    \"\"\"Searches for `pipeline_name` on PyGrid and loads it as a Language object.\n\n    Args:\n        pipeline_name (str): The name of the pipeline to search for  on PyGrid.\n\n    Returns:\n        a an object of the Language class, representing the requested pipeline.\n    \"\"\"\n\n    # Search for the pipeline\n    result = search_resource(query=pipeline_name, local_worker=LOCAL_WORKER)\n\n    pipeline = None\n\n    # If no pipeline is found, return\n    if not result:\n        return\n\n    # If a pipeline is found get either its pointer if it is remote\n    # or the pipeline itself if it is local\n    elif isinstance(result, PipelinePointer):\n\n        # The ID of the worker on which the pipeline is deployed\n        deployed_on = result.location.id\n\n        # Get a copy of the pipeline using its pointer\n        pipeline = result.get_copy()\n\n        # Save the pipeline to local storage\n        save(pipeline_name=pipeline_name, pipeline=pipeline, destination=\"local\")\n\n    elif isinstance(result, Pipeline):\n\n        # In this case, the Pipeline object is found on the local worker\n        # which is a virtual worker by default as of the current PySyft version\n        # 0.2.9. We do not consider that it is officially deployed.\n        deployed_on = None\n\n        # Get the pipeline object\n        pipeline = result\n\n    elif isinstance(result, tuple):\n\n        # In this case we get a simplified pipeline object,\n        # from the stored cache which is a tuple.\n        # The following code details it back to a pipeline object.\n\n        pipeline = Pipeline.detail(worker=LOCAL_WORKER, pipeline_simple=result)\n\n        # Since we found the model in local storage, deployed_on = None\n\n        deployed_on = None\n\n    # Instantiate a Language object\n    nlp = Language(\n        pipeline_name, owner=LOCAL_WORKER, tags=pipeline.tags, description=pipeline.description\n    )\n\n    # Set the `deployed_on` property\n    nlp.deployed_on = deployed_on\n\n    # Load the pipeline into the Language object\n    nlp.load_pipeline(template=pipeline.template, states_info=pipeline.states_info)\n\n    return nlp\n\n\ndef create(pipeline_name, tags: Set[str] = None, description: str = None):\n    \"\"\"Creates a new Language object. This function is used when a new pipeline\n    is constructed from local files.\n\n\n    Args:\n        pipeline_name (str): The name of the pipeline to create.\n        tags (set): A set of str that help search for the pipeline across workers.\n        description (str): A str that describes the Language object.\n\n\n    Returns:\n        a an object of the Language class, representing the created pipeline.\n    \"\"\"\n\n    # TODO: The create method should first search over pygrid to make sure no other\n    #      model has the same name\n\n    # Instantiate a Language object\n    nlp = Language(\n        pipeline_name=pipeline_name, owner=LOCAL_WORKER, tags=tags, description=description\n    )\n\n    return nlp\n\n\n# Set the default owners of some classes\n# SubPipeline.owner = LOCAL_WORKER\n\n\ndef save(pipeline_name: str, pipeline: \"Pipeline\", destination: Union[\"local\"] = \"local\") -> None:\n    \"\"\"Saves the pipeline and it's states to storage\n\n    Args:\n        pipeline_name (str): The name of the pipeline.\n        pipeline (Pipeline): The pipeline object itself\n        destination (Union): The location where to save that object, currently storage on local machine is implemented.\n\n    \"\"\"\n\n    # Path to the home/SyferText/cache/<pipeline_name> directory\n    data_path = os.path.join(str(Path.home()), \"SyferText\", \"cache\", pipeline_name)\n\n    # Creating a new directory if home/SyferText/cache/<pipeline_name> does not exist\n    if not os.path.exists(data_path):\n        os.makedirs(data_path, exist_ok=True)\n\n    # Making a target at the file\n    target = str(\"/{}.pkl\".format(pipeline_name))\n\n    # Opening cache file\n    pipeline_cache = open(data_path + target, \"wb\")\n\n    # Dumping data\n    dill.dump(pipeline.simplify(worker=LOCAL_WORKER, pipeline=pipeline), pipeline_cache)\n\n    # Loading states\n    for state in pipeline.states_info:\n        # Searching on state\n        state_id = create_state_query(pipeline_name=pipeline_name, state_name=state)\n\n        result = search_resource(query=state_id, local_worker=LOCAL_WORKER)\n\n        if isinstance(result, StatePointer):\n            # State target\n\n            # Since : is a reserved character for naming files, replacing with - instead\n            # Splitting tokens to get the name of the pipeline for the name of the pipeline directory\n\n            file_name = state_id.replace(\":\", \"-\")\n\n            target = str(\"/{}.pkl\".format(file_name))\n\n            state_obj = result.get_copy()\n\n            state_cache = open(data_path + target, \"wb\")\n\n            dill.dump(state_obj.simplify(worker=LOCAL_WORKER, state=state_obj), state_cache)\n\n    pipeline_cache.close()\n",
        "source_code_len": 5464,
        "target_code": "__version__ = \"0.2.0\"\n",
        "target_code_len": 22,
        "diff_format": "@@ -1,173 +1,1 @@\n-import syft\n-from syft.serde.msgpack.serde import msgpack_global_state\n-from syft.workers.base import BaseWorker\n-import torch\n-import dill\n-import os\n-from pathlib import Path\n-\n-# Get a torch hook\n-HOOK = syft.TorchHook(torch)\n-\n-# Set the local worker\n-LOCAL_WORKER = HOOK.local_worker\n-\n-from .language import Language\n-from .pipeline import SubPipeline\n-from .pipeline import Pipeline\n-from .pipeline.pointers.pipeline_pointer import PipelinePointer\n-from .pointers.state_pointer import StatePointer\n-from .utils import search_resource, create_state_query\n-\n-from typing import Set\n-from typing import Union\n-\n-\n-def load(pipeline_name: str) -> Language:\n-    \"\"\"Searches for `pipeline_name` on PyGrid and loads it as a Language object.\n-\n-    Args:\n-        pipeline_name (str): The name of the pipeline to search for  on PyGrid.\n-\n-    Returns:\n-        a an object of the Language class, representing the requested pipeline.\n-    \"\"\"\n-\n-    # Search for the pipeline\n-    result = search_resource(query=pipeline_name, local_worker=LOCAL_WORKER)\n-\n-    pipeline = None\n-\n-    # If no pipeline is found, return\n-    if not result:\n-        return\n-\n-    # If a pipeline is found get either its pointer if it is remote\n-    # or the pipeline itself if it is local\n-    elif isinstance(result, PipelinePointer):\n-\n-        # The ID of the worker on which the pipeline is deployed\n-        deployed_on = result.location.id\n-\n-        # Get a copy of the pipeline using its pointer\n-        pipeline = result.get_copy()\n-\n-        # Save the pipeline to local storage\n-        save(pipeline_name=pipeline_name, pipeline=pipeline, destination=\"local\")\n-\n-    elif isinstance(result, Pipeline):\n-\n-        # In this case, the Pipeline object is found on the local worker\n-        # which is a virtual worker by default as of the current PySyft version\n-        # 0.2.9. We do not consider that it is officially deployed.\n-        deployed_on = None\n-\n-        # Get the pipeline object\n-        pipeline = result\n-\n-    elif isinstance(result, tuple):\n-\n-        # In this case we get a simplified pipeline object,\n-        # from the stored cache which is a tuple.\n-        # The following code details it back to a pipeline object.\n-\n-        pipeline = Pipeline.detail(worker=LOCAL_WORKER, pipeline_simple=result)\n-\n-        # Since we found the model in local storage, deployed_on = None\n-\n-        deployed_on = None\n-\n-    # Instantiate a Language object\n-    nlp = Language(\n-        pipeline_name, owner=LOCAL_WORKER, tags=pipeline.tags, description=pipeline.description\n-    )\n-\n-    # Set the `deployed_on` property\n-    nlp.deployed_on = deployed_on\n-\n-    # Load the pipeline into the Language object\n-    nlp.load_pipeline(template=pipeline.template, states_info=pipeline.states_info)\n-\n-    return nlp\n-\n-\n-def create(pipeline_name, tags: Set[str] = None, description: str = None):\n-    \"\"\"Creates a new Language object. This function is used when a new pipeline\n-    is constructed from local files.\n-\n-\n-    Args:\n-        pipeline_name (str): The name of the pipeline to create.\n-        tags (set): A set of str that help search for the pipeline across workers.\n-        description (str): A str that describes the Language object.\n-\n-\n-    Returns:\n-        a an object of the Language class, representing the created pipeline.\n-    \"\"\"\n-\n-    # TODO: The create method should first search over pygrid to make sure no other\n-    #      model has the same name\n-\n-    # Instantiate a Language object\n-    nlp = Language(\n-        pipeline_name=pipeline_name, owner=LOCAL_WORKER, tags=tags, description=description\n-    )\n-\n-    return nlp\n-\n-\n-# Set the default owners of some classes\n-# SubPipeline.owner = LOCAL_WORKER\n-\n-\n-def save(pipeline_name: str, pipeline: \"Pipeline\", destination: Union[\"local\"] = \"local\") -> None:\n-    \"\"\"Saves the pipeline and it's states to storage\n-\n-    Args:\n-        pipeline_name (str): The name of the pipeline.\n-        pipeline (Pipeline): The pipeline object itself\n-        destination (Union): The location where to save that object, currently storage on local machine is implemented.\n-\n-    \"\"\"\n-\n-    # Path to the home/SyferText/cache/<pipeline_name> directory\n-    data_path = os.path.join(str(Path.home()), \"SyferText\", \"cache\", pipeline_name)\n-\n-    # Creating a new directory if home/SyferText/cache/<pipeline_name> does not exist\n-    if not os.path.exists(data_path):\n-        os.makedirs(data_path, exist_ok=True)\n-\n-    # Making a target at the file\n-    target = str(\"/{}.pkl\".format(pipeline_name))\n-\n-    # Opening cache file\n-    pipeline_cache = open(data_path + target, \"wb\")\n-\n-    # Dumping data\n-    dill.dump(pipeline.simplify(worker=LOCAL_WORKER, pipeline=pipeline), pipeline_cache)\n-\n-    # Loading states\n-    for state in pipeline.states_info:\n-        # Searching on state\n-        state_id = create_state_query(pipeline_name=pipeline_name, state_name=state)\n-\n-        result = search_resource(query=state_id, local_worker=LOCAL_WORKER)\n-\n-        if isinstance(result, StatePointer):\n-            # State target\n-\n-            # Since : is a reserved character for naming files, replacing with - instead\n-            # Splitting tokens to get the name of the pipeline for the name of the pipeline directory\n-\n-            file_name = state_id.replace(\":\", \"-\")\n-\n-            target = str(\"/{}.pkl\".format(file_name))\n-\n-            state_obj = result.get_copy()\n-\n-            state_cache = open(data_path + target, \"wb\")\n-\n-            dill.dump(state_obj.simplify(worker=LOCAL_WORKER, state=state_obj), state_cache)\n-\n-    pipeline_cache.close()\n+__version__ = \"0.2.0\"\n",
        "source_code_with_indent": "import syft\nfrom syft.serde.msgpack.serde import msgpack_global_state\nfrom syft.workers.base import BaseWorker\nimport torch\nimport dill\nimport os\nfrom pathlib import Path\n\n# Get a torch hook\nHOOK = syft.TorchHook(torch)\n\n# Set the local worker\nLOCAL_WORKER = HOOK.local_worker\n\nfrom .language import Language\nfrom .pipeline import SubPipeline\nfrom .pipeline import Pipeline\nfrom .pipeline.pointers.pipeline_pointer import PipelinePointer\nfrom .pointers.state_pointer import StatePointer\nfrom .utils import search_resource, create_state_query\n\nfrom typing import Set\nfrom typing import Union\n\n\ndef load(pipeline_name: str) -> Language:\n    <IND>\"\"\"Searches for `pipeline_name` on PyGrid and loads it as a Language object.\n\n    Args:\n        pipeline_name (str): The name of the pipeline to search for  on PyGrid.\n\n    Returns:\n        a an object of the Language class, representing the requested pipeline.\n    \"\"\"\n\n    # Search for the pipeline\n    result = search_resource(query=pipeline_name, local_worker=LOCAL_WORKER)\n\n    pipeline = None\n\n    # If no pipeline is found, return\n    if not result:\n        <IND>return\n\n    # If a pipeline is found get either its pointer if it is remote\n    # or the pipeline itself if it is local\n    <DED>elif isinstance(result, PipelinePointer):\n\n        # The ID of the worker on which the pipeline is deployed\n        <IND>deployed_on = result.location.id\n\n        # Get a copy of the pipeline using its pointer\n        pipeline = result.get_copy()\n\n        # Save the pipeline to local storage\n        save(pipeline_name=pipeline_name, pipeline=pipeline, destination=\"local\")\n\n    <DED>elif isinstance(result, Pipeline):\n\n        # In this case, the Pipeline object is found on the local worker\n        # which is a virtual worker by default as of the current PySyft version\n        # 0.2.9. We do not consider that it is officially deployed.\n        <IND>deployed_on = None\n\n        # Get the pipeline object\n        pipeline = result\n\n    <DED>elif isinstance(result, tuple):\n\n        # In this case we get a simplified pipeline object,\n        # from the stored cache which is a tuple.\n        # The following code details it back to a pipeline object.\n\n        <IND>pipeline = Pipeline.detail(worker=LOCAL_WORKER, pipeline_simple=result)\n\n        # Since we found the model in local storage, deployed_on = None\n\n        deployed_on = None\n\n    # Instantiate a Language object\n    <DED>nlp = Language(\n        pipeline_name, owner=LOCAL_WORKER, tags=pipeline.tags, description=pipeline.description\n    )\n\n    # Set the `deployed_on` property\n    nlp.deployed_on = deployed_on\n\n    # Load the pipeline into the Language object\n    nlp.load_pipeline(template=pipeline.template, states_info=pipeline.states_info)\n\n    return nlp\n\n\n<DED>def create(pipeline_name, tags: Set[str] = None, description: str = None):\n    <IND>\"\"\"Creates a new Language object. This function is used when a new pipeline\n    is constructed from local files.\n\n\n    Args:\n        pipeline_name (str): The name of the pipeline to create.\n        tags (set): A set of str that help search for the pipeline across workers.\n        description (str): A str that describes the Language object.\n\n\n    Returns:\n        a an object of the Language class, representing the created pipeline.\n    \"\"\"\n\n    # TODO: The create method should first search over pygrid to make sure no other\n    #      model has the same name\n\n    # Instantiate a Language object\n    nlp = Language(\n        pipeline_name=pipeline_name, owner=LOCAL_WORKER, tags=tags, description=description\n    )\n\n    return nlp\n\n\n# Set the default owners of some classes\n# SubPipeline.owner = LOCAL_WORKER\n\n\n<DED>def save(pipeline_name: str, pipeline: \"Pipeline\", destination: Union[\"local\"] = \"local\") -> None:\n    <IND>\"\"\"Saves the pipeline and it's states to storage\n\n    Args:\n        pipeline_name (str): The name of the pipeline.\n        pipeline (Pipeline): The pipeline object itself\n        destination (Union): The location where to save that object, currently storage on local machine is implemented.\n\n    \"\"\"\n\n    # Path to the home/SyferText/cache/<pipeline_name> directory\n    data_path = os.path.join(str(Path.home()), \"SyferText\", \"cache\", pipeline_name)\n\n    # Creating a new directory if home/SyferText/cache/<pipeline_name> does not exist\n    if not os.path.exists(data_path):\n        <IND>os.makedirs(data_path, exist_ok=True)\n\n    # Making a target at the file\n    <DED>target = str(\"/{}.pkl\".format(pipeline_name))\n\n    # Opening cache file\n    pipeline_cache = open(data_path + target, \"wb\")\n\n    # Dumping data\n    dill.dump(pipeline.simplify(worker=LOCAL_WORKER, pipeline=pipeline), pipeline_cache)\n\n    # Loading states\n    for state in pipeline.states_info:\n        # Searching on state\n        <IND>state_id = create_state_query(pipeline_name=pipeline_name, state_name=state)\n\n        result = search_resource(query=state_id, local_worker=LOCAL_WORKER)\n\n        if isinstance(result, StatePointer):\n            # State target\n\n            # Since : is a reserved character for naming files, replacing with - instead\n            # Splitting tokens to get the name of the pipeline for the name of the pipeline directory\n\n            <IND>file_name = state_id.replace(\":\", \"-\")\n\n            target = str(\"/{}.pkl\".format(file_name))\n\n            state_obj = result.get_copy()\n\n            state_cache = open(data_path + target, \"wb\")\n\n            dill.dump(state_obj.simplify(worker=LOCAL_WORKER, state=state_obj), state_cache)\n\n    <DED><DED>pipeline_cache.close()\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "__version__ = \"0.2.0\"\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/__init__.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/__init__.py",
    "file_hunks_size": 1,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "syfertext/__init__.py:94:26 Incompatible variable type [9]: tags is declared to have type `Set[str]` but is used as type `None`.",
    "message": " tags is declared to have type `Set[str]` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 94,
    "warning_line": "def create(pipeline_name, tags: Set[str] = None, description: str = None):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import syft\nfrom syft.serde.msgpack.serde import msgpack_global_state\nfrom syft.workers.base import BaseWorker\nimport torch\nimport dill\nimport os\nfrom pathlib import Path\n\n# Get a torch hook\nHOOK = syft.TorchHook(torch)\n\n# Set the local worker\nLOCAL_WORKER = HOOK.local_worker\n\nfrom .language import Language\nfrom .pipeline import SubPipeline\nfrom .pipeline import Pipeline\nfrom .pipeline.pointers.pipeline_pointer import PipelinePointer\nfrom .pointers.state_pointer import StatePointer\nfrom .utils import search_resource, create_state_query\n\nfrom typing import Set\nfrom typing import Union\n\n\ndef load(pipeline_name: str) -> Language:\n    \"\"\"Searches for `pipeline_name` on PyGrid and loads it as a Language object.\n\n    Args:\n        pipeline_name (str): The name of the pipeline to search for  on PyGrid.\n\n    Returns:\n        a an object of the Language class, representing the requested pipeline.\n    \"\"\"\n\n    # Search for the pipeline\n    result = search_resource(query=pipeline_name, local_worker=LOCAL_WORKER)\n\n    pipeline = None\n\n    # If no pipeline is found, return\n    if not result:\n        return\n\n    # If a pipeline is found get either its pointer if it is remote\n    # or the pipeline itself if it is local\n    elif isinstance(result, PipelinePointer):\n\n        # The ID of the worker on which the pipeline is deployed\n        deployed_on = result.location.id\n\n        # Get a copy of the pipeline using its pointer\n        pipeline = result.get_copy()\n\n        # Save the pipeline to local storage\n        save(pipeline_name=pipeline_name, pipeline=pipeline, destination=\"local\")\n\n    elif isinstance(result, Pipeline):\n\n        # In this case, the Pipeline object is found on the local worker\n        # which is a virtual worker by default as of the current PySyft version\n        # 0.2.9. We do not consider that it is officially deployed.\n        deployed_on = None\n\n        # Get the pipeline object\n        pipeline = result\n\n    elif isinstance(result, tuple):\n\n        # In this case we get a simplified pipeline object,\n        # from the stored cache which is a tuple.\n        # The following code details it back to a pipeline object.\n\n        pipeline = Pipeline.detail(worker=LOCAL_WORKER, pipeline_simple=result)\n\n        # Since we found the model in local storage, deployed_on = None\n\n        deployed_on = None\n\n    # Instantiate a Language object\n    nlp = Language(\n        pipeline_name, owner=LOCAL_WORKER, tags=pipeline.tags, description=pipeline.description\n    )\n\n    # Set the `deployed_on` property\n    nlp.deployed_on = deployed_on\n\n    # Load the pipeline into the Language object\n    nlp.load_pipeline(template=pipeline.template, states_info=pipeline.states_info)\n\n    return nlp\n\n\ndef create(pipeline_name, tags: Set[str] = None, description: str = None):\n    \"\"\"Creates a new Language object. This function is used when a new pipeline\n    is constructed from local files.\n\n\n    Args:\n        pipeline_name (str): The name of the pipeline to create.\n        tags (set): A set of str that help search for the pipeline across workers.\n        description (str): A str that describes the Language object.\n\n\n    Returns:\n        a an object of the Language class, representing the created pipeline.\n    \"\"\"\n\n    # TODO: The create method should first search over pygrid to make sure no other\n    #      model has the same name\n\n    # Instantiate a Language object\n    nlp = Language(\n        pipeline_name=pipeline_name, owner=LOCAL_WORKER, tags=tags, description=description\n    )\n\n    return nlp\n\n\n# Set the default owners of some classes\n# SubPipeline.owner = LOCAL_WORKER\n\n\ndef save(pipeline_name: str, pipeline: \"Pipeline\", destination: Union[\"local\"] = \"local\") -> None:\n    \"\"\"Saves the pipeline and it's states to storage\n\n    Args:\n        pipeline_name (str): The name of the pipeline.\n        pipeline (Pipeline): The pipeline object itself\n        destination (Union): The location where to save that object, currently storage on local machine is implemented.\n\n    \"\"\"\n\n    # Path to the home/SyferText/cache/<pipeline_name> directory\n    data_path = os.path.join(str(Path.home()), \"SyferText\", \"cache\", pipeline_name)\n\n    # Creating a new directory if home/SyferText/cache/<pipeline_name> does not exist\n    if not os.path.exists(data_path):\n        os.makedirs(data_path, exist_ok=True)\n\n    # Making a target at the file\n    target = str(\"/{}.pkl\".format(pipeline_name))\n\n    # Opening cache file\n    pipeline_cache = open(data_path + target, \"wb\")\n\n    # Dumping data\n    dill.dump(pipeline.simplify(worker=LOCAL_WORKER, pipeline=pipeline), pipeline_cache)\n\n    # Loading states\n    for state in pipeline.states_info:\n        # Searching on state\n        state_id = create_state_query(pipeline_name=pipeline_name, state_name=state)\n\n        result = search_resource(query=state_id, local_worker=LOCAL_WORKER)\n\n        if isinstance(result, StatePointer):\n            # State target\n\n            # Since : is a reserved character for naming files, replacing with - instead\n            # Splitting tokens to get the name of the pipeline for the name of the pipeline directory\n\n            file_name = state_id.replace(\":\", \"-\")\n\n            target = str(\"/{}.pkl\".format(file_name))\n\n            state_obj = result.get_copy()\n\n            state_cache = open(data_path + target, \"wb\")\n\n            dill.dump(state_obj.simplify(worker=LOCAL_WORKER, state=state_obj), state_cache)\n\n    pipeline_cache.close()\n",
        "source_code_len": 5464,
        "target_code": "__version__ = \"0.2.0\"\n",
        "target_code_len": 22,
        "diff_format": "@@ -1,173 +1,1 @@\n-import syft\n-from syft.serde.msgpack.serde import msgpack_global_state\n-from syft.workers.base import BaseWorker\n-import torch\n-import dill\n-import os\n-from pathlib import Path\n-\n-# Get a torch hook\n-HOOK = syft.TorchHook(torch)\n-\n-# Set the local worker\n-LOCAL_WORKER = HOOK.local_worker\n-\n-from .language import Language\n-from .pipeline import SubPipeline\n-from .pipeline import Pipeline\n-from .pipeline.pointers.pipeline_pointer import PipelinePointer\n-from .pointers.state_pointer import StatePointer\n-from .utils import search_resource, create_state_query\n-\n-from typing import Set\n-from typing import Union\n-\n-\n-def load(pipeline_name: str) -> Language:\n-    \"\"\"Searches for `pipeline_name` on PyGrid and loads it as a Language object.\n-\n-    Args:\n-        pipeline_name (str): The name of the pipeline to search for  on PyGrid.\n-\n-    Returns:\n-        a an object of the Language class, representing the requested pipeline.\n-    \"\"\"\n-\n-    # Search for the pipeline\n-    result = search_resource(query=pipeline_name, local_worker=LOCAL_WORKER)\n-\n-    pipeline = None\n-\n-    # If no pipeline is found, return\n-    if not result:\n-        return\n-\n-    # If a pipeline is found get either its pointer if it is remote\n-    # or the pipeline itself if it is local\n-    elif isinstance(result, PipelinePointer):\n-\n-        # The ID of the worker on which the pipeline is deployed\n-        deployed_on = result.location.id\n-\n-        # Get a copy of the pipeline using its pointer\n-        pipeline = result.get_copy()\n-\n-        # Save the pipeline to local storage\n-        save(pipeline_name=pipeline_name, pipeline=pipeline, destination=\"local\")\n-\n-    elif isinstance(result, Pipeline):\n-\n-        # In this case, the Pipeline object is found on the local worker\n-        # which is a virtual worker by default as of the current PySyft version\n-        # 0.2.9. We do not consider that it is officially deployed.\n-        deployed_on = None\n-\n-        # Get the pipeline object\n-        pipeline = result\n-\n-    elif isinstance(result, tuple):\n-\n-        # In this case we get a simplified pipeline object,\n-        # from the stored cache which is a tuple.\n-        # The following code details it back to a pipeline object.\n-\n-        pipeline = Pipeline.detail(worker=LOCAL_WORKER, pipeline_simple=result)\n-\n-        # Since we found the model in local storage, deployed_on = None\n-\n-        deployed_on = None\n-\n-    # Instantiate a Language object\n-    nlp = Language(\n-        pipeline_name, owner=LOCAL_WORKER, tags=pipeline.tags, description=pipeline.description\n-    )\n-\n-    # Set the `deployed_on` property\n-    nlp.deployed_on = deployed_on\n-\n-    # Load the pipeline into the Language object\n-    nlp.load_pipeline(template=pipeline.template, states_info=pipeline.states_info)\n-\n-    return nlp\n-\n-\n-def create(pipeline_name, tags: Set[str] = None, description: str = None):\n-    \"\"\"Creates a new Language object. This function is used when a new pipeline\n-    is constructed from local files.\n-\n-\n-    Args:\n-        pipeline_name (str): The name of the pipeline to create.\n-        tags (set): A set of str that help search for the pipeline across workers.\n-        description (str): A str that describes the Language object.\n-\n-\n-    Returns:\n-        a an object of the Language class, representing the created pipeline.\n-    \"\"\"\n-\n-    # TODO: The create method should first search over pygrid to make sure no other\n-    #      model has the same name\n-\n-    # Instantiate a Language object\n-    nlp = Language(\n-        pipeline_name=pipeline_name, owner=LOCAL_WORKER, tags=tags, description=description\n-    )\n-\n-    return nlp\n-\n-\n-# Set the default owners of some classes\n-# SubPipeline.owner = LOCAL_WORKER\n-\n-\n-def save(pipeline_name: str, pipeline: \"Pipeline\", destination: Union[\"local\"] = \"local\") -> None:\n-    \"\"\"Saves the pipeline and it's states to storage\n-\n-    Args:\n-        pipeline_name (str): The name of the pipeline.\n-        pipeline (Pipeline): The pipeline object itself\n-        destination (Union): The location where to save that object, currently storage on local machine is implemented.\n-\n-    \"\"\"\n-\n-    # Path to the home/SyferText/cache/<pipeline_name> directory\n-    data_path = os.path.join(str(Path.home()), \"SyferText\", \"cache\", pipeline_name)\n-\n-    # Creating a new directory if home/SyferText/cache/<pipeline_name> does not exist\n-    if not os.path.exists(data_path):\n-        os.makedirs(data_path, exist_ok=True)\n-\n-    # Making a target at the file\n-    target = str(\"/{}.pkl\".format(pipeline_name))\n-\n-    # Opening cache file\n-    pipeline_cache = open(data_path + target, \"wb\")\n-\n-    # Dumping data\n-    dill.dump(pipeline.simplify(worker=LOCAL_WORKER, pipeline=pipeline), pipeline_cache)\n-\n-    # Loading states\n-    for state in pipeline.states_info:\n-        # Searching on state\n-        state_id = create_state_query(pipeline_name=pipeline_name, state_name=state)\n-\n-        result = search_resource(query=state_id, local_worker=LOCAL_WORKER)\n-\n-        if isinstance(result, StatePointer):\n-            # State target\n-\n-            # Since : is a reserved character for naming files, replacing with - instead\n-            # Splitting tokens to get the name of the pipeline for the name of the pipeline directory\n-\n-            file_name = state_id.replace(\":\", \"-\")\n-\n-            target = str(\"/{}.pkl\".format(file_name))\n-\n-            state_obj = result.get_copy()\n-\n-            state_cache = open(data_path + target, \"wb\")\n-\n-            dill.dump(state_obj.simplify(worker=LOCAL_WORKER, state=state_obj), state_cache)\n-\n-    pipeline_cache.close()\n+__version__ = \"0.2.0\"\n",
        "source_code_with_indent": "import syft\nfrom syft.serde.msgpack.serde import msgpack_global_state\nfrom syft.workers.base import BaseWorker\nimport torch\nimport dill\nimport os\nfrom pathlib import Path\n\n# Get a torch hook\nHOOK = syft.TorchHook(torch)\n\n# Set the local worker\nLOCAL_WORKER = HOOK.local_worker\n\nfrom .language import Language\nfrom .pipeline import SubPipeline\nfrom .pipeline import Pipeline\nfrom .pipeline.pointers.pipeline_pointer import PipelinePointer\nfrom .pointers.state_pointer import StatePointer\nfrom .utils import search_resource, create_state_query\n\nfrom typing import Set\nfrom typing import Union\n\n\ndef load(pipeline_name: str) -> Language:\n    <IND>\"\"\"Searches for `pipeline_name` on PyGrid and loads it as a Language object.\n\n    Args:\n        pipeline_name (str): The name of the pipeline to search for  on PyGrid.\n\n    Returns:\n        a an object of the Language class, representing the requested pipeline.\n    \"\"\"\n\n    # Search for the pipeline\n    result = search_resource(query=pipeline_name, local_worker=LOCAL_WORKER)\n\n    pipeline = None\n\n    # If no pipeline is found, return\n    if not result:\n        <IND>return\n\n    # If a pipeline is found get either its pointer if it is remote\n    # or the pipeline itself if it is local\n    <DED>elif isinstance(result, PipelinePointer):\n\n        # The ID of the worker on which the pipeline is deployed\n        <IND>deployed_on = result.location.id\n\n        # Get a copy of the pipeline using its pointer\n        pipeline = result.get_copy()\n\n        # Save the pipeline to local storage\n        save(pipeline_name=pipeline_name, pipeline=pipeline, destination=\"local\")\n\n    <DED>elif isinstance(result, Pipeline):\n\n        # In this case, the Pipeline object is found on the local worker\n        # which is a virtual worker by default as of the current PySyft version\n        # 0.2.9. We do not consider that it is officially deployed.\n        <IND>deployed_on = None\n\n        # Get the pipeline object\n        pipeline = result\n\n    <DED>elif isinstance(result, tuple):\n\n        # In this case we get a simplified pipeline object,\n        # from the stored cache which is a tuple.\n        # The following code details it back to a pipeline object.\n\n        <IND>pipeline = Pipeline.detail(worker=LOCAL_WORKER, pipeline_simple=result)\n\n        # Since we found the model in local storage, deployed_on = None\n\n        deployed_on = None\n\n    # Instantiate a Language object\n    <DED>nlp = Language(\n        pipeline_name, owner=LOCAL_WORKER, tags=pipeline.tags, description=pipeline.description\n    )\n\n    # Set the `deployed_on` property\n    nlp.deployed_on = deployed_on\n\n    # Load the pipeline into the Language object\n    nlp.load_pipeline(template=pipeline.template, states_info=pipeline.states_info)\n\n    return nlp\n\n\n<DED>def create(pipeline_name, tags: Set[str] = None, description: str = None):\n    <IND>\"\"\"Creates a new Language object. This function is used when a new pipeline\n    is constructed from local files.\n\n\n    Args:\n        pipeline_name (str): The name of the pipeline to create.\n        tags (set): A set of str that help search for the pipeline across workers.\n        description (str): A str that describes the Language object.\n\n\n    Returns:\n        a an object of the Language class, representing the created pipeline.\n    \"\"\"\n\n    # TODO: The create method should first search over pygrid to make sure no other\n    #      model has the same name\n\n    # Instantiate a Language object\n    nlp = Language(\n        pipeline_name=pipeline_name, owner=LOCAL_WORKER, tags=tags, description=description\n    )\n\n    return nlp\n\n\n# Set the default owners of some classes\n# SubPipeline.owner = LOCAL_WORKER\n\n\n<DED>def save(pipeline_name: str, pipeline: \"Pipeline\", destination: Union[\"local\"] = \"local\") -> None:\n    <IND>\"\"\"Saves the pipeline and it's states to storage\n\n    Args:\n        pipeline_name (str): The name of the pipeline.\n        pipeline (Pipeline): The pipeline object itself\n        destination (Union): The location where to save that object, currently storage on local machine is implemented.\n\n    \"\"\"\n\n    # Path to the home/SyferText/cache/<pipeline_name> directory\n    data_path = os.path.join(str(Path.home()), \"SyferText\", \"cache\", pipeline_name)\n\n    # Creating a new directory if home/SyferText/cache/<pipeline_name> does not exist\n    if not os.path.exists(data_path):\n        <IND>os.makedirs(data_path, exist_ok=True)\n\n    # Making a target at the file\n    <DED>target = str(\"/{}.pkl\".format(pipeline_name))\n\n    # Opening cache file\n    pipeline_cache = open(data_path + target, \"wb\")\n\n    # Dumping data\n    dill.dump(pipeline.simplify(worker=LOCAL_WORKER, pipeline=pipeline), pipeline_cache)\n\n    # Loading states\n    for state in pipeline.states_info:\n        # Searching on state\n        <IND>state_id = create_state_query(pipeline_name=pipeline_name, state_name=state)\n\n        result = search_resource(query=state_id, local_worker=LOCAL_WORKER)\n\n        if isinstance(result, StatePointer):\n            # State target\n\n            # Since : is a reserved character for naming files, replacing with - instead\n            # Splitting tokens to get the name of the pipeline for the name of the pipeline directory\n\n            <IND>file_name = state_id.replace(\":\", \"-\")\n\n            target = str(\"/{}.pkl\".format(file_name))\n\n            state_obj = result.get_copy()\n\n            state_cache = open(data_path + target, \"wb\")\n\n            dill.dump(state_obj.simplify(worker=LOCAL_WORKER, state=state_obj), state_cache)\n\n    <DED><DED>pipeline_cache.close()\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "__version__ = \"0.2.0\"\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/__init__.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/__init__.py",
    "file_hunks_size": 1,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "syfertext/__init__.py:94:49 Incompatible variable type [9]: description is declared to have type `str` but is used as type `None`.",
    "message": " description is declared to have type `str` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 94,
    "warning_line": "def create(pipeline_name, tags: Set[str] = None, description: str = None):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import syft\nfrom syft.serde.msgpack.serde import msgpack_global_state\nfrom syft.workers.base import BaseWorker\nimport torch\nimport dill\nimport os\nfrom pathlib import Path\n\n# Get a torch hook\nHOOK = syft.TorchHook(torch)\n\n# Set the local worker\nLOCAL_WORKER = HOOK.local_worker\n\nfrom .language import Language\nfrom .pipeline import SubPipeline\nfrom .pipeline import Pipeline\nfrom .pipeline.pointers.pipeline_pointer import PipelinePointer\nfrom .pointers.state_pointer import StatePointer\nfrom .utils import search_resource, create_state_query\n\nfrom typing import Set\nfrom typing import Union\n\n\ndef load(pipeline_name: str) -> Language:\n    \"\"\"Searches for `pipeline_name` on PyGrid and loads it as a Language object.\n\n    Args:\n        pipeline_name (str): The name of the pipeline to search for  on PyGrid.\n\n    Returns:\n        a an object of the Language class, representing the requested pipeline.\n    \"\"\"\n\n    # Search for the pipeline\n    result = search_resource(query=pipeline_name, local_worker=LOCAL_WORKER)\n\n    pipeline = None\n\n    # If no pipeline is found, return\n    if not result:\n        return\n\n    # If a pipeline is found get either its pointer if it is remote\n    # or the pipeline itself if it is local\n    elif isinstance(result, PipelinePointer):\n\n        # The ID of the worker on which the pipeline is deployed\n        deployed_on = result.location.id\n\n        # Get a copy of the pipeline using its pointer\n        pipeline = result.get_copy()\n\n        # Save the pipeline to local storage\n        save(pipeline_name=pipeline_name, pipeline=pipeline, destination=\"local\")\n\n    elif isinstance(result, Pipeline):\n\n        # In this case, the Pipeline object is found on the local worker\n        # which is a virtual worker by default as of the current PySyft version\n        # 0.2.9. We do not consider that it is officially deployed.\n        deployed_on = None\n\n        # Get the pipeline object\n        pipeline = result\n\n    elif isinstance(result, tuple):\n\n        # In this case we get a simplified pipeline object,\n        # from the stored cache which is a tuple.\n        # The following code details it back to a pipeline object.\n\n        pipeline = Pipeline.detail(worker=LOCAL_WORKER, pipeline_simple=result)\n\n        # Since we found the model in local storage, deployed_on = None\n\n        deployed_on = None\n\n    # Instantiate a Language object\n    nlp = Language(\n        pipeline_name, owner=LOCAL_WORKER, tags=pipeline.tags, description=pipeline.description\n    )\n\n    # Set the `deployed_on` property\n    nlp.deployed_on = deployed_on\n\n    # Load the pipeline into the Language object\n    nlp.load_pipeline(template=pipeline.template, states_info=pipeline.states_info)\n\n    return nlp\n\n\ndef create(pipeline_name, tags: Set[str] = None, description: str = None):\n    \"\"\"Creates a new Language object. This function is used when a new pipeline\n    is constructed from local files.\n\n\n    Args:\n        pipeline_name (str): The name of the pipeline to create.\n        tags (set): A set of str that help search for the pipeline across workers.\n        description (str): A str that describes the Language object.\n\n\n    Returns:\n        a an object of the Language class, representing the created pipeline.\n    \"\"\"\n\n    # TODO: The create method should first search over pygrid to make sure no other\n    #      model has the same name\n\n    # Instantiate a Language object\n    nlp = Language(\n        pipeline_name=pipeline_name, owner=LOCAL_WORKER, tags=tags, description=description\n    )\n\n    return nlp\n\n\n# Set the default owners of some classes\n# SubPipeline.owner = LOCAL_WORKER\n\n\ndef save(pipeline_name: str, pipeline: \"Pipeline\", destination: Union[\"local\"] = \"local\") -> None:\n    \"\"\"Saves the pipeline and it's states to storage\n\n    Args:\n        pipeline_name (str): The name of the pipeline.\n        pipeline (Pipeline): The pipeline object itself\n        destination (Union): The location where to save that object, currently storage on local machine is implemented.\n\n    \"\"\"\n\n    # Path to the home/SyferText/cache/<pipeline_name> directory\n    data_path = os.path.join(str(Path.home()), \"SyferText\", \"cache\", pipeline_name)\n\n    # Creating a new directory if home/SyferText/cache/<pipeline_name> does not exist\n    if not os.path.exists(data_path):\n        os.makedirs(data_path, exist_ok=True)\n\n    # Making a target at the file\n    target = str(\"/{}.pkl\".format(pipeline_name))\n\n    # Opening cache file\n    pipeline_cache = open(data_path + target, \"wb\")\n\n    # Dumping data\n    dill.dump(pipeline.simplify(worker=LOCAL_WORKER, pipeline=pipeline), pipeline_cache)\n\n    # Loading states\n    for state in pipeline.states_info:\n        # Searching on state\n        state_id = create_state_query(pipeline_name=pipeline_name, state_name=state)\n\n        result = search_resource(query=state_id, local_worker=LOCAL_WORKER)\n\n        if isinstance(result, StatePointer):\n            # State target\n\n            # Since : is a reserved character for naming files, replacing with - instead\n            # Splitting tokens to get the name of the pipeline for the name of the pipeline directory\n\n            file_name = state_id.replace(\":\", \"-\")\n\n            target = str(\"/{}.pkl\".format(file_name))\n\n            state_obj = result.get_copy()\n\n            state_cache = open(data_path + target, \"wb\")\n\n            dill.dump(state_obj.simplify(worker=LOCAL_WORKER, state=state_obj), state_cache)\n\n    pipeline_cache.close()\n",
        "source_code_len": 5464,
        "target_code": "__version__ = \"0.2.0\"\n",
        "target_code_len": 22,
        "diff_format": "@@ -1,173 +1,1 @@\n-import syft\n-from syft.serde.msgpack.serde import msgpack_global_state\n-from syft.workers.base import BaseWorker\n-import torch\n-import dill\n-import os\n-from pathlib import Path\n-\n-# Get a torch hook\n-HOOK = syft.TorchHook(torch)\n-\n-# Set the local worker\n-LOCAL_WORKER = HOOK.local_worker\n-\n-from .language import Language\n-from .pipeline import SubPipeline\n-from .pipeline import Pipeline\n-from .pipeline.pointers.pipeline_pointer import PipelinePointer\n-from .pointers.state_pointer import StatePointer\n-from .utils import search_resource, create_state_query\n-\n-from typing import Set\n-from typing import Union\n-\n-\n-def load(pipeline_name: str) -> Language:\n-    \"\"\"Searches for `pipeline_name` on PyGrid and loads it as a Language object.\n-\n-    Args:\n-        pipeline_name (str): The name of the pipeline to search for  on PyGrid.\n-\n-    Returns:\n-        a an object of the Language class, representing the requested pipeline.\n-    \"\"\"\n-\n-    # Search for the pipeline\n-    result = search_resource(query=pipeline_name, local_worker=LOCAL_WORKER)\n-\n-    pipeline = None\n-\n-    # If no pipeline is found, return\n-    if not result:\n-        return\n-\n-    # If a pipeline is found get either its pointer if it is remote\n-    # or the pipeline itself if it is local\n-    elif isinstance(result, PipelinePointer):\n-\n-        # The ID of the worker on which the pipeline is deployed\n-        deployed_on = result.location.id\n-\n-        # Get a copy of the pipeline using its pointer\n-        pipeline = result.get_copy()\n-\n-        # Save the pipeline to local storage\n-        save(pipeline_name=pipeline_name, pipeline=pipeline, destination=\"local\")\n-\n-    elif isinstance(result, Pipeline):\n-\n-        # In this case, the Pipeline object is found on the local worker\n-        # which is a virtual worker by default as of the current PySyft version\n-        # 0.2.9. We do not consider that it is officially deployed.\n-        deployed_on = None\n-\n-        # Get the pipeline object\n-        pipeline = result\n-\n-    elif isinstance(result, tuple):\n-\n-        # In this case we get a simplified pipeline object,\n-        # from the stored cache which is a tuple.\n-        # The following code details it back to a pipeline object.\n-\n-        pipeline = Pipeline.detail(worker=LOCAL_WORKER, pipeline_simple=result)\n-\n-        # Since we found the model in local storage, deployed_on = None\n-\n-        deployed_on = None\n-\n-    # Instantiate a Language object\n-    nlp = Language(\n-        pipeline_name, owner=LOCAL_WORKER, tags=pipeline.tags, description=pipeline.description\n-    )\n-\n-    # Set the `deployed_on` property\n-    nlp.deployed_on = deployed_on\n-\n-    # Load the pipeline into the Language object\n-    nlp.load_pipeline(template=pipeline.template, states_info=pipeline.states_info)\n-\n-    return nlp\n-\n-\n-def create(pipeline_name, tags: Set[str] = None, description: str = None):\n-    \"\"\"Creates a new Language object. This function is used when a new pipeline\n-    is constructed from local files.\n-\n-\n-    Args:\n-        pipeline_name (str): The name of the pipeline to create.\n-        tags (set): A set of str that help search for the pipeline across workers.\n-        description (str): A str that describes the Language object.\n-\n-\n-    Returns:\n-        a an object of the Language class, representing the created pipeline.\n-    \"\"\"\n-\n-    # TODO: The create method should first search over pygrid to make sure no other\n-    #      model has the same name\n-\n-    # Instantiate a Language object\n-    nlp = Language(\n-        pipeline_name=pipeline_name, owner=LOCAL_WORKER, tags=tags, description=description\n-    )\n-\n-    return nlp\n-\n-\n-# Set the default owners of some classes\n-# SubPipeline.owner = LOCAL_WORKER\n-\n-\n-def save(pipeline_name: str, pipeline: \"Pipeline\", destination: Union[\"local\"] = \"local\") -> None:\n-    \"\"\"Saves the pipeline and it's states to storage\n-\n-    Args:\n-        pipeline_name (str): The name of the pipeline.\n-        pipeline (Pipeline): The pipeline object itself\n-        destination (Union): The location where to save that object, currently storage on local machine is implemented.\n-\n-    \"\"\"\n-\n-    # Path to the home/SyferText/cache/<pipeline_name> directory\n-    data_path = os.path.join(str(Path.home()), \"SyferText\", \"cache\", pipeline_name)\n-\n-    # Creating a new directory if home/SyferText/cache/<pipeline_name> does not exist\n-    if not os.path.exists(data_path):\n-        os.makedirs(data_path, exist_ok=True)\n-\n-    # Making a target at the file\n-    target = str(\"/{}.pkl\".format(pipeline_name))\n-\n-    # Opening cache file\n-    pipeline_cache = open(data_path + target, \"wb\")\n-\n-    # Dumping data\n-    dill.dump(pipeline.simplify(worker=LOCAL_WORKER, pipeline=pipeline), pipeline_cache)\n-\n-    # Loading states\n-    for state in pipeline.states_info:\n-        # Searching on state\n-        state_id = create_state_query(pipeline_name=pipeline_name, state_name=state)\n-\n-        result = search_resource(query=state_id, local_worker=LOCAL_WORKER)\n-\n-        if isinstance(result, StatePointer):\n-            # State target\n-\n-            # Since : is a reserved character for naming files, replacing with - instead\n-            # Splitting tokens to get the name of the pipeline for the name of the pipeline directory\n-\n-            file_name = state_id.replace(\":\", \"-\")\n-\n-            target = str(\"/{}.pkl\".format(file_name))\n-\n-            state_obj = result.get_copy()\n-\n-            state_cache = open(data_path + target, \"wb\")\n-\n-            dill.dump(state_obj.simplify(worker=LOCAL_WORKER, state=state_obj), state_cache)\n-\n-    pipeline_cache.close()\n+__version__ = \"0.2.0\"\n",
        "source_code_with_indent": "import syft\nfrom syft.serde.msgpack.serde import msgpack_global_state\nfrom syft.workers.base import BaseWorker\nimport torch\nimport dill\nimport os\nfrom pathlib import Path\n\n# Get a torch hook\nHOOK = syft.TorchHook(torch)\n\n# Set the local worker\nLOCAL_WORKER = HOOK.local_worker\n\nfrom .language import Language\nfrom .pipeline import SubPipeline\nfrom .pipeline import Pipeline\nfrom .pipeline.pointers.pipeline_pointer import PipelinePointer\nfrom .pointers.state_pointer import StatePointer\nfrom .utils import search_resource, create_state_query\n\nfrom typing import Set\nfrom typing import Union\n\n\ndef load(pipeline_name: str) -> Language:\n    <IND>\"\"\"Searches for `pipeline_name` on PyGrid and loads it as a Language object.\n\n    Args:\n        pipeline_name (str): The name of the pipeline to search for  on PyGrid.\n\n    Returns:\n        a an object of the Language class, representing the requested pipeline.\n    \"\"\"\n\n    # Search for the pipeline\n    result = search_resource(query=pipeline_name, local_worker=LOCAL_WORKER)\n\n    pipeline = None\n\n    # If no pipeline is found, return\n    if not result:\n        <IND>return\n\n    # If a pipeline is found get either its pointer if it is remote\n    # or the pipeline itself if it is local\n    <DED>elif isinstance(result, PipelinePointer):\n\n        # The ID of the worker on which the pipeline is deployed\n        <IND>deployed_on = result.location.id\n\n        # Get a copy of the pipeline using its pointer\n        pipeline = result.get_copy()\n\n        # Save the pipeline to local storage\n        save(pipeline_name=pipeline_name, pipeline=pipeline, destination=\"local\")\n\n    <DED>elif isinstance(result, Pipeline):\n\n        # In this case, the Pipeline object is found on the local worker\n        # which is a virtual worker by default as of the current PySyft version\n        # 0.2.9. We do not consider that it is officially deployed.\n        <IND>deployed_on = None\n\n        # Get the pipeline object\n        pipeline = result\n\n    <DED>elif isinstance(result, tuple):\n\n        # In this case we get a simplified pipeline object,\n        # from the stored cache which is a tuple.\n        # The following code details it back to a pipeline object.\n\n        <IND>pipeline = Pipeline.detail(worker=LOCAL_WORKER, pipeline_simple=result)\n\n        # Since we found the model in local storage, deployed_on = None\n\n        deployed_on = None\n\n    # Instantiate a Language object\n    <DED>nlp = Language(\n        pipeline_name, owner=LOCAL_WORKER, tags=pipeline.tags, description=pipeline.description\n    )\n\n    # Set the `deployed_on` property\n    nlp.deployed_on = deployed_on\n\n    # Load the pipeline into the Language object\n    nlp.load_pipeline(template=pipeline.template, states_info=pipeline.states_info)\n\n    return nlp\n\n\n<DED>def create(pipeline_name, tags: Set[str] = None, description: str = None):\n    <IND>\"\"\"Creates a new Language object. This function is used when a new pipeline\n    is constructed from local files.\n\n\n    Args:\n        pipeline_name (str): The name of the pipeline to create.\n        tags (set): A set of str that help search for the pipeline across workers.\n        description (str): A str that describes the Language object.\n\n\n    Returns:\n        a an object of the Language class, representing the created pipeline.\n    \"\"\"\n\n    # TODO: The create method should first search over pygrid to make sure no other\n    #      model has the same name\n\n    # Instantiate a Language object\n    nlp = Language(\n        pipeline_name=pipeline_name, owner=LOCAL_WORKER, tags=tags, description=description\n    )\n\n    return nlp\n\n\n# Set the default owners of some classes\n# SubPipeline.owner = LOCAL_WORKER\n\n\n<DED>def save(pipeline_name: str, pipeline: \"Pipeline\", destination: Union[\"local\"] = \"local\") -> None:\n    <IND>\"\"\"Saves the pipeline and it's states to storage\n\n    Args:\n        pipeline_name (str): The name of the pipeline.\n        pipeline (Pipeline): The pipeline object itself\n        destination (Union): The location where to save that object, currently storage on local machine is implemented.\n\n    \"\"\"\n\n    # Path to the home/SyferText/cache/<pipeline_name> directory\n    data_path = os.path.join(str(Path.home()), \"SyferText\", \"cache\", pipeline_name)\n\n    # Creating a new directory if home/SyferText/cache/<pipeline_name> does not exist\n    if not os.path.exists(data_path):\n        <IND>os.makedirs(data_path, exist_ok=True)\n\n    # Making a target at the file\n    <DED>target = str(\"/{}.pkl\".format(pipeline_name))\n\n    # Opening cache file\n    pipeline_cache = open(data_path + target, \"wb\")\n\n    # Dumping data\n    dill.dump(pipeline.simplify(worker=LOCAL_WORKER, pipeline=pipeline), pipeline_cache)\n\n    # Loading states\n    for state in pipeline.states_info:\n        # Searching on state\n        <IND>state_id = create_state_query(pipeline_name=pipeline_name, state_name=state)\n\n        result = search_resource(query=state_id, local_worker=LOCAL_WORKER)\n\n        if isinstance(result, StatePointer):\n            # State target\n\n            # Since : is a reserved character for naming files, replacing with - instead\n            # Splitting tokens to get the name of the pipeline for the name of the pipeline directory\n\n            <IND>file_name = state_id.replace(\":\", \"-\")\n\n            target = str(\"/{}.pkl\".format(file_name))\n\n            state_obj = result.get_copy()\n\n            state_cache = open(data_path + target, \"wb\")\n\n            dill.dump(state_obj.simplify(worker=LOCAL_WORKER, state=state_obj), state_cache)\n\n    <DED><DED>pipeline_cache.close()\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "__version__ = \"0.2.0\"\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/__init__.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/__init__.py",
    "file_hunks_size": 1,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "syfertext/__init__.py:114:57 Incompatible parameter type [6]: Expected `typing.List[str]` for 3rd parameter `tags` to call `Language.__init__` but got `Set[str]`.",
    "message": " Expected `typing.List[str]` for 3rd parameter `tags` to call `Language.__init__` but got `Set[str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 114,
    "warning_line": "        pipeline_name=pipeline_name, owner=LOCAL_WORKER, tags=tags, description=description",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import syft\nfrom syft.serde.msgpack.serde import msgpack_global_state\nfrom syft.workers.base import BaseWorker\nimport torch\nimport dill\nimport os\nfrom pathlib import Path\n\n# Get a torch hook\nHOOK = syft.TorchHook(torch)\n\n# Set the local worker\nLOCAL_WORKER = HOOK.local_worker\n\nfrom .language import Language\nfrom .pipeline import SubPipeline\nfrom .pipeline import Pipeline\nfrom .pipeline.pointers.pipeline_pointer import PipelinePointer\nfrom .pointers.state_pointer import StatePointer\nfrom .utils import search_resource, create_state_query\n\nfrom typing import Set\nfrom typing import Union\n\n\ndef load(pipeline_name: str) -> Language:\n    \"\"\"Searches for `pipeline_name` on PyGrid and loads it as a Language object.\n\n    Args:\n        pipeline_name (str): The name of the pipeline to search for  on PyGrid.\n\n    Returns:\n        a an object of the Language class, representing the requested pipeline.\n    \"\"\"\n\n    # Search for the pipeline\n    result = search_resource(query=pipeline_name, local_worker=LOCAL_WORKER)\n\n    pipeline = None\n\n    # If no pipeline is found, return\n    if not result:\n        return\n\n    # If a pipeline is found get either its pointer if it is remote\n    # or the pipeline itself if it is local\n    elif isinstance(result, PipelinePointer):\n\n        # The ID of the worker on which the pipeline is deployed\n        deployed_on = result.location.id\n\n        # Get a copy of the pipeline using its pointer\n        pipeline = result.get_copy()\n\n        # Save the pipeline to local storage\n        save(pipeline_name=pipeline_name, pipeline=pipeline, destination=\"local\")\n\n    elif isinstance(result, Pipeline):\n\n        # In this case, the Pipeline object is found on the local worker\n        # which is a virtual worker by default as of the current PySyft version\n        # 0.2.9. We do not consider that it is officially deployed.\n        deployed_on = None\n\n        # Get the pipeline object\n        pipeline = result\n\n    elif isinstance(result, tuple):\n\n        # In this case we get a simplified pipeline object,\n        # from the stored cache which is a tuple.\n        # The following code details it back to a pipeline object.\n\n        pipeline = Pipeline.detail(worker=LOCAL_WORKER, pipeline_simple=result)\n\n        # Since we found the model in local storage, deployed_on = None\n\n        deployed_on = None\n\n    # Instantiate a Language object\n    nlp = Language(\n        pipeline_name, owner=LOCAL_WORKER, tags=pipeline.tags, description=pipeline.description\n    )\n\n    # Set the `deployed_on` property\n    nlp.deployed_on = deployed_on\n\n    # Load the pipeline into the Language object\n    nlp.load_pipeline(template=pipeline.template, states_info=pipeline.states_info)\n\n    return nlp\n\n\ndef create(pipeline_name, tags: Set[str] = None, description: str = None):\n    \"\"\"Creates a new Language object. This function is used when a new pipeline\n    is constructed from local files.\n\n\n    Args:\n        pipeline_name (str): The name of the pipeline to create.\n        tags (set): A set of str that help search for the pipeline across workers.\n        description (str): A str that describes the Language object.\n\n\n    Returns:\n        a an object of the Language class, representing the created pipeline.\n    \"\"\"\n\n    # TODO: The create method should first search over pygrid to make sure no other\n    #      model has the same name\n\n    # Instantiate a Language object\n    nlp = Language(\n        pipeline_name=pipeline_name, owner=LOCAL_WORKER, tags=tags, description=description\n    )\n\n    return nlp\n\n\n# Set the default owners of some classes\n# SubPipeline.owner = LOCAL_WORKER\n\n\ndef save(pipeline_name: str, pipeline: \"Pipeline\", destination: Union[\"local\"] = \"local\") -> None:\n    \"\"\"Saves the pipeline and it's states to storage\n\n    Args:\n        pipeline_name (str): The name of the pipeline.\n        pipeline (Pipeline): The pipeline object itself\n        destination (Union): The location where to save that object, currently storage on local machine is implemented.\n\n    \"\"\"\n\n    # Path to the home/SyferText/cache/<pipeline_name> directory\n    data_path = os.path.join(str(Path.home()), \"SyferText\", \"cache\", pipeline_name)\n\n    # Creating a new directory if home/SyferText/cache/<pipeline_name> does not exist\n    if not os.path.exists(data_path):\n        os.makedirs(data_path, exist_ok=True)\n\n    # Making a target at the file\n    target = str(\"/{}.pkl\".format(pipeline_name))\n\n    # Opening cache file\n    pipeline_cache = open(data_path + target, \"wb\")\n\n    # Dumping data\n    dill.dump(pipeline.simplify(worker=LOCAL_WORKER, pipeline=pipeline), pipeline_cache)\n\n    # Loading states\n    for state in pipeline.states_info:\n        # Searching on state\n        state_id = create_state_query(pipeline_name=pipeline_name, state_name=state)\n\n        result = search_resource(query=state_id, local_worker=LOCAL_WORKER)\n\n        if isinstance(result, StatePointer):\n            # State target\n\n            # Since : is a reserved character for naming files, replacing with - instead\n            # Splitting tokens to get the name of the pipeline for the name of the pipeline directory\n\n            file_name = state_id.replace(\":\", \"-\")\n\n            target = str(\"/{}.pkl\".format(file_name))\n\n            state_obj = result.get_copy()\n\n            state_cache = open(data_path + target, \"wb\")\n\n            dill.dump(state_obj.simplify(worker=LOCAL_WORKER, state=state_obj), state_cache)\n\n    pipeline_cache.close()\n",
        "source_code_len": 5464,
        "target_code": "__version__ = \"0.2.0\"\n",
        "target_code_len": 22,
        "diff_format": "@@ -1,173 +1,1 @@\n-import syft\n-from syft.serde.msgpack.serde import msgpack_global_state\n-from syft.workers.base import BaseWorker\n-import torch\n-import dill\n-import os\n-from pathlib import Path\n-\n-# Get a torch hook\n-HOOK = syft.TorchHook(torch)\n-\n-# Set the local worker\n-LOCAL_WORKER = HOOK.local_worker\n-\n-from .language import Language\n-from .pipeline import SubPipeline\n-from .pipeline import Pipeline\n-from .pipeline.pointers.pipeline_pointer import PipelinePointer\n-from .pointers.state_pointer import StatePointer\n-from .utils import search_resource, create_state_query\n-\n-from typing import Set\n-from typing import Union\n-\n-\n-def load(pipeline_name: str) -> Language:\n-    \"\"\"Searches for `pipeline_name` on PyGrid and loads it as a Language object.\n-\n-    Args:\n-        pipeline_name (str): The name of the pipeline to search for  on PyGrid.\n-\n-    Returns:\n-        a an object of the Language class, representing the requested pipeline.\n-    \"\"\"\n-\n-    # Search for the pipeline\n-    result = search_resource(query=pipeline_name, local_worker=LOCAL_WORKER)\n-\n-    pipeline = None\n-\n-    # If no pipeline is found, return\n-    if not result:\n-        return\n-\n-    # If a pipeline is found get either its pointer if it is remote\n-    # or the pipeline itself if it is local\n-    elif isinstance(result, PipelinePointer):\n-\n-        # The ID of the worker on which the pipeline is deployed\n-        deployed_on = result.location.id\n-\n-        # Get a copy of the pipeline using its pointer\n-        pipeline = result.get_copy()\n-\n-        # Save the pipeline to local storage\n-        save(pipeline_name=pipeline_name, pipeline=pipeline, destination=\"local\")\n-\n-    elif isinstance(result, Pipeline):\n-\n-        # In this case, the Pipeline object is found on the local worker\n-        # which is a virtual worker by default as of the current PySyft version\n-        # 0.2.9. We do not consider that it is officially deployed.\n-        deployed_on = None\n-\n-        # Get the pipeline object\n-        pipeline = result\n-\n-    elif isinstance(result, tuple):\n-\n-        # In this case we get a simplified pipeline object,\n-        # from the stored cache which is a tuple.\n-        # The following code details it back to a pipeline object.\n-\n-        pipeline = Pipeline.detail(worker=LOCAL_WORKER, pipeline_simple=result)\n-\n-        # Since we found the model in local storage, deployed_on = None\n-\n-        deployed_on = None\n-\n-    # Instantiate a Language object\n-    nlp = Language(\n-        pipeline_name, owner=LOCAL_WORKER, tags=pipeline.tags, description=pipeline.description\n-    )\n-\n-    # Set the `deployed_on` property\n-    nlp.deployed_on = deployed_on\n-\n-    # Load the pipeline into the Language object\n-    nlp.load_pipeline(template=pipeline.template, states_info=pipeline.states_info)\n-\n-    return nlp\n-\n-\n-def create(pipeline_name, tags: Set[str] = None, description: str = None):\n-    \"\"\"Creates a new Language object. This function is used when a new pipeline\n-    is constructed from local files.\n-\n-\n-    Args:\n-        pipeline_name (str): The name of the pipeline to create.\n-        tags (set): A set of str that help search for the pipeline across workers.\n-        description (str): A str that describes the Language object.\n-\n-\n-    Returns:\n-        a an object of the Language class, representing the created pipeline.\n-    \"\"\"\n-\n-    # TODO: The create method should first search over pygrid to make sure no other\n-    #      model has the same name\n-\n-    # Instantiate a Language object\n-    nlp = Language(\n-        pipeline_name=pipeline_name, owner=LOCAL_WORKER, tags=tags, description=description\n-    )\n-\n-    return nlp\n-\n-\n-# Set the default owners of some classes\n-# SubPipeline.owner = LOCAL_WORKER\n-\n-\n-def save(pipeline_name: str, pipeline: \"Pipeline\", destination: Union[\"local\"] = \"local\") -> None:\n-    \"\"\"Saves the pipeline and it's states to storage\n-\n-    Args:\n-        pipeline_name (str): The name of the pipeline.\n-        pipeline (Pipeline): The pipeline object itself\n-        destination (Union): The location where to save that object, currently storage on local machine is implemented.\n-\n-    \"\"\"\n-\n-    # Path to the home/SyferText/cache/<pipeline_name> directory\n-    data_path = os.path.join(str(Path.home()), \"SyferText\", \"cache\", pipeline_name)\n-\n-    # Creating a new directory if home/SyferText/cache/<pipeline_name> does not exist\n-    if not os.path.exists(data_path):\n-        os.makedirs(data_path, exist_ok=True)\n-\n-    # Making a target at the file\n-    target = str(\"/{}.pkl\".format(pipeline_name))\n-\n-    # Opening cache file\n-    pipeline_cache = open(data_path + target, \"wb\")\n-\n-    # Dumping data\n-    dill.dump(pipeline.simplify(worker=LOCAL_WORKER, pipeline=pipeline), pipeline_cache)\n-\n-    # Loading states\n-    for state in pipeline.states_info:\n-        # Searching on state\n-        state_id = create_state_query(pipeline_name=pipeline_name, state_name=state)\n-\n-        result = search_resource(query=state_id, local_worker=LOCAL_WORKER)\n-\n-        if isinstance(result, StatePointer):\n-            # State target\n-\n-            # Since : is a reserved character for naming files, replacing with - instead\n-            # Splitting tokens to get the name of the pipeline for the name of the pipeline directory\n-\n-            file_name = state_id.replace(\":\", \"-\")\n-\n-            target = str(\"/{}.pkl\".format(file_name))\n-\n-            state_obj = result.get_copy()\n-\n-            state_cache = open(data_path + target, \"wb\")\n-\n-            dill.dump(state_obj.simplify(worker=LOCAL_WORKER, state=state_obj), state_cache)\n-\n-    pipeline_cache.close()\n+__version__ = \"0.2.0\"\n",
        "source_code_with_indent": "import syft\nfrom syft.serde.msgpack.serde import msgpack_global_state\nfrom syft.workers.base import BaseWorker\nimport torch\nimport dill\nimport os\nfrom pathlib import Path\n\n# Get a torch hook\nHOOK = syft.TorchHook(torch)\n\n# Set the local worker\nLOCAL_WORKER = HOOK.local_worker\n\nfrom .language import Language\nfrom .pipeline import SubPipeline\nfrom .pipeline import Pipeline\nfrom .pipeline.pointers.pipeline_pointer import PipelinePointer\nfrom .pointers.state_pointer import StatePointer\nfrom .utils import search_resource, create_state_query\n\nfrom typing import Set\nfrom typing import Union\n\n\ndef load(pipeline_name: str) -> Language:\n    <IND>\"\"\"Searches for `pipeline_name` on PyGrid and loads it as a Language object.\n\n    Args:\n        pipeline_name (str): The name of the pipeline to search for  on PyGrid.\n\n    Returns:\n        a an object of the Language class, representing the requested pipeline.\n    \"\"\"\n\n    # Search for the pipeline\n    result = search_resource(query=pipeline_name, local_worker=LOCAL_WORKER)\n\n    pipeline = None\n\n    # If no pipeline is found, return\n    if not result:\n        <IND>return\n\n    # If a pipeline is found get either its pointer if it is remote\n    # or the pipeline itself if it is local\n    <DED>elif isinstance(result, PipelinePointer):\n\n        # The ID of the worker on which the pipeline is deployed\n        <IND>deployed_on = result.location.id\n\n        # Get a copy of the pipeline using its pointer\n        pipeline = result.get_copy()\n\n        # Save the pipeline to local storage\n        save(pipeline_name=pipeline_name, pipeline=pipeline, destination=\"local\")\n\n    <DED>elif isinstance(result, Pipeline):\n\n        # In this case, the Pipeline object is found on the local worker\n        # which is a virtual worker by default as of the current PySyft version\n        # 0.2.9. We do not consider that it is officially deployed.\n        <IND>deployed_on = None\n\n        # Get the pipeline object\n        pipeline = result\n\n    <DED>elif isinstance(result, tuple):\n\n        # In this case we get a simplified pipeline object,\n        # from the stored cache which is a tuple.\n        # The following code details it back to a pipeline object.\n\n        <IND>pipeline = Pipeline.detail(worker=LOCAL_WORKER, pipeline_simple=result)\n\n        # Since we found the model in local storage, deployed_on = None\n\n        deployed_on = None\n\n    # Instantiate a Language object\n    <DED>nlp = Language(\n        pipeline_name, owner=LOCAL_WORKER, tags=pipeline.tags, description=pipeline.description\n    )\n\n    # Set the `deployed_on` property\n    nlp.deployed_on = deployed_on\n\n    # Load the pipeline into the Language object\n    nlp.load_pipeline(template=pipeline.template, states_info=pipeline.states_info)\n\n    return nlp\n\n\n<DED>def create(pipeline_name, tags: Set[str] = None, description: str = None):\n    <IND>\"\"\"Creates a new Language object. This function is used when a new pipeline\n    is constructed from local files.\n\n\n    Args:\n        pipeline_name (str): The name of the pipeline to create.\n        tags (set): A set of str that help search for the pipeline across workers.\n        description (str): A str that describes the Language object.\n\n\n    Returns:\n        a an object of the Language class, representing the created pipeline.\n    \"\"\"\n\n    # TODO: The create method should first search over pygrid to make sure no other\n    #      model has the same name\n\n    # Instantiate a Language object\n    nlp = Language(\n        pipeline_name=pipeline_name, owner=LOCAL_WORKER, tags=tags, description=description\n    )\n\n    return nlp\n\n\n# Set the default owners of some classes\n# SubPipeline.owner = LOCAL_WORKER\n\n\n<DED>def save(pipeline_name: str, pipeline: \"Pipeline\", destination: Union[\"local\"] = \"local\") -> None:\n    <IND>\"\"\"Saves the pipeline and it's states to storage\n\n    Args:\n        pipeline_name (str): The name of the pipeline.\n        pipeline (Pipeline): The pipeline object itself\n        destination (Union): The location where to save that object, currently storage on local machine is implemented.\n\n    \"\"\"\n\n    # Path to the home/SyferText/cache/<pipeline_name> directory\n    data_path = os.path.join(str(Path.home()), \"SyferText\", \"cache\", pipeline_name)\n\n    # Creating a new directory if home/SyferText/cache/<pipeline_name> does not exist\n    if not os.path.exists(data_path):\n        <IND>os.makedirs(data_path, exist_ok=True)\n\n    # Making a target at the file\n    <DED>target = str(\"/{}.pkl\".format(pipeline_name))\n\n    # Opening cache file\n    pipeline_cache = open(data_path + target, \"wb\")\n\n    # Dumping data\n    dill.dump(pipeline.simplify(worker=LOCAL_WORKER, pipeline=pipeline), pipeline_cache)\n\n    # Loading states\n    for state in pipeline.states_info:\n        # Searching on state\n        <IND>state_id = create_state_query(pipeline_name=pipeline_name, state_name=state)\n\n        result = search_resource(query=state_id, local_worker=LOCAL_WORKER)\n\n        if isinstance(result, StatePointer):\n            # State target\n\n            # Since : is a reserved character for naming files, replacing with - instead\n            # Splitting tokens to get the name of the pipeline for the name of the pipeline directory\n\n            <IND>file_name = state_id.replace(\":\", \"-\")\n\n            target = str(\"/{}.pkl\".format(file_name))\n\n            state_obj = result.get_copy()\n\n            state_cache = open(data_path + target, \"wb\")\n\n            dill.dump(state_obj.simplify(worker=LOCAL_WORKER, state=state_obj), state_cache)\n\n    <DED><DED>pipeline_cache.close()\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "__version__ = \"0.2.0\"\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/doc.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/doc.py:27:8 Incompatible variable type [9]: id is declared to have type `int` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/doc.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/doc.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/doc.py:29:8 Incompatible variable type [9]: tags is declared to have type `List[str]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/doc.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/doc.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/doc.py:30:8 Incompatible variable type [9]: description is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/doc.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/doc.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/doc.py:31:8 Incompatible variable type [9]: client_id is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/doc.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/doc.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/doc.py:220:25 Incompatible variable type [9]: excluded_tokens is declared to have type `Dict[str, Set[object]]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/doc.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/doc.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/doc.py:258:32 Incompatible variable type [9]: excluded_tokens is declared to have type `Dict[str, Set[object]]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/doc.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/doc.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/doc.py:292:8 Incompatible variable type [9]: excluded_tokens is declared to have type `Dict[str, Set[object]]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/doc.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/doc.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/doc.py:293:8 Incompatible variable type [9]: protocol is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/doc.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/doc.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/doc.py:333:8 Incompatible variable type [9]: excluded_tokens is declared to have type `Dict[str, Set[object]]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/doc.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/doc.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/doc.py:334:8 Incompatible variable type [9]: protocol is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/doc.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/doc.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/doc.py:409:14 Incompatible variable type [9]: excluded_tokens is declared to have type `Dict[str, Set[object]]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/doc.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/doc.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/doc.py:451:25 Invalid type [31]: Expression `str or int` is not a valid type.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/doc.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/doc.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/doc.py:454:17 Invalid type [31]: Expression `str or int` is not a valid type.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/doc.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/language.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/language.py:43:8 Incompatible variable type [9]: tags is declared to have type `List[str]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/language.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/language.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/language.py:44:8 Incompatible variable type [9]: description is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/language.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/language.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/language.py:88:50 Incompatible variable type [9]: name is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/language.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/language.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/language.py:88:68 Incompatible variable type [9]: access is declared to have type `Set[str]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/language.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/language.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/language.py:111:38 Incompatible variable type [9]: access is declared to have type `Set[str]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/language.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/language.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/language.py:177:51 Incompatible variable type [9]: access is declared to have type `Set[str]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/language.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/language.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/language.py:369:8 Incompatible variable type [9]: access is declared to have type `Set[str]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/language.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/language.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/language.py:370:8 Incompatible variable type [9]: name is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/language.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/language.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/language.py:371:8 Incompatible variable type [9]: before is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/language.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/language.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/language.py:372:8 Incompatible variable type [9]: after is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/language.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pipeline/average_doc_encoder.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pipeline/average_doc_encoder.py:28:14 Incompatible variable type [9]: excluded_tokens is declared to have type `Dict[str, Set[object]]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pipeline/average_doc_encoder.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pipeline/average_doc_encoder.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pipeline/average_doc_encoder.py:59:8 Incompatible variable type [9]: crypto_config is declared to have type `Dict[str, object]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pipeline/average_doc_encoder.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pipeline/pipeline.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pipeline/pipeline.py:30:8 Incompatible variable type [9]: tags is declared to have type `Set[str]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pipeline/pipeline.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pipeline/pipeline.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pipeline/pipeline.py:31:8 Incompatible variable type [9]: description is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pipeline/pipeline.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pipeline/pipeline.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pipeline/pipeline.py:121:8 Incompatible return type [7]: Expected `Pipeline` but got implicit return value of `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pipeline/pipeline.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pipeline/pipeline.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pipeline/pipeline.py:142:8 Incompatible variable type [9]: id_at_location is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pipeline/pipeline.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pipeline/pipeline.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pipeline/pipeline.py:143:8 Incompatible variable type [9]: tags is declared to have type `Set[str]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pipeline/pipeline.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pipeline/pipeline.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pipeline/pipeline.py:221:8 Incompatible return type [7]: Expected `Tuple[object]` but got `Tuple[typing.Any, typing.Any, typing.Any, typing.Any, typing.Any]`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pipeline/pipeline.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pipeline/pointers/pipeline_pointer.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pipeline/pointers/pipeline_pointer.py:97:8 Incompatible return type [7]: Expected `Tuple[object]` but got `Tuple[typing.Any, typing.Any]`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pipeline/pointers/pipeline_pointer.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pipeline/simple_tagger.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pipeline/simple_tagger.py:29:8 Incompatible variable type [9]: attribute is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pipeline/simple_tagger.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pipeline/simple_tagger.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pipeline/simple_tagger.py:30:8 Incompatible variable type [9]: lookups is declared to have type `Union[Dict[typing.Any, typing.Any], Set[typing.Any], typing.List[typing.Any]]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pipeline/simple_tagger.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pipeline/simple_tagger.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pipeline/simple_tagger.py:362:12 Incompatible parameter type [6]: Expected `typing.Tuple[object]` for 1st parameter `simple_obj` to call `State.__init__` but got `typing.Tuple[typing.Any, typing.Any, typing.Any, typing.Any, typing.Any]`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pipeline/simple_tagger.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pipeline/single_label_classifier.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pipeline/single_label_classifier.py:42:8 Incompatible variable type [9]: doc_encoder is declared to have type `AverageDocEncoder` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pipeline/single_label_classifier.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pipeline/single_label_classifier.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pipeline/single_label_classifier.py:44:8 Incompatible variable type [9]: encryption is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pipeline/single_label_classifier.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pipeline/single_label_classifier.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pipeline/single_label_classifier.py:45:8 Incompatible variable type [9]: labels is declared to have type `List[str]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pipeline/single_label_classifier.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pipeline/single_label_classifier.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pipeline/single_label_classifier.py:367:12 Incompatible parameter type [6]: Expected `typing.Tuple[object]` for 1st parameter `simple_obj` to call `State.__init__` but got `typing.Tuple[typing.Tuple[typing.Any, typing.Any], typing.Any, typing.Any, typing.Any, typing.Any]`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pipeline/single_label_classifier.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pipeline/single_label_classifier.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pipeline/single_label_classifier.py:415:54 Incompatible parameter type [6]: Expected `typing.Tuple[object]` for 2nd parameter `state_simple` to call `State.detail` but got `typing.Tuple[typing.Any, ...]`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pipeline/single_label_classifier.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pipeline/subpipeline.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pipeline/subpipeline.py:32:34 Incompatible variable type [9]: id is declared to have type `Union[int, str]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pipeline/subpipeline.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pipeline/subpipeline.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pipeline/subpipeline.py:105:8 Incompatible variable type [9]: input_id is declared to have type `Union[int, str]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pipeline/subpipeline.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pipeline/subpipeline.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pipeline/subpipeline.py:195:8 Incompatible variable type [9]: ptr_id is declared to have type `Union[int, str]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pipeline/subpipeline.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pipeline/subpipeline.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pipeline/subpipeline.py:263:8 Incompatible return type [7]: Expected `Tuple[object]` but got `Tuple[typing.Any, typing.Any, typing.Any, typing.Any, List[typing.Any]]`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pipeline/subpipeline.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pointers/doc_pointer.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pointers/doc_pointer.py:21:8 Incompatible variable type [9]: id_at_location is declared to have type `Union[int, str]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pointers/doc_pointer.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pointers/doc_pointer.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pointers/doc_pointer.py:23:8 Incompatible variable type [9]: id is declared to have type `Union[int, str]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pointers/doc_pointer.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pointers/doc_pointer.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pointers/doc_pointer.py:24:8 Incompatible variable type [9]: tags is declared to have type `List[str]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pointers/doc_pointer.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pointers/doc_pointer.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pointers/doc_pointer.py:25:8 Incompatible variable type [9]: description is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pointers/doc_pointer.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pointers/doc_pointer.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pointers/doc_pointer.py:106:8 Incompatible variable type [9]: excluded_tokens is declared to have type `Dict[str, Set[object]]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pointers/doc_pointer.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pointers/doc_pointer.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pointers/doc_pointer.py:107:8 Incompatible variable type [9]: protocol is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pointers/doc_pointer.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pointers/doc_pointer.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pointers/doc_pointer.py:156:8 Incompatible variable type [9]: excluded_tokens is declared to have type `Dict[str, Set[object]]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pointers/doc_pointer.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pointers/doc_pointer.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pointers/doc_pointer.py:157:8 Incompatible variable type [9]: protocol is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pointers/doc_pointer.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pointers/span_pointer.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pointers/span_pointer.py:15:8 Incompatible variable type [9]: id_at_location is declared to have type `Union[int, str]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pointers/span_pointer.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pointers/span_pointer.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pointers/span_pointer.py:17:8 Incompatible variable type [9]: id is declared to have type `Union[int, str]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pointers/span_pointer.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/pointers/state_pointer.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/pointers/state_pointer.py:93:8 Incompatible return type [7]: Expected `Tuple[object]` but got `Tuple[typing.Any, typing.Any]`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/pointers/state_pointer.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/span.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/span.py:28:8 Incompatible variable type [9]: id is declared to have type `int` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/span.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/span.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/span.py:158:25 Incompatible variable type [9]: excluded_tokens is declared to have type `Dict[str, Set[object]]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/span.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/span.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/span.py:198:14 Incompatible variable type [9]: excluded_tokens is declared to have type `Dict[str, Set[object]]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/span.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/span.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/span.py:271:25 Invalid type [31]: Expression `str or int` is not a valid type.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/span.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/span.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/span.py:274:17 Invalid type [31]: Expression `str or int` is not a valid type.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/span.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/state.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/state.py:21:8 Incompatible variable type [9]: tags is declared to have type `Set[str]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/state.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/state.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/state.py:22:8 Incompatible variable type [9]: description is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/state.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/state.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/state.py:111:8 Incompatible variable type [9]: id_at_location is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/state.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/state.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/state.py:112:8 Incompatible variable type [9]: tags is declared to have type `Set[str]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/state.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/state.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/state.py:179:8 Incompatible return type [7]: Expected `Tuple[object]` but got `Tuple[typing.Any, typing.Any, typing.Any, typing.Any, Tuple[object]]`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/state.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/token.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/token.py:23:8 Incompatible variable type [9]: id is declared to have type `int` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/token.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/token_exception.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/token_exception.py:518:26 Incompatible parameter type [6]: Expected `int` for 1st positional only parameter to call `int.__add__` but got `str`.",
    "exception": "PatchSet should only have 1 Patch, but it has 0",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/token_exception.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/token_exception.py:520:26 Incompatible parameter type [6]: Expected `int` for 1st positional only parameter to call `int.__add__` but got `str`.",
    "exception": "PatchSet should only have 1 Patch, but it has 0",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/tokenizer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/tokenizers/spacy_tokenizer.py",
    "file_hunks_size": 26,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "syfertext/tokenizer.py:69:8 Incompatible variable type [9]: exceptions is declared to have type `Dict[str, List[Dict[typing.Any, typing.Any]]]` but is used as type `None`.",
    "message": " exceptions is declared to have type `Dict[str, List[Dict[typing.Any, typing.Any]]]` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 69,
    "warning_line": "        exceptions: Dict[str, List[dict]] = None,"
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/tokenizer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/tokenizers/spacy_tokenizer.py",
    "file_hunks_size": 26,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "syfertext/tokenizer.py:70:8 Incompatible variable type [9]: prefixes is declared to have type `List[str]` but is used as type `None`.",
    "message": " prefixes is declared to have type `List[str]` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 70,
    "warning_line": "        prefixes: List[str] = None,"
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/tokenizer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/tokenizers/spacy_tokenizer.py",
    "file_hunks_size": 26,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "syfertext/tokenizer.py:71:8 Incompatible variable type [9]: suffixes is declared to have type `List[str]` but is used as type `None`.",
    "message": " suffixes is declared to have type `List[str]` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 71,
    "warning_line": "        suffixes: List[str] = None,"
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/tokenizer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/tokenizers/spacy_tokenizer.py",
    "file_hunks_size": 26,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "syfertext/tokenizer.py:72:8 Incompatible variable type [9]: infixes is declared to have type `List[str]` but is used as type `None`.",
    "message": " infixes is declared to have type `List[str]` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 72,
    "warning_line": "        infixes: List[str] = None,"
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/tokenizer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/tokenizers/spacy_tokenizer.py",
    "file_hunks_size": 26,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "syfertext/tokenizer.py:189:8 Incompatible variable type [9]: exceptions is declared to have type `Dict[str, List[Dict[typing.Any, typing.Any]]]` but is used as type `None`.",
    "message": " exceptions is declared to have type `Dict[str, List[Dict[typing.Any, typing.Any]]]` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 189,
    "warning_line": "        exceptions: Dict[str, List[dict]] = None,"
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/tokenizer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/tokenizers/spacy_tokenizer.py",
    "file_hunks_size": 26,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "syfertext/tokenizer.py:190:8 Incompatible variable type [9]: prefixes is declared to have type `List[str]` but is used as type `None`.",
    "message": " prefixes is declared to have type `List[str]` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 190,
    "warning_line": "        prefixes: List[str] = None,"
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/tokenizer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/tokenizers/spacy_tokenizer.py",
    "file_hunks_size": 26,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "syfertext/tokenizer.py:191:8 Incompatible variable type [9]: suffixes is declared to have type `List[str]` but is used as type `None`.",
    "message": " suffixes is declared to have type `List[str]` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 191,
    "warning_line": "        suffixes: List[str] = None,"
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/tokenizer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/tokenizers/spacy_tokenizer.py",
    "file_hunks_size": 26,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "syfertext/tokenizer.py:192:8 Incompatible variable type [9]: infixes is declared to have type `List[str]` but is used as type `None`.",
    "message": " infixes is declared to have type `List[str]` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 192,
    "warning_line": "        infixes: List[str] = None,"
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/tokenizer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/tokenizers/spacy_tokenizer.py",
    "file_hunks_size": 26,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "syfertext/tokenizer.py:292:54 Incompatible parameter type [6]: Expected `Tuple[object]` for 2nd parameter `state_simple` to call `State.detail` but got `typing.Tuple[typing.Any, ...]`.",
    "message": " Expected `Tuple[object]` for 2nd parameter `state_simple` to call `State.detail` but got `typing.Tuple[typing.Any, ...]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 292,
    "warning_line": "            state = State.detail(worker=LOCAL_WORKER, state_simple=result)"
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/tokenizer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/tokenizers/spacy_tokenizer.py",
    "file_hunks_size": 26,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "syfertext/tokenizer.py:326:12 Incompatible parameter type [6]: Expected `Tuple[object]` for 1st parameter `simple_obj` to call `State.__init__` but got `Tuple[typing.Any, typing.Any, typing.Any, typing.Any]`.",
    "message": " Expected `Tuple[object]` for 1st parameter `simple_obj` to call `State.__init__` but got `Tuple[typing.Any, typing.Any, typing.Any, typing.Any]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 326,
    "warning_line": "            simple_obj=(exceptions_simple, prefixes_simple, suffixes_simple, infixes_simple),"
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/tokenizer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/tokenizers/spacy_tokenizer.py",
    "file_hunks_size": 26,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "syfertext/tokenizer.py:626:12 Incompatible return type [7]: Expected `Tuple[TokenMeta, str]` but got `Tuple[None, str]`.",
    "message": " Expected `Tuple[TokenMeta, str]` but got `Tuple[None, str]`.",
    "rule_id": "Incompatible return type [7]",
    "warning_line_no": 626,
    "warning_line": "            return None, substring"
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/tokenizer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/tokenizers/spacy_tokenizer.py",
    "file_hunks_size": 26,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "syfertext/tokenizer.py:655:12 Incompatible return type [7]: Expected `Tuple[TokenMeta, str]` but got `Tuple[None, str]`.",
    "message": " Expected `Tuple[TokenMeta, str]` but got `Tuple[None, str]`.",
    "rule_id": "Incompatible return type [7]",
    "warning_line_no": 655,
    "warning_line": "            return None, substring"
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/utils.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/utils.py:29:56 Incompatible variable type [9]: step is declared to have type `int` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/utils.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/utils.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/utils.py:276:8 Incompatible return type [7]: Expected `Dict[str, object]` but got `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/utils.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/vocab.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/vocab.py:33:23 Incompatible variable type [9]: hash2row is declared to have type `Dict[int, int]` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/vocab.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/vocab.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/vocab.py:184:54 Incompatible parameter type [6]: Expected `typing.Tuple[object]` for 2nd parameter `state_simple` to call `State.detail` but got `typing.Tuple[typing.Any, ...]`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/vocab.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/vocab.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/vocab.py:213:22 Incompatible parameter type [6]: Expected `typing.Tuple[object]` for 1st parameter `simple_obj` to call `State.__init__` but got `typing.Tuple[typing.Any, typing.Any]`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/vocab.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/vocab.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/vocab.py:298:12 Incompatible return type [7]: Expected `LexemeMeta` but got `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/vocab.py'",
    "dd_fail": true
  },
  {
    "project": "OpenMined/SyferText",
    "commit": "a3cadaf6c850d25e81a0d092effda304859a8cfb",
    "filename": "syfertext/vocab.py",
    "min_patch_found": false,
    "full_warning_msg": "syfertext/vocab.py:335:12 Incompatible attribute type [8]: Attribute `id` declared in class `LexemeMeta` has type `int` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/OpenMined-SyferText/syfertext/vocab.py'",
    "dd_fail": true
  }
]