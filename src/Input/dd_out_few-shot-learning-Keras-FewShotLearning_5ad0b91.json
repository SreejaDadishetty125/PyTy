[
  {
    "project": "few-shot-learning/Keras-FewShotLearning",
    "commit": "5ad0b91da493c6665ea597f4ee9126fe559c5101",
    "filename": "notebooks/random_balanced_training.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/few-shot-learning-Keras-FewShotLearning/notebooks/siamese_nets_training.py",
    "file_hunks_size": 6,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "notebooks/random_balanced_training.py:157:4 Incompatible variable type [9]: test_sequence is declared to have type `training.single.deterministic_sequence.DeterministicSequence` but is used as type `prediction.pairs.product_sequence.ProductSequence`.",
    "message": " test_sequence is declared to have type `training.single.deterministic_sequence.DeterministicSequence` but is used as type `prediction.pairs.product_sequence.ProductSequence`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 157,
    "warning_line": "    test_sequence = prediction.pairs.ProductSequence(",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": ")\nsiamese_nets = load_model(output_folder / \"best_model.h5\")\n\n#%% Eval on test set\nk_shot = 3\nn_way = 10\nn_episode = 50\ntest_sequence = training.single.DeterministicSequence(test_set, preprocessings=preprocessing, batch_size=16)\nembeddings = siamese_nets.get_layer(\"branch_model\").predict_generator(test_sequence)\n\nscores = []\nfor _ in range(n_episode):\n    selected_labels = np.random.choice(test_set.label.unique(), size=n_way, replace=True)\n    support_set = (\n        test_set.loc[lambda df: df.label.isin(selected_labels)]\n        .groupby(\"label\")\n        .apply(lambda group: group.sample(k_shot))\n        .reset_index(\"label\", drop=True)\n    )\n    query_set = test_set.loc[lambda df: df.label.isin(selected_labels)].loc[lambda df: ~df.index.isin(support_set.index)]\n    support_set_embeddings = embeddings[support_set.index]\n    query_set_embeddings = embeddings[query_set.index]\n    test_sequence = prediction.pairs.ProductSequence(\n        support_images_array=support_set_embeddings,\n        query_images_array=query_set_embeddings,\n        support_labels=support_set.label.values,\n        query_labels=query_set.label.values,\n    )\n    scores += [\n        (\n            test_sequence.pairs_indexes.assign(\n                score=siamese_nets.get_layer(\"head_model\").predict_generator(test_sequence, verbose=1)\n            )\n            .groupby(\"query_index\")\n            .apply(\n                lambda group: (\n                    group.sort_values(\"score\", ascending=False)\n                    .assign(\n                        average_precision=lambda df: df.target.expanding().mean(),\n                        good_prediction=lambda df: df.target.iloc[0],\n                    )\n                    .loc[lambda df: df.target]\n                    .agg(\"mean\")\n                )\n            )\n            .agg(\"mean\")\n        )\n    ]\n\nscores = pd.DataFrame(scores)[[\"score\", \"average_precision\", \"good_prediction\"]]\nscores.to_csv(output_folder / \"scores.csv\", index=False)\n",
        "source_code_len": 1983,
        "target_code": ")\nsiamese_nets.save_model(str(output_folder / \"final_model.h5\"))\n",
        "target_code_len": 65,
        "diff_format": "@@ -135,51 +131,2 @@\n )\n-siamese_nets = load_model(output_folder / \"best_model.h5\")\n-\n-#%% Eval on test set\n-k_shot = 3\n-n_way = 10\n-n_episode = 50\n-test_sequence = training.single.DeterministicSequence(test_set, preprocessings=preprocessing, batch_size=16)\n-embeddings = siamese_nets.get_layer(\"branch_model\").predict_generator(test_sequence)\n-\n-scores = []\n-for _ in range(n_episode):\n-    selected_labels = np.random.choice(test_set.label.unique(), size=n_way, replace=True)\n-    support_set = (\n-        test_set.loc[lambda df: df.label.isin(selected_labels)]\n-        .groupby(\"label\")\n-        .apply(lambda group: group.sample(k_shot))\n-        .reset_index(\"label\", drop=True)\n-    )\n-    query_set = test_set.loc[lambda df: df.label.isin(selected_labels)].loc[lambda df: ~df.index.isin(support_set.index)]\n-    support_set_embeddings = embeddings[support_set.index]\n-    query_set_embeddings = embeddings[query_set.index]\n-    test_sequence = prediction.pairs.ProductSequence(\n-        support_images_array=support_set_embeddings,\n-        query_images_array=query_set_embeddings,\n-        support_labels=support_set.label.values,\n-        query_labels=query_set.label.values,\n-    )\n-    scores += [\n-        (\n-            test_sequence.pairs_indexes.assign(\n-                score=siamese_nets.get_layer(\"head_model\").predict_generator(test_sequence, verbose=1)\n-            )\n-            .groupby(\"query_index\")\n-            .apply(\n-                lambda group: (\n-                    group.sort_values(\"score\", ascending=False)\n-                    .assign(\n-                        average_precision=lambda df: df.target.expanding().mean(),\n-                        good_prediction=lambda df: df.target.iloc[0],\n-                    )\n-                    .loc[lambda df: df.target]\n-                    .agg(\"mean\")\n-                )\n-            )\n-            .agg(\"mean\")\n-        )\n-    ]\n-\n-scores = pd.DataFrame(scores)[[\"score\", \"average_precision\", \"good_prediction\"]]\n-scores.to_csv(output_folder / \"scores.csv\", index=False)\n+siamese_nets.save_model(str(output_folder / \"final_model.h5\"))\n",
        "source_code_with_indent": ")\nsiamese_nets = load_model(output_folder / \"best_model.h5\")\n\n#%% Eval on test set\nk_shot = 3\nn_way = 10\nn_episode = 50\ntest_sequence = training.single.DeterministicSequence(test_set, preprocessings=preprocessing, batch_size=16)\nembeddings = siamese_nets.get_layer(\"branch_model\").predict_generator(test_sequence)\n\nscores = []\nfor _ in range(n_episode):\n    <IND>selected_labels = np.random.choice(test_set.label.unique(), size=n_way, replace=True)\n    support_set = (\n        test_set.loc[lambda df: df.label.isin(selected_labels)]\n        .groupby(\"label\")\n        .apply(lambda group: group.sample(k_shot))\n        .reset_index(\"label\", drop=True)\n    )\n    query_set = test_set.loc[lambda df: df.label.isin(selected_labels)].loc[lambda df: ~df.index.isin(support_set.index)]\n    support_set_embeddings = embeddings[support_set.index]\n    query_set_embeddings = embeddings[query_set.index]\n    test_sequence = prediction.pairs.ProductSequence(\n        support_images_array=support_set_embeddings,\n        query_images_array=query_set_embeddings,\n        support_labels=support_set.label.values,\n        query_labels=query_set.label.values,\n    )\n    scores += [\n        (\n            test_sequence.pairs_indexes.assign(\n                score=siamese_nets.get_layer(\"head_model\").predict_generator(test_sequence, verbose=1)\n            )\n            .groupby(\"query_index\")\n            .apply(\n                lambda group: (\n                    group.sort_values(\"score\", ascending=False)\n                    .assign(\n                        average_precision=lambda df: df.target.expanding().mean(),\n                        good_prediction=lambda df: df.target.iloc[0],\n                    )\n                    .loc[lambda df: df.target]\n                    .agg(\"mean\")\n                )\n            )\n            .agg(\"mean\")\n        )\n    ]\n\n<DED>scores = pd.DataFrame(scores)[[\"score\", \"average_precision\", \"good_prediction\"]]\nscores.to_csv(output_folder / \"scores.csv\", index=False)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": ")\nsiamese_nets.save_model(str(output_folder / \"final_model.h5\"))\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  }
]