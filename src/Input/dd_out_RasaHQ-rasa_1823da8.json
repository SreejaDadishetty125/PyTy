[
  {
    "project": "RasaHQ/rasa",
    "commit": "1823da83403ca6b5fc76eaa5a231a3c9164157a6",
    "filename": "tests/nlu/classifiers/test_diet_classifier.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/tests/nlu/classifiers/test_diet_classifier.py",
    "file_hunks_size": 28,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "tests/nlu/classifiers/test_diet_classifier.py:136:28 Incompatible parameter type [6]: Expected `TrainingData` for 1st positional only parameter to call `rasa.nlu.components.Component.train` but got `str`.",
    "message": " Expected `TrainingData` for 1st positional only parameter to call `rasa.nlu.components.Component.train` but got `str`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 136,
    "warning_line": "            component.train(training_data)"
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "1823da83403ca6b5fc76eaa5a231a3c9164157a6",
    "filename": "tests/nlu/classifiers/test_diet_classifier.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/tests/nlu/classifiers/test_diet_classifier.py",
    "file_hunks_size": 28,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "tests/nlu/classifiers/test_diet_classifier.py:138:19 Incompatible parameter type [6]: Expected `TrainingData` for 1st parameter `training_data` to call `DIETClassifier.train` but got `str`.",
    "message": " Expected `TrainingData` for 1st parameter `training_data` to call `DIETClassifier.train` but got `str`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 138,
    "warning_line": "        diet.train(training_data=training_data)"
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "1823da83403ca6b5fc76eaa5a231a3c9164157a6",
    "filename": "tests/nlu/selectors/test_selectors.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/tests/nlu/selectors/test_selectors.py",
    "file_hunks_size": 30,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "tests/nlu/selectors/test_selectors.py:291:36 Incompatible parameter type [6]: Expected `List[Dict[str, str]]` for 1st positional only parameter to call `load_pipeline` but got `List[Union[Dict[str, Union[int, str]], Dict[str, str]]]`.",
    "message": " Expected `List[Dict[str, str]]` for 1st positional only parameter to call `load_pipeline` but got `List[Union[Dict[str, Union[int, str]], Dict[str, str]]]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 291,
    "warning_line": "    loaded_pipeline = load_pipeline(pipeline)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import numpy as np\nfrom typing import List, Dict, Text, Any, Optional, Union, Callable\nfrom unittest.mock import Mock\n",
        "source_code_len": 118,
        "target_code": "import numpy as np\nfrom typing import List, Dict, Text, Any, Optional, Tuple, Union, Callable\nfrom unittest.mock import Mock\n",
        "target_code_len": 125,
        "diff_format": "@@ -4,3 +4,3 @@\n import numpy as np\n-from typing import List, Dict, Text, Any, Optional, Union, Callable\n+from typing import List, Dict, Text, Any, Optional, Tuple, Union, Callable\n from unittest.mock import Mock\n",
        "source_code_with_indent": "import numpy as np\nfrom typing import List, Dict, Text, Any, Optional, Union, Callable\nfrom unittest.mock import Mock\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "import numpy as np\nfrom typing import List, Dict, Text, Any, Optional, Tuple, Union, Callable\nfrom unittest.mock import Mock\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import rasa.model\nimport rasa.nlu.train\nfrom rasa.engine.graph import ExecutionContext\nfrom rasa.engine.storage.resource import Resource\nfrom rasa.engine.storage.storage import ModelStorage\nfrom rasa.nlu import registry\nfrom rasa.nlu.components import Component\nfrom rasa.shared.importers.rasa import RasaFileImporter\n",
        "source_code_len": 318,
        "target_code": "import rasa.model\nfrom rasa.nlu.featurizers.sparse_featurizer.count_vectors_featurizer import (\n    CountVectorsFeaturizerGraphComponent,\n)\nfrom rasa.nlu.featurizers.sparse_featurizer.lexical_syntactic_featurizer import (\n    LexicalSyntacticFeaturizerGraphComponent,\n)\nfrom rasa.nlu.featurizers.sparse_featurizer.regex_featurizer import (\n    RegexFeaturizerGraphComponent,\n)\nfrom rasa.nlu.tokenizers.whitespace_tokenizer import WhitespaceTokenizerGraphComponent\nimport rasa.nlu.train\nfrom rasa.engine.graph import ExecutionContext, GraphComponent\nfrom rasa.engine.storage.resource import Resource\nfrom rasa.engine.storage.storage import ModelStorage\nfrom rasa.shared.importers.rasa import RasaFileImporter\n",
        "target_code_len": 708,
        "diff_format": "@@ -10,8 +10,16 @@\n import rasa.model\n+from rasa.nlu.featurizers.sparse_featurizer.count_vectors_featurizer import (\n+    CountVectorsFeaturizerGraphComponent,\n+)\n+from rasa.nlu.featurizers.sparse_featurizer.lexical_syntactic_featurizer import (\n+    LexicalSyntacticFeaturizerGraphComponent,\n+)\n+from rasa.nlu.featurizers.sparse_featurizer.regex_featurizer import (\n+    RegexFeaturizerGraphComponent,\n+)\n+from rasa.nlu.tokenizers.whitespace_tokenizer import WhitespaceTokenizerGraphComponent\n import rasa.nlu.train\n-from rasa.engine.graph import ExecutionContext\n+from rasa.engine.graph import ExecutionContext, GraphComponent\n from rasa.engine.storage.resource import Resource\n from rasa.engine.storage.storage import ModelStorage\n-from rasa.nlu import registry\n-from rasa.nlu.components import Component\n from rasa.shared.importers.rasa import RasaFileImporter\n",
        "source_code_with_indent": "import rasa.model\nimport rasa.nlu.train\nfrom rasa.engine.graph import ExecutionContext\nfrom rasa.engine.storage.resource import Resource\nfrom rasa.engine.storage.storage import ModelStorage\nfrom rasa.nlu import registry\nfrom rasa.nlu.components import Component\nfrom rasa.shared.importers.rasa import RasaFileImporter\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "import rasa.model\nfrom rasa.nlu.featurizers.sparse_featurizer.count_vectors_featurizer import (\n    CountVectorsFeaturizerGraphComponent,\n)\nfrom rasa.nlu.featurizers.sparse_featurizer.lexical_syntactic_featurizer import (\n    LexicalSyntacticFeaturizerGraphComponent,\n)\nfrom rasa.nlu.featurizers.sparse_featurizer.regex_featurizer import (\n    RegexFeaturizerGraphComponent,\n)\nfrom rasa.nlu.tokenizers.whitespace_tokenizer import WhitespaceTokenizerGraphComponent\nimport rasa.nlu.train\nfrom rasa.engine.graph import ExecutionContext, GraphComponent\nfrom rasa.engine.storage.resource import Resource\nfrom rasa.engine.storage.storage import ModelStorage\nfrom rasa.shared.importers.rasa import RasaFileImporter\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ],\n):\n    pipeline = [{\"name\": \"WhitespaceTokenizer\"}, {\"name\": \"CountVectorsFeaturizer\"}]\n    loaded_pipeline = [\n        registry.get_component_class(component.pop(\"name\"))(component)\n        for component in copy.deepcopy(pipeline)\n    ]\n\n    for component in loaded_pipeline:\n        component.train(response_selector_training_data)\n\n    response_selector = create_response_selector(config_params)\n\n    response_selector.train(training_data=response_selector_training_data)\n",
        "source_code_len": 482,
        "target_code": "    ],\n    default_model_storage: ModelStorage,\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    response_selector_training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, response_selector_training_data\n    )\n\n    response_selector = create_response_selector(config_params)\n    response_selector.train(training_data=response_selector_training_data)\n",
        "target_code_len": 595,
        "diff_format": "@@ -116,14 +166,15 @@\n     ],\n-):\n-    pipeline = [{\"name\": \"WhitespaceTokenizer\"}, {\"name\": \"CountVectorsFeaturizer\"}]\n-    loaded_pipeline = [\n-        registry.get_component_class(component.pop(\"name\"))(component)\n-        for component in copy.deepcopy(pipeline)\n+    default_model_storage: ModelStorage,\n+    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n+    process_message: Callable[..., Message],\n+):\n+    pipeline = [\n+        {\"component\": WhitespaceTokenizerGraphComponent},\n+        {\"component\": CountVectorsFeaturizerGraphComponent},\n     ]\n-\n-    for component in loaded_pipeline:\n-        component.train(response_selector_training_data)\n+    response_selector_training_data, loaded_pipeline = train_and_preprocess(\n+        pipeline, response_selector_training_data\n+    )\n \n     response_selector = create_response_selector(config_params)\n-\n     response_selector.train(training_data=response_selector_training_data)\n",
        "source_code_with_indent": "    ],\n):\n    <IND>pipeline = [{\"name\": \"WhitespaceTokenizer\"}, {\"name\": \"CountVectorsFeaturizer\"}]\n    loaded_pipeline = [\n        registry.get_component_class(component.pop(\"name\"))(component)\n        for component in copy.deepcopy(pipeline)\n    ]\n\n    for component in loaded_pipeline:\n        <IND>component.train(response_selector_training_data)\n\n    <DED>response_selector = create_response_selector(config_params)\n\n    response_selector.train(training_data=response_selector_training_data)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ],\n    default_model_storage: ModelStorage,\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    <IND>pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    response_selector_training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, response_selector_training_data\n    )\n\n    response_selector = create_response_selector(config_params)\n    response_selector.train(training_data=response_selector_training_data)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    message = Message(data={TEXT: \"hello\"})\n    for component in loaded_pipeline:\n        component.process(message)\n\n",
        "source_code_len": 118,
        "target_code": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_len": 101,
        "diff_format": "@@ -131,4 +182,3 @@\n     message = Message(data={TEXT: \"hello\"})\n-    for component in loaded_pipeline:\n-        component.process(message)\n+    message = process_message(loaded_pipeline, message)\n \n",
        "source_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n    for component in loaded_pipeline:\n        <IND>component.process(message)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "\ndef load_pipeline(pipeline: List[Dict[Text, Text]]) -> List[Component]:\n    loaded_pipeline = [\n        registry.get_component_class(component.pop(\"name\"))(component)\n        for component in copy.deepcopy(pipeline)\n    ]\n\n    return loaded_pipeline\n\n\ndef train_pipeline(\n    loaded_pipeline: List[Component], training_data_paths: List[Text],\n) -> TrainingData:\n    importer = RasaFileImporter(training_data_paths=training_data_paths)\n    training_data = importer.get_nlu_data()\n\n    for component in loaded_pipeline:\n        component.train(training_data)\n\n    return training_data\n\n\ndef test_train_model_checkpointing(\n",
        "source_code_len": 622,
        "target_code": "\ndef test_train_model_checkpointing(\n",
        "target_code_len": 37,
        "diff_format": "@@ -251,23 +301,2 @@\n \n-def load_pipeline(pipeline: List[Dict[Text, Text]]) -> List[Component]:\n-    loaded_pipeline = [\n-        registry.get_component_class(component.pop(\"name\"))(component)\n-        for component in copy.deepcopy(pipeline)\n-    ]\n-\n-    return loaded_pipeline\n-\n-\n-def train_pipeline(\n-    loaded_pipeline: List[Component], training_data_paths: List[Text],\n-) -> TrainingData:\n-    importer = RasaFileImporter(training_data_paths=training_data_paths)\n-    training_data = importer.get_nlu_data()\n-\n-    for component in loaded_pipeline:\n-        component.train(training_data)\n-\n-    return training_data\n-\n-\n def test_train_model_checkpointing(\n",
        "source_code_with_indent": "\n<DED>def load_pipeline(pipeline: List[Dict[Text, Text]]) -> List[Component]:\n    <IND>loaded_pipeline = [\n        registry.get_component_class(component.pop(\"name\"))(component)\n        for component in copy.deepcopy(pipeline)\n    ]\n\n    return loaded_pipeline\n\n\n<DED>def train_pipeline(\n    loaded_pipeline: List[Component], training_data_paths: List[Text],\n) -> TrainingData:\n    <IND>importer = RasaFileImporter(training_data_paths=training_data_paths)\n    training_data = importer.get_nlu_data()\n\n    for component in loaded_pipeline:\n        <IND>component.train(training_data)\n\n    <DED>return training_data\n\n\n<DED>def test_train_model_checkpointing(\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def test_train_model_checkpointing(\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    default_model_storage: ModelStorage,\n):\n    pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\n            \"name\": \"CountVectorsFeaturizer\",\n            \"analyzer\": \"char_wb\",\n",
        "source_code_len": 193,
        "target_code": "    default_model_storage: ModelStorage,\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n):\n    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\n            \"component\": CountVectorsFeaturizerGraphComponent,\n            \"analyzer\": \"char_wb\",\n",
        "target_code_len": 311,
        "diff_format": "@@ -277,7 +306,8 @@\n     default_model_storage: ModelStorage,\n+    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n ):\n     pipeline = [\n-        {\"name\": \"WhitespaceTokenizer\"},\n+        {\"component\": WhitespaceTokenizerGraphComponent},\n         {\n-            \"name\": \"CountVectorsFeaturizer\",\n+            \"component\": CountVectorsFeaturizerGraphComponent,\n             \"analyzer\": \"char_wb\",\n",
        "source_code_with_indent": "    default_model_storage: ModelStorage,\n):\n    <IND>pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\n            \"name\": \"CountVectorsFeaturizer\",\n            \"analyzer\": \"char_wb\",\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    default_model_storage: ModelStorage,\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n):\n    <IND>pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\n            \"component\": CountVectorsFeaturizerGraphComponent,\n            \"analyzer\": \"char_wb\",\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n\n",
        "source_code_len": 125,
        "target_code": "\n    training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, \"data/test_selectors\"\n    )\n\n",
        "target_code_len": 107,
        "diff_format": "@@ -290,4 +320,5 @@\n \n-    loaded_pipeline = load_pipeline(pipeline)\n-    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n+    training_data, loaded_pipeline = train_and_preprocess(\n+        pipeline, \"data/test_selectors\"\n+    )\n \n",
        "source_code_with_indent": "\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, \"data/test_selectors\"\n    )\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "\ndef _train_persist_load_with_different_settings(\n    pipeline: List[Dict[Text, Any]],\n    config_params: Dict[Text, Any],\n    create_response_selector: Callable[\n        [Dict[Text, Any]], ResponseSelectorGraphComponent\n    ],\n    load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n    should_finetune: bool,\n    default_execution_context: ExecutionContext,\n):\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(\n        loaded_pipeline, [\"data/examples/rasa/demo-rasa.yml\"]\n    )\n\n    response_selector = create_response_selector(config_params)\n    response_selector.train(training_data=training_data)\n\n    if should_finetune:\n        default_execution_context.is_finetuning = True\n\n    message = Message(data={TEXT: \"Rasa is great!\"})\n\n    for component in loaded_pipeline:\n        component.process(message)\n\n    message2 = copy.deepcopy(message)\n\n    classified_message = response_selector.process([message])[0]\n\n    loaded_selector = load_response_selector(config_params)\n\n    classified_message2 = loaded_selector.process([message2])[0]\n\n    assert classified_message2.fingerprint() == classified_message.fingerprint()\n\n\n@pytest.mark.skip_on_windows\n",
        "source_code_len": 1221,
        "target_code": "\n@pytest.mark.skip_on_windows\n",
        "target_code_len": 30,
        "diff_format": "@@ -319,39 +350,2 @@\n \n-def _train_persist_load_with_different_settings(\n-    pipeline: List[Dict[Text, Any]],\n-    config_params: Dict[Text, Any],\n-    create_response_selector: Callable[\n-        [Dict[Text, Any]], ResponseSelectorGraphComponent\n-    ],\n-    load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n-    should_finetune: bool,\n-    default_execution_context: ExecutionContext,\n-):\n-    loaded_pipeline = load_pipeline(pipeline)\n-    training_data = train_pipeline(\n-        loaded_pipeline, [\"data/examples/rasa/demo-rasa.yml\"]\n-    )\n-\n-    response_selector = create_response_selector(config_params)\n-    response_selector.train(training_data=training_data)\n-\n-    if should_finetune:\n-        default_execution_context.is_finetuning = True\n-\n-    message = Message(data={TEXT: \"Rasa is great!\"})\n-\n-    for component in loaded_pipeline:\n-        component.process(message)\n-\n-    message2 = copy.deepcopy(message)\n-\n-    classified_message = response_selector.process([message])[0]\n-\n-    loaded_selector = load_response_selector(config_params)\n-\n-    classified_message2 = loaded_selector.process([message2])[0]\n-\n-    assert classified_message2.fingerprint() == classified_message.fingerprint()\n-\n-\n @pytest.mark.skip_on_windows\n",
        "source_code_with_indent": "\n<DED><DED>def _train_persist_load_with_different_settings(\n    pipeline: List[Dict[Text, Any]],\n    config_params: Dict[Text, Any],\n    create_response_selector: Callable[\n        [Dict[Text, Any]], ResponseSelectorGraphComponent\n    ],\n    load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n    should_finetune: bool,\n    default_execution_context: ExecutionContext,\n):\n    <IND>loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(\n        loaded_pipeline, [\"data/examples/rasa/demo-rasa.yml\"]\n    )\n\n    response_selector = create_response_selector(config_params)\n    response_selector.train(training_data=training_data)\n\n    if should_finetune:\n        <IND>default_execution_context.is_finetuning = True\n\n    <DED>message = Message(data={TEXT: \"Rasa is great!\"})\n\n    for component in loaded_pipeline:\n        <IND>component.process(message)\n\n    <DED>message2 = copy.deepcopy(message)\n\n    classified_message = response_selector.process([message])[0]\n\n    loaded_selector = load_response_selector(config_params)\n\n    classified_message2 = loaded_selector.process([message2])[0]\n\n    assert classified_message2.fingerprint() == classified_message.fingerprint()\n\n\n<DED>@pytest.mark.skip_on_windows\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED><DED>@pytest.mark.skip_on_windows\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    default_execution_context: ExecutionContext,\n):\n    pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n",
        "source_code_len": 160,
        "target_code": "    default_execution_context: ExecutionContext,\n    train_persist_load_with_different_settings,\n):\n\n    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n",
        "target_code_len": 243,
        "diff_format": "@@ -363,6 +357,8 @@\n     default_execution_context: ExecutionContext,\n-):\n+    train_persist_load_with_different_settings,\n+):\n+\n     pipeline = [\n-        {\"name\": \"WhitespaceTokenizer\"},\n-        {\"name\": \"CountVectorsFeaturizer\"},\n+        {\"component\": WhitespaceTokenizerGraphComponent},\n+        {\"component\": CountVectorsFeaturizerGraphComponent},\n     ]\n",
        "source_code_with_indent": "    default_execution_context: ExecutionContext,\n):\n    <IND>pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    default_execution_context: ExecutionContext,\n    train_persist_load_with_different_settings,\n):\n\n    <IND>pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    _train_persist_load_with_different_settings(\n        pipeline,\n        config_params,\n        create_response_selector,\n        load_response_selector,\n        False,\n        default_execution_context,\n    )\n\n    _train_persist_load_with_different_settings(\n        pipeline,\n        config_params,\n        create_response_selector,\n        load_response_selector,\n        True,\n        default_execution_context,\n    )\n",
        "source_code_len": 425,
        "target_code": "\n    train_persist_load_with_different_settings(\n        pipeline, config_params, False,\n    )\n\n    train_persist_load_with_different_settings(\n        pipeline, config_params, True,\n    )\n",
        "target_code_len": 189,
        "diff_format": "@@ -370,18 +366,8 @@\n \n-    _train_persist_load_with_different_settings(\n-        pipeline,\n-        config_params,\n-        create_response_selector,\n-        load_response_selector,\n-        False,\n-        default_execution_context,\n-    )\n-\n-    _train_persist_load_with_different_settings(\n-        pipeline,\n-        config_params,\n-        create_response_selector,\n-        load_response_selector,\n-        True,\n-        default_execution_context,\n+    train_persist_load_with_different_settings(\n+        pipeline, config_params, False,\n+    )\n+\n+    train_persist_load_with_different_settings(\n+        pipeline, config_params, True,\n     )\n",
        "source_code_with_indent": "\n    _train_persist_load_with_different_settings(\n        pipeline,\n        config_params,\n        create_response_selector,\n        load_response_selector,\n        False,\n        default_execution_context,\n    )\n\n    _train_persist_load_with_different_settings(\n        pipeline,\n        config_params,\n        create_response_selector,\n        load_response_selector,\n        True,\n        default_execution_context,\n    )\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    train_persist_load_with_different_settings(\n        pipeline, config_params, False,\n    )\n\n    train_persist_load_with_different_settings(\n        pipeline, config_params, True,\n    )\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ],\n):\n",
        "source_code_len": 10,
        "target_code": "    ],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n",
        "target_code_len": 139,
        "diff_format": "@@ -394,2 +380,4 @@\n     ],\n+    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n+    process_message: Callable[..., Message],\n ):\n",
        "source_code_with_indent": "    ],\n):\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n    config_params = {EPOCHS: 1}\n\n    loaded_pipeline = load_pipeline(pipeline)\n\n",
        "source_code_len": 188,
        "target_code": "    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    config_params = {EPOCHS: 1}\n\n",
        "target_code_len": 175,
        "diff_format": "@@ -397,8 +385,6 @@\n     pipeline = [\n-        {\"name\": \"WhitespaceTokenizer\"},\n-        {\"name\": \"CountVectorsFeaturizer\"},\n+        {\"component\": WhitespaceTokenizerGraphComponent},\n+        {\"component\": CountVectorsFeaturizerGraphComponent},\n     ]\n     config_params = {EPOCHS: 1}\n-\n-    loaded_pipeline = load_pipeline(pipeline)\n \n",
        "source_code_with_indent": "    pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n    config_params = {EPOCHS: 1}\n\n    loaded_pipeline = load_pipeline(pipeline)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    config_params = {EPOCHS: 1}\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    for component in loaded_pipeline:\n        component.train(training_data)\n\n",
        "source_code_len": 79,
        "target_code": "\n    training_data, loaded_pipeline = train_and_preprocess(pipeline, training_data)\n\n",
        "target_code_len": 85,
        "diff_format": "@@ -415,4 +401,3 @@\n \n-    for component in loaded_pipeline:\n-        component.train(training_data)\n+    training_data, loaded_pipeline = train_and_preprocess(pipeline, training_data)\n \n",
        "source_code_with_indent": "\n    for component in loaded_pipeline:\n        <IND>component.train(training_data)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    training_data, loaded_pipeline = train_and_preprocess(pipeline, training_data)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    message = Message(data={TEXT: \"hello\"})\n\n    for component in loaded_pipeline:\n        component.process(message)\n\n",
        "source_code_len": 119,
        "target_code": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_len": 101,
        "diff_format": "@@ -424,5 +409,3 @@\n     message = Message(data={TEXT: \"hello\"})\n-\n-    for component in loaded_pipeline:\n-        component.process(message)\n+    message = process_message(loaded_pipeline, message)\n \n",
        "source_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n\n    for component in loaded_pipeline:\n        <IND>component.process(message)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ],\n):\n    pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n\n",
        "source_code_len": 242,
        "target_code": "    ],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, \"data/test_selectors\"\n    )\n\n",
        "target_code_len": 387,
        "diff_format": "@@ -452,9 +435,12 @@\n     ],\n+    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n+    process_message: Callable[..., Message],\n ):\n     pipeline = [\n-        {\"name\": \"WhitespaceTokenizer\"},\n-        {\"name\": \"CountVectorsFeaturizer\"},\n+        {\"component\": WhitespaceTokenizerGraphComponent},\n+        {\"component\": CountVectorsFeaturizerGraphComponent},\n     ]\n-    loaded_pipeline = load_pipeline(pipeline)\n-    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n+    training_data, loaded_pipeline = train_and_preprocess(\n+        pipeline, \"data/test_selectors\"\n+    )\n \n",
        "source_code_with_indent": "    ],\n):\n    <IND>pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    <IND>pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, \"data/test_selectors\"\n    )\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    message = Message(data={TEXT: \"hello\"})\n\n    for component in loaded_pipeline:\n        component.process(message)\n\n",
        "source_code_len": 119,
        "target_code": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_len": 101,
        "diff_format": "@@ -464,5 +450,3 @@\n     message = Message(data={TEXT: \"hello\"})\n-\n-    for component in loaded_pipeline:\n-        component.process(message)\n+    message = process_message(loaded_pipeline, message)\n \n",
        "source_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n\n    for component in loaded_pipeline:\n        <IND>component.process(message)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ],\n):\n    pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n\n",
        "source_code_len": 242,
        "target_code": "    ],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, \"data/test_selectors\"\n    )\n\n",
        "target_code_len": 387,
        "diff_format": "@@ -498,9 +482,12 @@\n     ],\n+    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n+    process_message: Callable[..., Message],\n ):\n     pipeline = [\n-        {\"name\": \"WhitespaceTokenizer\"},\n-        {\"name\": \"CountVectorsFeaturizer\"},\n+        {\"component\": WhitespaceTokenizerGraphComponent},\n+        {\"component\": CountVectorsFeaturizerGraphComponent},\n     ]\n-    loaded_pipeline = load_pipeline(pipeline)\n-    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n+    training_data, loaded_pipeline = train_and_preprocess(\n+        pipeline, \"data/test_selectors\"\n+    )\n \n",
        "source_code_with_indent": "    ],\n):\n    <IND>pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    <IND>pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, \"data/test_selectors\"\n    )\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    message = Message(data={TEXT: \"hello\"})\n\n    for component in loaded_pipeline:\n        component.process(message)\n\n",
        "source_code_len": 119,
        "target_code": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_len": 101,
        "diff_format": "@@ -510,5 +497,3 @@\n     message = Message(data={TEXT: \"hello\"})\n-\n-    for component in loaded_pipeline:\n-        component.process(message)\n+    message = process_message(loaded_pipeline, message)\n \n",
        "source_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n\n    for component in loaded_pipeline:\n        <IND>component.process(message)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n):\n",
        "source_code_len": 92,
        "target_code": "    load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n",
        "target_code_len": 221,
        "diff_format": "@@ -645,2 +630,4 @@\n     load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n+    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n+    process_message: Callable[..., Message],\n ):\n",
        "source_code_with_indent": "    load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n):\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [iter1_data_path])\n\n    response_selector = create_response_selector({EPOCHS: 1})\n",
        "source_code_len": 186,
        "target_code": "    ]\n    training_data, loaded_pipeline = train_and_preprocess(pipeline, iter1_data_path)\n    response_selector = create_response_selector({EPOCHS: 1})\n",
        "target_code_len": 153,
        "diff_format": "@@ -668,5 +655,3 @@\n     ]\n-    loaded_pipeline = load_pipeline(pipeline)\n-    training_data = train_pipeline(loaded_pipeline, [iter1_data_path])\n-\n+    training_data, loaded_pipeline = train_and_preprocess(pipeline, iter1_data_path)\n     response_selector = create_response_selector({EPOCHS: 1})\n",
        "source_code_with_indent": "    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [iter1_data_path])\n\n    response_selector = create_response_selector({EPOCHS: 1})\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ]\n    training_data, loaded_pipeline = train_and_preprocess(pipeline, iter1_data_path)\n    response_selector = create_response_selector({EPOCHS: 1})\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    message = Message(data={TEXT: \"Rasa is great!\"})\n\n    for component in loaded_pipeline:\n        component.process(message)\n\n",
        "source_code_len": 128,
        "target_code": "    message = Message(data={TEXT: \"Rasa is great!\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_len": 110,
        "diff_format": "@@ -678,5 +663,3 @@\n     message = Message(data={TEXT: \"Rasa is great!\"})\n-\n-    for component in loaded_pipeline:\n-        component.process(message)\n+    message = process_message(loaded_pipeline, message)\n \n",
        "source_code_with_indent": "    message = Message(data={TEXT: \"Rasa is great!\"})\n\n    for component in loaded_pipeline:\n        <IND>component.process(message)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    message = Message(data={TEXT: \"Rasa is great!\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    training_data2 = train_pipeline(loaded_pipeline, [iter2_data_path])\n\n",
        "source_code_len": 74,
        "target_code": "\n    training_data2, loaded_pipeline2 = train_and_preprocess(pipeline, iter2_data_path)\n\n",
        "target_code_len": 89,
        "diff_format": "@@ -715,3 +698,3 @@\n \n-    training_data2 = train_pipeline(loaded_pipeline, [iter2_data_path])\n+    training_data2, loaded_pipeline2 = train_and_preprocess(pipeline, iter2_data_path)\n \n",
        "source_code_with_indent": "\n    training_data2 = train_pipeline(loaded_pipeline, [iter2_data_path])\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    training_data2, loaded_pipeline2 = train_and_preprocess(pipeline, iter2_data_path)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    new_message = Message.build(text=\"Rasa is great!\")\n    for component in loaded_pipeline:\n        component.process(new_message)\n\n",
        "source_code_len": 133,
        "target_code": "    new_message = Message.build(text=\"Rasa is great!\")\n    new_message = process_message(loaded_pipeline2, new_message)\n\n",
        "target_code_len": 121,
        "diff_format": "@@ -720,4 +703,3 @@\n     new_message = Message.build(text=\"Rasa is great!\")\n-    for component in loaded_pipeline:\n-        component.process(new_message)\n+    new_message = process_message(loaded_pipeline2, new_message)\n \n",
        "source_code_with_indent": "    new_message = Message.build(text=\"Rasa is great!\")\n    for component in loaded_pipeline:\n        <IND>component.process(new_message)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    new_message = Message.build(text=\"Rasa is great!\")\n    new_message = process_message(loaded_pipeline2, new_message)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    default_execution_context: ExecutionContext,\n):\n    pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"LexicalSyntacticFeaturizer\"},\n        {\"name\": \"RegexFeaturizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n        {\n            \"name\": \"CountVectorsFeaturizer\",\n            \"analyzer\": \"char_wb\",\n",
        "source_code_len": 330,
        "target_code": "    default_execution_context: ExecutionContext,\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": LexicalSyntacticFeaturizerGraphComponent},\n        {\"component\": RegexFeaturizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n        {\n            \"component\": CountVectorsFeaturizerGraphComponent,\n            \"analyzer\": \"char_wb\",\n",
        "target_code_len": 544,
        "diff_format": "@@ -830,10 +812,12 @@\n     default_execution_context: ExecutionContext,\n+    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n+    process_message: Callable[..., Message],\n ):\n     pipeline = [\n-        {\"name\": \"WhitespaceTokenizer\"},\n-        {\"name\": \"LexicalSyntacticFeaturizer\"},\n-        {\"name\": \"RegexFeaturizer\"},\n-        {\"name\": \"CountVectorsFeaturizer\"},\n+        {\"component\": WhitespaceTokenizerGraphComponent},\n+        {\"component\": LexicalSyntacticFeaturizerGraphComponent},\n+        {\"component\": RegexFeaturizerGraphComponent},\n+        {\"component\": CountVectorsFeaturizerGraphComponent},\n         {\n-            \"name\": \"CountVectorsFeaturizer\",\n+            \"component\": CountVectorsFeaturizerGraphComponent,\n             \"analyzer\": \"char_wb\",\n",
        "source_code_with_indent": "    default_execution_context: ExecutionContext,\n):\n    <IND>pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"LexicalSyntacticFeaturizer\"},\n        {\"name\": \"RegexFeaturizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n        {\n            \"name\": \"CountVectorsFeaturizer\",\n            \"analyzer\": \"char_wb\",\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    default_execution_context: ExecutionContext,\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    <IND>pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": LexicalSyntacticFeaturizerGraphComponent},\n        {\"component\": RegexFeaturizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n        {\n            \"component\": CountVectorsFeaturizerGraphComponent,\n            \"analyzer\": \"char_wb\",\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [iter1_path])\n\n",
        "source_code_len": 119,
        "target_code": "    ]\n    training_data, loaded_pipeline = train_and_preprocess(pipeline, iter1_path)\n\n",
        "target_code_len": 87,
        "diff_format": "@@ -843,4 +827,3 @@\n     ]\n-    loaded_pipeline = load_pipeline(pipeline)\n-    training_data = train_pipeline(loaded_pipeline, [iter1_path])\n+    training_data, loaded_pipeline = train_and_preprocess(pipeline, iter1_path)\n \n",
        "source_code_with_indent": "    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [iter1_path])\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ]\n    training_data, loaded_pipeline = train_and_preprocess(pipeline, iter1_path)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    message = Message(data={TEXT: \"Rasa is great!\"})\n\n    for component in loaded_pipeline:\n        component.process(message)\n\n",
        "source_code_len": 128,
        "target_code": "    message = Message(data={TEXT: \"Rasa is great!\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_len": 110,
        "diff_format": "@@ -850,5 +833,3 @@\n     message = Message(data={TEXT: \"Rasa is great!\"})\n-\n-    for component in loaded_pipeline:\n-        component.process(message)\n+    message = process_message(loaded_pipeline, message)\n \n",
        "source_code_with_indent": "    message = Message(data={TEXT: \"Rasa is great!\"})\n\n    for component in loaded_pipeline:\n        <IND>component.process(message)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    message = Message(data={TEXT: \"Rasa is great!\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        with pytest.raises(Exception) as exec_info:\n            training_data2 = train_pipeline(loaded_pipeline, [iter2_path])\n            loaded_selector.train(training_data=training_data2)\n",
        "source_code_len": 191,
        "target_code": "        with pytest.raises(Exception) as exec_info:\n            training_data2, loaded_pipeline2 = train_and_preprocess(\n                pipeline, iter2_path\n            )\n            loaded_selector.train(training_data=training_data2)\n",
        "target_code_len": 236,
        "diff_format": "@@ -868,3 +849,5 @@\n         with pytest.raises(Exception) as exec_info:\n-            training_data2 = train_pipeline(loaded_pipeline, [iter2_path])\n+            training_data2, loaded_pipeline2 = train_and_preprocess(\n+                pipeline, iter2_path\n+            )\n             loaded_selector.train(training_data=training_data2)\n",
        "source_code_with_indent": "        <IND>with pytest.raises(Exception) as exec_info:\n            <IND>training_data2 = train_pipeline(loaded_pipeline, [iter2_path])\n            loaded_selector.train(training_data=training_data2)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        <IND>with pytest.raises(Exception) as exec_info:\n            <IND>training_data2, loaded_pipeline2 = train_and_preprocess(\n                pipeline, iter2_path\n            )\n            loaded_selector.train(training_data=training_data2)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    else:\n        training_data2 = train_pipeline(loaded_pipeline, [iter2_path])\n        loaded_selector.train(training_data=training_data2)\n",
        "source_code_len": 141,
        "target_code": "    else:\n        training_data2, loaded_pipeline2 = train_and_preprocess(pipeline, iter2_path)\n        loaded_selector.train(training_data=training_data2)\n",
        "target_code_len": 156,
        "diff_format": "@@ -872,3 +855,3 @@\n     else:\n-        training_data2 = train_pipeline(loaded_pipeline, [iter2_path])\n+        training_data2, loaded_pipeline2 = train_and_preprocess(pipeline, iter2_path)\n         loaded_selector.train(training_data=training_data2)\n",
        "source_code_with_indent": "    <DED>else:\n        <IND>training_data2 = train_pipeline(loaded_pipeline, [iter2_path])\n        loaded_selector.train(training_data=training_data2)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED>else:\n        <IND>training_data2, loaded_pipeline2 = train_and_preprocess(pipeline, iter2_path)\n        loaded_selector.train(training_data=training_data2)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "1823da83403ca6b5fc76eaa5a231a3c9164157a6",
    "filename": "tests/nlu/selectors/test_selectors.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/tests/nlu/selectors/test_selectors.py",
    "file_hunks_size": 30,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "tests/nlu/selectors/test_selectors.py:669:36 Incompatible parameter type [6]: Expected `List[Dict[str, str]]` for 1st positional only parameter to call `load_pipeline` but got `List[Union[Dict[str, Union[int, str]], Dict[str, str]]]`.",
    "message": " Expected `List[Dict[str, str]]` for 1st positional only parameter to call `load_pipeline` but got `List[Union[Dict[str, Union[int, str]], Dict[str, str]]]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 669,
    "warning_line": "    loaded_pipeline = load_pipeline(pipeline)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import numpy as np\nfrom typing import List, Dict, Text, Any, Optional, Union, Callable\nfrom unittest.mock import Mock\n",
        "source_code_len": 118,
        "target_code": "import numpy as np\nfrom typing import List, Dict, Text, Any, Optional, Tuple, Union, Callable\nfrom unittest.mock import Mock\n",
        "target_code_len": 125,
        "diff_format": "@@ -4,3 +4,3 @@\n import numpy as np\n-from typing import List, Dict, Text, Any, Optional, Union, Callable\n+from typing import List, Dict, Text, Any, Optional, Tuple, Union, Callable\n from unittest.mock import Mock\n",
        "source_code_with_indent": "import numpy as np\nfrom typing import List, Dict, Text, Any, Optional, Union, Callable\nfrom unittest.mock import Mock\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "import numpy as np\nfrom typing import List, Dict, Text, Any, Optional, Tuple, Union, Callable\nfrom unittest.mock import Mock\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import rasa.model\nimport rasa.nlu.train\nfrom rasa.engine.graph import ExecutionContext\nfrom rasa.engine.storage.resource import Resource\nfrom rasa.engine.storage.storage import ModelStorage\nfrom rasa.nlu import registry\nfrom rasa.nlu.components import Component\nfrom rasa.shared.importers.rasa import RasaFileImporter\n",
        "source_code_len": 318,
        "target_code": "import rasa.model\nfrom rasa.nlu.featurizers.sparse_featurizer.count_vectors_featurizer import (\n    CountVectorsFeaturizerGraphComponent,\n)\nfrom rasa.nlu.featurizers.sparse_featurizer.lexical_syntactic_featurizer import (\n    LexicalSyntacticFeaturizerGraphComponent,\n)\nfrom rasa.nlu.featurizers.sparse_featurizer.regex_featurizer import (\n    RegexFeaturizerGraphComponent,\n)\nfrom rasa.nlu.tokenizers.whitespace_tokenizer import WhitespaceTokenizerGraphComponent\nimport rasa.nlu.train\nfrom rasa.engine.graph import ExecutionContext, GraphComponent\nfrom rasa.engine.storage.resource import Resource\nfrom rasa.engine.storage.storage import ModelStorage\nfrom rasa.shared.importers.rasa import RasaFileImporter\n",
        "target_code_len": 708,
        "diff_format": "@@ -10,8 +10,16 @@\n import rasa.model\n+from rasa.nlu.featurizers.sparse_featurizer.count_vectors_featurizer import (\n+    CountVectorsFeaturizerGraphComponent,\n+)\n+from rasa.nlu.featurizers.sparse_featurizer.lexical_syntactic_featurizer import (\n+    LexicalSyntacticFeaturizerGraphComponent,\n+)\n+from rasa.nlu.featurizers.sparse_featurizer.regex_featurizer import (\n+    RegexFeaturizerGraphComponent,\n+)\n+from rasa.nlu.tokenizers.whitespace_tokenizer import WhitespaceTokenizerGraphComponent\n import rasa.nlu.train\n-from rasa.engine.graph import ExecutionContext\n+from rasa.engine.graph import ExecutionContext, GraphComponent\n from rasa.engine.storage.resource import Resource\n from rasa.engine.storage.storage import ModelStorage\n-from rasa.nlu import registry\n-from rasa.nlu.components import Component\n from rasa.shared.importers.rasa import RasaFileImporter\n",
        "source_code_with_indent": "import rasa.model\nimport rasa.nlu.train\nfrom rasa.engine.graph import ExecutionContext\nfrom rasa.engine.storage.resource import Resource\nfrom rasa.engine.storage.storage import ModelStorage\nfrom rasa.nlu import registry\nfrom rasa.nlu.components import Component\nfrom rasa.shared.importers.rasa import RasaFileImporter\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "import rasa.model\nfrom rasa.nlu.featurizers.sparse_featurizer.count_vectors_featurizer import (\n    CountVectorsFeaturizerGraphComponent,\n)\nfrom rasa.nlu.featurizers.sparse_featurizer.lexical_syntactic_featurizer import (\n    LexicalSyntacticFeaturizerGraphComponent,\n)\nfrom rasa.nlu.featurizers.sparse_featurizer.regex_featurizer import (\n    RegexFeaturizerGraphComponent,\n)\nfrom rasa.nlu.tokenizers.whitespace_tokenizer import WhitespaceTokenizerGraphComponent\nimport rasa.nlu.train\nfrom rasa.engine.graph import ExecutionContext, GraphComponent\nfrom rasa.engine.storage.resource import Resource\nfrom rasa.engine.storage.storage import ModelStorage\nfrom rasa.shared.importers.rasa import RasaFileImporter\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ],\n):\n    pipeline = [{\"name\": \"WhitespaceTokenizer\"}, {\"name\": \"CountVectorsFeaturizer\"}]\n    loaded_pipeline = [\n        registry.get_component_class(component.pop(\"name\"))(component)\n        for component in copy.deepcopy(pipeline)\n    ]\n\n    for component in loaded_pipeline:\n        component.train(response_selector_training_data)\n\n    response_selector = create_response_selector(config_params)\n\n    response_selector.train(training_data=response_selector_training_data)\n",
        "source_code_len": 482,
        "target_code": "    ],\n    default_model_storage: ModelStorage,\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    response_selector_training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, response_selector_training_data\n    )\n\n    response_selector = create_response_selector(config_params)\n    response_selector.train(training_data=response_selector_training_data)\n",
        "target_code_len": 595,
        "diff_format": "@@ -116,14 +166,15 @@\n     ],\n-):\n-    pipeline = [{\"name\": \"WhitespaceTokenizer\"}, {\"name\": \"CountVectorsFeaturizer\"}]\n-    loaded_pipeline = [\n-        registry.get_component_class(component.pop(\"name\"))(component)\n-        for component in copy.deepcopy(pipeline)\n+    default_model_storage: ModelStorage,\n+    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n+    process_message: Callable[..., Message],\n+):\n+    pipeline = [\n+        {\"component\": WhitespaceTokenizerGraphComponent},\n+        {\"component\": CountVectorsFeaturizerGraphComponent},\n     ]\n-\n-    for component in loaded_pipeline:\n-        component.train(response_selector_training_data)\n+    response_selector_training_data, loaded_pipeline = train_and_preprocess(\n+        pipeline, response_selector_training_data\n+    )\n \n     response_selector = create_response_selector(config_params)\n-\n     response_selector.train(training_data=response_selector_training_data)\n",
        "source_code_with_indent": "    ],\n):\n    <IND>pipeline = [{\"name\": \"WhitespaceTokenizer\"}, {\"name\": \"CountVectorsFeaturizer\"}]\n    loaded_pipeline = [\n        registry.get_component_class(component.pop(\"name\"))(component)\n        for component in copy.deepcopy(pipeline)\n    ]\n\n    for component in loaded_pipeline:\n        <IND>component.train(response_selector_training_data)\n\n    <DED>response_selector = create_response_selector(config_params)\n\n    response_selector.train(training_data=response_selector_training_data)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ],\n    default_model_storage: ModelStorage,\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    <IND>pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    response_selector_training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, response_selector_training_data\n    )\n\n    response_selector = create_response_selector(config_params)\n    response_selector.train(training_data=response_selector_training_data)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    message = Message(data={TEXT: \"hello\"})\n    for component in loaded_pipeline:\n        component.process(message)\n\n",
        "source_code_len": 118,
        "target_code": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_len": 101,
        "diff_format": "@@ -131,4 +182,3 @@\n     message = Message(data={TEXT: \"hello\"})\n-    for component in loaded_pipeline:\n-        component.process(message)\n+    message = process_message(loaded_pipeline, message)\n \n",
        "source_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n    for component in loaded_pipeline:\n        <IND>component.process(message)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "\ndef load_pipeline(pipeline: List[Dict[Text, Text]]) -> List[Component]:\n    loaded_pipeline = [\n        registry.get_component_class(component.pop(\"name\"))(component)\n        for component in copy.deepcopy(pipeline)\n    ]\n\n    return loaded_pipeline\n\n\ndef train_pipeline(\n    loaded_pipeline: List[Component], training_data_paths: List[Text],\n) -> TrainingData:\n    importer = RasaFileImporter(training_data_paths=training_data_paths)\n    training_data = importer.get_nlu_data()\n\n    for component in loaded_pipeline:\n        component.train(training_data)\n\n    return training_data\n\n\ndef test_train_model_checkpointing(\n",
        "source_code_len": 622,
        "target_code": "\ndef test_train_model_checkpointing(\n",
        "target_code_len": 37,
        "diff_format": "@@ -251,23 +301,2 @@\n \n-def load_pipeline(pipeline: List[Dict[Text, Text]]) -> List[Component]:\n-    loaded_pipeline = [\n-        registry.get_component_class(component.pop(\"name\"))(component)\n-        for component in copy.deepcopy(pipeline)\n-    ]\n-\n-    return loaded_pipeline\n-\n-\n-def train_pipeline(\n-    loaded_pipeline: List[Component], training_data_paths: List[Text],\n-) -> TrainingData:\n-    importer = RasaFileImporter(training_data_paths=training_data_paths)\n-    training_data = importer.get_nlu_data()\n-\n-    for component in loaded_pipeline:\n-        component.train(training_data)\n-\n-    return training_data\n-\n-\n def test_train_model_checkpointing(\n",
        "source_code_with_indent": "\n<DED>def load_pipeline(pipeline: List[Dict[Text, Text]]) -> List[Component]:\n    <IND>loaded_pipeline = [\n        registry.get_component_class(component.pop(\"name\"))(component)\n        for component in copy.deepcopy(pipeline)\n    ]\n\n    return loaded_pipeline\n\n\n<DED>def train_pipeline(\n    loaded_pipeline: List[Component], training_data_paths: List[Text],\n) -> TrainingData:\n    <IND>importer = RasaFileImporter(training_data_paths=training_data_paths)\n    training_data = importer.get_nlu_data()\n\n    for component in loaded_pipeline:\n        <IND>component.train(training_data)\n\n    <DED>return training_data\n\n\n<DED>def test_train_model_checkpointing(\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def test_train_model_checkpointing(\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    default_model_storage: ModelStorage,\n):\n    pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\n            \"name\": \"CountVectorsFeaturizer\",\n            \"analyzer\": \"char_wb\",\n",
        "source_code_len": 193,
        "target_code": "    default_model_storage: ModelStorage,\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n):\n    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\n            \"component\": CountVectorsFeaturizerGraphComponent,\n            \"analyzer\": \"char_wb\",\n",
        "target_code_len": 311,
        "diff_format": "@@ -277,7 +306,8 @@\n     default_model_storage: ModelStorage,\n+    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n ):\n     pipeline = [\n-        {\"name\": \"WhitespaceTokenizer\"},\n+        {\"component\": WhitespaceTokenizerGraphComponent},\n         {\n-            \"name\": \"CountVectorsFeaturizer\",\n+            \"component\": CountVectorsFeaturizerGraphComponent,\n             \"analyzer\": \"char_wb\",\n",
        "source_code_with_indent": "    default_model_storage: ModelStorage,\n):\n    <IND>pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\n            \"name\": \"CountVectorsFeaturizer\",\n            \"analyzer\": \"char_wb\",\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    default_model_storage: ModelStorage,\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n):\n    <IND>pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\n            \"component\": CountVectorsFeaturizerGraphComponent,\n            \"analyzer\": \"char_wb\",\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n\n",
        "source_code_len": 125,
        "target_code": "\n    training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, \"data/test_selectors\"\n    )\n\n",
        "target_code_len": 107,
        "diff_format": "@@ -290,4 +320,5 @@\n \n-    loaded_pipeline = load_pipeline(pipeline)\n-    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n+    training_data, loaded_pipeline = train_and_preprocess(\n+        pipeline, \"data/test_selectors\"\n+    )\n \n",
        "source_code_with_indent": "\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, \"data/test_selectors\"\n    )\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "\ndef _train_persist_load_with_different_settings(\n    pipeline: List[Dict[Text, Any]],\n    config_params: Dict[Text, Any],\n    create_response_selector: Callable[\n        [Dict[Text, Any]], ResponseSelectorGraphComponent\n    ],\n    load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n    should_finetune: bool,\n    default_execution_context: ExecutionContext,\n):\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(\n        loaded_pipeline, [\"data/examples/rasa/demo-rasa.yml\"]\n    )\n\n    response_selector = create_response_selector(config_params)\n    response_selector.train(training_data=training_data)\n\n    if should_finetune:\n        default_execution_context.is_finetuning = True\n\n    message = Message(data={TEXT: \"Rasa is great!\"})\n\n    for component in loaded_pipeline:\n        component.process(message)\n\n    message2 = copy.deepcopy(message)\n\n    classified_message = response_selector.process([message])[0]\n\n    loaded_selector = load_response_selector(config_params)\n\n    classified_message2 = loaded_selector.process([message2])[0]\n\n    assert classified_message2.fingerprint() == classified_message.fingerprint()\n\n\n@pytest.mark.skip_on_windows\n",
        "source_code_len": 1221,
        "target_code": "\n@pytest.mark.skip_on_windows\n",
        "target_code_len": 30,
        "diff_format": "@@ -319,39 +350,2 @@\n \n-def _train_persist_load_with_different_settings(\n-    pipeline: List[Dict[Text, Any]],\n-    config_params: Dict[Text, Any],\n-    create_response_selector: Callable[\n-        [Dict[Text, Any]], ResponseSelectorGraphComponent\n-    ],\n-    load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n-    should_finetune: bool,\n-    default_execution_context: ExecutionContext,\n-):\n-    loaded_pipeline = load_pipeline(pipeline)\n-    training_data = train_pipeline(\n-        loaded_pipeline, [\"data/examples/rasa/demo-rasa.yml\"]\n-    )\n-\n-    response_selector = create_response_selector(config_params)\n-    response_selector.train(training_data=training_data)\n-\n-    if should_finetune:\n-        default_execution_context.is_finetuning = True\n-\n-    message = Message(data={TEXT: \"Rasa is great!\"})\n-\n-    for component in loaded_pipeline:\n-        component.process(message)\n-\n-    message2 = copy.deepcopy(message)\n-\n-    classified_message = response_selector.process([message])[0]\n-\n-    loaded_selector = load_response_selector(config_params)\n-\n-    classified_message2 = loaded_selector.process([message2])[0]\n-\n-    assert classified_message2.fingerprint() == classified_message.fingerprint()\n-\n-\n @pytest.mark.skip_on_windows\n",
        "source_code_with_indent": "\n<DED><DED>def _train_persist_load_with_different_settings(\n    pipeline: List[Dict[Text, Any]],\n    config_params: Dict[Text, Any],\n    create_response_selector: Callable[\n        [Dict[Text, Any]], ResponseSelectorGraphComponent\n    ],\n    load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n    should_finetune: bool,\n    default_execution_context: ExecutionContext,\n):\n    <IND>loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(\n        loaded_pipeline, [\"data/examples/rasa/demo-rasa.yml\"]\n    )\n\n    response_selector = create_response_selector(config_params)\n    response_selector.train(training_data=training_data)\n\n    if should_finetune:\n        <IND>default_execution_context.is_finetuning = True\n\n    <DED>message = Message(data={TEXT: \"Rasa is great!\"})\n\n    for component in loaded_pipeline:\n        <IND>component.process(message)\n\n    <DED>message2 = copy.deepcopy(message)\n\n    classified_message = response_selector.process([message])[0]\n\n    loaded_selector = load_response_selector(config_params)\n\n    classified_message2 = loaded_selector.process([message2])[0]\n\n    assert classified_message2.fingerprint() == classified_message.fingerprint()\n\n\n<DED>@pytest.mark.skip_on_windows\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED><DED>@pytest.mark.skip_on_windows\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    default_execution_context: ExecutionContext,\n):\n    pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n",
        "source_code_len": 160,
        "target_code": "    default_execution_context: ExecutionContext,\n    train_persist_load_with_different_settings,\n):\n\n    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n",
        "target_code_len": 243,
        "diff_format": "@@ -363,6 +357,8 @@\n     default_execution_context: ExecutionContext,\n-):\n+    train_persist_load_with_different_settings,\n+):\n+\n     pipeline = [\n-        {\"name\": \"WhitespaceTokenizer\"},\n-        {\"name\": \"CountVectorsFeaturizer\"},\n+        {\"component\": WhitespaceTokenizerGraphComponent},\n+        {\"component\": CountVectorsFeaturizerGraphComponent},\n     ]\n",
        "source_code_with_indent": "    default_execution_context: ExecutionContext,\n):\n    <IND>pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    default_execution_context: ExecutionContext,\n    train_persist_load_with_different_settings,\n):\n\n    <IND>pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    _train_persist_load_with_different_settings(\n        pipeline,\n        config_params,\n        create_response_selector,\n        load_response_selector,\n        False,\n        default_execution_context,\n    )\n\n    _train_persist_load_with_different_settings(\n        pipeline,\n        config_params,\n        create_response_selector,\n        load_response_selector,\n        True,\n        default_execution_context,\n    )\n",
        "source_code_len": 425,
        "target_code": "\n    train_persist_load_with_different_settings(\n        pipeline, config_params, False,\n    )\n\n    train_persist_load_with_different_settings(\n        pipeline, config_params, True,\n    )\n",
        "target_code_len": 189,
        "diff_format": "@@ -370,18 +366,8 @@\n \n-    _train_persist_load_with_different_settings(\n-        pipeline,\n-        config_params,\n-        create_response_selector,\n-        load_response_selector,\n-        False,\n-        default_execution_context,\n-    )\n-\n-    _train_persist_load_with_different_settings(\n-        pipeline,\n-        config_params,\n-        create_response_selector,\n-        load_response_selector,\n-        True,\n-        default_execution_context,\n+    train_persist_load_with_different_settings(\n+        pipeline, config_params, False,\n+    )\n+\n+    train_persist_load_with_different_settings(\n+        pipeline, config_params, True,\n     )\n",
        "source_code_with_indent": "\n    _train_persist_load_with_different_settings(\n        pipeline,\n        config_params,\n        create_response_selector,\n        load_response_selector,\n        False,\n        default_execution_context,\n    )\n\n    _train_persist_load_with_different_settings(\n        pipeline,\n        config_params,\n        create_response_selector,\n        load_response_selector,\n        True,\n        default_execution_context,\n    )\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    train_persist_load_with_different_settings(\n        pipeline, config_params, False,\n    )\n\n    train_persist_load_with_different_settings(\n        pipeline, config_params, True,\n    )\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ],\n):\n",
        "source_code_len": 10,
        "target_code": "    ],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n",
        "target_code_len": 139,
        "diff_format": "@@ -394,2 +380,4 @@\n     ],\n+    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n+    process_message: Callable[..., Message],\n ):\n",
        "source_code_with_indent": "    ],\n):\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n    config_params = {EPOCHS: 1}\n\n    loaded_pipeline = load_pipeline(pipeline)\n\n",
        "source_code_len": 188,
        "target_code": "    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    config_params = {EPOCHS: 1}\n\n",
        "target_code_len": 175,
        "diff_format": "@@ -397,8 +385,6 @@\n     pipeline = [\n-        {\"name\": \"WhitespaceTokenizer\"},\n-        {\"name\": \"CountVectorsFeaturizer\"},\n+        {\"component\": WhitespaceTokenizerGraphComponent},\n+        {\"component\": CountVectorsFeaturizerGraphComponent},\n     ]\n     config_params = {EPOCHS: 1}\n-\n-    loaded_pipeline = load_pipeline(pipeline)\n \n",
        "source_code_with_indent": "    pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n    config_params = {EPOCHS: 1}\n\n    loaded_pipeline = load_pipeline(pipeline)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    config_params = {EPOCHS: 1}\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    for component in loaded_pipeline:\n        component.train(training_data)\n\n",
        "source_code_len": 79,
        "target_code": "\n    training_data, loaded_pipeline = train_and_preprocess(pipeline, training_data)\n\n",
        "target_code_len": 85,
        "diff_format": "@@ -415,4 +401,3 @@\n \n-    for component in loaded_pipeline:\n-        component.train(training_data)\n+    training_data, loaded_pipeline = train_and_preprocess(pipeline, training_data)\n \n",
        "source_code_with_indent": "\n    for component in loaded_pipeline:\n        <IND>component.train(training_data)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    training_data, loaded_pipeline = train_and_preprocess(pipeline, training_data)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    message = Message(data={TEXT: \"hello\"})\n\n    for component in loaded_pipeline:\n        component.process(message)\n\n",
        "source_code_len": 119,
        "target_code": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_len": 101,
        "diff_format": "@@ -424,5 +409,3 @@\n     message = Message(data={TEXT: \"hello\"})\n-\n-    for component in loaded_pipeline:\n-        component.process(message)\n+    message = process_message(loaded_pipeline, message)\n \n",
        "source_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n\n    for component in loaded_pipeline:\n        <IND>component.process(message)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ],\n):\n    pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n\n",
        "source_code_len": 242,
        "target_code": "    ],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, \"data/test_selectors\"\n    )\n\n",
        "target_code_len": 387,
        "diff_format": "@@ -452,9 +435,12 @@\n     ],\n+    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n+    process_message: Callable[..., Message],\n ):\n     pipeline = [\n-        {\"name\": \"WhitespaceTokenizer\"},\n-        {\"name\": \"CountVectorsFeaturizer\"},\n+        {\"component\": WhitespaceTokenizerGraphComponent},\n+        {\"component\": CountVectorsFeaturizerGraphComponent},\n     ]\n-    loaded_pipeline = load_pipeline(pipeline)\n-    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n+    training_data, loaded_pipeline = train_and_preprocess(\n+        pipeline, \"data/test_selectors\"\n+    )\n \n",
        "source_code_with_indent": "    ],\n):\n    <IND>pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    <IND>pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, \"data/test_selectors\"\n    )\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    message = Message(data={TEXT: \"hello\"})\n\n    for component in loaded_pipeline:\n        component.process(message)\n\n",
        "source_code_len": 119,
        "target_code": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_len": 101,
        "diff_format": "@@ -464,5 +450,3 @@\n     message = Message(data={TEXT: \"hello\"})\n-\n-    for component in loaded_pipeline:\n-        component.process(message)\n+    message = process_message(loaded_pipeline, message)\n \n",
        "source_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n\n    for component in loaded_pipeline:\n        <IND>component.process(message)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ],\n):\n    pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n\n",
        "source_code_len": 242,
        "target_code": "    ],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, \"data/test_selectors\"\n    )\n\n",
        "target_code_len": 387,
        "diff_format": "@@ -498,9 +482,12 @@\n     ],\n+    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n+    process_message: Callable[..., Message],\n ):\n     pipeline = [\n-        {\"name\": \"WhitespaceTokenizer\"},\n-        {\"name\": \"CountVectorsFeaturizer\"},\n+        {\"component\": WhitespaceTokenizerGraphComponent},\n+        {\"component\": CountVectorsFeaturizerGraphComponent},\n     ]\n-    loaded_pipeline = load_pipeline(pipeline)\n-    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n+    training_data, loaded_pipeline = train_and_preprocess(\n+        pipeline, \"data/test_selectors\"\n+    )\n \n",
        "source_code_with_indent": "    ],\n):\n    <IND>pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    <IND>pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, \"data/test_selectors\"\n    )\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    message = Message(data={TEXT: \"hello\"})\n\n    for component in loaded_pipeline:\n        component.process(message)\n\n",
        "source_code_len": 119,
        "target_code": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_len": 101,
        "diff_format": "@@ -510,5 +497,3 @@\n     message = Message(data={TEXT: \"hello\"})\n-\n-    for component in loaded_pipeline:\n-        component.process(message)\n+    message = process_message(loaded_pipeline, message)\n \n",
        "source_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n\n    for component in loaded_pipeline:\n        <IND>component.process(message)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n):\n",
        "source_code_len": 92,
        "target_code": "    load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n",
        "target_code_len": 221,
        "diff_format": "@@ -645,2 +630,4 @@\n     load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n+    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n+    process_message: Callable[..., Message],\n ):\n",
        "source_code_with_indent": "    load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n):\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [iter1_data_path])\n\n    response_selector = create_response_selector({EPOCHS: 1})\n",
        "source_code_len": 186,
        "target_code": "    ]\n    training_data, loaded_pipeline = train_and_preprocess(pipeline, iter1_data_path)\n    response_selector = create_response_selector({EPOCHS: 1})\n",
        "target_code_len": 153,
        "diff_format": "@@ -668,5 +655,3 @@\n     ]\n-    loaded_pipeline = load_pipeline(pipeline)\n-    training_data = train_pipeline(loaded_pipeline, [iter1_data_path])\n-\n+    training_data, loaded_pipeline = train_and_preprocess(pipeline, iter1_data_path)\n     response_selector = create_response_selector({EPOCHS: 1})\n",
        "source_code_with_indent": "    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [iter1_data_path])\n\n    response_selector = create_response_selector({EPOCHS: 1})\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ]\n    training_data, loaded_pipeline = train_and_preprocess(pipeline, iter1_data_path)\n    response_selector = create_response_selector({EPOCHS: 1})\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    message = Message(data={TEXT: \"Rasa is great!\"})\n\n    for component in loaded_pipeline:\n        component.process(message)\n\n",
        "source_code_len": 128,
        "target_code": "    message = Message(data={TEXT: \"Rasa is great!\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_len": 110,
        "diff_format": "@@ -678,5 +663,3 @@\n     message = Message(data={TEXT: \"Rasa is great!\"})\n-\n-    for component in loaded_pipeline:\n-        component.process(message)\n+    message = process_message(loaded_pipeline, message)\n \n",
        "source_code_with_indent": "    message = Message(data={TEXT: \"Rasa is great!\"})\n\n    for component in loaded_pipeline:\n        <IND>component.process(message)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    message = Message(data={TEXT: \"Rasa is great!\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    training_data2 = train_pipeline(loaded_pipeline, [iter2_data_path])\n\n",
        "source_code_len": 74,
        "target_code": "\n    training_data2, loaded_pipeline2 = train_and_preprocess(pipeline, iter2_data_path)\n\n",
        "target_code_len": 89,
        "diff_format": "@@ -715,3 +698,3 @@\n \n-    training_data2 = train_pipeline(loaded_pipeline, [iter2_data_path])\n+    training_data2, loaded_pipeline2 = train_and_preprocess(pipeline, iter2_data_path)\n \n",
        "source_code_with_indent": "\n    training_data2 = train_pipeline(loaded_pipeline, [iter2_data_path])\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    training_data2, loaded_pipeline2 = train_and_preprocess(pipeline, iter2_data_path)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    new_message = Message.build(text=\"Rasa is great!\")\n    for component in loaded_pipeline:\n        component.process(new_message)\n\n",
        "source_code_len": 133,
        "target_code": "    new_message = Message.build(text=\"Rasa is great!\")\n    new_message = process_message(loaded_pipeline2, new_message)\n\n",
        "target_code_len": 121,
        "diff_format": "@@ -720,4 +703,3 @@\n     new_message = Message.build(text=\"Rasa is great!\")\n-    for component in loaded_pipeline:\n-        component.process(new_message)\n+    new_message = process_message(loaded_pipeline2, new_message)\n \n",
        "source_code_with_indent": "    new_message = Message.build(text=\"Rasa is great!\")\n    for component in loaded_pipeline:\n        <IND>component.process(new_message)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    new_message = Message.build(text=\"Rasa is great!\")\n    new_message = process_message(loaded_pipeline2, new_message)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    default_execution_context: ExecutionContext,\n):\n    pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"LexicalSyntacticFeaturizer\"},\n        {\"name\": \"RegexFeaturizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n        {\n            \"name\": \"CountVectorsFeaturizer\",\n            \"analyzer\": \"char_wb\",\n",
        "source_code_len": 330,
        "target_code": "    default_execution_context: ExecutionContext,\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": LexicalSyntacticFeaturizerGraphComponent},\n        {\"component\": RegexFeaturizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n        {\n            \"component\": CountVectorsFeaturizerGraphComponent,\n            \"analyzer\": \"char_wb\",\n",
        "target_code_len": 544,
        "diff_format": "@@ -830,10 +812,12 @@\n     default_execution_context: ExecutionContext,\n+    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n+    process_message: Callable[..., Message],\n ):\n     pipeline = [\n-        {\"name\": \"WhitespaceTokenizer\"},\n-        {\"name\": \"LexicalSyntacticFeaturizer\"},\n-        {\"name\": \"RegexFeaturizer\"},\n-        {\"name\": \"CountVectorsFeaturizer\"},\n+        {\"component\": WhitespaceTokenizerGraphComponent},\n+        {\"component\": LexicalSyntacticFeaturizerGraphComponent},\n+        {\"component\": RegexFeaturizerGraphComponent},\n+        {\"component\": CountVectorsFeaturizerGraphComponent},\n         {\n-            \"name\": \"CountVectorsFeaturizer\",\n+            \"component\": CountVectorsFeaturizerGraphComponent,\n             \"analyzer\": \"char_wb\",\n",
        "source_code_with_indent": "    default_execution_context: ExecutionContext,\n):\n    <IND>pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"LexicalSyntacticFeaturizer\"},\n        {\"name\": \"RegexFeaturizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n        {\n            \"name\": \"CountVectorsFeaturizer\",\n            \"analyzer\": \"char_wb\",\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    default_execution_context: ExecutionContext,\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    <IND>pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": LexicalSyntacticFeaturizerGraphComponent},\n        {\"component\": RegexFeaturizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n        {\n            \"component\": CountVectorsFeaturizerGraphComponent,\n            \"analyzer\": \"char_wb\",\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [iter1_path])\n\n",
        "source_code_len": 119,
        "target_code": "    ]\n    training_data, loaded_pipeline = train_and_preprocess(pipeline, iter1_path)\n\n",
        "target_code_len": 87,
        "diff_format": "@@ -843,4 +827,3 @@\n     ]\n-    loaded_pipeline = load_pipeline(pipeline)\n-    training_data = train_pipeline(loaded_pipeline, [iter1_path])\n+    training_data, loaded_pipeline = train_and_preprocess(pipeline, iter1_path)\n \n",
        "source_code_with_indent": "    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [iter1_path])\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ]\n    training_data, loaded_pipeline = train_and_preprocess(pipeline, iter1_path)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    message = Message(data={TEXT: \"Rasa is great!\"})\n\n    for component in loaded_pipeline:\n        component.process(message)\n\n",
        "source_code_len": 128,
        "target_code": "    message = Message(data={TEXT: \"Rasa is great!\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_len": 110,
        "diff_format": "@@ -850,5 +833,3 @@\n     message = Message(data={TEXT: \"Rasa is great!\"})\n-\n-    for component in loaded_pipeline:\n-        component.process(message)\n+    message = process_message(loaded_pipeline, message)\n \n",
        "source_code_with_indent": "    message = Message(data={TEXT: \"Rasa is great!\"})\n\n    for component in loaded_pipeline:\n        <IND>component.process(message)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    message = Message(data={TEXT: \"Rasa is great!\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        with pytest.raises(Exception) as exec_info:\n            training_data2 = train_pipeline(loaded_pipeline, [iter2_path])\n            loaded_selector.train(training_data=training_data2)\n",
        "source_code_len": 191,
        "target_code": "        with pytest.raises(Exception) as exec_info:\n            training_data2, loaded_pipeline2 = train_and_preprocess(\n                pipeline, iter2_path\n            )\n            loaded_selector.train(training_data=training_data2)\n",
        "target_code_len": 236,
        "diff_format": "@@ -868,3 +849,5 @@\n         with pytest.raises(Exception) as exec_info:\n-            training_data2 = train_pipeline(loaded_pipeline, [iter2_path])\n+            training_data2, loaded_pipeline2 = train_and_preprocess(\n+                pipeline, iter2_path\n+            )\n             loaded_selector.train(training_data=training_data2)\n",
        "source_code_with_indent": "        <IND>with pytest.raises(Exception) as exec_info:\n            <IND>training_data2 = train_pipeline(loaded_pipeline, [iter2_path])\n            loaded_selector.train(training_data=training_data2)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        <IND>with pytest.raises(Exception) as exec_info:\n            <IND>training_data2, loaded_pipeline2 = train_and_preprocess(\n                pipeline, iter2_path\n            )\n            loaded_selector.train(training_data=training_data2)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    else:\n        training_data2 = train_pipeline(loaded_pipeline, [iter2_path])\n        loaded_selector.train(training_data=training_data2)\n",
        "source_code_len": 141,
        "target_code": "    else:\n        training_data2, loaded_pipeline2 = train_and_preprocess(pipeline, iter2_path)\n        loaded_selector.train(training_data=training_data2)\n",
        "target_code_len": 156,
        "diff_format": "@@ -872,3 +855,3 @@\n     else:\n-        training_data2 = train_pipeline(loaded_pipeline, [iter2_path])\n+        training_data2, loaded_pipeline2 = train_and_preprocess(pipeline, iter2_path)\n         loaded_selector.train(training_data=training_data2)\n",
        "source_code_with_indent": "    <DED>else:\n        <IND>training_data2 = train_pipeline(loaded_pipeline, [iter2_path])\n        loaded_selector.train(training_data=training_data2)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED>else:\n        <IND>training_data2, loaded_pipeline2 = train_and_preprocess(pipeline, iter2_path)\n        loaded_selector.train(training_data=training_data2)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "1823da83403ca6b5fc76eaa5a231a3c9164157a6",
    "filename": "tests/nlu/selectors/test_selectors.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/tests/nlu/selectors/test_selectors.py",
    "file_hunks_size": 30,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "tests/nlu/selectors/test_selectors.py:844:36 Incompatible parameter type [6]: Expected `List[Dict[str, str]]` for 1st positional only parameter to call `load_pipeline` but got `List[Union[Dict[str, Union[int, str]], Dict[str, str]]]`.",
    "message": " Expected `List[Dict[str, str]]` for 1st positional only parameter to call `load_pipeline` but got `List[Union[Dict[str, Union[int, str]], Dict[str, str]]]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 844,
    "warning_line": "    loaded_pipeline = load_pipeline(pipeline)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import numpy as np\nfrom typing import List, Dict, Text, Any, Optional, Union, Callable\nfrom unittest.mock import Mock\n",
        "source_code_len": 118,
        "target_code": "import numpy as np\nfrom typing import List, Dict, Text, Any, Optional, Tuple, Union, Callable\nfrom unittest.mock import Mock\n",
        "target_code_len": 125,
        "diff_format": "@@ -4,3 +4,3 @@\n import numpy as np\n-from typing import List, Dict, Text, Any, Optional, Union, Callable\n+from typing import List, Dict, Text, Any, Optional, Tuple, Union, Callable\n from unittest.mock import Mock\n",
        "source_code_with_indent": "import numpy as np\nfrom typing import List, Dict, Text, Any, Optional, Union, Callable\nfrom unittest.mock import Mock\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "import numpy as np\nfrom typing import List, Dict, Text, Any, Optional, Tuple, Union, Callable\nfrom unittest.mock import Mock\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import rasa.model\nimport rasa.nlu.train\nfrom rasa.engine.graph import ExecutionContext\nfrom rasa.engine.storage.resource import Resource\nfrom rasa.engine.storage.storage import ModelStorage\nfrom rasa.nlu import registry\nfrom rasa.nlu.components import Component\nfrom rasa.shared.importers.rasa import RasaFileImporter\n",
        "source_code_len": 318,
        "target_code": "import rasa.model\nfrom rasa.nlu.featurizers.sparse_featurizer.count_vectors_featurizer import (\n    CountVectorsFeaturizerGraphComponent,\n)\nfrom rasa.nlu.featurizers.sparse_featurizer.lexical_syntactic_featurizer import (\n    LexicalSyntacticFeaturizerGraphComponent,\n)\nfrom rasa.nlu.featurizers.sparse_featurizer.regex_featurizer import (\n    RegexFeaturizerGraphComponent,\n)\nfrom rasa.nlu.tokenizers.whitespace_tokenizer import WhitespaceTokenizerGraphComponent\nimport rasa.nlu.train\nfrom rasa.engine.graph import ExecutionContext, GraphComponent\nfrom rasa.engine.storage.resource import Resource\nfrom rasa.engine.storage.storage import ModelStorage\nfrom rasa.shared.importers.rasa import RasaFileImporter\n",
        "target_code_len": 708,
        "diff_format": "@@ -10,8 +10,16 @@\n import rasa.model\n+from rasa.nlu.featurizers.sparse_featurizer.count_vectors_featurizer import (\n+    CountVectorsFeaturizerGraphComponent,\n+)\n+from rasa.nlu.featurizers.sparse_featurizer.lexical_syntactic_featurizer import (\n+    LexicalSyntacticFeaturizerGraphComponent,\n+)\n+from rasa.nlu.featurizers.sparse_featurizer.regex_featurizer import (\n+    RegexFeaturizerGraphComponent,\n+)\n+from rasa.nlu.tokenizers.whitespace_tokenizer import WhitespaceTokenizerGraphComponent\n import rasa.nlu.train\n-from rasa.engine.graph import ExecutionContext\n+from rasa.engine.graph import ExecutionContext, GraphComponent\n from rasa.engine.storage.resource import Resource\n from rasa.engine.storage.storage import ModelStorage\n-from rasa.nlu import registry\n-from rasa.nlu.components import Component\n from rasa.shared.importers.rasa import RasaFileImporter\n",
        "source_code_with_indent": "import rasa.model\nimport rasa.nlu.train\nfrom rasa.engine.graph import ExecutionContext\nfrom rasa.engine.storage.resource import Resource\nfrom rasa.engine.storage.storage import ModelStorage\nfrom rasa.nlu import registry\nfrom rasa.nlu.components import Component\nfrom rasa.shared.importers.rasa import RasaFileImporter\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "import rasa.model\nfrom rasa.nlu.featurizers.sparse_featurizer.count_vectors_featurizer import (\n    CountVectorsFeaturizerGraphComponent,\n)\nfrom rasa.nlu.featurizers.sparse_featurizer.lexical_syntactic_featurizer import (\n    LexicalSyntacticFeaturizerGraphComponent,\n)\nfrom rasa.nlu.featurizers.sparse_featurizer.regex_featurizer import (\n    RegexFeaturizerGraphComponent,\n)\nfrom rasa.nlu.tokenizers.whitespace_tokenizer import WhitespaceTokenizerGraphComponent\nimport rasa.nlu.train\nfrom rasa.engine.graph import ExecutionContext, GraphComponent\nfrom rasa.engine.storage.resource import Resource\nfrom rasa.engine.storage.storage import ModelStorage\nfrom rasa.shared.importers.rasa import RasaFileImporter\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ],\n):\n    pipeline = [{\"name\": \"WhitespaceTokenizer\"}, {\"name\": \"CountVectorsFeaturizer\"}]\n    loaded_pipeline = [\n        registry.get_component_class(component.pop(\"name\"))(component)\n        for component in copy.deepcopy(pipeline)\n    ]\n\n    for component in loaded_pipeline:\n        component.train(response_selector_training_data)\n\n    response_selector = create_response_selector(config_params)\n\n    response_selector.train(training_data=response_selector_training_data)\n",
        "source_code_len": 482,
        "target_code": "    ],\n    default_model_storage: ModelStorage,\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    response_selector_training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, response_selector_training_data\n    )\n\n    response_selector = create_response_selector(config_params)\n    response_selector.train(training_data=response_selector_training_data)\n",
        "target_code_len": 595,
        "diff_format": "@@ -116,14 +166,15 @@\n     ],\n-):\n-    pipeline = [{\"name\": \"WhitespaceTokenizer\"}, {\"name\": \"CountVectorsFeaturizer\"}]\n-    loaded_pipeline = [\n-        registry.get_component_class(component.pop(\"name\"))(component)\n-        for component in copy.deepcopy(pipeline)\n+    default_model_storage: ModelStorage,\n+    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n+    process_message: Callable[..., Message],\n+):\n+    pipeline = [\n+        {\"component\": WhitespaceTokenizerGraphComponent},\n+        {\"component\": CountVectorsFeaturizerGraphComponent},\n     ]\n-\n-    for component in loaded_pipeline:\n-        component.train(response_selector_training_data)\n+    response_selector_training_data, loaded_pipeline = train_and_preprocess(\n+        pipeline, response_selector_training_data\n+    )\n \n     response_selector = create_response_selector(config_params)\n-\n     response_selector.train(training_data=response_selector_training_data)\n",
        "source_code_with_indent": "    ],\n):\n    <IND>pipeline = [{\"name\": \"WhitespaceTokenizer\"}, {\"name\": \"CountVectorsFeaturizer\"}]\n    loaded_pipeline = [\n        registry.get_component_class(component.pop(\"name\"))(component)\n        for component in copy.deepcopy(pipeline)\n    ]\n\n    for component in loaded_pipeline:\n        <IND>component.train(response_selector_training_data)\n\n    <DED>response_selector = create_response_selector(config_params)\n\n    response_selector.train(training_data=response_selector_training_data)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ],\n    default_model_storage: ModelStorage,\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    <IND>pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    response_selector_training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, response_selector_training_data\n    )\n\n    response_selector = create_response_selector(config_params)\n    response_selector.train(training_data=response_selector_training_data)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    message = Message(data={TEXT: \"hello\"})\n    for component in loaded_pipeline:\n        component.process(message)\n\n",
        "source_code_len": 118,
        "target_code": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_len": 101,
        "diff_format": "@@ -131,4 +182,3 @@\n     message = Message(data={TEXT: \"hello\"})\n-    for component in loaded_pipeline:\n-        component.process(message)\n+    message = process_message(loaded_pipeline, message)\n \n",
        "source_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n    for component in loaded_pipeline:\n        <IND>component.process(message)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "\ndef load_pipeline(pipeline: List[Dict[Text, Text]]) -> List[Component]:\n    loaded_pipeline = [\n        registry.get_component_class(component.pop(\"name\"))(component)\n        for component in copy.deepcopy(pipeline)\n    ]\n\n    return loaded_pipeline\n\n\ndef train_pipeline(\n    loaded_pipeline: List[Component], training_data_paths: List[Text],\n) -> TrainingData:\n    importer = RasaFileImporter(training_data_paths=training_data_paths)\n    training_data = importer.get_nlu_data()\n\n    for component in loaded_pipeline:\n        component.train(training_data)\n\n    return training_data\n\n\ndef test_train_model_checkpointing(\n",
        "source_code_len": 622,
        "target_code": "\ndef test_train_model_checkpointing(\n",
        "target_code_len": 37,
        "diff_format": "@@ -251,23 +301,2 @@\n \n-def load_pipeline(pipeline: List[Dict[Text, Text]]) -> List[Component]:\n-    loaded_pipeline = [\n-        registry.get_component_class(component.pop(\"name\"))(component)\n-        for component in copy.deepcopy(pipeline)\n-    ]\n-\n-    return loaded_pipeline\n-\n-\n-def train_pipeline(\n-    loaded_pipeline: List[Component], training_data_paths: List[Text],\n-) -> TrainingData:\n-    importer = RasaFileImporter(training_data_paths=training_data_paths)\n-    training_data = importer.get_nlu_data()\n-\n-    for component in loaded_pipeline:\n-        component.train(training_data)\n-\n-    return training_data\n-\n-\n def test_train_model_checkpointing(\n",
        "source_code_with_indent": "\n<DED>def load_pipeline(pipeline: List[Dict[Text, Text]]) -> List[Component]:\n    <IND>loaded_pipeline = [\n        registry.get_component_class(component.pop(\"name\"))(component)\n        for component in copy.deepcopy(pipeline)\n    ]\n\n    return loaded_pipeline\n\n\n<DED>def train_pipeline(\n    loaded_pipeline: List[Component], training_data_paths: List[Text],\n) -> TrainingData:\n    <IND>importer = RasaFileImporter(training_data_paths=training_data_paths)\n    training_data = importer.get_nlu_data()\n\n    for component in loaded_pipeline:\n        <IND>component.train(training_data)\n\n    <DED>return training_data\n\n\n<DED>def test_train_model_checkpointing(\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def test_train_model_checkpointing(\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    default_model_storage: ModelStorage,\n):\n    pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\n            \"name\": \"CountVectorsFeaturizer\",\n            \"analyzer\": \"char_wb\",\n",
        "source_code_len": 193,
        "target_code": "    default_model_storage: ModelStorage,\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n):\n    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\n            \"component\": CountVectorsFeaturizerGraphComponent,\n            \"analyzer\": \"char_wb\",\n",
        "target_code_len": 311,
        "diff_format": "@@ -277,7 +306,8 @@\n     default_model_storage: ModelStorage,\n+    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n ):\n     pipeline = [\n-        {\"name\": \"WhitespaceTokenizer\"},\n+        {\"component\": WhitespaceTokenizerGraphComponent},\n         {\n-            \"name\": \"CountVectorsFeaturizer\",\n+            \"component\": CountVectorsFeaturizerGraphComponent,\n             \"analyzer\": \"char_wb\",\n",
        "source_code_with_indent": "    default_model_storage: ModelStorage,\n):\n    <IND>pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\n            \"name\": \"CountVectorsFeaturizer\",\n            \"analyzer\": \"char_wb\",\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    default_model_storage: ModelStorage,\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n):\n    <IND>pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\n            \"component\": CountVectorsFeaturizerGraphComponent,\n            \"analyzer\": \"char_wb\",\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n\n",
        "source_code_len": 125,
        "target_code": "\n    training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, \"data/test_selectors\"\n    )\n\n",
        "target_code_len": 107,
        "diff_format": "@@ -290,4 +320,5 @@\n \n-    loaded_pipeline = load_pipeline(pipeline)\n-    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n+    training_data, loaded_pipeline = train_and_preprocess(\n+        pipeline, \"data/test_selectors\"\n+    )\n \n",
        "source_code_with_indent": "\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, \"data/test_selectors\"\n    )\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "\ndef _train_persist_load_with_different_settings(\n    pipeline: List[Dict[Text, Any]],\n    config_params: Dict[Text, Any],\n    create_response_selector: Callable[\n        [Dict[Text, Any]], ResponseSelectorGraphComponent\n    ],\n    load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n    should_finetune: bool,\n    default_execution_context: ExecutionContext,\n):\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(\n        loaded_pipeline, [\"data/examples/rasa/demo-rasa.yml\"]\n    )\n\n    response_selector = create_response_selector(config_params)\n    response_selector.train(training_data=training_data)\n\n    if should_finetune:\n        default_execution_context.is_finetuning = True\n\n    message = Message(data={TEXT: \"Rasa is great!\"})\n\n    for component in loaded_pipeline:\n        component.process(message)\n\n    message2 = copy.deepcopy(message)\n\n    classified_message = response_selector.process([message])[0]\n\n    loaded_selector = load_response_selector(config_params)\n\n    classified_message2 = loaded_selector.process([message2])[0]\n\n    assert classified_message2.fingerprint() == classified_message.fingerprint()\n\n\n@pytest.mark.skip_on_windows\n",
        "source_code_len": 1221,
        "target_code": "\n@pytest.mark.skip_on_windows\n",
        "target_code_len": 30,
        "diff_format": "@@ -319,39 +350,2 @@\n \n-def _train_persist_load_with_different_settings(\n-    pipeline: List[Dict[Text, Any]],\n-    config_params: Dict[Text, Any],\n-    create_response_selector: Callable[\n-        [Dict[Text, Any]], ResponseSelectorGraphComponent\n-    ],\n-    load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n-    should_finetune: bool,\n-    default_execution_context: ExecutionContext,\n-):\n-    loaded_pipeline = load_pipeline(pipeline)\n-    training_data = train_pipeline(\n-        loaded_pipeline, [\"data/examples/rasa/demo-rasa.yml\"]\n-    )\n-\n-    response_selector = create_response_selector(config_params)\n-    response_selector.train(training_data=training_data)\n-\n-    if should_finetune:\n-        default_execution_context.is_finetuning = True\n-\n-    message = Message(data={TEXT: \"Rasa is great!\"})\n-\n-    for component in loaded_pipeline:\n-        component.process(message)\n-\n-    message2 = copy.deepcopy(message)\n-\n-    classified_message = response_selector.process([message])[0]\n-\n-    loaded_selector = load_response_selector(config_params)\n-\n-    classified_message2 = loaded_selector.process([message2])[0]\n-\n-    assert classified_message2.fingerprint() == classified_message.fingerprint()\n-\n-\n @pytest.mark.skip_on_windows\n",
        "source_code_with_indent": "\n<DED><DED>def _train_persist_load_with_different_settings(\n    pipeline: List[Dict[Text, Any]],\n    config_params: Dict[Text, Any],\n    create_response_selector: Callable[\n        [Dict[Text, Any]], ResponseSelectorGraphComponent\n    ],\n    load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n    should_finetune: bool,\n    default_execution_context: ExecutionContext,\n):\n    <IND>loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(\n        loaded_pipeline, [\"data/examples/rasa/demo-rasa.yml\"]\n    )\n\n    response_selector = create_response_selector(config_params)\n    response_selector.train(training_data=training_data)\n\n    if should_finetune:\n        <IND>default_execution_context.is_finetuning = True\n\n    <DED>message = Message(data={TEXT: \"Rasa is great!\"})\n\n    for component in loaded_pipeline:\n        <IND>component.process(message)\n\n    <DED>message2 = copy.deepcopy(message)\n\n    classified_message = response_selector.process([message])[0]\n\n    loaded_selector = load_response_selector(config_params)\n\n    classified_message2 = loaded_selector.process([message2])[0]\n\n    assert classified_message2.fingerprint() == classified_message.fingerprint()\n\n\n<DED>@pytest.mark.skip_on_windows\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED><DED>@pytest.mark.skip_on_windows\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    default_execution_context: ExecutionContext,\n):\n    pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n",
        "source_code_len": 160,
        "target_code": "    default_execution_context: ExecutionContext,\n    train_persist_load_with_different_settings,\n):\n\n    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n",
        "target_code_len": 243,
        "diff_format": "@@ -363,6 +357,8 @@\n     default_execution_context: ExecutionContext,\n-):\n+    train_persist_load_with_different_settings,\n+):\n+\n     pipeline = [\n-        {\"name\": \"WhitespaceTokenizer\"},\n-        {\"name\": \"CountVectorsFeaturizer\"},\n+        {\"component\": WhitespaceTokenizerGraphComponent},\n+        {\"component\": CountVectorsFeaturizerGraphComponent},\n     ]\n",
        "source_code_with_indent": "    default_execution_context: ExecutionContext,\n):\n    <IND>pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    default_execution_context: ExecutionContext,\n    train_persist_load_with_different_settings,\n):\n\n    <IND>pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    _train_persist_load_with_different_settings(\n        pipeline,\n        config_params,\n        create_response_selector,\n        load_response_selector,\n        False,\n        default_execution_context,\n    )\n\n    _train_persist_load_with_different_settings(\n        pipeline,\n        config_params,\n        create_response_selector,\n        load_response_selector,\n        True,\n        default_execution_context,\n    )\n",
        "source_code_len": 425,
        "target_code": "\n    train_persist_load_with_different_settings(\n        pipeline, config_params, False,\n    )\n\n    train_persist_load_with_different_settings(\n        pipeline, config_params, True,\n    )\n",
        "target_code_len": 189,
        "diff_format": "@@ -370,18 +366,8 @@\n \n-    _train_persist_load_with_different_settings(\n-        pipeline,\n-        config_params,\n-        create_response_selector,\n-        load_response_selector,\n-        False,\n-        default_execution_context,\n-    )\n-\n-    _train_persist_load_with_different_settings(\n-        pipeline,\n-        config_params,\n-        create_response_selector,\n-        load_response_selector,\n-        True,\n-        default_execution_context,\n+    train_persist_load_with_different_settings(\n+        pipeline, config_params, False,\n+    )\n+\n+    train_persist_load_with_different_settings(\n+        pipeline, config_params, True,\n     )\n",
        "source_code_with_indent": "\n    _train_persist_load_with_different_settings(\n        pipeline,\n        config_params,\n        create_response_selector,\n        load_response_selector,\n        False,\n        default_execution_context,\n    )\n\n    _train_persist_load_with_different_settings(\n        pipeline,\n        config_params,\n        create_response_selector,\n        load_response_selector,\n        True,\n        default_execution_context,\n    )\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    train_persist_load_with_different_settings(\n        pipeline, config_params, False,\n    )\n\n    train_persist_load_with_different_settings(\n        pipeline, config_params, True,\n    )\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ],\n):\n",
        "source_code_len": 10,
        "target_code": "    ],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n",
        "target_code_len": 139,
        "diff_format": "@@ -394,2 +380,4 @@\n     ],\n+    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n+    process_message: Callable[..., Message],\n ):\n",
        "source_code_with_indent": "    ],\n):\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n    config_params = {EPOCHS: 1}\n\n    loaded_pipeline = load_pipeline(pipeline)\n\n",
        "source_code_len": 188,
        "target_code": "    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    config_params = {EPOCHS: 1}\n\n",
        "target_code_len": 175,
        "diff_format": "@@ -397,8 +385,6 @@\n     pipeline = [\n-        {\"name\": \"WhitespaceTokenizer\"},\n-        {\"name\": \"CountVectorsFeaturizer\"},\n+        {\"component\": WhitespaceTokenizerGraphComponent},\n+        {\"component\": CountVectorsFeaturizerGraphComponent},\n     ]\n     config_params = {EPOCHS: 1}\n-\n-    loaded_pipeline = load_pipeline(pipeline)\n \n",
        "source_code_with_indent": "    pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n    config_params = {EPOCHS: 1}\n\n    loaded_pipeline = load_pipeline(pipeline)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    config_params = {EPOCHS: 1}\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    for component in loaded_pipeline:\n        component.train(training_data)\n\n",
        "source_code_len": 79,
        "target_code": "\n    training_data, loaded_pipeline = train_and_preprocess(pipeline, training_data)\n\n",
        "target_code_len": 85,
        "diff_format": "@@ -415,4 +401,3 @@\n \n-    for component in loaded_pipeline:\n-        component.train(training_data)\n+    training_data, loaded_pipeline = train_and_preprocess(pipeline, training_data)\n \n",
        "source_code_with_indent": "\n    for component in loaded_pipeline:\n        <IND>component.train(training_data)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    training_data, loaded_pipeline = train_and_preprocess(pipeline, training_data)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    message = Message(data={TEXT: \"hello\"})\n\n    for component in loaded_pipeline:\n        component.process(message)\n\n",
        "source_code_len": 119,
        "target_code": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_len": 101,
        "diff_format": "@@ -424,5 +409,3 @@\n     message = Message(data={TEXT: \"hello\"})\n-\n-    for component in loaded_pipeline:\n-        component.process(message)\n+    message = process_message(loaded_pipeline, message)\n \n",
        "source_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n\n    for component in loaded_pipeline:\n        <IND>component.process(message)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ],\n):\n    pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n\n",
        "source_code_len": 242,
        "target_code": "    ],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, \"data/test_selectors\"\n    )\n\n",
        "target_code_len": 387,
        "diff_format": "@@ -452,9 +435,12 @@\n     ],\n+    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n+    process_message: Callable[..., Message],\n ):\n     pipeline = [\n-        {\"name\": \"WhitespaceTokenizer\"},\n-        {\"name\": \"CountVectorsFeaturizer\"},\n+        {\"component\": WhitespaceTokenizerGraphComponent},\n+        {\"component\": CountVectorsFeaturizerGraphComponent},\n     ]\n-    loaded_pipeline = load_pipeline(pipeline)\n-    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n+    training_data, loaded_pipeline = train_and_preprocess(\n+        pipeline, \"data/test_selectors\"\n+    )\n \n",
        "source_code_with_indent": "    ],\n):\n    <IND>pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    <IND>pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, \"data/test_selectors\"\n    )\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    message = Message(data={TEXT: \"hello\"})\n\n    for component in loaded_pipeline:\n        component.process(message)\n\n",
        "source_code_len": 119,
        "target_code": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_len": 101,
        "diff_format": "@@ -464,5 +450,3 @@\n     message = Message(data={TEXT: \"hello\"})\n-\n-    for component in loaded_pipeline:\n-        component.process(message)\n+    message = process_message(loaded_pipeline, message)\n \n",
        "source_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n\n    for component in loaded_pipeline:\n        <IND>component.process(message)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ],\n):\n    pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n\n",
        "source_code_len": 242,
        "target_code": "    ],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, \"data/test_selectors\"\n    )\n\n",
        "target_code_len": 387,
        "diff_format": "@@ -498,9 +482,12 @@\n     ],\n+    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n+    process_message: Callable[..., Message],\n ):\n     pipeline = [\n-        {\"name\": \"WhitespaceTokenizer\"},\n-        {\"name\": \"CountVectorsFeaturizer\"},\n+        {\"component\": WhitespaceTokenizerGraphComponent},\n+        {\"component\": CountVectorsFeaturizerGraphComponent},\n     ]\n-    loaded_pipeline = load_pipeline(pipeline)\n-    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n+    training_data, loaded_pipeline = train_and_preprocess(\n+        pipeline, \"data/test_selectors\"\n+    )\n \n",
        "source_code_with_indent": "    ],\n):\n    <IND>pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [\"data/test_selectors\"])\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    <IND>pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n    ]\n    training_data, loaded_pipeline = train_and_preprocess(\n        pipeline, \"data/test_selectors\"\n    )\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    message = Message(data={TEXT: \"hello\"})\n\n    for component in loaded_pipeline:\n        component.process(message)\n\n",
        "source_code_len": 119,
        "target_code": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_len": 101,
        "diff_format": "@@ -510,5 +497,3 @@\n     message = Message(data={TEXT: \"hello\"})\n-\n-    for component in loaded_pipeline:\n-        component.process(message)\n+    message = process_message(loaded_pipeline, message)\n \n",
        "source_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n\n    for component in loaded_pipeline:\n        <IND>component.process(message)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    message = Message(data={TEXT: \"hello\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n):\n",
        "source_code_len": 92,
        "target_code": "    load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n",
        "target_code_len": 221,
        "diff_format": "@@ -645,2 +630,4 @@\n     load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n+    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n+    process_message: Callable[..., Message],\n ):\n",
        "source_code_with_indent": "    load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n):\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    load_response_selector: Callable[[Dict[Text, Any]], ResponseSelectorGraphComponent],\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [iter1_data_path])\n\n    response_selector = create_response_selector({EPOCHS: 1})\n",
        "source_code_len": 186,
        "target_code": "    ]\n    training_data, loaded_pipeline = train_and_preprocess(pipeline, iter1_data_path)\n    response_selector = create_response_selector({EPOCHS: 1})\n",
        "target_code_len": 153,
        "diff_format": "@@ -668,5 +655,3 @@\n     ]\n-    loaded_pipeline = load_pipeline(pipeline)\n-    training_data = train_pipeline(loaded_pipeline, [iter1_data_path])\n-\n+    training_data, loaded_pipeline = train_and_preprocess(pipeline, iter1_data_path)\n     response_selector = create_response_selector({EPOCHS: 1})\n",
        "source_code_with_indent": "    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [iter1_data_path])\n\n    response_selector = create_response_selector({EPOCHS: 1})\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ]\n    training_data, loaded_pipeline = train_and_preprocess(pipeline, iter1_data_path)\n    response_selector = create_response_selector({EPOCHS: 1})\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    message = Message(data={TEXT: \"Rasa is great!\"})\n\n    for component in loaded_pipeline:\n        component.process(message)\n\n",
        "source_code_len": 128,
        "target_code": "    message = Message(data={TEXT: \"Rasa is great!\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_len": 110,
        "diff_format": "@@ -678,5 +663,3 @@\n     message = Message(data={TEXT: \"Rasa is great!\"})\n-\n-    for component in loaded_pipeline:\n-        component.process(message)\n+    message = process_message(loaded_pipeline, message)\n \n",
        "source_code_with_indent": "    message = Message(data={TEXT: \"Rasa is great!\"})\n\n    for component in loaded_pipeline:\n        <IND>component.process(message)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    message = Message(data={TEXT: \"Rasa is great!\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    training_data2 = train_pipeline(loaded_pipeline, [iter2_data_path])\n\n",
        "source_code_len": 74,
        "target_code": "\n    training_data2, loaded_pipeline2 = train_and_preprocess(pipeline, iter2_data_path)\n\n",
        "target_code_len": 89,
        "diff_format": "@@ -715,3 +698,3 @@\n \n-    training_data2 = train_pipeline(loaded_pipeline, [iter2_data_path])\n+    training_data2, loaded_pipeline2 = train_and_preprocess(pipeline, iter2_data_path)\n \n",
        "source_code_with_indent": "\n    training_data2 = train_pipeline(loaded_pipeline, [iter2_data_path])\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    training_data2, loaded_pipeline2 = train_and_preprocess(pipeline, iter2_data_path)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    new_message = Message.build(text=\"Rasa is great!\")\n    for component in loaded_pipeline:\n        component.process(new_message)\n\n",
        "source_code_len": 133,
        "target_code": "    new_message = Message.build(text=\"Rasa is great!\")\n    new_message = process_message(loaded_pipeline2, new_message)\n\n",
        "target_code_len": 121,
        "diff_format": "@@ -720,4 +703,3 @@\n     new_message = Message.build(text=\"Rasa is great!\")\n-    for component in loaded_pipeline:\n-        component.process(new_message)\n+    new_message = process_message(loaded_pipeline2, new_message)\n \n",
        "source_code_with_indent": "    new_message = Message.build(text=\"Rasa is great!\")\n    for component in loaded_pipeline:\n        <IND>component.process(new_message)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    new_message = Message.build(text=\"Rasa is great!\")\n    new_message = process_message(loaded_pipeline2, new_message)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    default_execution_context: ExecutionContext,\n):\n    pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"LexicalSyntacticFeaturizer\"},\n        {\"name\": \"RegexFeaturizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n        {\n            \"name\": \"CountVectorsFeaturizer\",\n            \"analyzer\": \"char_wb\",\n",
        "source_code_len": 330,
        "target_code": "    default_execution_context: ExecutionContext,\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": LexicalSyntacticFeaturizerGraphComponent},\n        {\"component\": RegexFeaturizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n        {\n            \"component\": CountVectorsFeaturizerGraphComponent,\n            \"analyzer\": \"char_wb\",\n",
        "target_code_len": 544,
        "diff_format": "@@ -830,10 +812,12 @@\n     default_execution_context: ExecutionContext,\n+    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n+    process_message: Callable[..., Message],\n ):\n     pipeline = [\n-        {\"name\": \"WhitespaceTokenizer\"},\n-        {\"name\": \"LexicalSyntacticFeaturizer\"},\n-        {\"name\": \"RegexFeaturizer\"},\n-        {\"name\": \"CountVectorsFeaturizer\"},\n+        {\"component\": WhitespaceTokenizerGraphComponent},\n+        {\"component\": LexicalSyntacticFeaturizerGraphComponent},\n+        {\"component\": RegexFeaturizerGraphComponent},\n+        {\"component\": CountVectorsFeaturizerGraphComponent},\n         {\n-            \"name\": \"CountVectorsFeaturizer\",\n+            \"component\": CountVectorsFeaturizerGraphComponent,\n             \"analyzer\": \"char_wb\",\n",
        "source_code_with_indent": "    default_execution_context: ExecutionContext,\n):\n    <IND>pipeline = [\n        {\"name\": \"WhitespaceTokenizer\"},\n        {\"name\": \"LexicalSyntacticFeaturizer\"},\n        {\"name\": \"RegexFeaturizer\"},\n        {\"name\": \"CountVectorsFeaturizer\"},\n        {\n            \"name\": \"CountVectorsFeaturizer\",\n            \"analyzer\": \"char_wb\",\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    default_execution_context: ExecutionContext,\n    train_and_preprocess: Callable[..., Tuple[TrainingData, List[GraphComponent]]],\n    process_message: Callable[..., Message],\n):\n    <IND>pipeline = [\n        {\"component\": WhitespaceTokenizerGraphComponent},\n        {\"component\": LexicalSyntacticFeaturizerGraphComponent},\n        {\"component\": RegexFeaturizerGraphComponent},\n        {\"component\": CountVectorsFeaturizerGraphComponent},\n        {\n            \"component\": CountVectorsFeaturizerGraphComponent,\n            \"analyzer\": \"char_wb\",\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [iter1_path])\n\n",
        "source_code_len": 119,
        "target_code": "    ]\n    training_data, loaded_pipeline = train_and_preprocess(pipeline, iter1_path)\n\n",
        "target_code_len": 87,
        "diff_format": "@@ -843,4 +827,3 @@\n     ]\n-    loaded_pipeline = load_pipeline(pipeline)\n-    training_data = train_pipeline(loaded_pipeline, [iter1_path])\n+    training_data, loaded_pipeline = train_and_preprocess(pipeline, iter1_path)\n \n",
        "source_code_with_indent": "    ]\n    loaded_pipeline = load_pipeline(pipeline)\n    training_data = train_pipeline(loaded_pipeline, [iter1_path])\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ]\n    training_data, loaded_pipeline = train_and_preprocess(pipeline, iter1_path)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    message = Message(data={TEXT: \"Rasa is great!\"})\n\n    for component in loaded_pipeline:\n        component.process(message)\n\n",
        "source_code_len": 128,
        "target_code": "    message = Message(data={TEXT: \"Rasa is great!\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_len": 110,
        "diff_format": "@@ -850,5 +833,3 @@\n     message = Message(data={TEXT: \"Rasa is great!\"})\n-\n-    for component in loaded_pipeline:\n-        component.process(message)\n+    message = process_message(loaded_pipeline, message)\n \n",
        "source_code_with_indent": "    message = Message(data={TEXT: \"Rasa is great!\"})\n\n    for component in loaded_pipeline:\n        <IND>component.process(message)\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    message = Message(data={TEXT: \"Rasa is great!\"})\n    message = process_message(loaded_pipeline, message)\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        with pytest.raises(Exception) as exec_info:\n            training_data2 = train_pipeline(loaded_pipeline, [iter2_path])\n            loaded_selector.train(training_data=training_data2)\n",
        "source_code_len": 191,
        "target_code": "        with pytest.raises(Exception) as exec_info:\n            training_data2, loaded_pipeline2 = train_and_preprocess(\n                pipeline, iter2_path\n            )\n            loaded_selector.train(training_data=training_data2)\n",
        "target_code_len": 236,
        "diff_format": "@@ -868,3 +849,5 @@\n         with pytest.raises(Exception) as exec_info:\n-            training_data2 = train_pipeline(loaded_pipeline, [iter2_path])\n+            training_data2, loaded_pipeline2 = train_and_preprocess(\n+                pipeline, iter2_path\n+            )\n             loaded_selector.train(training_data=training_data2)\n",
        "source_code_with_indent": "        <IND>with pytest.raises(Exception) as exec_info:\n            <IND>training_data2 = train_pipeline(loaded_pipeline, [iter2_path])\n            loaded_selector.train(training_data=training_data2)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        <IND>with pytest.raises(Exception) as exec_info:\n            <IND>training_data2, loaded_pipeline2 = train_and_preprocess(\n                pipeline, iter2_path\n            )\n            loaded_selector.train(training_data=training_data2)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    else:\n        training_data2 = train_pipeline(loaded_pipeline, [iter2_path])\n        loaded_selector.train(training_data=training_data2)\n",
        "source_code_len": 141,
        "target_code": "    else:\n        training_data2, loaded_pipeline2 = train_and_preprocess(pipeline, iter2_path)\n        loaded_selector.train(training_data=training_data2)\n",
        "target_code_len": 156,
        "diff_format": "@@ -872,3 +855,3 @@\n     else:\n-        training_data2 = train_pipeline(loaded_pipeline, [iter2_path])\n+        training_data2, loaded_pipeline2 = train_and_preprocess(pipeline, iter2_path)\n         loaded_selector.train(training_data=training_data2)\n",
        "source_code_with_indent": "    <DED>else:\n        <IND>training_data2 = train_pipeline(loaded_pipeline, [iter2_path])\n        loaded_selector.train(training_data=training_data2)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED>else:\n        <IND>training_data2, loaded_pipeline2 = train_and_preprocess(pipeline, iter2_path)\n        loaded_selector.train(training_data=training_data2)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "1823da83403ca6b5fc76eaa5a231a3c9164157a6",
    "filename": "tests/nlu/tokenizers/test_whitespace_tokenizer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/tests/nlu/tokenizers/test_whitespace_tokenizer.py",
    "file_hunks_size": 3,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "tests/nlu/tokenizers/test_whitespace_tokenizer.py:20:8 Incompatible parameter type [6]: Expected `rasa.engine.storage.storage.ModelStorage` for 2nd positional only parameter to call `WhitespaceTokenizerGraphComponent.create` but got `None`.",
    "message": " Expected `rasa.engine.storage.storage.ModelStorage` for 2nd positional only parameter to call `WhitespaceTokenizerGraphComponent.create` but got `None`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 20,
    "warning_line": "        None,",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    config = config if config else {}\n    return WhitespaceTokenizerGraphComponent.create(\n        {**WhitespaceTokenizerGraphComponent.get_default_config(), **config},\n        None,\n        None,\n        None,\n    )\n",
        "source_code_len": 217,
        "target_code": "    config = config if config else {}\n    return WhitespaceTokenizerGraphComponent(\n        {**WhitespaceTokenizerGraphComponent.get_default_config(), **config},\n    )\n",
        "target_code_len": 168,
        "diff_format": "@@ -17,7 +15,4 @@\n     config = config if config else {}\n-    return WhitespaceTokenizerGraphComponent.create(\n+    return WhitespaceTokenizerGraphComponent(\n         {**WhitespaceTokenizerGraphComponent.get_default_config(), **config},\n-        None,\n-        None,\n-        None,\n     )\n",
        "source_code_with_indent": "    <IND>config = config if config else {}\n    return WhitespaceTokenizerGraphComponent.create(\n        {**WhitespaceTokenizerGraphComponent.get_default_config(), **config},\n        None,\n        None,\n        None,\n    )\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <IND>config = config if config else {}\n    return WhitespaceTokenizerGraphComponent(\n        {**WhitespaceTokenizerGraphComponent.get_default_config(), **config},\n    )\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "1823da83403ca6b5fc76eaa5a231a3c9164157a6",
    "filename": "tests/nlu/tokenizers/test_whitespace_tokenizer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/tests/nlu/tokenizers/test_whitespace_tokenizer.py",
    "file_hunks_size": 3,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "tests/nlu/tokenizers/test_whitespace_tokenizer.py:21:8 Incompatible parameter type [6]: Expected `rasa.engine.storage.resource.Resource` for 3rd positional only parameter to call `WhitespaceTokenizerGraphComponent.create` but got `None`.",
    "message": " Expected `rasa.engine.storage.resource.Resource` for 3rd positional only parameter to call `WhitespaceTokenizerGraphComponent.create` but got `None`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 21,
    "warning_line": "        None,",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    config = config if config else {}\n    return WhitespaceTokenizerGraphComponent.create(\n        {**WhitespaceTokenizerGraphComponent.get_default_config(), **config},\n        None,\n        None,\n        None,\n    )\n",
        "source_code_len": 217,
        "target_code": "    config = config if config else {}\n    return WhitespaceTokenizerGraphComponent(\n        {**WhitespaceTokenizerGraphComponent.get_default_config(), **config},\n    )\n",
        "target_code_len": 168,
        "diff_format": "@@ -17,7 +15,4 @@\n     config = config if config else {}\n-    return WhitespaceTokenizerGraphComponent.create(\n+    return WhitespaceTokenizerGraphComponent(\n         {**WhitespaceTokenizerGraphComponent.get_default_config(), **config},\n-        None,\n-        None,\n-        None,\n     )\n",
        "source_code_with_indent": "    <IND>config = config if config else {}\n    return WhitespaceTokenizerGraphComponent.create(\n        {**WhitespaceTokenizerGraphComponent.get_default_config(), **config},\n        None,\n        None,\n        None,\n    )\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <IND>config = config if config else {}\n    return WhitespaceTokenizerGraphComponent(\n        {**WhitespaceTokenizerGraphComponent.get_default_config(), **config},\n    )\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "1823da83403ca6b5fc76eaa5a231a3c9164157a6",
    "filename": "tests/nlu/tokenizers/test_whitespace_tokenizer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/tests/nlu/tokenizers/test_whitespace_tokenizer.py",
    "file_hunks_size": 3,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "tests/nlu/tokenizers/test_whitespace_tokenizer.py:22:8 Incompatible parameter type [6]: Expected `rasa.engine.graph.ExecutionContext` for 4th positional only parameter to call `WhitespaceTokenizerGraphComponent.create` but got `None`.",
    "message": " Expected `rasa.engine.graph.ExecutionContext` for 4th positional only parameter to call `WhitespaceTokenizerGraphComponent.create` but got `None`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 22,
    "warning_line": "        None,",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    config = config if config else {}\n    return WhitespaceTokenizerGraphComponent.create(\n        {**WhitespaceTokenizerGraphComponent.get_default_config(), **config},\n        None,\n        None,\n        None,\n    )\n",
        "source_code_len": 217,
        "target_code": "    config = config if config else {}\n    return WhitespaceTokenizerGraphComponent(\n        {**WhitespaceTokenizerGraphComponent.get_default_config(), **config},\n    )\n",
        "target_code_len": 168,
        "diff_format": "@@ -17,7 +15,4 @@\n     config = config if config else {}\n-    return WhitespaceTokenizerGraphComponent.create(\n+    return WhitespaceTokenizerGraphComponent(\n         {**WhitespaceTokenizerGraphComponent.get_default_config(), **config},\n-        None,\n-        None,\n-        None,\n     )\n",
        "source_code_with_indent": "    <IND>config = config if config else {}\n    return WhitespaceTokenizerGraphComponent.create(\n        {**WhitespaceTokenizerGraphComponent.get_default_config(), **config},\n        None,\n        None,\n        None,\n    )\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <IND>config = config if config else {}\n    return WhitespaceTokenizerGraphComponent(\n        {**WhitespaceTokenizerGraphComponent.get_default_config(), **config},\n    )\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  }
]