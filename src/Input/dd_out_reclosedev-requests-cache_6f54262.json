[
  {
    "project": "reclosedev/requests-cache",
    "commit": "6f54262b06a96b1019339e655b22c63f5882a632",
    "filename": "requests_cache/backends/base.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/reclosedev-requests-cache/requests_cache/backends/base.py",
    "file_hunks_size": 7,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": true,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "requests_cache/backends/base.py:118:39 Unsupported operand [58]: `+` is not supported for operand types `Iterable[str]` and `typing.List[typing.Any]`.",
    "message": " `+` is not supported for operand types `Iterable[str]` and `typing.List[typing.Any]`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 118,
    "warning_line": "        self.redirects.bulk_delete(set(keys + invalid_redirects))",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        invalid_redirects = [k for k, v in self.redirects.items() if v not in self.responses]\n        self.redirects.bulk_delete(set(keys + invalid_redirects))\n\n",
        "source_code_len": 161,
        "target_code": "        invalid_redirects = [k for k, v in self.redirects.items() if v not in self.responses]\n        self.redirects.bulk_delete(set(keys) | set(invalid_redirects))\n\n",
        "target_code_len": 166,
        "diff_format": "@@ -117,3 +115,3 @@\n         invalid_redirects = [k for k, v in self.redirects.items() if v not in self.responses]\n-        self.redirects.bulk_delete(set(keys + invalid_redirects))\n+        self.redirects.bulk_delete(set(keys) | set(invalid_redirects))\n \n",
        "source_code_with_indent": "        invalid_redirects = [k for k, v in self.redirects.items() if v not in self.responses]\n        self.redirects.bulk_delete(set(keys + invalid_redirects))\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        invalid_redirects = [k for k, v in self.redirects.items() if v not in self.responses]\n        self.redirects.bulk_delete(set(keys) | set(invalid_redirects))\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "reclosedev/requests-cache",
    "commit": "6f54262b06a96b1019339e655b22c63f5882a632",
    "filename": "requests_cache/backends/sqlite.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/reclosedev-requests-cache/requests_cache/backends/sqlite.py",
    "file_hunks_size": 3,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "requests_cache/backends/sqlite.py:198:32 Incompatible parameter type [6]: Expected `typing.Sized` for 1st positional only parameter to call `len` but got `Iterable[typing.Any]`.",
    "message": " Expected `typing.Sized` for 1st positional only parameter to call `len` but got `Iterable[typing.Any]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 198,
    "warning_line": "    return ','.join(['?'] * len(values)), list(values)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from tempfile import gettempdir\nfrom typing import Iterable, List, Tuple, Type, Union\n\n",
        "source_code_len": 87,
        "target_code": "from tempfile import gettempdir\nfrom typing import Collection, Iterable, Iterator, List, Tuple, Type, Union\n\n",
        "target_code_len": 109,
        "diff_format": "@@ -8,3 +8,3 @@\n from tempfile import gettempdir\n-from typing import Iterable, List, Tuple, Type, Union\n+from typing import Collection, Iterable, Iterator, List, Tuple, Type, Union\n \n",
        "source_code_with_indent": "from tempfile import gettempdir\nfrom typing import Iterable, List, Tuple, Type, Union\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from tempfile import gettempdir\nfrom typing import Collection, Iterable, Iterator, List, Tuple, Type, Union\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef _format_sequence(values: Iterable) -> Tuple[str, List]:\n    \"\"\"Get SQL parameter marks for a sequence-based query, and ensure value is a sequence\"\"\"\n",
        "source_code_len": 154,
        "target_code": "\ndef _format_sequence(values: Collection) -> Tuple[str, List]:\n    \"\"\"Get SQL parameter marks for a sequence-based query, and ensure value is a sequence\"\"\"\n",
        "target_code_len": 156,
        "diff_format": "@@ -193,3 +193,3 @@\n \n-def _format_sequence(values: Iterable) -> Tuple[str, List]:\n+def _format_sequence(values: Collection) -> Tuple[str, List]:\n     \"\"\"Get SQL parameter marks for a sequence-based query, and ensure value is a sequence\"\"\"\n",
        "source_code_with_indent": "\n<DED><DED>def _format_sequence(values: Iterable) -> Tuple[str, List]:\n    <IND>\"\"\"Get SQL parameter marks for a sequence-based query, and ensure value is a sequence\"\"\"\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED><DED>def _format_sequence(values: Collection) -> Tuple[str, List]:\n    <IND>\"\"\"Get SQL parameter marks for a sequence-based query, and ensure value is a sequence\"\"\"\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "reclosedev/requests-cache",
    "commit": "6f54262b06a96b1019339e655b22c63f5882a632",
    "filename": "requests_cache/cache_control.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/reclosedev-requests-cache/requests_cache/cache_control.py",
    "file_hunks_size": 5,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "requests_cache/cache_control.py:53:47 Incompatible parameter type [6]: Expected `Dict[typing.Any, typing.Any]` for 1st positional only parameter to call `has_cache_headers` but got `requests.structures.CaseInsensitiveDict[str]`.",
    "message": " Expected `Dict[typing.Any, typing.Any]` for 1st positional only parameter to call `has_cache_headers` but got `requests.structures.CaseInsensitiveDict[str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 53,
    "warning_line": "        if cache_control and has_cache_headers(request.headers):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from logging import getLogger\nfrom typing import Any, Dict, Optional, Tuple, Union\n\n",
        "source_code_len": 84,
        "target_code": "from logging import getLogger\nfrom typing import Any, Dict, Mapping, Optional, Tuple, Union\n\n",
        "target_code_len": 93,
        "diff_format": "@@ -5,3 +5,3 @@\n from logging import getLogger\n-from typing import Any, Dict, Optional, Tuple, Union\n+from typing import Any, Dict, Mapping, Optional, Tuple, Union\n \n",
        "source_code_with_indent": "from logging import getLogger\nfrom typing import Any, Dict, Optional, Tuple, Union\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from logging import getLogger\nfrom typing import Any, Dict, Mapping, Optional, Tuple, Union\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef has_cache_headers(headers: Dict) -> bool:\n    \"\"\"Determine if headers contain cache directives **that we currently support**\"\"\"\n",
        "source_code_len": 133,
        "target_code": "\ndef has_cache_headers(headers: Mapping) -> bool:\n    \"\"\"Determine if headers contain cache directives **that we currently support**\"\"\"\n",
        "target_code_len": 136,
        "diff_format": "@@ -146,3 +151,3 @@\n \n-def has_cache_headers(headers: Dict) -> bool:\n+def has_cache_headers(headers: Mapping) -> bool:\n     \"\"\"Determine if headers contain cache directives **that we currently support**\"\"\"\n",
        "source_code_with_indent": "\n<DED>def has_cache_headers(headers: Dict) -> bool:\n    <IND>\"\"\"Determine if headers contain cache directives **that we currently support**\"\"\"\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def has_cache_headers(headers: Mapping) -> bool:\n    <IND>\"\"\"Determine if headers contain cache directives **that we currently support**\"\"\"\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "reclosedev/requests-cache",
    "commit": "6f54262b06a96b1019339e655b22c63f5882a632",
    "filename": "requests_cache/cache_control.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/reclosedev-requests-cache/requests_cache/cache_control.py",
    "file_hunks_size": 5,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "requests_cache/cache_control.py:54:36 Incompatible parameter type [6]: Expected `Dict[typing.Any, typing.Any]` for 1st positional only parameter to call `CacheActions._init_from_headers` but got `requests.structures.CaseInsensitiveDict[str]`.",
    "message": " Expected `Dict[typing.Any, typing.Any]` for 1st positional only parameter to call `CacheActions._init_from_headers` but got `requests.structures.CaseInsensitiveDict[str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 54,
    "warning_line": "            self._init_from_headers(request.headers)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from logging import getLogger\nfrom typing import Any, Dict, Optional, Tuple, Union\n\n",
        "source_code_len": 84,
        "target_code": "from logging import getLogger\nfrom typing import Any, Dict, Mapping, Optional, Tuple, Union\n\n",
        "target_code_len": 93,
        "diff_format": "@@ -5,3 +5,3 @@\n from logging import getLogger\n-from typing import Any, Dict, Optional, Tuple, Union\n+from typing import Any, Dict, Mapping, Optional, Tuple, Union\n \n",
        "source_code_with_indent": "from logging import getLogger\nfrom typing import Any, Dict, Optional, Tuple, Union\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from logging import getLogger\nfrom typing import Any, Dict, Mapping, Optional, Tuple, Union\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    def _init_from_headers(self, headers: Dict):\n        \"\"\"Initialize from request headers\"\"\"\n",
        "source_code_len": 96,
        "target_code": "\n    def _init_from_headers(self, headers: Mapping):\n        \"\"\"Initialize from request headers\"\"\"\n",
        "target_code_len": 99,
        "diff_format": "@@ -57,3 +57,3 @@\n \n-    def _init_from_headers(self, headers: Dict):\n+    def _init_from_headers(self, headers: Mapping):\n         \"\"\"Initialize from request headers\"\"\"\n",
        "source_code_with_indent": "\n    <DED><DED>def _init_from_headers(self, headers: Dict):\n        <IND>\"\"\"Initialize from request headers\"\"\"\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED><DED>def _init_from_headers(self, headers: Mapping):\n        <IND>\"\"\"Initialize from request headers\"\"\"\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef get_cache_directives(headers: Dict) -> Dict:\n    \"\"\"Get all Cache-Control directives, and handle multiple headers and comma-separated lists\"\"\"\n",
        "source_code_len": 148,
        "target_code": "\ndef get_cache_directives(headers: Mapping) -> Dict:\n    \"\"\"Get all Cache-Control directives, and handle multiple headers and comma-separated lists\"\"\"\n",
        "target_code_len": 151,
        "diff_format": "@@ -124,3 +124,3 @@\n \n-def get_cache_directives(headers: Dict) -> Dict:\n+def get_cache_directives(headers: Mapping) -> Dict:\n     \"\"\"Get all Cache-Control directives, and handle multiple headers and comma-separated lists\"\"\"\n",
        "source_code_with_indent": "\n<DED>def get_cache_directives(headers: Dict) -> Dict:\n    <IND>\"\"\"Get all Cache-Control directives, and handle multiple headers and comma-separated lists\"\"\"\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def get_cache_directives(headers: Mapping) -> Dict:\n    <IND>\"\"\"Get all Cache-Control directives, and handle multiple headers and comma-separated lists\"\"\"\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "reclosedev/requests-cache",
    "commit": "6f54262b06a96b1019339e655b22c63f5882a632",
    "filename": "requests_cache/cache_control.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/reclosedev-requests-cache/requests_cache/cache_control.py",
    "file_hunks_size": 5,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "requests_cache/cache_control.py:94:42 Incompatible parameter type [6]: Expected `Dict[typing.Any, typing.Any]` for 1st positional only parameter to call `get_cache_directives` but got `requests.structures.CaseInsensitiveDict[str]`.",
    "message": " Expected `Dict[typing.Any, typing.Any]` for 1st positional only parameter to call `get_cache_directives` but got `requests.structures.CaseInsensitiveDict[str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 94,
    "warning_line": "        directives = get_cache_directives(response.headers)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from logging import getLogger\nfrom typing import Any, Dict, Optional, Tuple, Union\n\n",
        "source_code_len": 84,
        "target_code": "from logging import getLogger\nfrom typing import Any, Dict, Mapping, Optional, Tuple, Union\n\n",
        "target_code_len": 93,
        "diff_format": "@@ -5,3 +5,3 @@\n from logging import getLogger\n-from typing import Any, Dict, Optional, Tuple, Union\n+from typing import Any, Dict, Mapping, Optional, Tuple, Union\n \n",
        "source_code_with_indent": "from logging import getLogger\nfrom typing import Any, Dict, Optional, Tuple, Union\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from logging import getLogger\nfrom typing import Any, Dict, Mapping, Optional, Tuple, Union\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef get_cache_directives(headers: Dict) -> Dict:\n    \"\"\"Get all Cache-Control directives, and handle multiple headers and comma-separated lists\"\"\"\n",
        "source_code_len": 148,
        "target_code": "\ndef get_cache_directives(headers: Mapping) -> Dict:\n    \"\"\"Get all Cache-Control directives, and handle multiple headers and comma-separated lists\"\"\"\n",
        "target_code_len": 151,
        "diff_format": "@@ -124,3 +124,3 @@\n \n-def get_cache_directives(headers: Dict) -> Dict:\n+def get_cache_directives(headers: Mapping) -> Dict:\n     \"\"\"Get all Cache-Control directives, and handle multiple headers and comma-separated lists\"\"\"\n",
        "source_code_with_indent": "\n<DED>def get_cache_directives(headers: Dict) -> Dict:\n    <IND>\"\"\"Get all Cache-Control directives, and handle multiple headers and comma-separated lists\"\"\"\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def get_cache_directives(headers: Mapping) -> Dict:\n    <IND>\"\"\"Get all Cache-Control directives, and handle multiple headers and comma-separated lists\"\"\"\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "reclosedev/requests-cache",
    "commit": "6f54262b06a96b1019339e655b22c63f5882a632",
    "filename": "requests_cache/cache_keys.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/reclosedev-requests-cache/requests_cache/cache_keys.py",
    "file_hunks_size": 11,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "requests_cache/cache_keys.py:43:4 Incompatible attribute type [8]: Attribute `headers` declared in class `requests.models.PreparedRequest` has type `requests.structures.CaseInsensitiveDict[str]` but is used as type `typing.Dict[typing.Any, typing.Any]`.",
    "message": " Attribute `headers` declared in class `requests.models.PreparedRequest` has type `requests.structures.CaseInsensitiveDict[str]` but is used as type `typing.Dict[typing.Any, typing.Any]`.",
    "rule_id": "Incompatible attribute type [8]",
    "warning_line_no": 43,
    "warning_line": "    request.headers = remove_ignored_headers(request, ignored_params)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport requests\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = requests.utils.default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "source_code_len": 310,
        "target_code": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Optional, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nfrom requests import PreparedRequest, Request, Session\nfrom requests.models import CaseInsensitiveDict\nfrom requests.utils import default_headers\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "target_code_len": 435,
        "diff_format": "@@ -3,9 +3,11 @@\n from operator import itemgetter\n-from typing import Iterable, List, Mapping, Tuple, Union\n+from typing import Iterable, List, Mapping, Optional, Tuple, Union\n from urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n \n-import requests\n+from requests import PreparedRequest, Request, Session\n+from requests.models import CaseInsensitiveDict\n+from requests.utils import default_headers\n from url_normalize import url_normalize\n \n-DEFAULT_HEADERS = requests.utils.default_headers()\n+DEFAULT_HEADERS = default_headers()\n RequestContent = Union[Mapping, str, bytes]\n",
        "source_code_with_indent": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport requests\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = requests.utils.default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Optional, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nfrom requests import PreparedRequest, Request, Session\nfrom requests.models import CaseInsensitiveDict\nfrom requests.utils import default_headers\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def create_key(\n    request: requests.PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "source_code_len": 97,
        "target_code": "def create_key(\n    request: PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "target_code_len": 88,
        "diff_format": "@@ -14,3 +16,3 @@\n def create_key(\n-    request: requests.PreparedRequest,\n+    request: PreparedRequest,\n     ignored_params: Iterable[str] = None,\n",
        "source_code_with_indent": "def create_key(\n    request: requests.PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "def create_key(\n    request: PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    key = hashlib.sha256()\n    key.update(encode(request.method.upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_len": 135,
        "target_code": "    key = hashlib.sha256()\n    key.update(encode((request.method or '').upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "target_code_len": 143,
        "diff_format": "@@ -21,3 +23,3 @@\n     key = hashlib.sha256()\n-    key.update(encode(request.method.upper()))\n+    key.update(encode((request.method or '').upper()))\n     url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_with_indent": "    key = hashlib.sha256()\n    key.update(encode(request.method.upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    key = hashlib.sha256()\n    key.update(encode((request.method or '').upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def remove_ignored_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> requests.PreparedRequest:\n    if not ignored_params:\n",
        "source_code_len": 154,
        "target_code": "def remove_ignored_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> PreparedRequest:\n    if not ignored_params:\n",
        "target_code_len": 146,
        "diff_format": "@@ -38,4 +40,4 @@\n def remove_ignored_params(\n-    request: requests.PreparedRequest, ignored_params: Iterable[str]\n-) -> requests.PreparedRequest:\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n+) -> PreparedRequest:\n     if not ignored_params:\n",
        "source_code_with_indent": "<DED>def remove_ignored_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> requests.PreparedRequest:\n    <IND>if not ignored_params:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def remove_ignored_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> PreparedRequest:\n    <IND>if not ignored_params:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n    if not ignored_params:\n        return request.headers\n    headers = request.headers.copy()\n    headers.update({k: None for k in ignored_params})\n    return headers\n",
        "source_code_len": 271,
        "target_code": "\ndef remove_ignored_headers(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> CaseInsensitiveDict:\n    if not ignored_params:\n        return request.headers\n    headers = CaseInsensitiveDict(request.headers.copy())\n    for k in ignored_params:\n        headers.pop(k, None)\n    return headers\n",
        "target_code_len": 318,
        "diff_format": "@@ -48,7 +50,10 @@\n \n-def remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n+def remove_ignored_headers(\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n+) -> CaseInsensitiveDict:\n     if not ignored_params:\n         return request.headers\n-    headers = request.headers.copy()\n-    headers.update({k: None for k in ignored_params})\n+    headers = CaseInsensitiveDict(request.headers.copy())\n+    for k in ignored_params:\n+        headers.pop(k, None)\n     return headers\n",
        "source_code_with_indent": "\n<DED>def remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n    <IND>if not ignored_params:\n        <IND>return request.headers\n    <DED>headers = request.headers.copy()\n    headers.update({k: None for k in ignored_params})\n    return headers\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def remove_ignored_headers(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> CaseInsensitiveDict:\n    <IND>if not ignored_params:\n        <IND>return request.headers\n    <DED>headers = CaseInsensitiveDict(request.headers.copy())\n    for k in ignored_params:\n        <IND>headers.pop(k, None)\n    <DED>return headers\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n    url = str(request.url)\n    if not ignored_params:\n        return url\n\n    url = urlparse(url)\n    query = parse_qsl(url.query)\n    query = filter_params(query, ignored_params)\n    query = urlencode(query)\n    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n    return url\n\n",
        "source_code_len": 420,
        "target_code": "\ndef remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n    url_str = str(request.url)\n    if not ignored_params:\n        return url_str\n\n    url = urlparse(url_str)\n    query = filter_params(parse_qsl(url.query), ignored_params)\n    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n\n",
        "target_code_len": 383,
        "diff_format": "@@ -56,13 +61,10 @@\n \n-def remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n-    url = str(request.url)\n+def remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n+    url_str = str(request.url)\n     if not ignored_params:\n-        return url\n+        return url_str\n \n-    url = urlparse(url)\n-    query = parse_qsl(url.query)\n-    query = filter_params(query, ignored_params)\n-    query = urlencode(query)\n-    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n-    return url\n+    url = urlparse(url_str)\n+    query = filter_params(parse_qsl(url.query), ignored_params)\n+    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n \n",
        "source_code_with_indent": "\n<DED>def remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n    <IND>url = str(request.url)\n    if not ignored_params:\n        <IND>return url\n\n    <DED>url = urlparse(url)\n    query = parse_qsl(url.query)\n    query = filter_params(query, ignored_params)\n    query = urlencode(query)\n    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n    return url\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n    <IND>url_str = str(request.url)\n    if not ignored_params:\n        <IND>return url_str\n\n    <DED>url = urlparse(url_str)\n    query = filter_params(parse_qsl(url.query), ignored_params)\n    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "def remove_ignored_body_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> bytes:\n    body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not body or not content_type:\n        return encode(request.body)\n\n    if content_type == 'application/x-www-form-urlencoded':\n        body = parse_qsl(body)\n        body = filter_params(body, ignored_params)\n        body = urlencode(body)\n    elif content_type == 'application/json':\n        body = json.loads(decode(body))\n        body = filter_params(sorted(body.items()), ignored_params)\n        body = json.dumps(body)\n    return encode(body)\n\n\ndef filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n    return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_len": 824,
        "target_code": "def remove_ignored_body_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> bytes:\n    original_body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not original_body or not content_type:\n        return encode(original_body)\n\n    if content_type == 'application/x-www-form-urlencoded':\n        body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n        filtered_body = urlencode(body)\n    elif content_type == 'application/json':\n        body = json.loads(decode(original_body)).items()\n        body = filter_params(sorted(body), ignored_params)\n        filtered_body = json.dumps(body)\n    else:\n        filtered_body = original_body  # type: ignore\n\n    return encode(filtered_body)\n\n\ndef filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n    return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "target_code_len": 962,
        "diff_format": "@@ -70,21 +72,23 @@\n def remove_ignored_body_params(\n-    request: requests.PreparedRequest, ignored_params: Iterable[str]\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n ) -> bytes:\n-    body = request.body\n+    original_body = request.body\n     content_type = request.headers.get('content-type')\n-    if not ignored_params or not body or not content_type:\n-        return encode(request.body)\n+    if not ignored_params or not original_body or not content_type:\n+        return encode(original_body)\n \n     if content_type == 'application/x-www-form-urlencoded':\n-        body = parse_qsl(body)\n-        body = filter_params(body, ignored_params)\n-        body = urlencode(body)\n+        body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n+        filtered_body = urlencode(body)\n     elif content_type == 'application/json':\n-        body = json.loads(decode(body))\n-        body = filter_params(sorted(body.items()), ignored_params)\n-        body = json.dumps(body)\n-    return encode(body)\n+        body = json.loads(decode(original_body)).items()\n+        body = filter_params(sorted(body), ignored_params)\n+        filtered_body = json.dumps(body)\n+    else:\n+        filtered_body = original_body  # type: ignore\n+\n+    return encode(filtered_body)\n \n \n-def filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n+def filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n     return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_with_indent": "<DED>def remove_ignored_body_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> bytes:\n    <IND>body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not body or not content_type:\n        <IND>return encode(request.body)\n\n    <DED>if content_type == 'application/x-www-form-urlencoded':\n        <IND>body = parse_qsl(body)\n        body = filter_params(body, ignored_params)\n        body = urlencode(body)\n    <DED>elif content_type == 'application/json':\n        <IND>body = json.loads(decode(body))\n        body = filter_params(sorted(body.items()), ignored_params)\n        body = json.dumps(body)\n    <DED>return encode(body)\n\n\n<DED>def filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n    <IND>return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def remove_ignored_body_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> bytes:\n    <IND>original_body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not original_body or not content_type:\n        <IND>return encode(original_body)\n\n    <DED>if content_type == 'application/x-www-form-urlencoded':\n        <IND>body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n        filtered_body = urlencode(body)\n    <DED>elif content_type == 'application/json':\n        <IND>body = json.loads(decode(original_body)).items()\n        body = filter_params(sorted(body), ignored_params)\n        filtered_body = json.dumps(body)\n    <DED>else:\n        <IND>filtered_body = original_body  # type: ignore\n\n    <DED>return encode(filtered_body)\n\n\n<DED>def filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n    <IND>return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def url_to_key(url: str, *args, **kwargs) -> str:\n    request = requests.Session().prepare_request(requests.Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "source_code_len": 177,
        "target_code": "def url_to_key(url: str, *args, **kwargs) -> str:\n    request = Session().prepare_request(Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "target_code_len": 159,
        "diff_format": "@@ -118,3 +126,3 @@\n def url_to_key(url: str, *args, **kwargs) -> str:\n-    request = requests.Session().prepare_request(requests.Request('GET', url))\n+    request = Session().prepare_request(Request('GET', url))\n     return create_key(request, *args, **kwargs)\n",
        "source_code_with_indent": "<DED>def url_to_key(url: str, *args, **kwargs) -> str:\n    <IND>request = requests.Session().prepare_request(requests.Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def url_to_key(url: str, *args, **kwargs) -> str:\n    <IND>request = Session().prepare_request(Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "reclosedev/requests-cache",
    "commit": "6f54262b06a96b1019339e655b22c63f5882a632",
    "filename": "requests_cache/cache_keys.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/reclosedev-requests-cache/requests_cache/cache_keys.py",
    "file_hunks_size": 11,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "requests_cache/cache_keys.py:51:8 Incompatible return type [7]: Expected `typing.Dict[typing.Any, typing.Any]` but got `requests.structures.CaseInsensitiveDict[str]`.",
    "message": " Expected `typing.Dict[typing.Any, typing.Any]` but got `requests.structures.CaseInsensitiveDict[str]`.",
    "rule_id": "Incompatible return type [7]",
    "warning_line_no": 51,
    "warning_line": "        return request.headers",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport requests\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = requests.utils.default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "source_code_len": 310,
        "target_code": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Optional, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nfrom requests import PreparedRequest, Request, Session\nfrom requests.models import CaseInsensitiveDict\nfrom requests.utils import default_headers\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "target_code_len": 435,
        "diff_format": "@@ -3,9 +3,11 @@\n from operator import itemgetter\n-from typing import Iterable, List, Mapping, Tuple, Union\n+from typing import Iterable, List, Mapping, Optional, Tuple, Union\n from urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n \n-import requests\n+from requests import PreparedRequest, Request, Session\n+from requests.models import CaseInsensitiveDict\n+from requests.utils import default_headers\n from url_normalize import url_normalize\n \n-DEFAULT_HEADERS = requests.utils.default_headers()\n+DEFAULT_HEADERS = default_headers()\n RequestContent = Union[Mapping, str, bytes]\n",
        "source_code_with_indent": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport requests\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = requests.utils.default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Optional, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nfrom requests import PreparedRequest, Request, Session\nfrom requests.models import CaseInsensitiveDict\nfrom requests.utils import default_headers\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def create_key(\n    request: requests.PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "source_code_len": 97,
        "target_code": "def create_key(\n    request: PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "target_code_len": 88,
        "diff_format": "@@ -14,3 +16,3 @@\n def create_key(\n-    request: requests.PreparedRequest,\n+    request: PreparedRequest,\n     ignored_params: Iterable[str] = None,\n",
        "source_code_with_indent": "def create_key(\n    request: requests.PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "def create_key(\n    request: PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    key = hashlib.sha256()\n    key.update(encode(request.method.upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_len": 135,
        "target_code": "    key = hashlib.sha256()\n    key.update(encode((request.method or '').upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "target_code_len": 143,
        "diff_format": "@@ -21,3 +23,3 @@\n     key = hashlib.sha256()\n-    key.update(encode(request.method.upper()))\n+    key.update(encode((request.method or '').upper()))\n     url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_with_indent": "    key = hashlib.sha256()\n    key.update(encode(request.method.upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    key = hashlib.sha256()\n    key.update(encode((request.method or '').upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def remove_ignored_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> requests.PreparedRequest:\n    if not ignored_params:\n",
        "source_code_len": 154,
        "target_code": "def remove_ignored_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> PreparedRequest:\n    if not ignored_params:\n",
        "target_code_len": 146,
        "diff_format": "@@ -38,4 +40,4 @@\n def remove_ignored_params(\n-    request: requests.PreparedRequest, ignored_params: Iterable[str]\n-) -> requests.PreparedRequest:\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n+) -> PreparedRequest:\n     if not ignored_params:\n",
        "source_code_with_indent": "<DED>def remove_ignored_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> requests.PreparedRequest:\n    <IND>if not ignored_params:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def remove_ignored_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> PreparedRequest:\n    <IND>if not ignored_params:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n    if not ignored_params:\n        return request.headers\n    headers = request.headers.copy()\n    headers.update({k: None for k in ignored_params})\n    return headers\n",
        "source_code_len": 271,
        "target_code": "\ndef remove_ignored_headers(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> CaseInsensitiveDict:\n    if not ignored_params:\n        return request.headers\n    headers = CaseInsensitiveDict(request.headers.copy())\n    for k in ignored_params:\n        headers.pop(k, None)\n    return headers\n",
        "target_code_len": 318,
        "diff_format": "@@ -48,7 +50,10 @@\n \n-def remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n+def remove_ignored_headers(\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n+) -> CaseInsensitiveDict:\n     if not ignored_params:\n         return request.headers\n-    headers = request.headers.copy()\n-    headers.update({k: None for k in ignored_params})\n+    headers = CaseInsensitiveDict(request.headers.copy())\n+    for k in ignored_params:\n+        headers.pop(k, None)\n     return headers\n",
        "source_code_with_indent": "\n<DED>def remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n    <IND>if not ignored_params:\n        <IND>return request.headers\n    <DED>headers = request.headers.copy()\n    headers.update({k: None for k in ignored_params})\n    return headers\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def remove_ignored_headers(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> CaseInsensitiveDict:\n    <IND>if not ignored_params:\n        <IND>return request.headers\n    <DED>headers = CaseInsensitiveDict(request.headers.copy())\n    for k in ignored_params:\n        <IND>headers.pop(k, None)\n    <DED>return headers\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n    url = str(request.url)\n    if not ignored_params:\n        return url\n\n    url = urlparse(url)\n    query = parse_qsl(url.query)\n    query = filter_params(query, ignored_params)\n    query = urlencode(query)\n    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n    return url\n\n",
        "source_code_len": 420,
        "target_code": "\ndef remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n    url_str = str(request.url)\n    if not ignored_params:\n        return url_str\n\n    url = urlparse(url_str)\n    query = filter_params(parse_qsl(url.query), ignored_params)\n    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n\n",
        "target_code_len": 383,
        "diff_format": "@@ -56,13 +61,10 @@\n \n-def remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n-    url = str(request.url)\n+def remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n+    url_str = str(request.url)\n     if not ignored_params:\n-        return url\n+        return url_str\n \n-    url = urlparse(url)\n-    query = parse_qsl(url.query)\n-    query = filter_params(query, ignored_params)\n-    query = urlencode(query)\n-    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n-    return url\n+    url = urlparse(url_str)\n+    query = filter_params(parse_qsl(url.query), ignored_params)\n+    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n \n",
        "source_code_with_indent": "\n<DED>def remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n    <IND>url = str(request.url)\n    if not ignored_params:\n        <IND>return url\n\n    <DED>url = urlparse(url)\n    query = parse_qsl(url.query)\n    query = filter_params(query, ignored_params)\n    query = urlencode(query)\n    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n    return url\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n    <IND>url_str = str(request.url)\n    if not ignored_params:\n        <IND>return url_str\n\n    <DED>url = urlparse(url_str)\n    query = filter_params(parse_qsl(url.query), ignored_params)\n    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "def remove_ignored_body_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> bytes:\n    body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not body or not content_type:\n        return encode(request.body)\n\n    if content_type == 'application/x-www-form-urlencoded':\n        body = parse_qsl(body)\n        body = filter_params(body, ignored_params)\n        body = urlencode(body)\n    elif content_type == 'application/json':\n        body = json.loads(decode(body))\n        body = filter_params(sorted(body.items()), ignored_params)\n        body = json.dumps(body)\n    return encode(body)\n\n\ndef filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n    return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_len": 824,
        "target_code": "def remove_ignored_body_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> bytes:\n    original_body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not original_body or not content_type:\n        return encode(original_body)\n\n    if content_type == 'application/x-www-form-urlencoded':\n        body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n        filtered_body = urlencode(body)\n    elif content_type == 'application/json':\n        body = json.loads(decode(original_body)).items()\n        body = filter_params(sorted(body), ignored_params)\n        filtered_body = json.dumps(body)\n    else:\n        filtered_body = original_body  # type: ignore\n\n    return encode(filtered_body)\n\n\ndef filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n    return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "target_code_len": 962,
        "diff_format": "@@ -70,21 +72,23 @@\n def remove_ignored_body_params(\n-    request: requests.PreparedRequest, ignored_params: Iterable[str]\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n ) -> bytes:\n-    body = request.body\n+    original_body = request.body\n     content_type = request.headers.get('content-type')\n-    if not ignored_params or not body or not content_type:\n-        return encode(request.body)\n+    if not ignored_params or not original_body or not content_type:\n+        return encode(original_body)\n \n     if content_type == 'application/x-www-form-urlencoded':\n-        body = parse_qsl(body)\n-        body = filter_params(body, ignored_params)\n-        body = urlencode(body)\n+        body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n+        filtered_body = urlencode(body)\n     elif content_type == 'application/json':\n-        body = json.loads(decode(body))\n-        body = filter_params(sorted(body.items()), ignored_params)\n-        body = json.dumps(body)\n-    return encode(body)\n+        body = json.loads(decode(original_body)).items()\n+        body = filter_params(sorted(body), ignored_params)\n+        filtered_body = json.dumps(body)\n+    else:\n+        filtered_body = original_body  # type: ignore\n+\n+    return encode(filtered_body)\n \n \n-def filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n+def filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n     return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_with_indent": "<DED>def remove_ignored_body_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> bytes:\n    <IND>body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not body or not content_type:\n        <IND>return encode(request.body)\n\n    <DED>if content_type == 'application/x-www-form-urlencoded':\n        <IND>body = parse_qsl(body)\n        body = filter_params(body, ignored_params)\n        body = urlencode(body)\n    <DED>elif content_type == 'application/json':\n        <IND>body = json.loads(decode(body))\n        body = filter_params(sorted(body.items()), ignored_params)\n        body = json.dumps(body)\n    <DED>return encode(body)\n\n\n<DED>def filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n    <IND>return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def remove_ignored_body_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> bytes:\n    <IND>original_body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not original_body or not content_type:\n        <IND>return encode(original_body)\n\n    <DED>if content_type == 'application/x-www-form-urlencoded':\n        <IND>body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n        filtered_body = urlencode(body)\n    <DED>elif content_type == 'application/json':\n        <IND>body = json.loads(decode(original_body)).items()\n        body = filter_params(sorted(body), ignored_params)\n        filtered_body = json.dumps(body)\n    <DED>else:\n        <IND>filtered_body = original_body  # type: ignore\n\n    <DED>return encode(filtered_body)\n\n\n<DED>def filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n    <IND>return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def url_to_key(url: str, *args, **kwargs) -> str:\n    request = requests.Session().prepare_request(requests.Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "source_code_len": 177,
        "target_code": "def url_to_key(url: str, *args, **kwargs) -> str:\n    request = Session().prepare_request(Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "target_code_len": 159,
        "diff_format": "@@ -118,3 +126,3 @@\n def url_to_key(url: str, *args, **kwargs) -> str:\n-    request = requests.Session().prepare_request(requests.Request('GET', url))\n+    request = Session().prepare_request(Request('GET', url))\n     return create_key(request, *args, **kwargs)\n",
        "source_code_with_indent": "<DED>def url_to_key(url: str, *args, **kwargs) -> str:\n    <IND>request = requests.Session().prepare_request(requests.Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def url_to_key(url: str, *args, **kwargs) -> str:\n    <IND>request = Session().prepare_request(Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "reclosedev/requests-cache",
    "commit": "6f54262b06a96b1019339e655b22c63f5882a632",
    "filename": "requests_cache/cache_keys.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/reclosedev-requests-cache/requests_cache/cache_keys.py",
    "file_hunks_size": 11,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "requests_cache/cache_keys.py:53:19 Incompatible parameter type [6]: Expected `Mapping[str, str]` for 1st positional only parameter to call `typing.MutableMapping.update` but got `typing.Dict[str, None]`.",
    "message": " Expected `Mapping[str, str]` for 1st positional only parameter to call `typing.MutableMapping.update` but got `typing.Dict[str, None]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 53,
    "warning_line": "    headers.update({k: None for k in ignored_params})",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport requests\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = requests.utils.default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "source_code_len": 310,
        "target_code": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Optional, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nfrom requests import PreparedRequest, Request, Session\nfrom requests.models import CaseInsensitiveDict\nfrom requests.utils import default_headers\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "target_code_len": 435,
        "diff_format": "@@ -3,9 +3,11 @@\n from operator import itemgetter\n-from typing import Iterable, List, Mapping, Tuple, Union\n+from typing import Iterable, List, Mapping, Optional, Tuple, Union\n from urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n \n-import requests\n+from requests import PreparedRequest, Request, Session\n+from requests.models import CaseInsensitiveDict\n+from requests.utils import default_headers\n from url_normalize import url_normalize\n \n-DEFAULT_HEADERS = requests.utils.default_headers()\n+DEFAULT_HEADERS = default_headers()\n RequestContent = Union[Mapping, str, bytes]\n",
        "source_code_with_indent": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport requests\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = requests.utils.default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Optional, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nfrom requests import PreparedRequest, Request, Session\nfrom requests.models import CaseInsensitiveDict\nfrom requests.utils import default_headers\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def create_key(\n    request: requests.PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "source_code_len": 97,
        "target_code": "def create_key(\n    request: PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "target_code_len": 88,
        "diff_format": "@@ -14,3 +16,3 @@\n def create_key(\n-    request: requests.PreparedRequest,\n+    request: PreparedRequest,\n     ignored_params: Iterable[str] = None,\n",
        "source_code_with_indent": "def create_key(\n    request: requests.PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "def create_key(\n    request: PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    key = hashlib.sha256()\n    key.update(encode(request.method.upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_len": 135,
        "target_code": "    key = hashlib.sha256()\n    key.update(encode((request.method or '').upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "target_code_len": 143,
        "diff_format": "@@ -21,3 +23,3 @@\n     key = hashlib.sha256()\n-    key.update(encode(request.method.upper()))\n+    key.update(encode((request.method or '').upper()))\n     url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_with_indent": "    key = hashlib.sha256()\n    key.update(encode(request.method.upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    key = hashlib.sha256()\n    key.update(encode((request.method or '').upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def remove_ignored_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> requests.PreparedRequest:\n    if not ignored_params:\n",
        "source_code_len": 154,
        "target_code": "def remove_ignored_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> PreparedRequest:\n    if not ignored_params:\n",
        "target_code_len": 146,
        "diff_format": "@@ -38,4 +40,4 @@\n def remove_ignored_params(\n-    request: requests.PreparedRequest, ignored_params: Iterable[str]\n-) -> requests.PreparedRequest:\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n+) -> PreparedRequest:\n     if not ignored_params:\n",
        "source_code_with_indent": "<DED>def remove_ignored_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> requests.PreparedRequest:\n    <IND>if not ignored_params:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def remove_ignored_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> PreparedRequest:\n    <IND>if not ignored_params:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n    if not ignored_params:\n        return request.headers\n    headers = request.headers.copy()\n    headers.update({k: None for k in ignored_params})\n    return headers\n",
        "source_code_len": 271,
        "target_code": "\ndef remove_ignored_headers(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> CaseInsensitiveDict:\n    if not ignored_params:\n        return request.headers\n    headers = CaseInsensitiveDict(request.headers.copy())\n    for k in ignored_params:\n        headers.pop(k, None)\n    return headers\n",
        "target_code_len": 318,
        "diff_format": "@@ -48,7 +50,10 @@\n \n-def remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n+def remove_ignored_headers(\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n+) -> CaseInsensitiveDict:\n     if not ignored_params:\n         return request.headers\n-    headers = request.headers.copy()\n-    headers.update({k: None for k in ignored_params})\n+    headers = CaseInsensitiveDict(request.headers.copy())\n+    for k in ignored_params:\n+        headers.pop(k, None)\n     return headers\n",
        "source_code_with_indent": "\n<DED>def remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n    <IND>if not ignored_params:\n        <IND>return request.headers\n    <DED>headers = request.headers.copy()\n    headers.update({k: None for k in ignored_params})\n    return headers\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def remove_ignored_headers(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> CaseInsensitiveDict:\n    <IND>if not ignored_params:\n        <IND>return request.headers\n    <DED>headers = CaseInsensitiveDict(request.headers.copy())\n    for k in ignored_params:\n        <IND>headers.pop(k, None)\n    <DED>return headers\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n    url = str(request.url)\n    if not ignored_params:\n        return url\n\n    url = urlparse(url)\n    query = parse_qsl(url.query)\n    query = filter_params(query, ignored_params)\n    query = urlencode(query)\n    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n    return url\n\n",
        "source_code_len": 420,
        "target_code": "\ndef remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n    url_str = str(request.url)\n    if not ignored_params:\n        return url_str\n\n    url = urlparse(url_str)\n    query = filter_params(parse_qsl(url.query), ignored_params)\n    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n\n",
        "target_code_len": 383,
        "diff_format": "@@ -56,13 +61,10 @@\n \n-def remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n-    url = str(request.url)\n+def remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n+    url_str = str(request.url)\n     if not ignored_params:\n-        return url\n+        return url_str\n \n-    url = urlparse(url)\n-    query = parse_qsl(url.query)\n-    query = filter_params(query, ignored_params)\n-    query = urlencode(query)\n-    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n-    return url\n+    url = urlparse(url_str)\n+    query = filter_params(parse_qsl(url.query), ignored_params)\n+    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n \n",
        "source_code_with_indent": "\n<DED>def remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n    <IND>url = str(request.url)\n    if not ignored_params:\n        <IND>return url\n\n    <DED>url = urlparse(url)\n    query = parse_qsl(url.query)\n    query = filter_params(query, ignored_params)\n    query = urlencode(query)\n    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n    return url\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n    <IND>url_str = str(request.url)\n    if not ignored_params:\n        <IND>return url_str\n\n    <DED>url = urlparse(url_str)\n    query = filter_params(parse_qsl(url.query), ignored_params)\n    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "def remove_ignored_body_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> bytes:\n    body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not body or not content_type:\n        return encode(request.body)\n\n    if content_type == 'application/x-www-form-urlencoded':\n        body = parse_qsl(body)\n        body = filter_params(body, ignored_params)\n        body = urlencode(body)\n    elif content_type == 'application/json':\n        body = json.loads(decode(body))\n        body = filter_params(sorted(body.items()), ignored_params)\n        body = json.dumps(body)\n    return encode(body)\n\n\ndef filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n    return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_len": 824,
        "target_code": "def remove_ignored_body_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> bytes:\n    original_body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not original_body or not content_type:\n        return encode(original_body)\n\n    if content_type == 'application/x-www-form-urlencoded':\n        body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n        filtered_body = urlencode(body)\n    elif content_type == 'application/json':\n        body = json.loads(decode(original_body)).items()\n        body = filter_params(sorted(body), ignored_params)\n        filtered_body = json.dumps(body)\n    else:\n        filtered_body = original_body  # type: ignore\n\n    return encode(filtered_body)\n\n\ndef filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n    return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "target_code_len": 962,
        "diff_format": "@@ -70,21 +72,23 @@\n def remove_ignored_body_params(\n-    request: requests.PreparedRequest, ignored_params: Iterable[str]\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n ) -> bytes:\n-    body = request.body\n+    original_body = request.body\n     content_type = request.headers.get('content-type')\n-    if not ignored_params or not body or not content_type:\n-        return encode(request.body)\n+    if not ignored_params or not original_body or not content_type:\n+        return encode(original_body)\n \n     if content_type == 'application/x-www-form-urlencoded':\n-        body = parse_qsl(body)\n-        body = filter_params(body, ignored_params)\n-        body = urlencode(body)\n+        body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n+        filtered_body = urlencode(body)\n     elif content_type == 'application/json':\n-        body = json.loads(decode(body))\n-        body = filter_params(sorted(body.items()), ignored_params)\n-        body = json.dumps(body)\n-    return encode(body)\n+        body = json.loads(decode(original_body)).items()\n+        body = filter_params(sorted(body), ignored_params)\n+        filtered_body = json.dumps(body)\n+    else:\n+        filtered_body = original_body  # type: ignore\n+\n+    return encode(filtered_body)\n \n \n-def filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n+def filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n     return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_with_indent": "<DED>def remove_ignored_body_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> bytes:\n    <IND>body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not body or not content_type:\n        <IND>return encode(request.body)\n\n    <DED>if content_type == 'application/x-www-form-urlencoded':\n        <IND>body = parse_qsl(body)\n        body = filter_params(body, ignored_params)\n        body = urlencode(body)\n    <DED>elif content_type == 'application/json':\n        <IND>body = json.loads(decode(body))\n        body = filter_params(sorted(body.items()), ignored_params)\n        body = json.dumps(body)\n    <DED>return encode(body)\n\n\n<DED>def filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n    <IND>return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def remove_ignored_body_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> bytes:\n    <IND>original_body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not original_body or not content_type:\n        <IND>return encode(original_body)\n\n    <DED>if content_type == 'application/x-www-form-urlencoded':\n        <IND>body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n        filtered_body = urlencode(body)\n    <DED>elif content_type == 'application/json':\n        <IND>body = json.loads(decode(original_body)).items()\n        body = filter_params(sorted(body), ignored_params)\n        filtered_body = json.dumps(body)\n    <DED>else:\n        <IND>filtered_body = original_body  # type: ignore\n\n    <DED>return encode(filtered_body)\n\n\n<DED>def filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n    <IND>return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def url_to_key(url: str, *args, **kwargs) -> str:\n    request = requests.Session().prepare_request(requests.Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "source_code_len": 177,
        "target_code": "def url_to_key(url: str, *args, **kwargs) -> str:\n    request = Session().prepare_request(Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "target_code_len": 159,
        "diff_format": "@@ -118,3 +126,3 @@\n def url_to_key(url: str, *args, **kwargs) -> str:\n-    request = requests.Session().prepare_request(requests.Request('GET', url))\n+    request = Session().prepare_request(Request('GET', url))\n     return create_key(request, *args, **kwargs)\n",
        "source_code_with_indent": "<DED>def url_to_key(url: str, *args, **kwargs) -> str:\n    <IND>request = requests.Session().prepare_request(requests.Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def url_to_key(url: str, *args, **kwargs) -> str:\n    <IND>request = Session().prepare_request(Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "reclosedev/requests-cache",
    "commit": "6f54262b06a96b1019339e655b22c63f5882a632",
    "filename": "requests_cache/cache_keys.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/reclosedev-requests-cache/requests_cache/cache_keys.py",
    "file_hunks_size": 11,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "requests_cache/cache_keys.py:54:4 Incompatible return type [7]: Expected `typing.Dict[typing.Any, typing.Any]` but got `requests.structures.CaseInsensitiveDict[str]`.",
    "message": " Expected `typing.Dict[typing.Any, typing.Any]` but got `requests.structures.CaseInsensitiveDict[str]`.",
    "rule_id": "Incompatible return type [7]",
    "warning_line_no": 54,
    "warning_line": "    return headers",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport requests\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = requests.utils.default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "source_code_len": 310,
        "target_code": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Optional, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nfrom requests import PreparedRequest, Request, Session\nfrom requests.models import CaseInsensitiveDict\nfrom requests.utils import default_headers\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "target_code_len": 435,
        "diff_format": "@@ -3,9 +3,11 @@\n from operator import itemgetter\n-from typing import Iterable, List, Mapping, Tuple, Union\n+from typing import Iterable, List, Mapping, Optional, Tuple, Union\n from urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n \n-import requests\n+from requests import PreparedRequest, Request, Session\n+from requests.models import CaseInsensitiveDict\n+from requests.utils import default_headers\n from url_normalize import url_normalize\n \n-DEFAULT_HEADERS = requests.utils.default_headers()\n+DEFAULT_HEADERS = default_headers()\n RequestContent = Union[Mapping, str, bytes]\n",
        "source_code_with_indent": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport requests\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = requests.utils.default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Optional, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nfrom requests import PreparedRequest, Request, Session\nfrom requests.models import CaseInsensitiveDict\nfrom requests.utils import default_headers\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def create_key(\n    request: requests.PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "source_code_len": 97,
        "target_code": "def create_key(\n    request: PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "target_code_len": 88,
        "diff_format": "@@ -14,3 +16,3 @@\n def create_key(\n-    request: requests.PreparedRequest,\n+    request: PreparedRequest,\n     ignored_params: Iterable[str] = None,\n",
        "source_code_with_indent": "def create_key(\n    request: requests.PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "def create_key(\n    request: PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    key = hashlib.sha256()\n    key.update(encode(request.method.upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_len": 135,
        "target_code": "    key = hashlib.sha256()\n    key.update(encode((request.method or '').upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "target_code_len": 143,
        "diff_format": "@@ -21,3 +23,3 @@\n     key = hashlib.sha256()\n-    key.update(encode(request.method.upper()))\n+    key.update(encode((request.method or '').upper()))\n     url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_with_indent": "    key = hashlib.sha256()\n    key.update(encode(request.method.upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    key = hashlib.sha256()\n    key.update(encode((request.method or '').upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def remove_ignored_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> requests.PreparedRequest:\n    if not ignored_params:\n",
        "source_code_len": 154,
        "target_code": "def remove_ignored_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> PreparedRequest:\n    if not ignored_params:\n",
        "target_code_len": 146,
        "diff_format": "@@ -38,4 +40,4 @@\n def remove_ignored_params(\n-    request: requests.PreparedRequest, ignored_params: Iterable[str]\n-) -> requests.PreparedRequest:\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n+) -> PreparedRequest:\n     if not ignored_params:\n",
        "source_code_with_indent": "<DED>def remove_ignored_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> requests.PreparedRequest:\n    <IND>if not ignored_params:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def remove_ignored_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> PreparedRequest:\n    <IND>if not ignored_params:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n    if not ignored_params:\n        return request.headers\n    headers = request.headers.copy()\n    headers.update({k: None for k in ignored_params})\n    return headers\n",
        "source_code_len": 271,
        "target_code": "\ndef remove_ignored_headers(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> CaseInsensitiveDict:\n    if not ignored_params:\n        return request.headers\n    headers = CaseInsensitiveDict(request.headers.copy())\n    for k in ignored_params:\n        headers.pop(k, None)\n    return headers\n",
        "target_code_len": 318,
        "diff_format": "@@ -48,7 +50,10 @@\n \n-def remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n+def remove_ignored_headers(\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n+) -> CaseInsensitiveDict:\n     if not ignored_params:\n         return request.headers\n-    headers = request.headers.copy()\n-    headers.update({k: None for k in ignored_params})\n+    headers = CaseInsensitiveDict(request.headers.copy())\n+    for k in ignored_params:\n+        headers.pop(k, None)\n     return headers\n",
        "source_code_with_indent": "\n<DED>def remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n    <IND>if not ignored_params:\n        <IND>return request.headers\n    <DED>headers = request.headers.copy()\n    headers.update({k: None for k in ignored_params})\n    return headers\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def remove_ignored_headers(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> CaseInsensitiveDict:\n    <IND>if not ignored_params:\n        <IND>return request.headers\n    <DED>headers = CaseInsensitiveDict(request.headers.copy())\n    for k in ignored_params:\n        <IND>headers.pop(k, None)\n    <DED>return headers\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n    url = str(request.url)\n    if not ignored_params:\n        return url\n\n    url = urlparse(url)\n    query = parse_qsl(url.query)\n    query = filter_params(query, ignored_params)\n    query = urlencode(query)\n    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n    return url\n\n",
        "source_code_len": 420,
        "target_code": "\ndef remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n    url_str = str(request.url)\n    if not ignored_params:\n        return url_str\n\n    url = urlparse(url_str)\n    query = filter_params(parse_qsl(url.query), ignored_params)\n    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n\n",
        "target_code_len": 383,
        "diff_format": "@@ -56,13 +61,10 @@\n \n-def remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n-    url = str(request.url)\n+def remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n+    url_str = str(request.url)\n     if not ignored_params:\n-        return url\n+        return url_str\n \n-    url = urlparse(url)\n-    query = parse_qsl(url.query)\n-    query = filter_params(query, ignored_params)\n-    query = urlencode(query)\n-    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n-    return url\n+    url = urlparse(url_str)\n+    query = filter_params(parse_qsl(url.query), ignored_params)\n+    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n \n",
        "source_code_with_indent": "\n<DED>def remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n    <IND>url = str(request.url)\n    if not ignored_params:\n        <IND>return url\n\n    <DED>url = urlparse(url)\n    query = parse_qsl(url.query)\n    query = filter_params(query, ignored_params)\n    query = urlencode(query)\n    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n    return url\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n    <IND>url_str = str(request.url)\n    if not ignored_params:\n        <IND>return url_str\n\n    <DED>url = urlparse(url_str)\n    query = filter_params(parse_qsl(url.query), ignored_params)\n    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "def remove_ignored_body_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> bytes:\n    body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not body or not content_type:\n        return encode(request.body)\n\n    if content_type == 'application/x-www-form-urlencoded':\n        body = parse_qsl(body)\n        body = filter_params(body, ignored_params)\n        body = urlencode(body)\n    elif content_type == 'application/json':\n        body = json.loads(decode(body))\n        body = filter_params(sorted(body.items()), ignored_params)\n        body = json.dumps(body)\n    return encode(body)\n\n\ndef filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n    return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_len": 824,
        "target_code": "def remove_ignored_body_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> bytes:\n    original_body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not original_body or not content_type:\n        return encode(original_body)\n\n    if content_type == 'application/x-www-form-urlencoded':\n        body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n        filtered_body = urlencode(body)\n    elif content_type == 'application/json':\n        body = json.loads(decode(original_body)).items()\n        body = filter_params(sorted(body), ignored_params)\n        filtered_body = json.dumps(body)\n    else:\n        filtered_body = original_body  # type: ignore\n\n    return encode(filtered_body)\n\n\ndef filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n    return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "target_code_len": 962,
        "diff_format": "@@ -70,21 +72,23 @@\n def remove_ignored_body_params(\n-    request: requests.PreparedRequest, ignored_params: Iterable[str]\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n ) -> bytes:\n-    body = request.body\n+    original_body = request.body\n     content_type = request.headers.get('content-type')\n-    if not ignored_params or not body or not content_type:\n-        return encode(request.body)\n+    if not ignored_params or not original_body or not content_type:\n+        return encode(original_body)\n \n     if content_type == 'application/x-www-form-urlencoded':\n-        body = parse_qsl(body)\n-        body = filter_params(body, ignored_params)\n-        body = urlencode(body)\n+        body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n+        filtered_body = urlencode(body)\n     elif content_type == 'application/json':\n-        body = json.loads(decode(body))\n-        body = filter_params(sorted(body.items()), ignored_params)\n-        body = json.dumps(body)\n-    return encode(body)\n+        body = json.loads(decode(original_body)).items()\n+        body = filter_params(sorted(body), ignored_params)\n+        filtered_body = json.dumps(body)\n+    else:\n+        filtered_body = original_body  # type: ignore\n+\n+    return encode(filtered_body)\n \n \n-def filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n+def filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n     return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_with_indent": "<DED>def remove_ignored_body_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> bytes:\n    <IND>body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not body or not content_type:\n        <IND>return encode(request.body)\n\n    <DED>if content_type == 'application/x-www-form-urlencoded':\n        <IND>body = parse_qsl(body)\n        body = filter_params(body, ignored_params)\n        body = urlencode(body)\n    <DED>elif content_type == 'application/json':\n        <IND>body = json.loads(decode(body))\n        body = filter_params(sorted(body.items()), ignored_params)\n        body = json.dumps(body)\n    <DED>return encode(body)\n\n\n<DED>def filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n    <IND>return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def remove_ignored_body_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> bytes:\n    <IND>original_body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not original_body or not content_type:\n        <IND>return encode(original_body)\n\n    <DED>if content_type == 'application/x-www-form-urlencoded':\n        <IND>body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n        filtered_body = urlencode(body)\n    <DED>elif content_type == 'application/json':\n        <IND>body = json.loads(decode(original_body)).items()\n        body = filter_params(sorted(body), ignored_params)\n        filtered_body = json.dumps(body)\n    <DED>else:\n        <IND>filtered_body = original_body  # type: ignore\n\n    <DED>return encode(filtered_body)\n\n\n<DED>def filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n    <IND>return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def url_to_key(url: str, *args, **kwargs) -> str:\n    request = requests.Session().prepare_request(requests.Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "source_code_len": 177,
        "target_code": "def url_to_key(url: str, *args, **kwargs) -> str:\n    request = Session().prepare_request(Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "target_code_len": 159,
        "diff_format": "@@ -118,3 +126,3 @@\n def url_to_key(url: str, *args, **kwargs) -> str:\n-    request = requests.Session().prepare_request(requests.Request('GET', url))\n+    request = Session().prepare_request(Request('GET', url))\n     return create_key(request, *args, **kwargs)\n",
        "source_code_with_indent": "<DED>def url_to_key(url: str, *args, **kwargs) -> str:\n    <IND>request = requests.Session().prepare_request(requests.Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def url_to_key(url: str, *args, **kwargs) -> str:\n    <IND>request = Session().prepare_request(Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "reclosedev/requests-cache",
    "commit": "6f54262b06a96b1019339e655b22c63f5882a632",
    "filename": "requests_cache/cache_keys.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/reclosedev-requests-cache/requests_cache/cache_keys.py",
    "file_hunks_size": 11,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "requests_cache/cache_keys.py:64:26 Incompatible parameter type [6]: Expected `List[typing.Tuple[typing.Any, ...]]` for 1st positional only parameter to call `filter_params` but got `List[Tuple[str, str]]`.",
    "message": " Expected `List[typing.Tuple[typing.Any, ...]]` for 1st positional only parameter to call `filter_params` but got `List[Tuple[str, str]]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 64,
    "warning_line": "    query = filter_params(query, ignored_params)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport requests\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = requests.utils.default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "source_code_len": 310,
        "target_code": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Optional, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nfrom requests import PreparedRequest, Request, Session\nfrom requests.models import CaseInsensitiveDict\nfrom requests.utils import default_headers\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "target_code_len": 435,
        "diff_format": "@@ -3,9 +3,11 @@\n from operator import itemgetter\n-from typing import Iterable, List, Mapping, Tuple, Union\n+from typing import Iterable, List, Mapping, Optional, Tuple, Union\n from urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n \n-import requests\n+from requests import PreparedRequest, Request, Session\n+from requests.models import CaseInsensitiveDict\n+from requests.utils import default_headers\n from url_normalize import url_normalize\n \n-DEFAULT_HEADERS = requests.utils.default_headers()\n+DEFAULT_HEADERS = default_headers()\n RequestContent = Union[Mapping, str, bytes]\n",
        "source_code_with_indent": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport requests\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = requests.utils.default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Optional, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nfrom requests import PreparedRequest, Request, Session\nfrom requests.models import CaseInsensitiveDict\nfrom requests.utils import default_headers\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def create_key(\n    request: requests.PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "source_code_len": 97,
        "target_code": "def create_key(\n    request: PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "target_code_len": 88,
        "diff_format": "@@ -14,3 +16,3 @@\n def create_key(\n-    request: requests.PreparedRequest,\n+    request: PreparedRequest,\n     ignored_params: Iterable[str] = None,\n",
        "source_code_with_indent": "def create_key(\n    request: requests.PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "def create_key(\n    request: PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    key = hashlib.sha256()\n    key.update(encode(request.method.upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_len": 135,
        "target_code": "    key = hashlib.sha256()\n    key.update(encode((request.method or '').upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "target_code_len": 143,
        "diff_format": "@@ -21,3 +23,3 @@\n     key = hashlib.sha256()\n-    key.update(encode(request.method.upper()))\n+    key.update(encode((request.method or '').upper()))\n     url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_with_indent": "    key = hashlib.sha256()\n    key.update(encode(request.method.upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    key = hashlib.sha256()\n    key.update(encode((request.method or '').upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def remove_ignored_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> requests.PreparedRequest:\n    if not ignored_params:\n",
        "source_code_len": 154,
        "target_code": "def remove_ignored_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> PreparedRequest:\n    if not ignored_params:\n",
        "target_code_len": 146,
        "diff_format": "@@ -38,4 +40,4 @@\n def remove_ignored_params(\n-    request: requests.PreparedRequest, ignored_params: Iterable[str]\n-) -> requests.PreparedRequest:\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n+) -> PreparedRequest:\n     if not ignored_params:\n",
        "source_code_with_indent": "<DED>def remove_ignored_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> requests.PreparedRequest:\n    <IND>if not ignored_params:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def remove_ignored_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> PreparedRequest:\n    <IND>if not ignored_params:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n    if not ignored_params:\n        return request.headers\n    headers = request.headers.copy()\n    headers.update({k: None for k in ignored_params})\n    return headers\n",
        "source_code_len": 271,
        "target_code": "\ndef remove_ignored_headers(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> CaseInsensitiveDict:\n    if not ignored_params:\n        return request.headers\n    headers = CaseInsensitiveDict(request.headers.copy())\n    for k in ignored_params:\n        headers.pop(k, None)\n    return headers\n",
        "target_code_len": 318,
        "diff_format": "@@ -48,7 +50,10 @@\n \n-def remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n+def remove_ignored_headers(\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n+) -> CaseInsensitiveDict:\n     if not ignored_params:\n         return request.headers\n-    headers = request.headers.copy()\n-    headers.update({k: None for k in ignored_params})\n+    headers = CaseInsensitiveDict(request.headers.copy())\n+    for k in ignored_params:\n+        headers.pop(k, None)\n     return headers\n",
        "source_code_with_indent": "\n<DED>def remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n    <IND>if not ignored_params:\n        <IND>return request.headers\n    <DED>headers = request.headers.copy()\n    headers.update({k: None for k in ignored_params})\n    return headers\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def remove_ignored_headers(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> CaseInsensitiveDict:\n    <IND>if not ignored_params:\n        <IND>return request.headers\n    <DED>headers = CaseInsensitiveDict(request.headers.copy())\n    for k in ignored_params:\n        <IND>headers.pop(k, None)\n    <DED>return headers\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n    url = str(request.url)\n    if not ignored_params:\n        return url\n\n    url = urlparse(url)\n    query = parse_qsl(url.query)\n    query = filter_params(query, ignored_params)\n    query = urlencode(query)\n    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n    return url\n\n",
        "source_code_len": 420,
        "target_code": "\ndef remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n    url_str = str(request.url)\n    if not ignored_params:\n        return url_str\n\n    url = urlparse(url_str)\n    query = filter_params(parse_qsl(url.query), ignored_params)\n    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n\n",
        "target_code_len": 383,
        "diff_format": "@@ -56,13 +61,10 @@\n \n-def remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n-    url = str(request.url)\n+def remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n+    url_str = str(request.url)\n     if not ignored_params:\n-        return url\n+        return url_str\n \n-    url = urlparse(url)\n-    query = parse_qsl(url.query)\n-    query = filter_params(query, ignored_params)\n-    query = urlencode(query)\n-    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n-    return url\n+    url = urlparse(url_str)\n+    query = filter_params(parse_qsl(url.query), ignored_params)\n+    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n \n",
        "source_code_with_indent": "\n<DED>def remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n    <IND>url = str(request.url)\n    if not ignored_params:\n        <IND>return url\n\n    <DED>url = urlparse(url)\n    query = parse_qsl(url.query)\n    query = filter_params(query, ignored_params)\n    query = urlencode(query)\n    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n    return url\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n    <IND>url_str = str(request.url)\n    if not ignored_params:\n        <IND>return url_str\n\n    <DED>url = urlparse(url_str)\n    query = filter_params(parse_qsl(url.query), ignored_params)\n    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "def remove_ignored_body_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> bytes:\n    body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not body or not content_type:\n        return encode(request.body)\n\n    if content_type == 'application/x-www-form-urlencoded':\n        body = parse_qsl(body)\n        body = filter_params(body, ignored_params)\n        body = urlencode(body)\n    elif content_type == 'application/json':\n        body = json.loads(decode(body))\n        body = filter_params(sorted(body.items()), ignored_params)\n        body = json.dumps(body)\n    return encode(body)\n\n\ndef filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n    return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_len": 824,
        "target_code": "def remove_ignored_body_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> bytes:\n    original_body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not original_body or not content_type:\n        return encode(original_body)\n\n    if content_type == 'application/x-www-form-urlencoded':\n        body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n        filtered_body = urlencode(body)\n    elif content_type == 'application/json':\n        body = json.loads(decode(original_body)).items()\n        body = filter_params(sorted(body), ignored_params)\n        filtered_body = json.dumps(body)\n    else:\n        filtered_body = original_body  # type: ignore\n\n    return encode(filtered_body)\n\n\ndef filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n    return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "target_code_len": 962,
        "diff_format": "@@ -70,21 +72,23 @@\n def remove_ignored_body_params(\n-    request: requests.PreparedRequest, ignored_params: Iterable[str]\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n ) -> bytes:\n-    body = request.body\n+    original_body = request.body\n     content_type = request.headers.get('content-type')\n-    if not ignored_params or not body or not content_type:\n-        return encode(request.body)\n+    if not ignored_params or not original_body or not content_type:\n+        return encode(original_body)\n \n     if content_type == 'application/x-www-form-urlencoded':\n-        body = parse_qsl(body)\n-        body = filter_params(body, ignored_params)\n-        body = urlencode(body)\n+        body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n+        filtered_body = urlencode(body)\n     elif content_type == 'application/json':\n-        body = json.loads(decode(body))\n-        body = filter_params(sorted(body.items()), ignored_params)\n-        body = json.dumps(body)\n-    return encode(body)\n+        body = json.loads(decode(original_body)).items()\n+        body = filter_params(sorted(body), ignored_params)\n+        filtered_body = json.dumps(body)\n+    else:\n+        filtered_body = original_body  # type: ignore\n+\n+    return encode(filtered_body)\n \n \n-def filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n+def filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n     return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_with_indent": "<DED>def remove_ignored_body_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> bytes:\n    <IND>body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not body or not content_type:\n        <IND>return encode(request.body)\n\n    <DED>if content_type == 'application/x-www-form-urlencoded':\n        <IND>body = parse_qsl(body)\n        body = filter_params(body, ignored_params)\n        body = urlencode(body)\n    <DED>elif content_type == 'application/json':\n        <IND>body = json.loads(decode(body))\n        body = filter_params(sorted(body.items()), ignored_params)\n        body = json.dumps(body)\n    <DED>return encode(body)\n\n\n<DED>def filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n    <IND>return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def remove_ignored_body_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> bytes:\n    <IND>original_body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not original_body or not content_type:\n        <IND>return encode(original_body)\n\n    <DED>if content_type == 'application/x-www-form-urlencoded':\n        <IND>body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n        filtered_body = urlencode(body)\n    <DED>elif content_type == 'application/json':\n        <IND>body = json.loads(decode(original_body)).items()\n        body = filter_params(sorted(body), ignored_params)\n        filtered_body = json.dumps(body)\n    <DED>else:\n        <IND>filtered_body = original_body  # type: ignore\n\n    <DED>return encode(filtered_body)\n\n\n<DED>def filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n    <IND>return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def url_to_key(url: str, *args, **kwargs) -> str:\n    request = requests.Session().prepare_request(requests.Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "source_code_len": 177,
        "target_code": "def url_to_key(url: str, *args, **kwargs) -> str:\n    request = Session().prepare_request(Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "target_code_len": 159,
        "diff_format": "@@ -118,3 +126,3 @@\n def url_to_key(url: str, *args, **kwargs) -> str:\n-    request = requests.Session().prepare_request(requests.Request('GET', url))\n+    request = Session().prepare_request(Request('GET', url))\n     return create_key(request, *args, **kwargs)\n",
        "source_code_with_indent": "<DED>def url_to_key(url: str, *args, **kwargs) -> str:\n    <IND>request = requests.Session().prepare_request(requests.Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def url_to_key(url: str, *args, **kwargs) -> str:\n    <IND>request = Session().prepare_request(Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "reclosedev/requests-cache",
    "commit": "6f54262b06a96b1019339e655b22c63f5882a632",
    "filename": "requests_cache/cache_keys.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/reclosedev-requests-cache/requests_cache/cache_keys.py",
    "file_hunks_size": 11,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "requests_cache/cache_keys.py:65:22 Incompatible parameter type [6]: Expected `Union[Mapping[typing.Any, typing.Any], Mapping[typing.Any, typing.Sequence[typing.Any]], typing.Sequence[Tuple[typing.Any, typing.Any]], typing.Sequence[Tuple[typing.Any, typing.Sequence[typing.Any]]]]` for 1st positional only parameter to call `urlencode` but got `List[typing.Tuple[typing.Any, ...]]`.",
    "message": " Expected `Union[Mapping[typing.Any, typing.Any], Mapping[typing.Any, typing.Sequence[typing.Any]], typing.Sequence[Tuple[typing.Any, typing.Any]], typing.Sequence[Tuple[typing.Any, typing.Sequence[typing.Any]]]]` for 1st positional only parameter to call `urlencode` but got `List[typing.Tuple[typing.Any, ...]]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 65,
    "warning_line": "    query = urlencode(query)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport requests\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = requests.utils.default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "source_code_len": 310,
        "target_code": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Optional, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nfrom requests import PreparedRequest, Request, Session\nfrom requests.models import CaseInsensitiveDict\nfrom requests.utils import default_headers\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "target_code_len": 435,
        "diff_format": "@@ -3,9 +3,11 @@\n from operator import itemgetter\n-from typing import Iterable, List, Mapping, Tuple, Union\n+from typing import Iterable, List, Mapping, Optional, Tuple, Union\n from urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n \n-import requests\n+from requests import PreparedRequest, Request, Session\n+from requests.models import CaseInsensitiveDict\n+from requests.utils import default_headers\n from url_normalize import url_normalize\n \n-DEFAULT_HEADERS = requests.utils.default_headers()\n+DEFAULT_HEADERS = default_headers()\n RequestContent = Union[Mapping, str, bytes]\n",
        "source_code_with_indent": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport requests\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = requests.utils.default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Optional, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nfrom requests import PreparedRequest, Request, Session\nfrom requests.models import CaseInsensitiveDict\nfrom requests.utils import default_headers\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def create_key(\n    request: requests.PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "source_code_len": 97,
        "target_code": "def create_key(\n    request: PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "target_code_len": 88,
        "diff_format": "@@ -14,3 +16,3 @@\n def create_key(\n-    request: requests.PreparedRequest,\n+    request: PreparedRequest,\n     ignored_params: Iterable[str] = None,\n",
        "source_code_with_indent": "def create_key(\n    request: requests.PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "def create_key(\n    request: PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    key = hashlib.sha256()\n    key.update(encode(request.method.upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_len": 135,
        "target_code": "    key = hashlib.sha256()\n    key.update(encode((request.method or '').upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "target_code_len": 143,
        "diff_format": "@@ -21,3 +23,3 @@\n     key = hashlib.sha256()\n-    key.update(encode(request.method.upper()))\n+    key.update(encode((request.method or '').upper()))\n     url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_with_indent": "    key = hashlib.sha256()\n    key.update(encode(request.method.upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    key = hashlib.sha256()\n    key.update(encode((request.method or '').upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def remove_ignored_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> requests.PreparedRequest:\n    if not ignored_params:\n",
        "source_code_len": 154,
        "target_code": "def remove_ignored_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> PreparedRequest:\n    if not ignored_params:\n",
        "target_code_len": 146,
        "diff_format": "@@ -38,4 +40,4 @@\n def remove_ignored_params(\n-    request: requests.PreparedRequest, ignored_params: Iterable[str]\n-) -> requests.PreparedRequest:\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n+) -> PreparedRequest:\n     if not ignored_params:\n",
        "source_code_with_indent": "<DED>def remove_ignored_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> requests.PreparedRequest:\n    <IND>if not ignored_params:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def remove_ignored_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> PreparedRequest:\n    <IND>if not ignored_params:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n    if not ignored_params:\n        return request.headers\n    headers = request.headers.copy()\n    headers.update({k: None for k in ignored_params})\n    return headers\n",
        "source_code_len": 271,
        "target_code": "\ndef remove_ignored_headers(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> CaseInsensitiveDict:\n    if not ignored_params:\n        return request.headers\n    headers = CaseInsensitiveDict(request.headers.copy())\n    for k in ignored_params:\n        headers.pop(k, None)\n    return headers\n",
        "target_code_len": 318,
        "diff_format": "@@ -48,7 +50,10 @@\n \n-def remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n+def remove_ignored_headers(\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n+) -> CaseInsensitiveDict:\n     if not ignored_params:\n         return request.headers\n-    headers = request.headers.copy()\n-    headers.update({k: None for k in ignored_params})\n+    headers = CaseInsensitiveDict(request.headers.copy())\n+    for k in ignored_params:\n+        headers.pop(k, None)\n     return headers\n",
        "source_code_with_indent": "\n<DED>def remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n    <IND>if not ignored_params:\n        <IND>return request.headers\n    <DED>headers = request.headers.copy()\n    headers.update({k: None for k in ignored_params})\n    return headers\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def remove_ignored_headers(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> CaseInsensitiveDict:\n    <IND>if not ignored_params:\n        <IND>return request.headers\n    <DED>headers = CaseInsensitiveDict(request.headers.copy())\n    for k in ignored_params:\n        <IND>headers.pop(k, None)\n    <DED>return headers\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n    url = str(request.url)\n    if not ignored_params:\n        return url\n\n    url = urlparse(url)\n    query = parse_qsl(url.query)\n    query = filter_params(query, ignored_params)\n    query = urlencode(query)\n    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n    return url\n\n",
        "source_code_len": 420,
        "target_code": "\ndef remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n    url_str = str(request.url)\n    if not ignored_params:\n        return url_str\n\n    url = urlparse(url_str)\n    query = filter_params(parse_qsl(url.query), ignored_params)\n    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n\n",
        "target_code_len": 383,
        "diff_format": "@@ -56,13 +61,10 @@\n \n-def remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n-    url = str(request.url)\n+def remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n+    url_str = str(request.url)\n     if not ignored_params:\n-        return url\n+        return url_str\n \n-    url = urlparse(url)\n-    query = parse_qsl(url.query)\n-    query = filter_params(query, ignored_params)\n-    query = urlencode(query)\n-    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n-    return url\n+    url = urlparse(url_str)\n+    query = filter_params(parse_qsl(url.query), ignored_params)\n+    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n \n",
        "source_code_with_indent": "\n<DED>def remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n    <IND>url = str(request.url)\n    if not ignored_params:\n        <IND>return url\n\n    <DED>url = urlparse(url)\n    query = parse_qsl(url.query)\n    query = filter_params(query, ignored_params)\n    query = urlencode(query)\n    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n    return url\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n    <IND>url_str = str(request.url)\n    if not ignored_params:\n        <IND>return url_str\n\n    <DED>url = urlparse(url_str)\n    query = filter_params(parse_qsl(url.query), ignored_params)\n    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "def remove_ignored_body_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> bytes:\n    body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not body or not content_type:\n        return encode(request.body)\n\n    if content_type == 'application/x-www-form-urlencoded':\n        body = parse_qsl(body)\n        body = filter_params(body, ignored_params)\n        body = urlencode(body)\n    elif content_type == 'application/json':\n        body = json.loads(decode(body))\n        body = filter_params(sorted(body.items()), ignored_params)\n        body = json.dumps(body)\n    return encode(body)\n\n\ndef filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n    return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_len": 824,
        "target_code": "def remove_ignored_body_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> bytes:\n    original_body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not original_body or not content_type:\n        return encode(original_body)\n\n    if content_type == 'application/x-www-form-urlencoded':\n        body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n        filtered_body = urlencode(body)\n    elif content_type == 'application/json':\n        body = json.loads(decode(original_body)).items()\n        body = filter_params(sorted(body), ignored_params)\n        filtered_body = json.dumps(body)\n    else:\n        filtered_body = original_body  # type: ignore\n\n    return encode(filtered_body)\n\n\ndef filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n    return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "target_code_len": 962,
        "diff_format": "@@ -70,21 +72,23 @@\n def remove_ignored_body_params(\n-    request: requests.PreparedRequest, ignored_params: Iterable[str]\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n ) -> bytes:\n-    body = request.body\n+    original_body = request.body\n     content_type = request.headers.get('content-type')\n-    if not ignored_params or not body or not content_type:\n-        return encode(request.body)\n+    if not ignored_params or not original_body or not content_type:\n+        return encode(original_body)\n \n     if content_type == 'application/x-www-form-urlencoded':\n-        body = parse_qsl(body)\n-        body = filter_params(body, ignored_params)\n-        body = urlencode(body)\n+        body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n+        filtered_body = urlencode(body)\n     elif content_type == 'application/json':\n-        body = json.loads(decode(body))\n-        body = filter_params(sorted(body.items()), ignored_params)\n-        body = json.dumps(body)\n-    return encode(body)\n+        body = json.loads(decode(original_body)).items()\n+        body = filter_params(sorted(body), ignored_params)\n+        filtered_body = json.dumps(body)\n+    else:\n+        filtered_body = original_body  # type: ignore\n+\n+    return encode(filtered_body)\n \n \n-def filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n+def filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n     return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_with_indent": "<DED>def remove_ignored_body_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> bytes:\n    <IND>body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not body or not content_type:\n        <IND>return encode(request.body)\n\n    <DED>if content_type == 'application/x-www-form-urlencoded':\n        <IND>body = parse_qsl(body)\n        body = filter_params(body, ignored_params)\n        body = urlencode(body)\n    <DED>elif content_type == 'application/json':\n        <IND>body = json.loads(decode(body))\n        body = filter_params(sorted(body.items()), ignored_params)\n        body = json.dumps(body)\n    <DED>return encode(body)\n\n\n<DED>def filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n    <IND>return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def remove_ignored_body_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> bytes:\n    <IND>original_body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not original_body or not content_type:\n        <IND>return encode(original_body)\n\n    <DED>if content_type == 'application/x-www-form-urlencoded':\n        <IND>body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n        filtered_body = urlencode(body)\n    <DED>elif content_type == 'application/json':\n        <IND>body = json.loads(decode(original_body)).items()\n        body = filter_params(sorted(body), ignored_params)\n        filtered_body = json.dumps(body)\n    <DED>else:\n        <IND>filtered_body = original_body  # type: ignore\n\n    <DED>return encode(filtered_body)\n\n\n<DED>def filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n    <IND>return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def url_to_key(url: str, *args, **kwargs) -> str:\n    request = requests.Session().prepare_request(requests.Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "source_code_len": 177,
        "target_code": "def url_to_key(url: str, *args, **kwargs) -> str:\n    request = Session().prepare_request(Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "target_code_len": 159,
        "diff_format": "@@ -118,3 +126,3 @@\n def url_to_key(url: str, *args, **kwargs) -> str:\n-    request = requests.Session().prepare_request(requests.Request('GET', url))\n+    request = Session().prepare_request(Request('GET', url))\n     return create_key(request, *args, **kwargs)\n",
        "source_code_with_indent": "<DED>def url_to_key(url: str, *args, **kwargs) -> str:\n    <IND>request = requests.Session().prepare_request(requests.Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def url_to_key(url: str, *args, **kwargs) -> str:\n    <IND>request = Session().prepare_request(Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "reclosedev/requests-cache",
    "commit": "6f54262b06a96b1019339e655b22c63f5882a632",
    "filename": "requests_cache/cache_keys.py",
    "min_patch_found": false,
    "full_warning_msg": "requests_cache/cache_keys.py:79:25 Incompatible parameter type [6]: Expected `typing.Optional[Variable[typing.AnyStr <: [str, bytes]]]` for 1st positional only parameter to call `parse_qsl` but got `Union[bytes, str]`.",
    "exception": "too many values to unpack (expected 2)",
    "dd_fail": true
  },
  {
    "project": "reclosedev/requests-cache",
    "commit": "6f54262b06a96b1019339e655b22c63f5882a632",
    "filename": "requests_cache/cache_keys.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/reclosedev-requests-cache/requests_cache/cache_keys.py",
    "file_hunks_size": 11,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "requests_cache/cache_keys.py:80:29 Incompatible parameter type [6]: Expected `List[typing.Tuple[typing.Any, ...]]` for 1st positional only parameter to call `filter_params` but got `List[Tuple[typing.Any, typing.Any]]`.",
    "message": " Expected `List[typing.Tuple[typing.Any, ...]]` for 1st positional only parameter to call `filter_params` but got `List[Tuple[typing.Any, typing.Any]]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 80,
    "warning_line": "        body = filter_params(body, ignored_params)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport requests\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = requests.utils.default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "source_code_len": 310,
        "target_code": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Optional, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nfrom requests import PreparedRequest, Request, Session\nfrom requests.models import CaseInsensitiveDict\nfrom requests.utils import default_headers\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "target_code_len": 435,
        "diff_format": "@@ -3,9 +3,11 @@\n from operator import itemgetter\n-from typing import Iterable, List, Mapping, Tuple, Union\n+from typing import Iterable, List, Mapping, Optional, Tuple, Union\n from urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n \n-import requests\n+from requests import PreparedRequest, Request, Session\n+from requests.models import CaseInsensitiveDict\n+from requests.utils import default_headers\n from url_normalize import url_normalize\n \n-DEFAULT_HEADERS = requests.utils.default_headers()\n+DEFAULT_HEADERS = default_headers()\n RequestContent = Union[Mapping, str, bytes]\n",
        "source_code_with_indent": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport requests\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = requests.utils.default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Optional, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nfrom requests import PreparedRequest, Request, Session\nfrom requests.models import CaseInsensitiveDict\nfrom requests.utils import default_headers\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def create_key(\n    request: requests.PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "source_code_len": 97,
        "target_code": "def create_key(\n    request: PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "target_code_len": 88,
        "diff_format": "@@ -14,3 +16,3 @@\n def create_key(\n-    request: requests.PreparedRequest,\n+    request: PreparedRequest,\n     ignored_params: Iterable[str] = None,\n",
        "source_code_with_indent": "def create_key(\n    request: requests.PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "def create_key(\n    request: PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    key = hashlib.sha256()\n    key.update(encode(request.method.upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_len": 135,
        "target_code": "    key = hashlib.sha256()\n    key.update(encode((request.method or '').upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "target_code_len": 143,
        "diff_format": "@@ -21,3 +23,3 @@\n     key = hashlib.sha256()\n-    key.update(encode(request.method.upper()))\n+    key.update(encode((request.method or '').upper()))\n     url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_with_indent": "    key = hashlib.sha256()\n    key.update(encode(request.method.upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    key = hashlib.sha256()\n    key.update(encode((request.method or '').upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def remove_ignored_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> requests.PreparedRequest:\n    if not ignored_params:\n",
        "source_code_len": 154,
        "target_code": "def remove_ignored_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> PreparedRequest:\n    if not ignored_params:\n",
        "target_code_len": 146,
        "diff_format": "@@ -38,4 +40,4 @@\n def remove_ignored_params(\n-    request: requests.PreparedRequest, ignored_params: Iterable[str]\n-) -> requests.PreparedRequest:\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n+) -> PreparedRequest:\n     if not ignored_params:\n",
        "source_code_with_indent": "<DED>def remove_ignored_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> requests.PreparedRequest:\n    <IND>if not ignored_params:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def remove_ignored_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> PreparedRequest:\n    <IND>if not ignored_params:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n    if not ignored_params:\n        return request.headers\n    headers = request.headers.copy()\n    headers.update({k: None for k in ignored_params})\n    return headers\n",
        "source_code_len": 271,
        "target_code": "\ndef remove_ignored_headers(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> CaseInsensitiveDict:\n    if not ignored_params:\n        return request.headers\n    headers = CaseInsensitiveDict(request.headers.copy())\n    for k in ignored_params:\n        headers.pop(k, None)\n    return headers\n",
        "target_code_len": 318,
        "diff_format": "@@ -48,7 +50,10 @@\n \n-def remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n+def remove_ignored_headers(\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n+) -> CaseInsensitiveDict:\n     if not ignored_params:\n         return request.headers\n-    headers = request.headers.copy()\n-    headers.update({k: None for k in ignored_params})\n+    headers = CaseInsensitiveDict(request.headers.copy())\n+    for k in ignored_params:\n+        headers.pop(k, None)\n     return headers\n",
        "source_code_with_indent": "\n<DED>def remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n    <IND>if not ignored_params:\n        <IND>return request.headers\n    <DED>headers = request.headers.copy()\n    headers.update({k: None for k in ignored_params})\n    return headers\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def remove_ignored_headers(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> CaseInsensitiveDict:\n    <IND>if not ignored_params:\n        <IND>return request.headers\n    <DED>headers = CaseInsensitiveDict(request.headers.copy())\n    for k in ignored_params:\n        <IND>headers.pop(k, None)\n    <DED>return headers\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n    url = str(request.url)\n    if not ignored_params:\n        return url\n\n    url = urlparse(url)\n    query = parse_qsl(url.query)\n    query = filter_params(query, ignored_params)\n    query = urlencode(query)\n    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n    return url\n\n",
        "source_code_len": 420,
        "target_code": "\ndef remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n    url_str = str(request.url)\n    if not ignored_params:\n        return url_str\n\n    url = urlparse(url_str)\n    query = filter_params(parse_qsl(url.query), ignored_params)\n    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n\n",
        "target_code_len": 383,
        "diff_format": "@@ -56,13 +61,10 @@\n \n-def remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n-    url = str(request.url)\n+def remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n+    url_str = str(request.url)\n     if not ignored_params:\n-        return url\n+        return url_str\n \n-    url = urlparse(url)\n-    query = parse_qsl(url.query)\n-    query = filter_params(query, ignored_params)\n-    query = urlencode(query)\n-    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n-    return url\n+    url = urlparse(url_str)\n+    query = filter_params(parse_qsl(url.query), ignored_params)\n+    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n \n",
        "source_code_with_indent": "\n<DED>def remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n    <IND>url = str(request.url)\n    if not ignored_params:\n        <IND>return url\n\n    <DED>url = urlparse(url)\n    query = parse_qsl(url.query)\n    query = filter_params(query, ignored_params)\n    query = urlencode(query)\n    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n    return url\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n    <IND>url_str = str(request.url)\n    if not ignored_params:\n        <IND>return url_str\n\n    <DED>url = urlparse(url_str)\n    query = filter_params(parse_qsl(url.query), ignored_params)\n    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "def remove_ignored_body_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> bytes:\n    body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not body or not content_type:\n        return encode(request.body)\n\n    if content_type == 'application/x-www-form-urlencoded':\n        body = parse_qsl(body)\n        body = filter_params(body, ignored_params)\n        body = urlencode(body)\n    elif content_type == 'application/json':\n        body = json.loads(decode(body))\n        body = filter_params(sorted(body.items()), ignored_params)\n        body = json.dumps(body)\n    return encode(body)\n\n\ndef filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n    return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_len": 824,
        "target_code": "def remove_ignored_body_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> bytes:\n    original_body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not original_body or not content_type:\n        return encode(original_body)\n\n    if content_type == 'application/x-www-form-urlencoded':\n        body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n        filtered_body = urlencode(body)\n    elif content_type == 'application/json':\n        body = json.loads(decode(original_body)).items()\n        body = filter_params(sorted(body), ignored_params)\n        filtered_body = json.dumps(body)\n    else:\n        filtered_body = original_body  # type: ignore\n\n    return encode(filtered_body)\n\n\ndef filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n    return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "target_code_len": 962,
        "diff_format": "@@ -70,21 +72,23 @@\n def remove_ignored_body_params(\n-    request: requests.PreparedRequest, ignored_params: Iterable[str]\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n ) -> bytes:\n-    body = request.body\n+    original_body = request.body\n     content_type = request.headers.get('content-type')\n-    if not ignored_params or not body or not content_type:\n-        return encode(request.body)\n+    if not ignored_params or not original_body or not content_type:\n+        return encode(original_body)\n \n     if content_type == 'application/x-www-form-urlencoded':\n-        body = parse_qsl(body)\n-        body = filter_params(body, ignored_params)\n-        body = urlencode(body)\n+        body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n+        filtered_body = urlencode(body)\n     elif content_type == 'application/json':\n-        body = json.loads(decode(body))\n-        body = filter_params(sorted(body.items()), ignored_params)\n-        body = json.dumps(body)\n-    return encode(body)\n+        body = json.loads(decode(original_body)).items()\n+        body = filter_params(sorted(body), ignored_params)\n+        filtered_body = json.dumps(body)\n+    else:\n+        filtered_body = original_body  # type: ignore\n+\n+    return encode(filtered_body)\n \n \n-def filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n+def filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n     return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_with_indent": "<DED>def remove_ignored_body_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> bytes:\n    <IND>body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not body or not content_type:\n        <IND>return encode(request.body)\n\n    <DED>if content_type == 'application/x-www-form-urlencoded':\n        <IND>body = parse_qsl(body)\n        body = filter_params(body, ignored_params)\n        body = urlencode(body)\n    <DED>elif content_type == 'application/json':\n        <IND>body = json.loads(decode(body))\n        body = filter_params(sorted(body.items()), ignored_params)\n        body = json.dumps(body)\n    <DED>return encode(body)\n\n\n<DED>def filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n    <IND>return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def remove_ignored_body_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> bytes:\n    <IND>original_body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not original_body or not content_type:\n        <IND>return encode(original_body)\n\n    <DED>if content_type == 'application/x-www-form-urlencoded':\n        <IND>body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n        filtered_body = urlencode(body)\n    <DED>elif content_type == 'application/json':\n        <IND>body = json.loads(decode(original_body)).items()\n        body = filter_params(sorted(body), ignored_params)\n        filtered_body = json.dumps(body)\n    <DED>else:\n        <IND>filtered_body = original_body  # type: ignore\n\n    <DED>return encode(filtered_body)\n\n\n<DED>def filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n    <IND>return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def url_to_key(url: str, *args, **kwargs) -> str:\n    request = requests.Session().prepare_request(requests.Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "source_code_len": 177,
        "target_code": "def url_to_key(url: str, *args, **kwargs) -> str:\n    request = Session().prepare_request(Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "target_code_len": 159,
        "diff_format": "@@ -118,3 +126,3 @@\n def url_to_key(url: str, *args, **kwargs) -> str:\n-    request = requests.Session().prepare_request(requests.Request('GET', url))\n+    request = Session().prepare_request(Request('GET', url))\n     return create_key(request, *args, **kwargs)\n",
        "source_code_with_indent": "<DED>def url_to_key(url: str, *args, **kwargs) -> str:\n    <IND>request = requests.Session().prepare_request(requests.Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def url_to_key(url: str, *args, **kwargs) -> str:\n    <IND>request = Session().prepare_request(Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "reclosedev/requests-cache",
    "commit": "6f54262b06a96b1019339e655b22c63f5882a632",
    "filename": "requests_cache/cache_keys.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/reclosedev-requests-cache/requests_cache/cache_keys.py",
    "file_hunks_size": 11,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "requests_cache/cache_keys.py:81:25 Incompatible parameter type [6]: Expected `Union[Mapping[typing.Any, typing.Any], Mapping[typing.Any, typing.Sequence[typing.Any]], typing.Sequence[Tuple[typing.Any, typing.Any]], typing.Sequence[Tuple[typing.Any, typing.Sequence[typing.Any]]]]` for 1st positional only parameter to call `urlencode` but got `List[typing.Tuple[typing.Any, ...]]`.",
    "message": " Expected `Union[Mapping[typing.Any, typing.Any], Mapping[typing.Any, typing.Sequence[typing.Any]], typing.Sequence[Tuple[typing.Any, typing.Any]], typing.Sequence[Tuple[typing.Any, typing.Sequence[typing.Any]]]]` for 1st positional only parameter to call `urlencode` but got `List[typing.Tuple[typing.Any, ...]]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 81,
    "warning_line": "        body = urlencode(body)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport requests\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = requests.utils.default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "source_code_len": 310,
        "target_code": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Optional, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nfrom requests import PreparedRequest, Request, Session\nfrom requests.models import CaseInsensitiveDict\nfrom requests.utils import default_headers\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "target_code_len": 435,
        "diff_format": "@@ -3,9 +3,11 @@\n from operator import itemgetter\n-from typing import Iterable, List, Mapping, Tuple, Union\n+from typing import Iterable, List, Mapping, Optional, Tuple, Union\n from urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n \n-import requests\n+from requests import PreparedRequest, Request, Session\n+from requests.models import CaseInsensitiveDict\n+from requests.utils import default_headers\n from url_normalize import url_normalize\n \n-DEFAULT_HEADERS = requests.utils.default_headers()\n+DEFAULT_HEADERS = default_headers()\n RequestContent = Union[Mapping, str, bytes]\n",
        "source_code_with_indent": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport requests\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = requests.utils.default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Optional, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nfrom requests import PreparedRequest, Request, Session\nfrom requests.models import CaseInsensitiveDict\nfrom requests.utils import default_headers\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def create_key(\n    request: requests.PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "source_code_len": 97,
        "target_code": "def create_key(\n    request: PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "target_code_len": 88,
        "diff_format": "@@ -14,3 +16,3 @@\n def create_key(\n-    request: requests.PreparedRequest,\n+    request: PreparedRequest,\n     ignored_params: Iterable[str] = None,\n",
        "source_code_with_indent": "def create_key(\n    request: requests.PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "def create_key(\n    request: PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    key = hashlib.sha256()\n    key.update(encode(request.method.upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_len": 135,
        "target_code": "    key = hashlib.sha256()\n    key.update(encode((request.method or '').upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "target_code_len": 143,
        "diff_format": "@@ -21,3 +23,3 @@\n     key = hashlib.sha256()\n-    key.update(encode(request.method.upper()))\n+    key.update(encode((request.method or '').upper()))\n     url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_with_indent": "    key = hashlib.sha256()\n    key.update(encode(request.method.upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    key = hashlib.sha256()\n    key.update(encode((request.method or '').upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def remove_ignored_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> requests.PreparedRequest:\n    if not ignored_params:\n",
        "source_code_len": 154,
        "target_code": "def remove_ignored_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> PreparedRequest:\n    if not ignored_params:\n",
        "target_code_len": 146,
        "diff_format": "@@ -38,4 +40,4 @@\n def remove_ignored_params(\n-    request: requests.PreparedRequest, ignored_params: Iterable[str]\n-) -> requests.PreparedRequest:\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n+) -> PreparedRequest:\n     if not ignored_params:\n",
        "source_code_with_indent": "<DED>def remove_ignored_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> requests.PreparedRequest:\n    <IND>if not ignored_params:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def remove_ignored_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> PreparedRequest:\n    <IND>if not ignored_params:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n    if not ignored_params:\n        return request.headers\n    headers = request.headers.copy()\n    headers.update({k: None for k in ignored_params})\n    return headers\n",
        "source_code_len": 271,
        "target_code": "\ndef remove_ignored_headers(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> CaseInsensitiveDict:\n    if not ignored_params:\n        return request.headers\n    headers = CaseInsensitiveDict(request.headers.copy())\n    for k in ignored_params:\n        headers.pop(k, None)\n    return headers\n",
        "target_code_len": 318,
        "diff_format": "@@ -48,7 +50,10 @@\n \n-def remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n+def remove_ignored_headers(\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n+) -> CaseInsensitiveDict:\n     if not ignored_params:\n         return request.headers\n-    headers = request.headers.copy()\n-    headers.update({k: None for k in ignored_params})\n+    headers = CaseInsensitiveDict(request.headers.copy())\n+    for k in ignored_params:\n+        headers.pop(k, None)\n     return headers\n",
        "source_code_with_indent": "\n<DED>def remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n    <IND>if not ignored_params:\n        <IND>return request.headers\n    <DED>headers = request.headers.copy()\n    headers.update({k: None for k in ignored_params})\n    return headers\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def remove_ignored_headers(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> CaseInsensitiveDict:\n    <IND>if not ignored_params:\n        <IND>return request.headers\n    <DED>headers = CaseInsensitiveDict(request.headers.copy())\n    for k in ignored_params:\n        <IND>headers.pop(k, None)\n    <DED>return headers\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n    url = str(request.url)\n    if not ignored_params:\n        return url\n\n    url = urlparse(url)\n    query = parse_qsl(url.query)\n    query = filter_params(query, ignored_params)\n    query = urlencode(query)\n    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n    return url\n\n",
        "source_code_len": 420,
        "target_code": "\ndef remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n    url_str = str(request.url)\n    if not ignored_params:\n        return url_str\n\n    url = urlparse(url_str)\n    query = filter_params(parse_qsl(url.query), ignored_params)\n    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n\n",
        "target_code_len": 383,
        "diff_format": "@@ -56,13 +61,10 @@\n \n-def remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n-    url = str(request.url)\n+def remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n+    url_str = str(request.url)\n     if not ignored_params:\n-        return url\n+        return url_str\n \n-    url = urlparse(url)\n-    query = parse_qsl(url.query)\n-    query = filter_params(query, ignored_params)\n-    query = urlencode(query)\n-    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n-    return url\n+    url = urlparse(url_str)\n+    query = filter_params(parse_qsl(url.query), ignored_params)\n+    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n \n",
        "source_code_with_indent": "\n<DED>def remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n    <IND>url = str(request.url)\n    if not ignored_params:\n        <IND>return url\n\n    <DED>url = urlparse(url)\n    query = parse_qsl(url.query)\n    query = filter_params(query, ignored_params)\n    query = urlencode(query)\n    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n    return url\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n    <IND>url_str = str(request.url)\n    if not ignored_params:\n        <IND>return url_str\n\n    <DED>url = urlparse(url_str)\n    query = filter_params(parse_qsl(url.query), ignored_params)\n    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "def remove_ignored_body_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> bytes:\n    body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not body or not content_type:\n        return encode(request.body)\n\n    if content_type == 'application/x-www-form-urlencoded':\n        body = parse_qsl(body)\n        body = filter_params(body, ignored_params)\n        body = urlencode(body)\n    elif content_type == 'application/json':\n        body = json.loads(decode(body))\n        body = filter_params(sorted(body.items()), ignored_params)\n        body = json.dumps(body)\n    return encode(body)\n\n\ndef filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n    return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_len": 824,
        "target_code": "def remove_ignored_body_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> bytes:\n    original_body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not original_body or not content_type:\n        return encode(original_body)\n\n    if content_type == 'application/x-www-form-urlencoded':\n        body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n        filtered_body = urlencode(body)\n    elif content_type == 'application/json':\n        body = json.loads(decode(original_body)).items()\n        body = filter_params(sorted(body), ignored_params)\n        filtered_body = json.dumps(body)\n    else:\n        filtered_body = original_body  # type: ignore\n\n    return encode(filtered_body)\n\n\ndef filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n    return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "target_code_len": 962,
        "diff_format": "@@ -70,21 +72,23 @@\n def remove_ignored_body_params(\n-    request: requests.PreparedRequest, ignored_params: Iterable[str]\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n ) -> bytes:\n-    body = request.body\n+    original_body = request.body\n     content_type = request.headers.get('content-type')\n-    if not ignored_params or not body or not content_type:\n-        return encode(request.body)\n+    if not ignored_params or not original_body or not content_type:\n+        return encode(original_body)\n \n     if content_type == 'application/x-www-form-urlencoded':\n-        body = parse_qsl(body)\n-        body = filter_params(body, ignored_params)\n-        body = urlencode(body)\n+        body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n+        filtered_body = urlencode(body)\n     elif content_type == 'application/json':\n-        body = json.loads(decode(body))\n-        body = filter_params(sorted(body.items()), ignored_params)\n-        body = json.dumps(body)\n-    return encode(body)\n+        body = json.loads(decode(original_body)).items()\n+        body = filter_params(sorted(body), ignored_params)\n+        filtered_body = json.dumps(body)\n+    else:\n+        filtered_body = original_body  # type: ignore\n+\n+    return encode(filtered_body)\n \n \n-def filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n+def filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n     return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_with_indent": "<DED>def remove_ignored_body_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> bytes:\n    <IND>body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not body or not content_type:\n        <IND>return encode(request.body)\n\n    <DED>if content_type == 'application/x-www-form-urlencoded':\n        <IND>body = parse_qsl(body)\n        body = filter_params(body, ignored_params)\n        body = urlencode(body)\n    <DED>elif content_type == 'application/json':\n        <IND>body = json.loads(decode(body))\n        body = filter_params(sorted(body.items()), ignored_params)\n        body = json.dumps(body)\n    <DED>return encode(body)\n\n\n<DED>def filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n    <IND>return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def remove_ignored_body_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> bytes:\n    <IND>original_body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not original_body or not content_type:\n        <IND>return encode(original_body)\n\n    <DED>if content_type == 'application/x-www-form-urlencoded':\n        <IND>body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n        filtered_body = urlencode(body)\n    <DED>elif content_type == 'application/json':\n        <IND>body = json.loads(decode(original_body)).items()\n        body = filter_params(sorted(body), ignored_params)\n        filtered_body = json.dumps(body)\n    <DED>else:\n        <IND>filtered_body = original_body  # type: ignore\n\n    <DED>return encode(filtered_body)\n\n\n<DED>def filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n    <IND>return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def url_to_key(url: str, *args, **kwargs) -> str:\n    request = requests.Session().prepare_request(requests.Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "source_code_len": 177,
        "target_code": "def url_to_key(url: str, *args, **kwargs) -> str:\n    request = Session().prepare_request(Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "target_code_len": 159,
        "diff_format": "@@ -118,3 +126,3 @@\n def url_to_key(url: str, *args, **kwargs) -> str:\n-    request = requests.Session().prepare_request(requests.Request('GET', url))\n+    request = Session().prepare_request(Request('GET', url))\n     return create_key(request, *args, **kwargs)\n",
        "source_code_with_indent": "<DED>def url_to_key(url: str, *args, **kwargs) -> str:\n    <IND>request = requests.Session().prepare_request(requests.Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def url_to_key(url: str, *args, **kwargs) -> str:\n    <IND>request = Session().prepare_request(Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "reclosedev/requests-cache",
    "commit": "6f54262b06a96b1019339e655b22c63f5882a632",
    "filename": "requests_cache/cache_keys.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/reclosedev-requests-cache/requests_cache/cache_keys.py",
    "file_hunks_size": 11,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "requests_cache/cache_keys.py:93:19 Incompatible variable type [9]: items is declared to have type `Union[Mapping[typing.Any, typing.Any], bytes, str]` but is used as type `None`.",
    "message": " items is declared to have type `Union[Mapping[typing.Any, typing.Any], bytes, str]` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 93,
    "warning_line": "def normalize_dict(items: RequestContent = None, normalize_data: bool = True) -> RequestContent:",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport requests\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = requests.utils.default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "source_code_len": 310,
        "target_code": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Optional, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nfrom requests import PreparedRequest, Request, Session\nfrom requests.models import CaseInsensitiveDict\nfrom requests.utils import default_headers\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "target_code_len": 435,
        "diff_format": "@@ -3,9 +3,11 @@\n from operator import itemgetter\n-from typing import Iterable, List, Mapping, Tuple, Union\n+from typing import Iterable, List, Mapping, Optional, Tuple, Union\n from urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n \n-import requests\n+from requests import PreparedRequest, Request, Session\n+from requests.models import CaseInsensitiveDict\n+from requests.utils import default_headers\n from url_normalize import url_normalize\n \n-DEFAULT_HEADERS = requests.utils.default_headers()\n+DEFAULT_HEADERS = default_headers()\n RequestContent = Union[Mapping, str, bytes]\n",
        "source_code_with_indent": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport requests\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = requests.utils.default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from operator import itemgetter\nfrom typing import Iterable, List, Mapping, Optional, Tuple, Union\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nfrom requests import PreparedRequest, Request, Session\nfrom requests.models import CaseInsensitiveDict\nfrom requests.utils import default_headers\nfrom url_normalize import url_normalize\n\nDEFAULT_HEADERS = default_headers()\nRequestContent = Union[Mapping, str, bytes]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def create_key(\n    request: requests.PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "source_code_len": 97,
        "target_code": "def create_key(\n    request: PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "target_code_len": 88,
        "diff_format": "@@ -14,3 +16,3 @@\n def create_key(\n-    request: requests.PreparedRequest,\n+    request: PreparedRequest,\n     ignored_params: Iterable[str] = None,\n",
        "source_code_with_indent": "def create_key(\n    request: requests.PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "def create_key(\n    request: PreparedRequest,\n    ignored_params: Iterable[str] = None,\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    key = hashlib.sha256()\n    key.update(encode(request.method.upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_len": 135,
        "target_code": "    key = hashlib.sha256()\n    key.update(encode((request.method or '').upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "target_code_len": 143,
        "diff_format": "@@ -21,3 +23,3 @@\n     key = hashlib.sha256()\n-    key.update(encode(request.method.upper()))\n+    key.update(encode((request.method or '').upper()))\n     url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_with_indent": "    key = hashlib.sha256()\n    key.update(encode(request.method.upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    key = hashlib.sha256()\n    key.update(encode((request.method or '').upper()))\n    url = remove_ignored_url_params(request, ignored_params)\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "    if include_get_headers and request.headers != DEFAULT_HEADERS:\n        for name, value in normalize_dict(request.headers).items():\n            key.update(encode(f'{name}={value}'))\n",
        "source_code_len": 185,
        "target_code": "    if include_get_headers and request.headers != DEFAULT_HEADERS:\n        for name, value in normalize_dict(request.headers).items():  # type: ignore\n            key.update(encode(f'{name}={value}'))\n",
        "target_code_len": 201,
        "diff_format": "@@ -31,3 +33,3 @@\n     if include_get_headers and request.headers != DEFAULT_HEADERS:\n-        for name, value in normalize_dict(request.headers).items():\n+        for name, value in normalize_dict(request.headers).items():  # type: ignore\n             key.update(encode(f'{name}={value}'))\n",
        "source_code_with_indent": "    <DED>if include_get_headers and request.headers != DEFAULT_HEADERS:\n        <IND>for name, value in normalize_dict(request.headers).items():\n            <IND>key.update(encode(f'{name}={value}'))\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED>if include_get_headers and request.headers != DEFAULT_HEADERS:\n        <IND>for name, value in normalize_dict(request.headers).items():  # type: ignore\n            <IND>key.update(encode(f'{name}={value}'))\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def remove_ignored_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> requests.PreparedRequest:\n    if not ignored_params:\n",
        "source_code_len": 154,
        "target_code": "def remove_ignored_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> PreparedRequest:\n    if not ignored_params:\n",
        "target_code_len": 146,
        "diff_format": "@@ -38,4 +40,4 @@\n def remove_ignored_params(\n-    request: requests.PreparedRequest, ignored_params: Iterable[str]\n-) -> requests.PreparedRequest:\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n+) -> PreparedRequest:\n     if not ignored_params:\n",
        "source_code_with_indent": "<DED>def remove_ignored_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> requests.PreparedRequest:\n    <IND>if not ignored_params:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def remove_ignored_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> PreparedRequest:\n    <IND>if not ignored_params:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n    if not ignored_params:\n        return request.headers\n    headers = request.headers.copy()\n    headers.update({k: None for k in ignored_params})\n    return headers\n",
        "source_code_len": 271,
        "target_code": "\ndef remove_ignored_headers(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> CaseInsensitiveDict:\n    if not ignored_params:\n        return request.headers\n    headers = CaseInsensitiveDict(request.headers.copy())\n    for k in ignored_params:\n        headers.pop(k, None)\n    return headers\n",
        "target_code_len": 318,
        "diff_format": "@@ -48,7 +50,10 @@\n \n-def remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n+def remove_ignored_headers(\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n+) -> CaseInsensitiveDict:\n     if not ignored_params:\n         return request.headers\n-    headers = request.headers.copy()\n-    headers.update({k: None for k in ignored_params})\n+    headers = CaseInsensitiveDict(request.headers.copy())\n+    for k in ignored_params:\n+        headers.pop(k, None)\n     return headers\n",
        "source_code_with_indent": "\n<DED>def remove_ignored_headers(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> dict:\n    <IND>if not ignored_params:\n        <IND>return request.headers\n    <DED>headers = request.headers.copy()\n    headers.update({k: None for k in ignored_params})\n    return headers\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def remove_ignored_headers(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> CaseInsensitiveDict:\n    <IND>if not ignored_params:\n        <IND>return request.headers\n    <DED>headers = CaseInsensitiveDict(request.headers.copy())\n    for k in ignored_params:\n        <IND>headers.pop(k, None)\n    <DED>return headers\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n    url = str(request.url)\n    if not ignored_params:\n        return url\n\n    url = urlparse(url)\n    query = parse_qsl(url.query)\n    query = filter_params(query, ignored_params)\n    query = urlencode(query)\n    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n    return url\n\n",
        "source_code_len": 420,
        "target_code": "\ndef remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n    url_str = str(request.url)\n    if not ignored_params:\n        return url_str\n\n    url = urlparse(url_str)\n    query = filter_params(parse_qsl(url.query), ignored_params)\n    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n\n",
        "target_code_len": 383,
        "diff_format": "@@ -56,13 +61,10 @@\n \n-def remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n-    url = str(request.url)\n+def remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n+    url_str = str(request.url)\n     if not ignored_params:\n-        return url\n+        return url_str\n \n-    url = urlparse(url)\n-    query = parse_qsl(url.query)\n-    query = filter_params(query, ignored_params)\n-    query = urlencode(query)\n-    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n-    return url\n+    url = urlparse(url_str)\n+    query = filter_params(parse_qsl(url.query), ignored_params)\n+    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n \n",
        "source_code_with_indent": "\n<DED>def remove_ignored_url_params(request: requests.PreparedRequest, ignored_params: Iterable[str]) -> str:\n    <IND>url = str(request.url)\n    if not ignored_params:\n        <IND>return url\n\n    <DED>url = urlparse(url)\n    query = parse_qsl(url.query)\n    query = filter_params(query, ignored_params)\n    query = urlencode(query)\n    url = urlunparse((url.scheme, url.netloc, url.path, url.params, query, url.fragment))\n    return url\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def remove_ignored_url_params(request: PreparedRequest, ignored_params: Optional[Iterable[str]]) -> str:\n    <IND>url_str = str(request.url)\n    if not ignored_params:\n        <IND>return url_str\n\n    <DED>url = urlparse(url_str)\n    query = filter_params(parse_qsl(url.query), ignored_params)\n    return urlunparse((url.scheme, url.netloc, url.path, url.params, urlencode(query), url.fragment))\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "def remove_ignored_body_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> bytes:\n    body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not body or not content_type:\n        return encode(request.body)\n\n    if content_type == 'application/x-www-form-urlencoded':\n        body = parse_qsl(body)\n        body = filter_params(body, ignored_params)\n        body = urlencode(body)\n    elif content_type == 'application/json':\n        body = json.loads(decode(body))\n        body = filter_params(sorted(body.items()), ignored_params)\n        body = json.dumps(body)\n    return encode(body)\n\n\ndef filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n    return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_len": 824,
        "target_code": "def remove_ignored_body_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> bytes:\n    original_body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not original_body or not content_type:\n        return encode(original_body)\n\n    if content_type == 'application/x-www-form-urlencoded':\n        body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n        filtered_body = urlencode(body)\n    elif content_type == 'application/json':\n        body = json.loads(decode(original_body)).items()\n        body = filter_params(sorted(body), ignored_params)\n        filtered_body = json.dumps(body)\n    else:\n        filtered_body = original_body  # type: ignore\n\n    return encode(filtered_body)\n\n\ndef filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n    return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "target_code_len": 962,
        "diff_format": "@@ -70,21 +72,23 @@\n def remove_ignored_body_params(\n-    request: requests.PreparedRequest, ignored_params: Iterable[str]\n+    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n ) -> bytes:\n-    body = request.body\n+    original_body = request.body\n     content_type = request.headers.get('content-type')\n-    if not ignored_params or not body or not content_type:\n-        return encode(request.body)\n+    if not ignored_params or not original_body or not content_type:\n+        return encode(original_body)\n \n     if content_type == 'application/x-www-form-urlencoded':\n-        body = parse_qsl(body)\n-        body = filter_params(body, ignored_params)\n-        body = urlencode(body)\n+        body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n+        filtered_body = urlencode(body)\n     elif content_type == 'application/json':\n-        body = json.loads(decode(body))\n-        body = filter_params(sorted(body.items()), ignored_params)\n-        body = json.dumps(body)\n-    return encode(body)\n+        body = json.loads(decode(original_body)).items()\n+        body = filter_params(sorted(body), ignored_params)\n+        filtered_body = json.dumps(body)\n+    else:\n+        filtered_body = original_body  # type: ignore\n+\n+    return encode(filtered_body)\n \n \n-def filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n+def filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n     return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_with_indent": "<DED>def remove_ignored_body_params(\n    request: requests.PreparedRequest, ignored_params: Iterable[str]\n) -> bytes:\n    <IND>body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not body or not content_type:\n        <IND>return encode(request.body)\n\n    <DED>if content_type == 'application/x-www-form-urlencoded':\n        <IND>body = parse_qsl(body)\n        body = filter_params(body, ignored_params)\n        body = urlencode(body)\n    <DED>elif content_type == 'application/json':\n        <IND>body = json.loads(decode(body))\n        body = filter_params(sorted(body.items()), ignored_params)\n        body = json.dumps(body)\n    <DED>return encode(body)\n\n\n<DED>def filter_params(data: List[Tuple], ignored_params: Iterable[str]) -> List[Tuple]:\n    <IND>return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def remove_ignored_body_params(\n    request: PreparedRequest, ignored_params: Optional[Iterable[str]]\n) -> bytes:\n    <IND>original_body = request.body\n    content_type = request.headers.get('content-type')\n    if not ignored_params or not original_body or not content_type:\n        <IND>return encode(original_body)\n\n    <DED>if content_type == 'application/x-www-form-urlencoded':\n        <IND>body = filter_params(parse_qsl(decode(original_body)), ignored_params)\n        filtered_body = urlencode(body)\n    <DED>elif content_type == 'application/json':\n        <IND>body = json.loads(decode(original_body)).items()\n        body = filter_params(sorted(body), ignored_params)\n        filtered_body = json.dumps(body)\n    <DED>else:\n        <IND>filtered_body = original_body  # type: ignore\n\n    <DED>return encode(filtered_body)\n\n\n<DED>def filter_params(data: List[Tuple[str, str]], ignored_params: Iterable[str]) -> List[Tuple[str, str]]:\n    <IND>return [(k, v) for k, v in data if k not in set(ignored_params)]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef normalize_dict(items: RequestContent = None, normalize_data: bool = True) -> RequestContent:\n    \"\"\"Sort items in a dict\n",
        "source_code_len": 126,
        "target_code": "\ndef normalize_dict(\n    items: Optional[RequestContent], normalize_data: bool = True\n) -> Optional[RequestContent]:\n    \"\"\"Sort items in a dict\n",
        "target_code_len": 145,
        "diff_format": "@@ -92,3 +96,5 @@\n \n-def normalize_dict(items: RequestContent = None, normalize_data: bool = True) -> RequestContent:\n+def normalize_dict(\n+    items: Optional[RequestContent], normalize_data: bool = True\n+) -> Optional[RequestContent]:\n     \"\"\"Sort items in a dict\n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "\n<DED>def normalize_dict(items: RequestContent = None, normalize_data: bool = True) -> RequestContent:\n    <IND>",
        "target_code_with_indent": "\n<DED>def normalize_dict(\n    items: Optional[RequestContent], normalize_data: bool = True\n) -> Optional[RequestContent]:\n    <IND>"
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def url_to_key(url: str, *args, **kwargs) -> str:\n    request = requests.Session().prepare_request(requests.Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "source_code_len": 177,
        "target_code": "def url_to_key(url: str, *args, **kwargs) -> str:\n    request = Session().prepare_request(Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "target_code_len": 159,
        "diff_format": "@@ -118,3 +126,3 @@\n def url_to_key(url: str, *args, **kwargs) -> str:\n-    request = requests.Session().prepare_request(requests.Request('GET', url))\n+    request = Session().prepare_request(Request('GET', url))\n     return create_key(request, *args, **kwargs)\n",
        "source_code_with_indent": "<DED>def url_to_key(url: str, *args, **kwargs) -> str:\n    <IND>request = requests.Session().prepare_request(requests.Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "<DED>def url_to_key(url: str, *args, **kwargs) -> str:\n    <IND>request = Session().prepare_request(Request('GET', url))\n    return create_key(request, *args, **kwargs)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "reclosedev/requests-cache",
    "commit": "6f54262b06a96b1019339e655b22c63f5882a632",
    "filename": "requests_cache/models/response.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/reclosedev-requests-cache/requests_cache/models/response.py",
    "file_hunks_size": 7,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "requests_cache/models/response.py:98:8 Incompatible attribute type [8]: Attribute `expires` declared in class `CachedResponse` has type `datetime` but is used as type `Optional[datetime]`.",
    "message": " Attribute `expires` declared in class `CachedResponse` has type `datetime` but is used as type `Optional[datetime]`.",
    "rule_id": "Incompatible attribute type [8]",
    "warning_line_no": 98,
    "warning_line": "        self.expires = get_expiration_datetime(expire_after)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    status_code: int = field(default=0)\n    cookies: RequestsCookieJar = field(factory=dict)\n    created_at: datetime = field(factory=datetime.utcnow)\n    elapsed: timedelta = field(factory=timedelta)\n    expires: datetime = field(default=None)\n    encoding: str = field(default=None)\n",
        "source_code_len": 285,
        "target_code": "    status_code: int = field(default=0)\n    cookies: RequestsCookieJar = field(factory=RequestsCookieJar)\n    created_at: datetime = field(factory=datetime.utcnow)\n    elapsed: timedelta = field(factory=timedelta)\n    expires: Optional[datetime] = field(default=None)\n    encoding: str = field(default=None)\n",
        "target_code_len": 308,
        "diff_format": "@@ -37,6 +37,6 @@\n     status_code: int = field(default=0)\n-    cookies: RequestsCookieJar = field(factory=dict)\n+    cookies: RequestsCookieJar = field(factory=RequestsCookieJar)\n     created_at: datetime = field(factory=datetime.utcnow)\n     elapsed: timedelta = field(factory=timedelta)\n-    expires: datetime = field(default=None)\n+    expires: Optional[datetime] = field(default=None)\n     encoding: str = field(default=None)\n",
        "source_code_with_indent": "    status_code: int = field(default=0)\n    cookies: RequestsCookieJar = field(factory=dict)\n    created_at: datetime = field(factory=datetime.utcnow)\n    elapsed: timedelta = field(factory=timedelta)\n    expires: datetime = field(default=None)\n    encoding: str = field(default=None)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    status_code: int = field(default=0)\n    cookies: RequestsCookieJar = field(factory=RequestsCookieJar)\n    created_at: datetime = field(factory=datetime.utcnow)\n    elapsed: timedelta = field(factory=timedelta)\n    expires: Optional[datetime] = field(default=None)\n    encoding: str = field(default=None)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "reclosedev/requests-cache",
    "commit": "6f54262b06a96b1019339e655b22c63f5882a632",
    "filename": "requests_cache/models/response.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/reclosedev-requests-cache/requests_cache/models/response.py",
    "file_hunks_size": 7,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "requests_cache/models/response.py:140:8 Incompatible return type [7]: Expected `str` but got implicit return value of `None`.",
    "message": " Expected `str` but got implicit return value of `None`.",
    "rule_id": "Incompatible return type [7]",
    "warning_line_no": 140,
    "warning_line": "        filesize /= 1024"
  }
]