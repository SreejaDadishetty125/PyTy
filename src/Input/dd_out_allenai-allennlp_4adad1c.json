[
  {
    "project": "allenai/allennlp",
    "commit": "4adad1ca217fa5154937946350e0a8d1a05b410d",
    "filename": "allennlp/data/tokenizers/token.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/tokenizers/token.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/tokenizers/token.py:4:0 Incompatible variable type [9]: dep_ is declared to have type `str` but is used as type `None`.",
    "message": " dep_ is declared to have type `str` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 4,
    "warning_line": "class Token(NamedTuple):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from typing import NamedTuple\n\n",
        "source_code_len": 31,
        "target_code": "from typing import NamedTuple, Optional\n\n",
        "target_code_len": 41,
        "diff_format": "@@ -1,2 +1,2 @@\n-from typing import NamedTuple\n+from typing import NamedTuple, Optional\n \n",
        "source_code_with_indent": "from typing import NamedTuple\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from typing import NamedTuple, Optional\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_len": 203,
        "target_code": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_len": 293,
        "diff_format": "@@ -38,11 +38,11 @@\n \n-    text: str = None\n-    idx: int = None\n-    lemma_: str = None\n-    pos_: str = None\n-    tag_: str = None\n-    dep_: str = None\n-    ent_type_: str = None\n-    text_id: int = None\n-    type_id: int = None\n+    text: Optional[str] = None\n+    idx: Optional[int] = None\n+    lemma_: Optional[str] = None\n+    pos_: Optional[str] = None\n+    tag_: Optional[str] = None\n+    dep_: Optional[str] = None\n+    ent_type_: Optional[str] = None\n+    text_id: Optional[int] = None\n+    type_id: Optional[int] = None\n \n",
        "source_code_with_indent": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "4adad1ca217fa5154937946350e0a8d1a05b410d",
    "filename": "allennlp/data/tokenizers/token.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/tokenizers/token.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/tokenizers/token.py:4:0 Incompatible variable type [9]: dep_ is declared to have type `str` but is used as type `None`.",
    "message": " dep_ is declared to have type `str` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 4,
    "warning_line": "class Token(NamedTuple):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from typing import NamedTuple\n\n",
        "source_code_len": 31,
        "target_code": "from typing import NamedTuple, Optional\n\n",
        "target_code_len": 41,
        "diff_format": "@@ -1,2 +1,2 @@\n-from typing import NamedTuple\n+from typing import NamedTuple, Optional\n \n",
        "source_code_with_indent": "from typing import NamedTuple\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from typing import NamedTuple, Optional\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_len": 203,
        "target_code": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_len": 293,
        "diff_format": "@@ -38,11 +38,11 @@\n \n-    text: str = None\n-    idx: int = None\n-    lemma_: str = None\n-    pos_: str = None\n-    tag_: str = None\n-    dep_: str = None\n-    ent_type_: str = None\n-    text_id: int = None\n-    type_id: int = None\n+    text: Optional[str] = None\n+    idx: Optional[int] = None\n+    lemma_: Optional[str] = None\n+    pos_: Optional[str] = None\n+    tag_: Optional[str] = None\n+    dep_: Optional[str] = None\n+    ent_type_: Optional[str] = None\n+    text_id: Optional[int] = None\n+    type_id: Optional[int] = None\n \n",
        "source_code_with_indent": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "4adad1ca217fa5154937946350e0a8d1a05b410d",
    "filename": "allennlp/data/tokenizers/token.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/tokenizers/token.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/tokenizers/token.py:4:0 Incompatible variable type [9]: ent_type_ is declared to have type `str` but is used as type `None`.",
    "message": " ent_type_ is declared to have type `str` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 4,
    "warning_line": "class Token(NamedTuple):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from typing import NamedTuple\n\n",
        "source_code_len": 31,
        "target_code": "from typing import NamedTuple, Optional\n\n",
        "target_code_len": 41,
        "diff_format": "@@ -1,2 +1,2 @@\n-from typing import NamedTuple\n+from typing import NamedTuple, Optional\n \n",
        "source_code_with_indent": "from typing import NamedTuple\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from typing import NamedTuple, Optional\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_len": 203,
        "target_code": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_len": 293,
        "diff_format": "@@ -38,11 +38,11 @@\n \n-    text: str = None\n-    idx: int = None\n-    lemma_: str = None\n-    pos_: str = None\n-    tag_: str = None\n-    dep_: str = None\n-    ent_type_: str = None\n-    text_id: int = None\n-    type_id: int = None\n+    text: Optional[str] = None\n+    idx: Optional[int] = None\n+    lemma_: Optional[str] = None\n+    pos_: Optional[str] = None\n+    tag_: Optional[str] = None\n+    dep_: Optional[str] = None\n+    ent_type_: Optional[str] = None\n+    text_id: Optional[int] = None\n+    type_id: Optional[int] = None\n \n",
        "source_code_with_indent": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "4adad1ca217fa5154937946350e0a8d1a05b410d",
    "filename": "allennlp/data/tokenizers/token.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/tokenizers/token.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/tokenizers/token.py:4:0 Incompatible variable type [9]: ent_type_ is declared to have type `str` but is used as type `None`.",
    "message": " ent_type_ is declared to have type `str` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 4,
    "warning_line": "class Token(NamedTuple):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from typing import NamedTuple\n\n",
        "source_code_len": 31,
        "target_code": "from typing import NamedTuple, Optional\n\n",
        "target_code_len": 41,
        "diff_format": "@@ -1,2 +1,2 @@\n-from typing import NamedTuple\n+from typing import NamedTuple, Optional\n \n",
        "source_code_with_indent": "from typing import NamedTuple\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from typing import NamedTuple, Optional\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_len": 203,
        "target_code": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_len": 293,
        "diff_format": "@@ -38,11 +38,11 @@\n \n-    text: str = None\n-    idx: int = None\n-    lemma_: str = None\n-    pos_: str = None\n-    tag_: str = None\n-    dep_: str = None\n-    ent_type_: str = None\n-    text_id: int = None\n-    type_id: int = None\n+    text: Optional[str] = None\n+    idx: Optional[int] = None\n+    lemma_: Optional[str] = None\n+    pos_: Optional[str] = None\n+    tag_: Optional[str] = None\n+    dep_: Optional[str] = None\n+    ent_type_: Optional[str] = None\n+    text_id: Optional[int] = None\n+    type_id: Optional[int] = None\n \n",
        "source_code_with_indent": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "4adad1ca217fa5154937946350e0a8d1a05b410d",
    "filename": "allennlp/data/tokenizers/token.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/tokenizers/token.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/tokenizers/token.py:4:0 Incompatible variable type [9]: idx is declared to have type `int` but is used as type `None`.",
    "message": " idx is declared to have type `int` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 4,
    "warning_line": "class Token(NamedTuple):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from typing import NamedTuple\n\n",
        "source_code_len": 31,
        "target_code": "from typing import NamedTuple, Optional\n\n",
        "target_code_len": 41,
        "diff_format": "@@ -1,2 +1,2 @@\n-from typing import NamedTuple\n+from typing import NamedTuple, Optional\n \n",
        "source_code_with_indent": "from typing import NamedTuple\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from typing import NamedTuple, Optional\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_len": 203,
        "target_code": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_len": 293,
        "diff_format": "@@ -38,11 +38,11 @@\n \n-    text: str = None\n-    idx: int = None\n-    lemma_: str = None\n-    pos_: str = None\n-    tag_: str = None\n-    dep_: str = None\n-    ent_type_: str = None\n-    text_id: int = None\n-    type_id: int = None\n+    text: Optional[str] = None\n+    idx: Optional[int] = None\n+    lemma_: Optional[str] = None\n+    pos_: Optional[str] = None\n+    tag_: Optional[str] = None\n+    dep_: Optional[str] = None\n+    ent_type_: Optional[str] = None\n+    text_id: Optional[int] = None\n+    type_id: Optional[int] = None\n \n",
        "source_code_with_indent": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "4adad1ca217fa5154937946350e0a8d1a05b410d",
    "filename": "allennlp/data/tokenizers/token.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/tokenizers/token.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/tokenizers/token.py:4:0 Incompatible variable type [9]: idx is declared to have type `int` but is used as type `None`.",
    "message": " idx is declared to have type `int` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 4,
    "warning_line": "class Token(NamedTuple):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from typing import NamedTuple\n\n",
        "source_code_len": 31,
        "target_code": "from typing import NamedTuple, Optional\n\n",
        "target_code_len": 41,
        "diff_format": "@@ -1,2 +1,2 @@\n-from typing import NamedTuple\n+from typing import NamedTuple, Optional\n \n",
        "source_code_with_indent": "from typing import NamedTuple\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from typing import NamedTuple, Optional\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_len": 203,
        "target_code": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_len": 293,
        "diff_format": "@@ -38,11 +38,11 @@\n \n-    text: str = None\n-    idx: int = None\n-    lemma_: str = None\n-    pos_: str = None\n-    tag_: str = None\n-    dep_: str = None\n-    ent_type_: str = None\n-    text_id: int = None\n-    type_id: int = None\n+    text: Optional[str] = None\n+    idx: Optional[int] = None\n+    lemma_: Optional[str] = None\n+    pos_: Optional[str] = None\n+    tag_: Optional[str] = None\n+    dep_: Optional[str] = None\n+    ent_type_: Optional[str] = None\n+    text_id: Optional[int] = None\n+    type_id: Optional[int] = None\n \n",
        "source_code_with_indent": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "4adad1ca217fa5154937946350e0a8d1a05b410d",
    "filename": "allennlp/data/tokenizers/token.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/tokenizers/token.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/tokenizers/token.py:4:0 Incompatible variable type [9]: lemma_ is declared to have type `str` but is used as type `None`.",
    "message": " lemma_ is declared to have type `str` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 4,
    "warning_line": "class Token(NamedTuple):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from typing import NamedTuple\n\n",
        "source_code_len": 31,
        "target_code": "from typing import NamedTuple, Optional\n\n",
        "target_code_len": 41,
        "diff_format": "@@ -1,2 +1,2 @@\n-from typing import NamedTuple\n+from typing import NamedTuple, Optional\n \n",
        "source_code_with_indent": "from typing import NamedTuple\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from typing import NamedTuple, Optional\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_len": 203,
        "target_code": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_len": 293,
        "diff_format": "@@ -38,11 +38,11 @@\n \n-    text: str = None\n-    idx: int = None\n-    lemma_: str = None\n-    pos_: str = None\n-    tag_: str = None\n-    dep_: str = None\n-    ent_type_: str = None\n-    text_id: int = None\n-    type_id: int = None\n+    text: Optional[str] = None\n+    idx: Optional[int] = None\n+    lemma_: Optional[str] = None\n+    pos_: Optional[str] = None\n+    tag_: Optional[str] = None\n+    dep_: Optional[str] = None\n+    ent_type_: Optional[str] = None\n+    text_id: Optional[int] = None\n+    type_id: Optional[int] = None\n \n",
        "source_code_with_indent": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "4adad1ca217fa5154937946350e0a8d1a05b410d",
    "filename": "allennlp/data/tokenizers/token.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/tokenizers/token.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/tokenizers/token.py:4:0 Incompatible variable type [9]: lemma_ is declared to have type `str` but is used as type `None`.",
    "message": " lemma_ is declared to have type `str` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 4,
    "warning_line": "class Token(NamedTuple):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from typing import NamedTuple\n\n",
        "source_code_len": 31,
        "target_code": "from typing import NamedTuple, Optional\n\n",
        "target_code_len": 41,
        "diff_format": "@@ -1,2 +1,2 @@\n-from typing import NamedTuple\n+from typing import NamedTuple, Optional\n \n",
        "source_code_with_indent": "from typing import NamedTuple\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from typing import NamedTuple, Optional\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_len": 203,
        "target_code": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_len": 293,
        "diff_format": "@@ -38,11 +38,11 @@\n \n-    text: str = None\n-    idx: int = None\n-    lemma_: str = None\n-    pos_: str = None\n-    tag_: str = None\n-    dep_: str = None\n-    ent_type_: str = None\n-    text_id: int = None\n-    type_id: int = None\n+    text: Optional[str] = None\n+    idx: Optional[int] = None\n+    lemma_: Optional[str] = None\n+    pos_: Optional[str] = None\n+    tag_: Optional[str] = None\n+    dep_: Optional[str] = None\n+    ent_type_: Optional[str] = None\n+    text_id: Optional[int] = None\n+    type_id: Optional[int] = None\n \n",
        "source_code_with_indent": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "4adad1ca217fa5154937946350e0a8d1a05b410d",
    "filename": "allennlp/data/tokenizers/token.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/tokenizers/token.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/tokenizers/token.py:4:0 Incompatible variable type [9]: pos_ is declared to have type `str` but is used as type `None`.",
    "message": " pos_ is declared to have type `str` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 4,
    "warning_line": "class Token(NamedTuple):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from typing import NamedTuple\n\n",
        "source_code_len": 31,
        "target_code": "from typing import NamedTuple, Optional\n\n",
        "target_code_len": 41,
        "diff_format": "@@ -1,2 +1,2 @@\n-from typing import NamedTuple\n+from typing import NamedTuple, Optional\n \n",
        "source_code_with_indent": "from typing import NamedTuple\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from typing import NamedTuple, Optional\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_len": 203,
        "target_code": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_len": 293,
        "diff_format": "@@ -38,11 +38,11 @@\n \n-    text: str = None\n-    idx: int = None\n-    lemma_: str = None\n-    pos_: str = None\n-    tag_: str = None\n-    dep_: str = None\n-    ent_type_: str = None\n-    text_id: int = None\n-    type_id: int = None\n+    text: Optional[str] = None\n+    idx: Optional[int] = None\n+    lemma_: Optional[str] = None\n+    pos_: Optional[str] = None\n+    tag_: Optional[str] = None\n+    dep_: Optional[str] = None\n+    ent_type_: Optional[str] = None\n+    text_id: Optional[int] = None\n+    type_id: Optional[int] = None\n \n",
        "source_code_with_indent": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "4adad1ca217fa5154937946350e0a8d1a05b410d",
    "filename": "allennlp/data/tokenizers/token.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/tokenizers/token.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/tokenizers/token.py:4:0 Incompatible variable type [9]: pos_ is declared to have type `str` but is used as type `None`.",
    "message": " pos_ is declared to have type `str` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 4,
    "warning_line": "class Token(NamedTuple):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from typing import NamedTuple\n\n",
        "source_code_len": 31,
        "target_code": "from typing import NamedTuple, Optional\n\n",
        "target_code_len": 41,
        "diff_format": "@@ -1,2 +1,2 @@\n-from typing import NamedTuple\n+from typing import NamedTuple, Optional\n \n",
        "source_code_with_indent": "from typing import NamedTuple\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from typing import NamedTuple, Optional\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_len": 203,
        "target_code": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_len": 293,
        "diff_format": "@@ -38,11 +38,11 @@\n \n-    text: str = None\n-    idx: int = None\n-    lemma_: str = None\n-    pos_: str = None\n-    tag_: str = None\n-    dep_: str = None\n-    ent_type_: str = None\n-    text_id: int = None\n-    type_id: int = None\n+    text: Optional[str] = None\n+    idx: Optional[int] = None\n+    lemma_: Optional[str] = None\n+    pos_: Optional[str] = None\n+    tag_: Optional[str] = None\n+    dep_: Optional[str] = None\n+    ent_type_: Optional[str] = None\n+    text_id: Optional[int] = None\n+    type_id: Optional[int] = None\n \n",
        "source_code_with_indent": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "4adad1ca217fa5154937946350e0a8d1a05b410d",
    "filename": "allennlp/data/tokenizers/token.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/tokenizers/token.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/tokenizers/token.py:4:0 Incompatible variable type [9]: tag_ is declared to have type `str` but is used as type `None`.",
    "message": " tag_ is declared to have type `str` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 4,
    "warning_line": "class Token(NamedTuple):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from typing import NamedTuple\n\n",
        "source_code_len": 31,
        "target_code": "from typing import NamedTuple, Optional\n\n",
        "target_code_len": 41,
        "diff_format": "@@ -1,2 +1,2 @@\n-from typing import NamedTuple\n+from typing import NamedTuple, Optional\n \n",
        "source_code_with_indent": "from typing import NamedTuple\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from typing import NamedTuple, Optional\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_len": 203,
        "target_code": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_len": 293,
        "diff_format": "@@ -38,11 +38,11 @@\n \n-    text: str = None\n-    idx: int = None\n-    lemma_: str = None\n-    pos_: str = None\n-    tag_: str = None\n-    dep_: str = None\n-    ent_type_: str = None\n-    text_id: int = None\n-    type_id: int = None\n+    text: Optional[str] = None\n+    idx: Optional[int] = None\n+    lemma_: Optional[str] = None\n+    pos_: Optional[str] = None\n+    tag_: Optional[str] = None\n+    dep_: Optional[str] = None\n+    ent_type_: Optional[str] = None\n+    text_id: Optional[int] = None\n+    type_id: Optional[int] = None\n \n",
        "source_code_with_indent": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "4adad1ca217fa5154937946350e0a8d1a05b410d",
    "filename": "allennlp/data/tokenizers/token.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/tokenizers/token.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/tokenizers/token.py:4:0 Incompatible variable type [9]: tag_ is declared to have type `str` but is used as type `None`.",
    "message": " tag_ is declared to have type `str` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 4,
    "warning_line": "class Token(NamedTuple):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from typing import NamedTuple\n\n",
        "source_code_len": 31,
        "target_code": "from typing import NamedTuple, Optional\n\n",
        "target_code_len": 41,
        "diff_format": "@@ -1,2 +1,2 @@\n-from typing import NamedTuple\n+from typing import NamedTuple, Optional\n \n",
        "source_code_with_indent": "from typing import NamedTuple\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from typing import NamedTuple, Optional\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_len": 203,
        "target_code": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_len": 293,
        "diff_format": "@@ -38,11 +38,11 @@\n \n-    text: str = None\n-    idx: int = None\n-    lemma_: str = None\n-    pos_: str = None\n-    tag_: str = None\n-    dep_: str = None\n-    ent_type_: str = None\n-    text_id: int = None\n-    type_id: int = None\n+    text: Optional[str] = None\n+    idx: Optional[int] = None\n+    lemma_: Optional[str] = None\n+    pos_: Optional[str] = None\n+    tag_: Optional[str] = None\n+    dep_: Optional[str] = None\n+    ent_type_: Optional[str] = None\n+    text_id: Optional[int] = None\n+    type_id: Optional[int] = None\n \n",
        "source_code_with_indent": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "4adad1ca217fa5154937946350e0a8d1a05b410d",
    "filename": "allennlp/data/tokenizers/token.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/tokenizers/token.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/tokenizers/token.py:4:0 Incompatible variable type [9]: text is declared to have type `str` but is used as type `None`.",
    "message": " text is declared to have type `str` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 4,
    "warning_line": "class Token(NamedTuple):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from typing import NamedTuple\n\n",
        "source_code_len": 31,
        "target_code": "from typing import NamedTuple, Optional\n\n",
        "target_code_len": 41,
        "diff_format": "@@ -1,2 +1,2 @@\n-from typing import NamedTuple\n+from typing import NamedTuple, Optional\n \n",
        "source_code_with_indent": "from typing import NamedTuple\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from typing import NamedTuple, Optional\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_len": 203,
        "target_code": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_len": 293,
        "diff_format": "@@ -38,11 +38,11 @@\n \n-    text: str = None\n-    idx: int = None\n-    lemma_: str = None\n-    pos_: str = None\n-    tag_: str = None\n-    dep_: str = None\n-    ent_type_: str = None\n-    text_id: int = None\n-    type_id: int = None\n+    text: Optional[str] = None\n+    idx: Optional[int] = None\n+    lemma_: Optional[str] = None\n+    pos_: Optional[str] = None\n+    tag_: Optional[str] = None\n+    dep_: Optional[str] = None\n+    ent_type_: Optional[str] = None\n+    text_id: Optional[int] = None\n+    type_id: Optional[int] = None\n \n",
        "source_code_with_indent": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "4adad1ca217fa5154937946350e0a8d1a05b410d",
    "filename": "allennlp/data/tokenizers/token.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/tokenizers/token.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/tokenizers/token.py:4:0 Incompatible variable type [9]: text is declared to have type `str` but is used as type `None`.",
    "message": " text is declared to have type `str` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 4,
    "warning_line": "class Token(NamedTuple):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from typing import NamedTuple\n\n",
        "source_code_len": 31,
        "target_code": "from typing import NamedTuple, Optional\n\n",
        "target_code_len": 41,
        "diff_format": "@@ -1,2 +1,2 @@\n-from typing import NamedTuple\n+from typing import NamedTuple, Optional\n \n",
        "source_code_with_indent": "from typing import NamedTuple\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from typing import NamedTuple, Optional\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_len": 203,
        "target_code": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_len": 293,
        "diff_format": "@@ -38,11 +38,11 @@\n \n-    text: str = None\n-    idx: int = None\n-    lemma_: str = None\n-    pos_: str = None\n-    tag_: str = None\n-    dep_: str = None\n-    ent_type_: str = None\n-    text_id: int = None\n-    type_id: int = None\n+    text: Optional[str] = None\n+    idx: Optional[int] = None\n+    lemma_: Optional[str] = None\n+    pos_: Optional[str] = None\n+    tag_: Optional[str] = None\n+    dep_: Optional[str] = None\n+    ent_type_: Optional[str] = None\n+    text_id: Optional[int] = None\n+    type_id: Optional[int] = None\n \n",
        "source_code_with_indent": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "4adad1ca217fa5154937946350e0a8d1a05b410d",
    "filename": "allennlp/data/tokenizers/token.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/tokenizers/token.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/tokenizers/token.py:4:0 Incompatible variable type [9]: text_id is declared to have type `int` but is used as type `None`.",
    "message": " text_id is declared to have type `int` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 4,
    "warning_line": "class Token(NamedTuple):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from typing import NamedTuple\n\n",
        "source_code_len": 31,
        "target_code": "from typing import NamedTuple, Optional\n\n",
        "target_code_len": 41,
        "diff_format": "@@ -1,2 +1,2 @@\n-from typing import NamedTuple\n+from typing import NamedTuple, Optional\n \n",
        "source_code_with_indent": "from typing import NamedTuple\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from typing import NamedTuple, Optional\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_len": 203,
        "target_code": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_len": 293,
        "diff_format": "@@ -38,11 +38,11 @@\n \n-    text: str = None\n-    idx: int = None\n-    lemma_: str = None\n-    pos_: str = None\n-    tag_: str = None\n-    dep_: str = None\n-    ent_type_: str = None\n-    text_id: int = None\n-    type_id: int = None\n+    text: Optional[str] = None\n+    idx: Optional[int] = None\n+    lemma_: Optional[str] = None\n+    pos_: Optional[str] = None\n+    tag_: Optional[str] = None\n+    dep_: Optional[str] = None\n+    ent_type_: Optional[str] = None\n+    text_id: Optional[int] = None\n+    type_id: Optional[int] = None\n \n",
        "source_code_with_indent": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "4adad1ca217fa5154937946350e0a8d1a05b410d",
    "filename": "allennlp/data/tokenizers/token.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/tokenizers/token.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/tokenizers/token.py:4:0 Incompatible variable type [9]: text_id is declared to have type `int` but is used as type `None`.",
    "message": " text_id is declared to have type `int` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 4,
    "warning_line": "class Token(NamedTuple):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from typing import NamedTuple\n\n",
        "source_code_len": 31,
        "target_code": "from typing import NamedTuple, Optional\n\n",
        "target_code_len": 41,
        "diff_format": "@@ -1,2 +1,2 @@\n-from typing import NamedTuple\n+from typing import NamedTuple, Optional\n \n",
        "source_code_with_indent": "from typing import NamedTuple\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from typing import NamedTuple, Optional\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_len": 203,
        "target_code": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_len": 293,
        "diff_format": "@@ -38,11 +38,11 @@\n \n-    text: str = None\n-    idx: int = None\n-    lemma_: str = None\n-    pos_: str = None\n-    tag_: str = None\n-    dep_: str = None\n-    ent_type_: str = None\n-    text_id: int = None\n-    type_id: int = None\n+    text: Optional[str] = None\n+    idx: Optional[int] = None\n+    lemma_: Optional[str] = None\n+    pos_: Optional[str] = None\n+    tag_: Optional[str] = None\n+    dep_: Optional[str] = None\n+    ent_type_: Optional[str] = None\n+    text_id: Optional[int] = None\n+    type_id: Optional[int] = None\n \n",
        "source_code_with_indent": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "4adad1ca217fa5154937946350e0a8d1a05b410d",
    "filename": "allennlp/data/tokenizers/token.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/tokenizers/token.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/tokenizers/token.py:4:0 Incompatible variable type [9]: type_id is declared to have type `int` but is used as type `None`.",
    "message": " type_id is declared to have type `int` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 4,
    "warning_line": "class Token(NamedTuple):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from typing import NamedTuple\n\n",
        "source_code_len": 31,
        "target_code": "from typing import NamedTuple, Optional\n\n",
        "target_code_len": 41,
        "diff_format": "@@ -1,2 +1,2 @@\n-from typing import NamedTuple\n+from typing import NamedTuple, Optional\n \n",
        "source_code_with_indent": "from typing import NamedTuple\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from typing import NamedTuple, Optional\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_len": 203,
        "target_code": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_len": 293,
        "diff_format": "@@ -38,11 +38,11 @@\n \n-    text: str = None\n-    idx: int = None\n-    lemma_: str = None\n-    pos_: str = None\n-    tag_: str = None\n-    dep_: str = None\n-    ent_type_: str = None\n-    text_id: int = None\n-    type_id: int = None\n+    text: Optional[str] = None\n+    idx: Optional[int] = None\n+    lemma_: Optional[str] = None\n+    pos_: Optional[str] = None\n+    tag_: Optional[str] = None\n+    dep_: Optional[str] = None\n+    ent_type_: Optional[str] = None\n+    text_id: Optional[int] = None\n+    type_id: Optional[int] = None\n \n",
        "source_code_with_indent": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "allenai/allennlp",
    "commit": "4adad1ca217fa5154937946350e0a8d1a05b410d",
    "filename": "allennlp/data/tokenizers/token.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/allenai-allennlp/allennlp/data/tokenizers/token.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "allennlp/data/tokenizers/token.py:4:0 Incompatible variable type [9]: type_id is declared to have type `int` but is used as type `None`.",
    "message": " type_id is declared to have type `int` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 4,
    "warning_line": "class Token(NamedTuple):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from typing import NamedTuple\n\n",
        "source_code_len": 31,
        "target_code": "from typing import NamedTuple, Optional\n\n",
        "target_code_len": 41,
        "diff_format": "@@ -1,2 +1,2 @@\n-from typing import NamedTuple\n+from typing import NamedTuple, Optional\n \n",
        "source_code_with_indent": "from typing import NamedTuple\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from typing import NamedTuple, Optional\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_len": 203,
        "target_code": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_len": 293,
        "diff_format": "@@ -38,11 +38,11 @@\n \n-    text: str = None\n-    idx: int = None\n-    lemma_: str = None\n-    pos_: str = None\n-    tag_: str = None\n-    dep_: str = None\n-    ent_type_: str = None\n-    text_id: int = None\n-    type_id: int = None\n+    text: Optional[str] = None\n+    idx: Optional[int] = None\n+    lemma_: Optional[str] = None\n+    pos_: Optional[str] = None\n+    tag_: Optional[str] = None\n+    dep_: Optional[str] = None\n+    ent_type_: Optional[str] = None\n+    text_id: Optional[int] = None\n+    type_id: Optional[int] = None\n \n",
        "source_code_with_indent": "\n    text: str = None\n    idx: int = None\n    lemma_: str = None\n    pos_: str = None\n    tag_: str = None\n    dep_: str = None\n    ent_type_: str = None\n    text_id: int = None\n    type_id: int = None\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    text: Optional[str] = None\n    idx: Optional[int] = None\n    lemma_: Optional[str] = None\n    pos_: Optional[str] = None\n    tag_: Optional[str] = None\n    dep_: Optional[str] = None\n    ent_type_: Optional[str] = None\n    text_id: Optional[int] = None\n    type_id: Optional[int] = None\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  }
]