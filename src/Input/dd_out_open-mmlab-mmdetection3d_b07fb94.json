[
  {
    "project": "open-mmlab/mmdetection3d",
    "commit": "b07fb946e0b409bc88590247b5a40f31d94254aa",
    "filename": "mmdet3d/ops/pointnet_modules/point_sa_module.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/open-mmlab-mmdetection3d/mmdet3d/ops/pointnet_modules/point_sa_module.py",
    "file_hunks_size": 14,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "mmdet3d/ops/pointnet_modules/point_sa_module.py:127:10 Invalid type [31]: Expression `(torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor)` is not a valid type.",
    "message": " Expression `(torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor)` is not a valid type.",
    "rule_id": "Invalid type [31]",
    "warning_line_no": 127,
    "warning_line": "    ) -> (torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n        for i in range(len(self.groupers)):\n            # (B, C, num_point, nsample)\n            new_features = self.groupers[i](points_xyz, new_xyz, features)\n\n            # (B, mlp[-1], num_point, nsample)\n            new_features = self.mlps[i](new_features)\n            if self.pool_mod == 'max':\n                # (B, mlp[-1], num_point, 1)\n                new_features = F.max_pool2d(\n                    new_features, kernel_size=[1, new_features.size(3)])\n            elif self.pool_mod == 'avg':\n                # (B, mlp[-1], num_point, 1)\n                new_features = F.avg_pool2d(\n                    new_features, kernel_size=[1, new_features.size(3)])\n            else:\n                raise NotImplementedError\n\n            new_features = new_features.squeeze(-1)  # (B, mlp[-1], num_point)\n            new_features_list.append(new_features)\n",
        "source_code_len": 860,
        "target_code": "\n        return new_xyz, indices\n\n    def _pool_features(self, features):\n        \"\"\"Perform feature aggregation using pooling operation.\n\n        Args:\n            features (torch.Tensor): (B, C, N, K)\n                Features of locally grouped points before pooling.\n\n        Returns:\n            torch.Tensor: (B, C, N)\n                Pooled features aggregating local information.\n        \"\"\"\n        if self.pool_mod == 'max':\n            # (B, C, N, 1)\n            new_features = F.max_pool2d(\n                features, kernel_size=[1, features.size(3)])\n        elif self.pool_mod == 'avg':\n            # (B, C, N, 1)\n            new_features = F.avg_pool2d(\n                features, kernel_size=[1, features.size(3)])\n        else:\n            raise NotImplementedError\n\n        return new_features.squeeze(-1).contiguous()\n\n    def forward(\n        self,\n        points_xyz,\n        features=None,\n        indices=None,\n        target_xyz=None,\n    ):\n        \"\"\"forward.\n\n        Args:\n            points_xyz (Tensor): (B, N, 3) xyz coordinates of the features.\n            features (Tensor): (B, C, N) features of each point.\n                Default: None.\n            indices (Tensor): (B, num_point) Index of the features.\n                Default: None.\n            target_xyz (Tensor): (B, M, 3) new_xyz coordinates of the outputs.\n\n        Returns:\n            Tensor: (B, M, 3) where M is the number of points.\n                New features xyz.\n            Tensor: (B, M, sum_k(mlps[k][-1])) where M is the number\n                of points. New feature descriptors.\n            Tensor: (B, M) where M is the number of points.\n                Index of the features.\n        \"\"\"\n        new_features_list = []\n\n        # sample points, (B, num_point, 3), (B, num_point)\n        new_xyz, indices = self._sample_points(points_xyz, features, indices,\n                                               target_xyz)\n\n        for i in range(len(self.groupers)):\n            # grouped_results may contain:\n            # - grouped_features: (B, C, num_point, nsample)\n            # - grouped_xyz: (B, 3, num_point, nsample)\n            # - grouped_idx: (B, num_point, nsample)\n            grouped_results = self.groupers[i](points_xyz, new_xyz, features)\n\n            # (B, mlp[-1], num_point, nsample)\n            new_features = self.mlps[i](grouped_results)\n\n            # this is a bit hack because PAConv outputs two values\n            # we take the first one as feature\n            if isinstance(self.mlps[i][0], PAConv):\n                assert isinstance(new_features, tuple)\n                new_features = new_features[0]\n\n            # (B, mlp[-1], num_point)\n            new_features = self._pool_features(new_features)\n            new_features_list.append(new_features)\n",
        "target_code_len": 2785,
        "diff_format": "@@ -158,20 +133,77 @@\n \n+        return new_xyz, indices\n+\n+    def _pool_features(self, features):\n+        \"\"\"Perform feature aggregation using pooling operation.\n+\n+        Args:\n+            features (torch.Tensor): (B, C, N, K)\n+                Features of locally grouped points before pooling.\n+\n+        Returns:\n+            torch.Tensor: (B, C, N)\n+                Pooled features aggregating local information.\n+        \"\"\"\n+        if self.pool_mod == 'max':\n+            # (B, C, N, 1)\n+            new_features = F.max_pool2d(\n+                features, kernel_size=[1, features.size(3)])\n+        elif self.pool_mod == 'avg':\n+            # (B, C, N, 1)\n+            new_features = F.avg_pool2d(\n+                features, kernel_size=[1, features.size(3)])\n+        else:\n+            raise NotImplementedError\n+\n+        return new_features.squeeze(-1).contiguous()\n+\n+    def forward(\n+        self,\n+        points_xyz,\n+        features=None,\n+        indices=None,\n+        target_xyz=None,\n+    ):\n+        \"\"\"forward.\n+\n+        Args:\n+            points_xyz (Tensor): (B, N, 3) xyz coordinates of the features.\n+            features (Tensor): (B, C, N) features of each point.\n+                Default: None.\n+            indices (Tensor): (B, num_point) Index of the features.\n+                Default: None.\n+            target_xyz (Tensor): (B, M, 3) new_xyz coordinates of the outputs.\n+\n+        Returns:\n+            Tensor: (B, M, 3) where M is the number of points.\n+                New features xyz.\n+            Tensor: (B, M, sum_k(mlps[k][-1])) where M is the number\n+                of points. New feature descriptors.\n+            Tensor: (B, M) where M is the number of points.\n+                Index of the features.\n+        \"\"\"\n+        new_features_list = []\n+\n+        # sample points, (B, num_point, 3), (B, num_point)\n+        new_xyz, indices = self._sample_points(points_xyz, features, indices,\n+                                               target_xyz)\n+\n         for i in range(len(self.groupers)):\n-            # (B, C, num_point, nsample)\n-            new_features = self.groupers[i](points_xyz, new_xyz, features)\n+            # grouped_results may contain:\n+            # - grouped_features: (B, C, num_point, nsample)\n+            # - grouped_xyz: (B, 3, num_point, nsample)\n+            # - grouped_idx: (B, num_point, nsample)\n+            grouped_results = self.groupers[i](points_xyz, new_xyz, features)\n \n             # (B, mlp[-1], num_point, nsample)\n-            new_features = self.mlps[i](new_features)\n-            if self.pool_mod == 'max':\n-                # (B, mlp[-1], num_point, 1)\n-                new_features = F.max_pool2d(\n-                    new_features, kernel_size=[1, new_features.size(3)])\n-            elif self.pool_mod == 'avg':\n-                # (B, mlp[-1], num_point, 1)\n-                new_features = F.avg_pool2d(\n-                    new_features, kernel_size=[1, new_features.size(3)])\n-            else:\n-                raise NotImplementedError\n-\n-            new_features = new_features.squeeze(-1)  # (B, mlp[-1], num_point)\n+            new_features = self.mlps[i](grouped_results)\n+\n+            # this is a bit hack because PAConv outputs two values\n+            # we take the first one as feature\n+            if isinstance(self.mlps[i][0], PAConv):\n+                assert isinstance(new_features, tuple)\n+                new_features = new_features[0]\n+\n+            # (B, mlp[-1], num_point)\n+            new_features = self._pool_features(new_features)\n             new_features_list.append(new_features)\n",
        "source_code_with_indent": "\n        <DED>for i in range(len(self.groupers)):\n            # (B, C, num_point, nsample)\n            <IND>new_features = self.groupers[i](points_xyz, new_xyz, features)\n\n            # (B, mlp[-1], num_point, nsample)\n            new_features = self.mlps[i](new_features)\n            if self.pool_mod == 'max':\n                # (B, mlp[-1], num_point, 1)\n                <IND>new_features = F.max_pool2d(\n                    new_features, kernel_size=[1, new_features.size(3)])\n            <DED>elif self.pool_mod == 'avg':\n                # (B, mlp[-1], num_point, 1)\n                <IND>new_features = F.avg_pool2d(\n                    new_features, kernel_size=[1, new_features.size(3)])\n            <DED>else:\n                <IND>raise NotImplementedError\n\n            <DED>new_features = new_features.squeeze(-1)  # (B, mlp[-1], num_point)\n            new_features_list.append(new_features)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n        <DED>return new_xyz, indices\n\n    <DED>def _pool_features(self, features):\n        <IND>\"\"\"Perform feature aggregation using pooling operation.\n\n        Args:\n            features (torch.Tensor): (B, C, N, K)\n                Features of locally grouped points before pooling.\n\n        Returns:\n            torch.Tensor: (B, C, N)\n                Pooled features aggregating local information.\n        \"\"\"\n        if self.pool_mod == 'max':\n            # (B, C, N, 1)\n            <IND>new_features = F.max_pool2d(\n                features, kernel_size=[1, features.size(3)])\n        <DED>elif self.pool_mod == 'avg':\n            # (B, C, N, 1)\n            <IND>new_features = F.avg_pool2d(\n                features, kernel_size=[1, features.size(3)])\n        <DED>else:\n            <IND>raise NotImplementedError\n\n        <DED>return new_features.squeeze(-1).contiguous()\n\n    <DED>def forward(\n        self,\n        points_xyz,\n        features=None,\n        indices=None,\n        target_xyz=None,\n    ):\n        <IND>\"\"\"forward.\n\n        Args:\n            points_xyz (Tensor): (B, N, 3) xyz coordinates of the features.\n            features (Tensor): (B, C, N) features of each point.\n                Default: None.\n            indices (Tensor): (B, num_point) Index of the features.\n                Default: None.\n            target_xyz (Tensor): (B, M, 3) new_xyz coordinates of the outputs.\n\n        Returns:\n            Tensor: (B, M, 3) where M is the number of points.\n                New features xyz.\n            Tensor: (B, M, sum_k(mlps[k][-1])) where M is the number\n                of points. New feature descriptors.\n            Tensor: (B, M) where M is the number of points.\n                Index of the features.\n        \"\"\"\n        new_features_list = []\n\n        # sample points, (B, num_point, 3), (B, num_point)\n        new_xyz, indices = self._sample_points(points_xyz, features, indices,\n                                               target_xyz)\n\n        for i in range(len(self.groupers)):\n            # grouped_results may contain:\n            # - grouped_features: (B, C, num_point, nsample)\n            # - grouped_xyz: (B, 3, num_point, nsample)\n            # - grouped_idx: (B, num_point, nsample)\n            <IND>grouped_results = self.groupers[i](points_xyz, new_xyz, features)\n\n            # (B, mlp[-1], num_point, nsample)\n            new_features = self.mlps[i](grouped_results)\n\n            # this is a bit hack because PAConv outputs two values\n            # we take the first one as feature\n            if isinstance(self.mlps[i][0], PAConv):\n                <IND>assert isinstance(new_features, tuple)\n                new_features = new_features[0]\n\n            # (B, mlp[-1], num_point)\n            <DED>new_features = self._pool_features(new_features)\n            new_features_list.append(new_features)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "open-mmlab/mmdetection3d",
    "commit": "b07fb946e0b409bc88590247b5a40f31d94254aa",
    "filename": "mmdet3d/ops/pointnet_modules/point_sa_module.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/open-mmlab-mmdetection3d/mmdet3d/ops/pointnet_modules/point_sa_module.py",
    "file_hunks_size": 14,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "mmdet3d/ops/pointnet_modules/point_sa_module.py:155:22 Call error [29]: `mmdet3d.ops.furthest_point_sample.points_sampler.Points_Sampler` is not a function.",
    "message": " `mmdet3d.ops.furthest_point_sample.points_sampler.Points_Sampler` is not a function.",
    "rule_id": "Call error [29]",
    "warning_line_no": 155,
    "warning_line": "            indices = self.points_sampler(points_xyz, features)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n        for i in range(len(self.groupers)):\n            # (B, C, num_point, nsample)\n            new_features = self.groupers[i](points_xyz, new_xyz, features)\n\n            # (B, mlp[-1], num_point, nsample)\n            new_features = self.mlps[i](new_features)\n            if self.pool_mod == 'max':\n                # (B, mlp[-1], num_point, 1)\n                new_features = F.max_pool2d(\n                    new_features, kernel_size=[1, new_features.size(3)])\n            elif self.pool_mod == 'avg':\n                # (B, mlp[-1], num_point, 1)\n                new_features = F.avg_pool2d(\n                    new_features, kernel_size=[1, new_features.size(3)])\n            else:\n                raise NotImplementedError\n\n            new_features = new_features.squeeze(-1)  # (B, mlp[-1], num_point)\n            new_features_list.append(new_features)\n",
        "source_code_len": 860,
        "target_code": "\n        return new_xyz, indices\n\n    def _pool_features(self, features):\n        \"\"\"Perform feature aggregation using pooling operation.\n\n        Args:\n            features (torch.Tensor): (B, C, N, K)\n                Features of locally grouped points before pooling.\n\n        Returns:\n            torch.Tensor: (B, C, N)\n                Pooled features aggregating local information.\n        \"\"\"\n        if self.pool_mod == 'max':\n            # (B, C, N, 1)\n            new_features = F.max_pool2d(\n                features, kernel_size=[1, features.size(3)])\n        elif self.pool_mod == 'avg':\n            # (B, C, N, 1)\n            new_features = F.avg_pool2d(\n                features, kernel_size=[1, features.size(3)])\n        else:\n            raise NotImplementedError\n\n        return new_features.squeeze(-1).contiguous()\n\n    def forward(\n        self,\n        points_xyz,\n        features=None,\n        indices=None,\n        target_xyz=None,\n    ):\n        \"\"\"forward.\n\n        Args:\n            points_xyz (Tensor): (B, N, 3) xyz coordinates of the features.\n            features (Tensor): (B, C, N) features of each point.\n                Default: None.\n            indices (Tensor): (B, num_point) Index of the features.\n                Default: None.\n            target_xyz (Tensor): (B, M, 3) new_xyz coordinates of the outputs.\n\n        Returns:\n            Tensor: (B, M, 3) where M is the number of points.\n                New features xyz.\n            Tensor: (B, M, sum_k(mlps[k][-1])) where M is the number\n                of points. New feature descriptors.\n            Tensor: (B, M) where M is the number of points.\n                Index of the features.\n        \"\"\"\n        new_features_list = []\n\n        # sample points, (B, num_point, 3), (B, num_point)\n        new_xyz, indices = self._sample_points(points_xyz, features, indices,\n                                               target_xyz)\n\n        for i in range(len(self.groupers)):\n            # grouped_results may contain:\n            # - grouped_features: (B, C, num_point, nsample)\n            # - grouped_xyz: (B, 3, num_point, nsample)\n            # - grouped_idx: (B, num_point, nsample)\n            grouped_results = self.groupers[i](points_xyz, new_xyz, features)\n\n            # (B, mlp[-1], num_point, nsample)\n            new_features = self.mlps[i](grouped_results)\n\n            # this is a bit hack because PAConv outputs two values\n            # we take the first one as feature\n            if isinstance(self.mlps[i][0], PAConv):\n                assert isinstance(new_features, tuple)\n                new_features = new_features[0]\n\n            # (B, mlp[-1], num_point)\n            new_features = self._pool_features(new_features)\n            new_features_list.append(new_features)\n",
        "target_code_len": 2785,
        "diff_format": "@@ -158,20 +133,77 @@\n \n+        return new_xyz, indices\n+\n+    def _pool_features(self, features):\n+        \"\"\"Perform feature aggregation using pooling operation.\n+\n+        Args:\n+            features (torch.Tensor): (B, C, N, K)\n+                Features of locally grouped points before pooling.\n+\n+        Returns:\n+            torch.Tensor: (B, C, N)\n+                Pooled features aggregating local information.\n+        \"\"\"\n+        if self.pool_mod == 'max':\n+            # (B, C, N, 1)\n+            new_features = F.max_pool2d(\n+                features, kernel_size=[1, features.size(3)])\n+        elif self.pool_mod == 'avg':\n+            # (B, C, N, 1)\n+            new_features = F.avg_pool2d(\n+                features, kernel_size=[1, features.size(3)])\n+        else:\n+            raise NotImplementedError\n+\n+        return new_features.squeeze(-1).contiguous()\n+\n+    def forward(\n+        self,\n+        points_xyz,\n+        features=None,\n+        indices=None,\n+        target_xyz=None,\n+    ):\n+        \"\"\"forward.\n+\n+        Args:\n+            points_xyz (Tensor): (B, N, 3) xyz coordinates of the features.\n+            features (Tensor): (B, C, N) features of each point.\n+                Default: None.\n+            indices (Tensor): (B, num_point) Index of the features.\n+                Default: None.\n+            target_xyz (Tensor): (B, M, 3) new_xyz coordinates of the outputs.\n+\n+        Returns:\n+            Tensor: (B, M, 3) where M is the number of points.\n+                New features xyz.\n+            Tensor: (B, M, sum_k(mlps[k][-1])) where M is the number\n+                of points. New feature descriptors.\n+            Tensor: (B, M) where M is the number of points.\n+                Index of the features.\n+        \"\"\"\n+        new_features_list = []\n+\n+        # sample points, (B, num_point, 3), (B, num_point)\n+        new_xyz, indices = self._sample_points(points_xyz, features, indices,\n+                                               target_xyz)\n+\n         for i in range(len(self.groupers)):\n-            # (B, C, num_point, nsample)\n-            new_features = self.groupers[i](points_xyz, new_xyz, features)\n+            # grouped_results may contain:\n+            # - grouped_features: (B, C, num_point, nsample)\n+            # - grouped_xyz: (B, 3, num_point, nsample)\n+            # - grouped_idx: (B, num_point, nsample)\n+            grouped_results = self.groupers[i](points_xyz, new_xyz, features)\n \n             # (B, mlp[-1], num_point, nsample)\n-            new_features = self.mlps[i](new_features)\n-            if self.pool_mod == 'max':\n-                # (B, mlp[-1], num_point, 1)\n-                new_features = F.max_pool2d(\n-                    new_features, kernel_size=[1, new_features.size(3)])\n-            elif self.pool_mod == 'avg':\n-                # (B, mlp[-1], num_point, 1)\n-                new_features = F.avg_pool2d(\n-                    new_features, kernel_size=[1, new_features.size(3)])\n-            else:\n-                raise NotImplementedError\n-\n-            new_features = new_features.squeeze(-1)  # (B, mlp[-1], num_point)\n+            new_features = self.mlps[i](grouped_results)\n+\n+            # this is a bit hack because PAConv outputs two values\n+            # we take the first one as feature\n+            if isinstance(self.mlps[i][0], PAConv):\n+                assert isinstance(new_features, tuple)\n+                new_features = new_features[0]\n+\n+            # (B, mlp[-1], num_point)\n+            new_features = self._pool_features(new_features)\n             new_features_list.append(new_features)\n",
        "source_code_with_indent": "\n        <DED>for i in range(len(self.groupers)):\n            # (B, C, num_point, nsample)\n            <IND>new_features = self.groupers[i](points_xyz, new_xyz, features)\n\n            # (B, mlp[-1], num_point, nsample)\n            new_features = self.mlps[i](new_features)\n            if self.pool_mod == 'max':\n                # (B, mlp[-1], num_point, 1)\n                <IND>new_features = F.max_pool2d(\n                    new_features, kernel_size=[1, new_features.size(3)])\n            <DED>elif self.pool_mod == 'avg':\n                # (B, mlp[-1], num_point, 1)\n                <IND>new_features = F.avg_pool2d(\n                    new_features, kernel_size=[1, new_features.size(3)])\n            <DED>else:\n                <IND>raise NotImplementedError\n\n            <DED>new_features = new_features.squeeze(-1)  # (B, mlp[-1], num_point)\n            new_features_list.append(new_features)\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n        <DED>return new_xyz, indices\n\n    <DED>def _pool_features(self, features):\n        <IND>\"\"\"Perform feature aggregation using pooling operation.\n\n        Args:\n            features (torch.Tensor): (B, C, N, K)\n                Features of locally grouped points before pooling.\n\n        Returns:\n            torch.Tensor: (B, C, N)\n                Pooled features aggregating local information.\n        \"\"\"\n        if self.pool_mod == 'max':\n            # (B, C, N, 1)\n            <IND>new_features = F.max_pool2d(\n                features, kernel_size=[1, features.size(3)])\n        <DED>elif self.pool_mod == 'avg':\n            # (B, C, N, 1)\n            <IND>new_features = F.avg_pool2d(\n                features, kernel_size=[1, features.size(3)])\n        <DED>else:\n            <IND>raise NotImplementedError\n\n        <DED>return new_features.squeeze(-1).contiguous()\n\n    <DED>def forward(\n        self,\n        points_xyz,\n        features=None,\n        indices=None,\n        target_xyz=None,\n    ):\n        <IND>\"\"\"forward.\n\n        Args:\n            points_xyz (Tensor): (B, N, 3) xyz coordinates of the features.\n            features (Tensor): (B, C, N) features of each point.\n                Default: None.\n            indices (Tensor): (B, num_point) Index of the features.\n                Default: None.\n            target_xyz (Tensor): (B, M, 3) new_xyz coordinates of the outputs.\n\n        Returns:\n            Tensor: (B, M, 3) where M is the number of points.\n                New features xyz.\n            Tensor: (B, M, sum_k(mlps[k][-1])) where M is the number\n                of points. New feature descriptors.\n            Tensor: (B, M) where M is the number of points.\n                Index of the features.\n        \"\"\"\n        new_features_list = []\n\n        # sample points, (B, num_point, 3), (B, num_point)\n        new_xyz, indices = self._sample_points(points_xyz, features, indices,\n                                               target_xyz)\n\n        for i in range(len(self.groupers)):\n            # grouped_results may contain:\n            # - grouped_features: (B, C, num_point, nsample)\n            # - grouped_xyz: (B, 3, num_point, nsample)\n            # - grouped_idx: (B, num_point, nsample)\n            <IND>grouped_results = self.groupers[i](points_xyz, new_xyz, features)\n\n            # (B, mlp[-1], num_point, nsample)\n            new_features = self.mlps[i](grouped_results)\n\n            # this is a bit hack because PAConv outputs two values\n            # we take the first one as feature\n            if isinstance(self.mlps[i][0], PAConv):\n                <IND>assert isinstance(new_features, tuple)\n                new_features = new_features[0]\n\n            # (B, mlp[-1], num_point)\n            <DED>new_features = self._pool_features(new_features)\n            new_features_list.append(new_features)\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "open-mmlab/mmdetection3d",
    "commit": "b07fb946e0b409bc88590247b5a40f31d94254aa",
    "filename": "mmdet3d/ops/pointnet_modules/point_sa_module.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/open-mmlab-mmdetection3d/mmdet3d/ops/pointnet_modules/point_sa_module.py",
    "file_hunks_size": 14,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "mmdet3d/ops/pointnet_modules/point_sa_module.py:211:17 Incompatible variable type [9]: num_point is declared to have type `int` but is used as type `None`.",
    "message": " num_point is declared to have type `int` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 211,
    "warning_line": "                 num_point: int = None,",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    def __init__(self,\n                 mlp_channels: List[int],\n                 num_point: int = None,\n                 radius: float = None,\n                 num_sample: int = None,\n                 norm_cfg: dict = dict(type='BN2d'),\n                 use_xyz: bool = True,\n                 pool_mod: str = 'max',\n                 fps_mod: List[str] = ['D-FPS'],\n                 fps_sample_range_list: List[int] = [-1],\n                 normalize_xyz: bool = False):\n        super().__init__(\n            mlp_channels=[mlp_channels],\n",
        "source_code_len": 538,
        "target_code": "    def __init__(self,\n                 mlp_channels,\n                 num_point=None,\n                 radius=None,\n                 num_sample=None,\n                 norm_cfg=dict(type='BN2d'),\n                 use_xyz=True,\n                 pool_mod='max',\n                 fps_mod=['D-FPS'],\n                 fps_sample_range_list=[-1],\n                 normalize_xyz=False):\n        super(PointSAModule, self).__init__(\n            mlp_channels=[mlp_channels],\n",
        "target_code_len": 466,
        "diff_format": "@@ -209,13 +320,13 @@\n     def __init__(self,\n-                 mlp_channels: List[int],\n-                 num_point: int = None,\n-                 radius: float = None,\n-                 num_sample: int = None,\n-                 norm_cfg: dict = dict(type='BN2d'),\n-                 use_xyz: bool = True,\n-                 pool_mod: str = 'max',\n-                 fps_mod: List[str] = ['D-FPS'],\n-                 fps_sample_range_list: List[int] = [-1],\n-                 normalize_xyz: bool = False):\n-        super().__init__(\n+                 mlp_channels,\n+                 num_point=None,\n+                 radius=None,\n+                 num_sample=None,\n+                 norm_cfg=dict(type='BN2d'),\n+                 use_xyz=True,\n+                 pool_mod='max',\n+                 fps_mod=['D-FPS'],\n+                 fps_sample_range_list=[-1],\n+                 normalize_xyz=False):\n+        super(PointSAModule, self).__init__(\n             mlp_channels=[mlp_channels],\n",
        "source_code_with_indent": "    def __init__(self,\n                 mlp_channels: List[int],\n                 num_point: int = None,\n                 radius: float = None,\n                 num_sample: int = None,\n                 norm_cfg: dict = dict(type='BN2d'),\n                 use_xyz: bool = True,\n                 pool_mod: str = 'max',\n                 fps_mod: List[str] = ['D-FPS'],\n                 fps_sample_range_list: List[int] = [-1],\n                 normalize_xyz: bool = False):\n        <IND>super().__init__(\n            mlp_channels=[mlp_channels],\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    def __init__(self,\n                 mlp_channels,\n                 num_point=None,\n                 radius=None,\n                 num_sample=None,\n                 norm_cfg=dict(type='BN2d'),\n                 use_xyz=True,\n                 pool_mod='max',\n                 fps_mod=['D-FPS'],\n                 fps_sample_range_list=[-1],\n                 normalize_xyz=False):\n        <IND>super(PointSAModule, self).__init__(\n            mlp_channels=[mlp_channels],\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "open-mmlab/mmdetection3d",
    "commit": "b07fb946e0b409bc88590247b5a40f31d94254aa",
    "filename": "mmdet3d/ops/pointnet_modules/point_sa_module.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/open-mmlab-mmdetection3d/mmdet3d/ops/pointnet_modules/point_sa_module.py",
    "file_hunks_size": 14,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "mmdet3d/ops/pointnet_modules/point_sa_module.py:212:17 Incompatible variable type [9]: radius is declared to have type `float` but is used as type `None`.",
    "message": " radius is declared to have type `float` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 212,
    "warning_line": "                 radius: float = None,",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    def __init__(self,\n                 mlp_channels: List[int],\n                 num_point: int = None,\n                 radius: float = None,\n                 num_sample: int = None,\n                 norm_cfg: dict = dict(type='BN2d'),\n                 use_xyz: bool = True,\n                 pool_mod: str = 'max',\n                 fps_mod: List[str] = ['D-FPS'],\n                 fps_sample_range_list: List[int] = [-1],\n                 normalize_xyz: bool = False):\n        super().__init__(\n            mlp_channels=[mlp_channels],\n",
        "source_code_len": 538,
        "target_code": "    def __init__(self,\n                 mlp_channels,\n                 num_point=None,\n                 radius=None,\n                 num_sample=None,\n                 norm_cfg=dict(type='BN2d'),\n                 use_xyz=True,\n                 pool_mod='max',\n                 fps_mod=['D-FPS'],\n                 fps_sample_range_list=[-1],\n                 normalize_xyz=False):\n        super(PointSAModule, self).__init__(\n            mlp_channels=[mlp_channels],\n",
        "target_code_len": 466,
        "diff_format": "@@ -209,13 +320,13 @@\n     def __init__(self,\n-                 mlp_channels: List[int],\n-                 num_point: int = None,\n-                 radius: float = None,\n-                 num_sample: int = None,\n-                 norm_cfg: dict = dict(type='BN2d'),\n-                 use_xyz: bool = True,\n-                 pool_mod: str = 'max',\n-                 fps_mod: List[str] = ['D-FPS'],\n-                 fps_sample_range_list: List[int] = [-1],\n-                 normalize_xyz: bool = False):\n-        super().__init__(\n+                 mlp_channels,\n+                 num_point=None,\n+                 radius=None,\n+                 num_sample=None,\n+                 norm_cfg=dict(type='BN2d'),\n+                 use_xyz=True,\n+                 pool_mod='max',\n+                 fps_mod=['D-FPS'],\n+                 fps_sample_range_list=[-1],\n+                 normalize_xyz=False):\n+        super(PointSAModule, self).__init__(\n             mlp_channels=[mlp_channels],\n",
        "source_code_with_indent": "    def __init__(self,\n                 mlp_channels: List[int],\n                 num_point: int = None,\n                 radius: float = None,\n                 num_sample: int = None,\n                 norm_cfg: dict = dict(type='BN2d'),\n                 use_xyz: bool = True,\n                 pool_mod: str = 'max',\n                 fps_mod: List[str] = ['D-FPS'],\n                 fps_sample_range_list: List[int] = [-1],\n                 normalize_xyz: bool = False):\n        <IND>super().__init__(\n            mlp_channels=[mlp_channels],\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    def __init__(self,\n                 mlp_channels,\n                 num_point=None,\n                 radius=None,\n                 num_sample=None,\n                 norm_cfg=dict(type='BN2d'),\n                 use_xyz=True,\n                 pool_mod='max',\n                 fps_mod=['D-FPS'],\n                 fps_sample_range_list=[-1],\n                 normalize_xyz=False):\n        <IND>super(PointSAModule, self).__init__(\n            mlp_channels=[mlp_channels],\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "open-mmlab/mmdetection3d",
    "commit": "b07fb946e0b409bc88590247b5a40f31d94254aa",
    "filename": "mmdet3d/ops/pointnet_modules/point_sa_module.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/open-mmlab-mmdetection3d/mmdet3d/ops/pointnet_modules/point_sa_module.py",
    "file_hunks_size": 14,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "mmdet3d/ops/pointnet_modules/point_sa_module.py:213:17 Incompatible variable type [9]: num_sample is declared to have type `int` but is used as type `None`.",
    "message": " num_sample is declared to have type `int` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 213,
    "warning_line": "                 num_sample: int = None,",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    def __init__(self,\n                 mlp_channels: List[int],\n                 num_point: int = None,\n                 radius: float = None,\n                 num_sample: int = None,\n                 norm_cfg: dict = dict(type='BN2d'),\n                 use_xyz: bool = True,\n                 pool_mod: str = 'max',\n                 fps_mod: List[str] = ['D-FPS'],\n                 fps_sample_range_list: List[int] = [-1],\n                 normalize_xyz: bool = False):\n        super().__init__(\n            mlp_channels=[mlp_channels],\n",
        "source_code_len": 538,
        "target_code": "    def __init__(self,\n                 mlp_channels,\n                 num_point=None,\n                 radius=None,\n                 num_sample=None,\n                 norm_cfg=dict(type='BN2d'),\n                 use_xyz=True,\n                 pool_mod='max',\n                 fps_mod=['D-FPS'],\n                 fps_sample_range_list=[-1],\n                 normalize_xyz=False):\n        super(PointSAModule, self).__init__(\n            mlp_channels=[mlp_channels],\n",
        "target_code_len": 466,
        "diff_format": "@@ -209,13 +320,13 @@\n     def __init__(self,\n-                 mlp_channels: List[int],\n-                 num_point: int = None,\n-                 radius: float = None,\n-                 num_sample: int = None,\n-                 norm_cfg: dict = dict(type='BN2d'),\n-                 use_xyz: bool = True,\n-                 pool_mod: str = 'max',\n-                 fps_mod: List[str] = ['D-FPS'],\n-                 fps_sample_range_list: List[int] = [-1],\n-                 normalize_xyz: bool = False):\n-        super().__init__(\n+                 mlp_channels,\n+                 num_point=None,\n+                 radius=None,\n+                 num_sample=None,\n+                 norm_cfg=dict(type='BN2d'),\n+                 use_xyz=True,\n+                 pool_mod='max',\n+                 fps_mod=['D-FPS'],\n+                 fps_sample_range_list=[-1],\n+                 normalize_xyz=False):\n+        super(PointSAModule, self).__init__(\n             mlp_channels=[mlp_channels],\n",
        "source_code_with_indent": "    def __init__(self,\n                 mlp_channels: List[int],\n                 num_point: int = None,\n                 radius: float = None,\n                 num_sample: int = None,\n                 norm_cfg: dict = dict(type='BN2d'),\n                 use_xyz: bool = True,\n                 pool_mod: str = 'max',\n                 fps_mod: List[str] = ['D-FPS'],\n                 fps_sample_range_list: List[int] = [-1],\n                 normalize_xyz: bool = False):\n        <IND>super().__init__(\n            mlp_channels=[mlp_channels],\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    def __init__(self,\n                 mlp_channels,\n                 num_point=None,\n                 radius=None,\n                 num_sample=None,\n                 norm_cfg=dict(type='BN2d'),\n                 use_xyz=True,\n                 pool_mod='max',\n                 fps_mod=['D-FPS'],\n                 fps_sample_range_list=[-1],\n                 normalize_xyz=False):\n        <IND>super(PointSAModule, self).__init__(\n            mlp_channels=[mlp_channels],\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  }
]