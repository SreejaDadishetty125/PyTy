[
  {
    "project": "tensorlayer/TensorLayer",
    "commit": "6f539ad2324ddccc18b6ac39e4a2f4aeb12173a2",
    "filename": "tests/test_layers_core.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/tensorlayer-TensorLayer/tests/test_layers_core.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "tests/test_layers_core.py:27:0 Incompatible variable type [9]: net is declared to have type `tl.layers.core.InputLayer` but is used as type `tl.layers.core.OneHotInputLayer`.",
    "message": " net is declared to have type `tl.layers.core.InputLayer` but is used as type `tl.layers.core.OneHotInputLayer`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 27,
    "warning_line": "net = tl.layers.OneHotInputLayer(x, depth=8, name='onehot')",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import tensorflow as tf\n",
        "source_code_len": 24,
        "target_code": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_len": 87,
        "diff_format": "@@ -1,1 +1,5 @@\n+#!/usr/bin/env python\n+# -*- coding: utf-8 -*-\n+import unittest\n+\n import tensorflow as tf\n",
        "source_code_with_indent": "import tensorflow as tf\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n## DenseLayer\nx = tf.placeholder(tf.float32, shape=[None, 30])\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=10, name='dense')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 10:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 1:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 2:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 310:\n    raise Exception(\"params do not match\")\n\n## OneHotInputLayer\nx = tf.placeholder(tf.int32, shape=[None])\nnet = tl.layers.OneHotInputLayer(x, depth=8, name='onehot')\nprint(net)\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 8:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 0:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 0:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 0:\n    raise Exception(\"params do not match\")\n\n## Word2vecEmbeddingInputlayer\nbatch_size = 8\ntrain_inputs = tf.placeholder(tf.int32, shape=(batch_size))\ntrain_labels = tf.placeholder(tf.int32, shape=(batch_size, 1))\nnet = tl.layers.Word2vecEmbeddingInputlayer(\n    inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\ncost = net.nce_cost\ntrain_params = net.all_params\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [8, 200]:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 1:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 3:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 401000:\n    raise Exception(\"params do not match\")\n\n## EmbeddingInputlayer\nbatch_size = 8\nx = tf.placeholder(tf.int32, shape=(batch_size, ))\nnet = tl.layers.EmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='embed')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [batch_size, 50]:  # (8, 50)\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 1:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 1:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 50000:\n    raise Exception(\"params do not match\")\n\n## AverageEmbeddingInputlayer\nbatch_size = 8\nlength = 5\nx = tf.placeholder(tf.int32, shape=(batch_size, length))\nnet = tl.layers.AverageEmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='avg')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [batch_size, 50]:  # (8, 50)\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 1:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 1:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 50000:\n    raise Exception(\"params do not match\")\n\n## ReconLayer\nx = tf.placeholder(tf.float32, shape=(None, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=196, act=tf.nn.sigmoid, name='dense2')\nnet = tl.layers.ReconLayer(net, x_recon=x, n_units=784, act=tf.nn.sigmoid, name='recon')\n# sess = tf.InteractiveSession()\n# tl.layers.initialize_global_variables(sess)\n# X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n# net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 784:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 2:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 4:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 308308:\n    raise Exception(\"params do not match\")\n\n## GaussianNoiseLayer\nx = tf.placeholder(tf.float32, shape=(64, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense3')\nnet = tl.layers.GaussianNoiseLayer(net, name='gaussian')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [64, 100]:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 2:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 2:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 78500:\n    raise Exception(\"params do not match\")\n\n## DropconnectDenseLayer\nx = tf.placeholder(tf.float32, shape=(64, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense4')\nnet = tl.layers.DropconnectDenseLayer(net, keep=0.8, name='dropconnect')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [64, 100]:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 2:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 4:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 88600:\n    raise Exception(\"params do not match\")\n",
        "source_code_len": 5232,
        "target_code": "\n\nclass Layer_Core_Test(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n\n        cls.batch_size = 8\n\n        # ============== DenseLayer ==============\n\n        x1 = tf.placeholder(tf.float32, shape=[None, 30])\n        net1 = tl.layers.InputLayer(x1, name='input')\n        net1 = tl.layers.DenseLayer(net1, n_units=10, name='dense')\n\n        net1.print_layers()\n        net1.print_params(False)\n\n        cls.net1_shape = net1.outputs.get_shape().as_list()\n        cls.net1_layers = net1.all_layers\n        cls.net1_params = net1.all_params\n        cls.net1_n_params = net1.count_params()\n\n        # ============== OneHotInputLayer ==============\n\n        x2 = tf.placeholder(tf.int32, shape=[None])\n        net2 = tl.layers.OneHotInputLayer(x2, depth=8, name='onehot')\n\n        net2.print_layers()\n        net2.print_params(False)\n\n        cls.net2_shape = net2.outputs.get_shape().as_list()\n        cls.net2_layers = net2.all_layers\n        cls.net2_params = net2.all_params\n        cls.net2_n_params = net2.count_params()\n\n        # ============== Word2vecEmbeddingInputlayer ==============\n\n        train_inputs = tf.placeholder(tf.int32, shape=cls.batch_size)\n        train_labels = tf.placeholder(tf.int32, shape=(cls.batch_size, 1))\n        net3 = tl.layers.Word2vecEmbeddingInputlayer(\n            inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\n\n        net3.print_layers()\n        net3.print_params(False)\n\n        cls.net3_shape = net3.outputs.get_shape().as_list()\n        cls.net3_layers = net3.all_layers\n        cls.net3_params = net3.all_params\n        cls.net3_n_params = net3.count_params()\n\n        # ============== EmbeddingInputlayer ==============\n\n        x4 = tf.placeholder(tf.int32, shape=(cls.batch_size, ))\n        net4 = tl.layers.EmbeddingInputlayer(inputs=x4, vocabulary_size=1000, embedding_size=50, name='embed')\n\n        net4.print_layers()\n        net4.print_params(False)\n\n        cls.net4_shape = net4.outputs.get_shape().as_list()\n        cls.net4_layers = net4.all_layers\n        cls.net4_params = net4.all_params\n        cls.net4_n_params = net4.count_params()\n\n        # ============== AverageEmbeddingInputlayer ==============\n\n        length = 5\n        x5 = tf.placeholder(tf.int32, shape=(cls.batch_size, length))\n        net5 = tl.layers.AverageEmbeddingInputlayer(inputs=x5, vocabulary_size=1000, embedding_size=50, name='avg')\n\n        net5.print_layers()\n        net5.print_params(False)\n\n        cls.net5_shape = net5.outputs.get_shape().as_list()\n        cls.net5_layers = net5.all_layers\n        cls.net5_params = net5.all_params\n        cls.net5_n_params = net5.count_params()\n\n        # ============== ReconLayer ==============\n\n        x6 = tf.placeholder(tf.float32, shape=(None, 784))\n        net6 = tl.layers.InputLayer(x6, name='input')\n        net6 = tl.layers.DenseLayer(net6, n_units=196, act=tf.nn.sigmoid, name='dense2')\n        net6 = tl.layers.ReconLayer(net6, x_recon=x6, n_units=784, act=tf.nn.sigmoid, name='recon')\n\n        # sess = tf.InteractiveSession()\n        # tl.layers.initialize_global_variables(sess)\n        # X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n        # net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n\n        net6.print_layers()\n        net6.print_params(False)\n\n        cls.net6_shape = net6.outputs.get_shape().as_list()\n        cls.net6_layers = net6.all_layers\n        cls.net6_params = net6.all_params\n        cls.net6_n_params = net6.count_params()\n\n        # ============== GaussianNoiseLayer ==============\n\n        x7 = tf.placeholder(tf.float32, shape=(64, 784))\n        net7 = tl.layers.InputLayer(x7, name='input')\n        net7 = tl.layers.DenseLayer(net7, n_units=100, act=tf.nn.relu, name='dense3')\n        net7 = tl.layers.GaussianNoiseLayer(net7, name='gaussian')\n\n        net7.print_layers()\n        net7.print_params(False)\n\n        cls.net7_shape = net7.outputs.get_shape().as_list()\n        cls.net7_layers = net7.all_layers\n        cls.net7_params = net7.all_params\n        cls.net7_n_params = net7.count_params()\n\n        # ============== DropconnectDenseLayer ==============\n\n        x8 = tf.placeholder(tf.float32, shape=(64, 784))\n        net8 = tl.layers.InputLayer(x8, name='input')\n        net8 = tl.layers.DenseLayer(net8, n_units=100, act=tf.nn.relu, name='dense4')\n        net8 = tl.layers.DropconnectDenseLayer(net8, keep=0.8, name='dropconnect')\n\n        net8.print_layers()\n        net8.print_params(False)\n\n        cls.net8_shape = net8.outputs.get_shape().as_list()\n        cls.net8_layers = net8.all_layers\n        cls.net8_params = net8.all_params\n        cls.net8_n_params = net8.count_params()\n\n    @classmethod\n    def tearDownClass(cls):\n        tf.reset_default_graph()\n\n    def test_net1(self):\n        self.assertEqual(self.net1_shape[-1], 10)\n        self.assertEqual(len(self.net1_layers), 1)\n        self.assertEqual(len(self.net1_params), 2)\n        self.assertEqual(self.net1_n_params, 310)\n\n    def test_net2(self):\n        self.assertEqual(self.net2_shape[-1], 8)\n        self.assertEqual(len(self.net2_layers), 0)\n        self.assertEqual(len(self.net2_params), 0)\n        self.assertEqual(self.net2_n_params, 0)\n\n    def test_net3(self):\n        self.assertEqual(self.net3_shape, [self.batch_size, 200])\n        self.assertEqual(len(self.net3_layers), 1)\n        self.assertEqual(len(self.net3_params), 3)\n        self.assertEqual(self.net3_n_params, 401000)\n\n    def test_net4(self):\n        self.assertEqual(self.net4_shape, [self.batch_size, 50])\n        self.assertEqual(len(self.net4_layers), 1)\n        self.assertEqual(len(self.net4_params), 1)\n        self.assertEqual(self.net4_n_params, 50000)\n\n    def test_net5(self):\n        self.assertEqual(self.net5_shape, [self.batch_size, 50])\n        self.assertEqual(len(self.net5_layers), 1)\n        self.assertEqual(len(self.net5_params), 1)\n        self.assertEqual(self.net5_n_params, 50000)\n\n    def test_net6(self):\n        self.assertEqual(self.net6_shape[-1], 784)\n        self.assertEqual(len(self.net6_layers), 2)\n        self.assertEqual(len(self.net6_params), 4)\n        self.assertEqual(self.net6_n_params, 308308)\n\n    def test_net7(self):\n        self.assertEqual(self.net7_shape, [64, 100])\n        self.assertEqual(len(self.net7_layers), 2)\n        self.assertEqual(len(self.net7_params), 2)\n        self.assertEqual(self.net7_n_params, 78500)\n\n    def test_net8(self):\n        self.assertEqual(self.net8_shape, [64, 100])\n        self.assertEqual(len(self.net8_layers), 2)\n        self.assertEqual(len(self.net8_params), 4)\n        self.assertEqual(self.net8_n_params, 88600)\n\n\nif __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_len": 6975,
        "diff_format": "@@ -3,180 +7,186 @@\n \n-## DenseLayer\n-x = tf.placeholder(tf.float32, shape=[None, 30])\n-net = tl.layers.InputLayer(x, name='input')\n-net = tl.layers.DenseLayer(net, n_units=10, name='dense')\n \n-net.print_layers()\n-net.print_params(False)\n+class Layer_Core_Test(unittest.TestCase):\n+    @classmethod\n+    def setUpClass(cls):\n \n-shape = net.outputs.get_shape().as_list()\n-if shape[-1] != 10:\n-    raise Exception(\"shape do not match\")\n+        cls.batch_size = 8\n \n-if len(net.all_layers) != 1:\n-    raise Exception(\"layers do not match\")\n+        # ============== DenseLayer ==============\n \n-if len(net.all_params) != 2:\n-    raise Exception(\"params do not match\")\n+        x1 = tf.placeholder(tf.float32, shape=[None, 30])\n+        net1 = tl.layers.InputLayer(x1, name='input')\n+        net1 = tl.layers.DenseLayer(net1, n_units=10, name='dense')\n \n-if net.count_params() != 310:\n-    raise Exception(\"params do not match\")\n+        net1.print_layers()\n+        net1.print_params(False)\n \n-## OneHotInputLayer\n-x = tf.placeholder(tf.int32, shape=[None])\n-net = tl.layers.OneHotInputLayer(x, depth=8, name='onehot')\n-print(net)\n+        cls.net1_shape = net1.outputs.get_shape().as_list()\n+        cls.net1_layers = net1.all_layers\n+        cls.net1_params = net1.all_params\n+        cls.net1_n_params = net1.count_params()\n \n-net.print_layers()\n-net.print_params(False)\n+        # ============== OneHotInputLayer ==============\n \n-shape = net.outputs.get_shape().as_list()\n-if shape[-1] != 8:\n-    raise Exception(\"shape do not match\")\n+        x2 = tf.placeholder(tf.int32, shape=[None])\n+        net2 = tl.layers.OneHotInputLayer(x2, depth=8, name='onehot')\n \n-if len(net.all_layers) != 0:\n-    raise Exception(\"layers do not match\")\n+        net2.print_layers()\n+        net2.print_params(False)\n \n-if len(net.all_params) != 0:\n-    raise Exception(\"params do not match\")\n+        cls.net2_shape = net2.outputs.get_shape().as_list()\n+        cls.net2_layers = net2.all_layers\n+        cls.net2_params = net2.all_params\n+        cls.net2_n_params = net2.count_params()\n \n-if net.count_params() != 0:\n-    raise Exception(\"params do not match\")\n+        # ============== Word2vecEmbeddingInputlayer ==============\n \n-## Word2vecEmbeddingInputlayer\n-batch_size = 8\n-train_inputs = tf.placeholder(tf.int32, shape=(batch_size))\n-train_labels = tf.placeholder(tf.int32, shape=(batch_size, 1))\n-net = tl.layers.Word2vecEmbeddingInputlayer(\n-    inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\n-cost = net.nce_cost\n-train_params = net.all_params\n+        train_inputs = tf.placeholder(tf.int32, shape=cls.batch_size)\n+        train_labels = tf.placeholder(tf.int32, shape=(cls.batch_size, 1))\n+        net3 = tl.layers.Word2vecEmbeddingInputlayer(\n+            inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\n \n-net.print_layers()\n-net.print_params(False)\n+        net3.print_layers()\n+        net3.print_params(False)\n \n-shape = net.outputs.get_shape().as_list()\n-if shape != [8, 200]:\n-    raise Exception(\"shape do not match\")\n+        cls.net3_shape = net3.outputs.get_shape().as_list()\n+        cls.net3_layers = net3.all_layers\n+        cls.net3_params = net3.all_params\n+        cls.net3_n_params = net3.count_params()\n \n-if len(net.all_layers) != 1:\n-    raise Exception(\"layers do not match\")\n+        # ============== EmbeddingInputlayer ==============\n \n-if len(net.all_params) != 3:\n-    raise Exception(\"params do not match\")\n+        x4 = tf.placeholder(tf.int32, shape=(cls.batch_size, ))\n+        net4 = tl.layers.EmbeddingInputlayer(inputs=x4, vocabulary_size=1000, embedding_size=50, name='embed')\n \n-if net.count_params() != 401000:\n-    raise Exception(\"params do not match\")\n+        net4.print_layers()\n+        net4.print_params(False)\n \n-## EmbeddingInputlayer\n-batch_size = 8\n-x = tf.placeholder(tf.int32, shape=(batch_size, ))\n-net = tl.layers.EmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='embed')\n+        cls.net4_shape = net4.outputs.get_shape().as_list()\n+        cls.net4_layers = net4.all_layers\n+        cls.net4_params = net4.all_params\n+        cls.net4_n_params = net4.count_params()\n \n-net.print_layers()\n-net.print_params(False)\n+        # ============== AverageEmbeddingInputlayer ==============\n \n-shape = net.outputs.get_shape().as_list()\n-if shape != [batch_size, 50]:  # (8, 50)\n-    raise Exception(\"shape do not match\")\n+        length = 5\n+        x5 = tf.placeholder(tf.int32, shape=(cls.batch_size, length))\n+        net5 = tl.layers.AverageEmbeddingInputlayer(inputs=x5, vocabulary_size=1000, embedding_size=50, name='avg')\n \n-if len(net.all_layers) != 1:\n-    raise Exception(\"layers do not match\")\n+        net5.print_layers()\n+        net5.print_params(False)\n \n-if len(net.all_params) != 1:\n-    raise Exception(\"params do not match\")\n+        cls.net5_shape = net5.outputs.get_shape().as_list()\n+        cls.net5_layers = net5.all_layers\n+        cls.net5_params = net5.all_params\n+        cls.net5_n_params = net5.count_params()\n \n-if net.count_params() != 50000:\n-    raise Exception(\"params do not match\")\n+        # ============== ReconLayer ==============\n \n-## AverageEmbeddingInputlayer\n-batch_size = 8\n-length = 5\n-x = tf.placeholder(tf.int32, shape=(batch_size, length))\n-net = tl.layers.AverageEmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='avg')\n+        x6 = tf.placeholder(tf.float32, shape=(None, 784))\n+        net6 = tl.layers.InputLayer(x6, name='input')\n+        net6 = tl.layers.DenseLayer(net6, n_units=196, act=tf.nn.sigmoid, name='dense2')\n+        net6 = tl.layers.ReconLayer(net6, x_recon=x6, n_units=784, act=tf.nn.sigmoid, name='recon')\n \n-net.print_layers()\n-net.print_params(False)\n+        # sess = tf.InteractiveSession()\n+        # tl.layers.initialize_global_variables(sess)\n+        # X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n+        # net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n \n-shape = net.outputs.get_shape().as_list()\n-if shape != [batch_size, 50]:  # (8, 50)\n-    raise Exception(\"shape do not match\")\n+        net6.print_layers()\n+        net6.print_params(False)\n \n-if len(net.all_layers) != 1:\n-    raise Exception(\"layers do not match\")\n+        cls.net6_shape = net6.outputs.get_shape().as_list()\n+        cls.net6_layers = net6.all_layers\n+        cls.net6_params = net6.all_params\n+        cls.net6_n_params = net6.count_params()\n \n-if len(net.all_params) != 1:\n-    raise Exception(\"params do not match\")\n+        # ============== GaussianNoiseLayer ==============\n \n-if net.count_params() != 50000:\n-    raise Exception(\"params do not match\")\n+        x7 = tf.placeholder(tf.float32, shape=(64, 784))\n+        net7 = tl.layers.InputLayer(x7, name='input')\n+        net7 = tl.layers.DenseLayer(net7, n_units=100, act=tf.nn.relu, name='dense3')\n+        net7 = tl.layers.GaussianNoiseLayer(net7, name='gaussian')\n \n-## ReconLayer\n-x = tf.placeholder(tf.float32, shape=(None, 784))\n-net = tl.layers.InputLayer(x, name='input')\n-net = tl.layers.DenseLayer(net, n_units=196, act=tf.nn.sigmoid, name='dense2')\n-net = tl.layers.ReconLayer(net, x_recon=x, n_units=784, act=tf.nn.sigmoid, name='recon')\n-# sess = tf.InteractiveSession()\n-# tl.layers.initialize_global_variables(sess)\n-# X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n-# net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n+        net7.print_layers()\n+        net7.print_params(False)\n \n-net.print_layers()\n-net.print_params(False)\n+        cls.net7_shape = net7.outputs.get_shape().as_list()\n+        cls.net7_layers = net7.all_layers\n+        cls.net7_params = net7.all_params\n+        cls.net7_n_params = net7.count_params()\n \n-shape = net.outputs.get_shape().as_list()\n-if shape[-1] != 784:\n-    raise Exception(\"shape do not match\")\n+        # ============== DropconnectDenseLayer ==============\n \n-if len(net.all_layers) != 2:\n-    raise Exception(\"layers do not match\")\n+        x8 = tf.placeholder(tf.float32, shape=(64, 784))\n+        net8 = tl.layers.InputLayer(x8, name='input')\n+        net8 = tl.layers.DenseLayer(net8, n_units=100, act=tf.nn.relu, name='dense4')\n+        net8 = tl.layers.DropconnectDenseLayer(net8, keep=0.8, name='dropconnect')\n \n-if len(net.all_params) != 4:\n-    raise Exception(\"params do not match\")\n+        net8.print_layers()\n+        net8.print_params(False)\n \n-if net.count_params() != 308308:\n-    raise Exception(\"params do not match\")\n+        cls.net8_shape = net8.outputs.get_shape().as_list()\n+        cls.net8_layers = net8.all_layers\n+        cls.net8_params = net8.all_params\n+        cls.net8_n_params = net8.count_params()\n \n-## GaussianNoiseLayer\n-x = tf.placeholder(tf.float32, shape=(64, 784))\n-net = tl.layers.InputLayer(x, name='input')\n-net = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense3')\n-net = tl.layers.GaussianNoiseLayer(net, name='gaussian')\n+    @classmethod\n+    def tearDownClass(cls):\n+        tf.reset_default_graph()\n \n-net.print_layers()\n-net.print_params(False)\n+    def test_net1(self):\n+        self.assertEqual(self.net1_shape[-1], 10)\n+        self.assertEqual(len(self.net1_layers), 1)\n+        self.assertEqual(len(self.net1_params), 2)\n+        self.assertEqual(self.net1_n_params, 310)\n \n-shape = net.outputs.get_shape().as_list()\n-if shape != [64, 100]:\n-    raise Exception(\"shape do not match\")\n+    def test_net2(self):\n+        self.assertEqual(self.net2_shape[-1], 8)\n+        self.assertEqual(len(self.net2_layers), 0)\n+        self.assertEqual(len(self.net2_params), 0)\n+        self.assertEqual(self.net2_n_params, 0)\n \n-if len(net.all_layers) != 2:\n-    raise Exception(\"layers do not match\")\n+    def test_net3(self):\n+        self.assertEqual(self.net3_shape, [self.batch_size, 200])\n+        self.assertEqual(len(self.net3_layers), 1)\n+        self.assertEqual(len(self.net3_params), 3)\n+        self.assertEqual(self.net3_n_params, 401000)\n \n-if len(net.all_params) != 2:\n-    raise Exception(\"params do not match\")\n+    def test_net4(self):\n+        self.assertEqual(self.net4_shape, [self.batch_size, 50])\n+        self.assertEqual(len(self.net4_layers), 1)\n+        self.assertEqual(len(self.net4_params), 1)\n+        self.assertEqual(self.net4_n_params, 50000)\n \n-if net.count_params() != 78500:\n-    raise Exception(\"params do not match\")\n+    def test_net5(self):\n+        self.assertEqual(self.net5_shape, [self.batch_size, 50])\n+        self.assertEqual(len(self.net5_layers), 1)\n+        self.assertEqual(len(self.net5_params), 1)\n+        self.assertEqual(self.net5_n_params, 50000)\n \n-## DropconnectDenseLayer\n-x = tf.placeholder(tf.float32, shape=(64, 784))\n-net = tl.layers.InputLayer(x, name='input')\n-net = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense4')\n-net = tl.layers.DropconnectDenseLayer(net, keep=0.8, name='dropconnect')\n+    def test_net6(self):\n+        self.assertEqual(self.net6_shape[-1], 784)\n+        self.assertEqual(len(self.net6_layers), 2)\n+        self.assertEqual(len(self.net6_params), 4)\n+        self.assertEqual(self.net6_n_params, 308308)\n \n-net.print_layers()\n-net.print_params(False)\n+    def test_net7(self):\n+        self.assertEqual(self.net7_shape, [64, 100])\n+        self.assertEqual(len(self.net7_layers), 2)\n+        self.assertEqual(len(self.net7_params), 2)\n+        self.assertEqual(self.net7_n_params, 78500)\n \n-shape = net.outputs.get_shape().as_list()\n-if shape != [64, 100]:\n-    raise Exception(\"shape do not match\")\n+    def test_net8(self):\n+        self.assertEqual(self.net8_shape, [64, 100])\n+        self.assertEqual(len(self.net8_layers), 2)\n+        self.assertEqual(len(self.net8_params), 4)\n+        self.assertEqual(self.net8_n_params, 88600)\n \n-if len(net.all_layers) != 2:\n-    raise Exception(\"layers do not match\")\n \n-if len(net.all_params) != 4:\n-    raise Exception(\"params do not match\")\n+if __name__ == '__main__':\n \n-if net.count_params() != 88600:\n-    raise Exception(\"params do not match\")\n+    # tf.logging.set_verbosity(tf.logging.INFO)\n+    tf.logging.set_verbosity(tf.logging.DEBUG)\n+\n+    unittest.main()\n",
        "source_code_with_indent": "\n## DenseLayer\nx = tf.placeholder(tf.float32, shape=[None, 30])\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=10, name='dense')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 10:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 1:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 2:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 310:\n    <IND>raise Exception(\"params do not match\")\n\n## OneHotInputLayer\n<DED>x = tf.placeholder(tf.int32, shape=[None])\nnet = tl.layers.OneHotInputLayer(x, depth=8, name='onehot')\nprint(net)\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 8:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 0:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 0:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 0:\n    <IND>raise Exception(\"params do not match\")\n\n## Word2vecEmbeddingInputlayer\n<DED>batch_size = 8\ntrain_inputs = tf.placeholder(tf.int32, shape=(batch_size))\ntrain_labels = tf.placeholder(tf.int32, shape=(batch_size, 1))\nnet = tl.layers.Word2vecEmbeddingInputlayer(\n    inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\ncost = net.nce_cost\ntrain_params = net.all_params\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [8, 200]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 1:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 3:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 401000:\n    <IND>raise Exception(\"params do not match\")\n\n## EmbeddingInputlayer\n<DED>batch_size = 8\nx = tf.placeholder(tf.int32, shape=(batch_size, ))\nnet = tl.layers.EmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='embed')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [batch_size, 50]:  # (8, 50)\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 1:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 1:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 50000:\n    <IND>raise Exception(\"params do not match\")\n\n## AverageEmbeddingInputlayer\n<DED>batch_size = 8\nlength = 5\nx = tf.placeholder(tf.int32, shape=(batch_size, length))\nnet = tl.layers.AverageEmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='avg')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [batch_size, 50]:  # (8, 50)\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 1:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 1:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 50000:\n    <IND>raise Exception(\"params do not match\")\n\n## ReconLayer\n<DED>x = tf.placeholder(tf.float32, shape=(None, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=196, act=tf.nn.sigmoid, name='dense2')\nnet = tl.layers.ReconLayer(net, x_recon=x, n_units=784, act=tf.nn.sigmoid, name='recon')\n# sess = tf.InteractiveSession()\n# tl.layers.initialize_global_variables(sess)\n# X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n# net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 784:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 2:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 4:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 308308:\n    <IND>raise Exception(\"params do not match\")\n\n## GaussianNoiseLayer\n<DED>x = tf.placeholder(tf.float32, shape=(64, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense3')\nnet = tl.layers.GaussianNoiseLayer(net, name='gaussian')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [64, 100]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 2:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 2:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 78500:\n    <IND>raise Exception(\"params do not match\")\n\n## DropconnectDenseLayer\n<DED>x = tf.placeholder(tf.float32, shape=(64, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense4')\nnet = tl.layers.DropconnectDenseLayer(net, keep=0.8, name='dropconnect')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [64, 100]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 2:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 4:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 88600:\n    <IND>raise Exception(\"params do not match\")\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n\nclass Layer_Core_Test(unittest.TestCase):\n    <IND>@classmethod\n    def setUpClass(cls):\n\n        <IND>cls.batch_size = 8\n\n        # ============== DenseLayer ==============\n\n        x1 = tf.placeholder(tf.float32, shape=[None, 30])\n        net1 = tl.layers.InputLayer(x1, name='input')\n        net1 = tl.layers.DenseLayer(net1, n_units=10, name='dense')\n\n        net1.print_layers()\n        net1.print_params(False)\n\n        cls.net1_shape = net1.outputs.get_shape().as_list()\n        cls.net1_layers = net1.all_layers\n        cls.net1_params = net1.all_params\n        cls.net1_n_params = net1.count_params()\n\n        # ============== OneHotInputLayer ==============\n\n        x2 = tf.placeholder(tf.int32, shape=[None])\n        net2 = tl.layers.OneHotInputLayer(x2, depth=8, name='onehot')\n\n        net2.print_layers()\n        net2.print_params(False)\n\n        cls.net2_shape = net2.outputs.get_shape().as_list()\n        cls.net2_layers = net2.all_layers\n        cls.net2_params = net2.all_params\n        cls.net2_n_params = net2.count_params()\n\n        # ============== Word2vecEmbeddingInputlayer ==============\n\n        train_inputs = tf.placeholder(tf.int32, shape=cls.batch_size)\n        train_labels = tf.placeholder(tf.int32, shape=(cls.batch_size, 1))\n        net3 = tl.layers.Word2vecEmbeddingInputlayer(\n            inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\n\n        net3.print_layers()\n        net3.print_params(False)\n\n        cls.net3_shape = net3.outputs.get_shape().as_list()\n        cls.net3_layers = net3.all_layers\n        cls.net3_params = net3.all_params\n        cls.net3_n_params = net3.count_params()\n\n        # ============== EmbeddingInputlayer ==============\n\n        x4 = tf.placeholder(tf.int32, shape=(cls.batch_size, ))\n        net4 = tl.layers.EmbeddingInputlayer(inputs=x4, vocabulary_size=1000, embedding_size=50, name='embed')\n\n        net4.print_layers()\n        net4.print_params(False)\n\n        cls.net4_shape = net4.outputs.get_shape().as_list()\n        cls.net4_layers = net4.all_layers\n        cls.net4_params = net4.all_params\n        cls.net4_n_params = net4.count_params()\n\n        # ============== AverageEmbeddingInputlayer ==============\n\n        length = 5\n        x5 = tf.placeholder(tf.int32, shape=(cls.batch_size, length))\n        net5 = tl.layers.AverageEmbeddingInputlayer(inputs=x5, vocabulary_size=1000, embedding_size=50, name='avg')\n\n        net5.print_layers()\n        net5.print_params(False)\n\n        cls.net5_shape = net5.outputs.get_shape().as_list()\n        cls.net5_layers = net5.all_layers\n        cls.net5_params = net5.all_params\n        cls.net5_n_params = net5.count_params()\n\n        # ============== ReconLayer ==============\n\n        x6 = tf.placeholder(tf.float32, shape=(None, 784))\n        net6 = tl.layers.InputLayer(x6, name='input')\n        net6 = tl.layers.DenseLayer(net6, n_units=196, act=tf.nn.sigmoid, name='dense2')\n        net6 = tl.layers.ReconLayer(net6, x_recon=x6, n_units=784, act=tf.nn.sigmoid, name='recon')\n\n        # sess = tf.InteractiveSession()\n        # tl.layers.initialize_global_variables(sess)\n        # X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n        # net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n\n        net6.print_layers()\n        net6.print_params(False)\n\n        cls.net6_shape = net6.outputs.get_shape().as_list()\n        cls.net6_layers = net6.all_layers\n        cls.net6_params = net6.all_params\n        cls.net6_n_params = net6.count_params()\n\n        # ============== GaussianNoiseLayer ==============\n\n        x7 = tf.placeholder(tf.float32, shape=(64, 784))\n        net7 = tl.layers.InputLayer(x7, name='input')\n        net7 = tl.layers.DenseLayer(net7, n_units=100, act=tf.nn.relu, name='dense3')\n        net7 = tl.layers.GaussianNoiseLayer(net7, name='gaussian')\n\n        net7.print_layers()\n        net7.print_params(False)\n\n        cls.net7_shape = net7.outputs.get_shape().as_list()\n        cls.net7_layers = net7.all_layers\n        cls.net7_params = net7.all_params\n        cls.net7_n_params = net7.count_params()\n\n        # ============== DropconnectDenseLayer ==============\n\n        x8 = tf.placeholder(tf.float32, shape=(64, 784))\n        net8 = tl.layers.InputLayer(x8, name='input')\n        net8 = tl.layers.DenseLayer(net8, n_units=100, act=tf.nn.relu, name='dense4')\n        net8 = tl.layers.DropconnectDenseLayer(net8, keep=0.8, name='dropconnect')\n\n        net8.print_layers()\n        net8.print_params(False)\n\n        cls.net8_shape = net8.outputs.get_shape().as_list()\n        cls.net8_layers = net8.all_layers\n        cls.net8_params = net8.all_params\n        cls.net8_n_params = net8.count_params()\n\n    <DED>@classmethod\n    def tearDownClass(cls):\n        <IND>tf.reset_default_graph()\n\n    <DED>def test_net1(self):\n        <IND>self.assertEqual(self.net1_shape[-1], 10)\n        self.assertEqual(len(self.net1_layers), 1)\n        self.assertEqual(len(self.net1_params), 2)\n        self.assertEqual(self.net1_n_params, 310)\n\n    <DED>def test_net2(self):\n        <IND>self.assertEqual(self.net2_shape[-1], 8)\n        self.assertEqual(len(self.net2_layers), 0)\n        self.assertEqual(len(self.net2_params), 0)\n        self.assertEqual(self.net2_n_params, 0)\n\n    <DED>def test_net3(self):\n        <IND>self.assertEqual(self.net3_shape, [self.batch_size, 200])\n        self.assertEqual(len(self.net3_layers), 1)\n        self.assertEqual(len(self.net3_params), 3)\n        self.assertEqual(self.net3_n_params, 401000)\n\n    <DED>def test_net4(self):\n        <IND>self.assertEqual(self.net4_shape, [self.batch_size, 50])\n        self.assertEqual(len(self.net4_layers), 1)\n        self.assertEqual(len(self.net4_params), 1)\n        self.assertEqual(self.net4_n_params, 50000)\n\n    <DED>def test_net5(self):\n        <IND>self.assertEqual(self.net5_shape, [self.batch_size, 50])\n        self.assertEqual(len(self.net5_layers), 1)\n        self.assertEqual(len(self.net5_params), 1)\n        self.assertEqual(self.net5_n_params, 50000)\n\n    <DED>def test_net6(self):\n        <IND>self.assertEqual(self.net6_shape[-1], 784)\n        self.assertEqual(len(self.net6_layers), 2)\n        self.assertEqual(len(self.net6_params), 4)\n        self.assertEqual(self.net6_n_params, 308308)\n\n    <DED>def test_net7(self):\n        <IND>self.assertEqual(self.net7_shape, [64, 100])\n        self.assertEqual(len(self.net7_layers), 2)\n        self.assertEqual(len(self.net7_params), 2)\n        self.assertEqual(self.net7_n_params, 78500)\n\n    <DED>def test_net8(self):\n        <IND>self.assertEqual(self.net8_shape, [64, 100])\n        self.assertEqual(len(self.net8_layers), 2)\n        self.assertEqual(len(self.net8_params), 4)\n        self.assertEqual(self.net8_n_params, 88600)\n\n\n<DED><DED>if __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    <IND>tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "tensorlayer/TensorLayer",
    "commit": "6f539ad2324ddccc18b6ac39e4a2f4aeb12173a2",
    "filename": "tests/test_layers_core.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/tensorlayer-TensorLayer/tests/test_layers_core.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "tests/test_layers_core.py:50:0 Incompatible variable type [9]: net is declared to have type `tl.layers.core.InputLayer` but is used as type `tl.layers.core.Word2vecEmbeddingInputlayer`.",
    "message": " net is declared to have type `tl.layers.core.InputLayer` but is used as type `tl.layers.core.Word2vecEmbeddingInputlayer`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 50,
    "warning_line": "net = tl.layers.Word2vecEmbeddingInputlayer(",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import tensorflow as tf\n",
        "source_code_len": 24,
        "target_code": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_len": 87,
        "diff_format": "@@ -1,1 +1,5 @@\n+#!/usr/bin/env python\n+# -*- coding: utf-8 -*-\n+import unittest\n+\n import tensorflow as tf\n",
        "source_code_with_indent": "import tensorflow as tf\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n## DenseLayer\nx = tf.placeholder(tf.float32, shape=[None, 30])\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=10, name='dense')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 10:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 1:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 2:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 310:\n    raise Exception(\"params do not match\")\n\n## OneHotInputLayer\nx = tf.placeholder(tf.int32, shape=[None])\nnet = tl.layers.OneHotInputLayer(x, depth=8, name='onehot')\nprint(net)\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 8:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 0:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 0:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 0:\n    raise Exception(\"params do not match\")\n\n## Word2vecEmbeddingInputlayer\nbatch_size = 8\ntrain_inputs = tf.placeholder(tf.int32, shape=(batch_size))\ntrain_labels = tf.placeholder(tf.int32, shape=(batch_size, 1))\nnet = tl.layers.Word2vecEmbeddingInputlayer(\n    inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\ncost = net.nce_cost\ntrain_params = net.all_params\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [8, 200]:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 1:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 3:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 401000:\n    raise Exception(\"params do not match\")\n\n## EmbeddingInputlayer\nbatch_size = 8\nx = tf.placeholder(tf.int32, shape=(batch_size, ))\nnet = tl.layers.EmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='embed')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [batch_size, 50]:  # (8, 50)\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 1:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 1:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 50000:\n    raise Exception(\"params do not match\")\n\n## AverageEmbeddingInputlayer\nbatch_size = 8\nlength = 5\nx = tf.placeholder(tf.int32, shape=(batch_size, length))\nnet = tl.layers.AverageEmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='avg')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [batch_size, 50]:  # (8, 50)\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 1:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 1:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 50000:\n    raise Exception(\"params do not match\")\n\n## ReconLayer\nx = tf.placeholder(tf.float32, shape=(None, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=196, act=tf.nn.sigmoid, name='dense2')\nnet = tl.layers.ReconLayer(net, x_recon=x, n_units=784, act=tf.nn.sigmoid, name='recon')\n# sess = tf.InteractiveSession()\n# tl.layers.initialize_global_variables(sess)\n# X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n# net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 784:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 2:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 4:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 308308:\n    raise Exception(\"params do not match\")\n\n## GaussianNoiseLayer\nx = tf.placeholder(tf.float32, shape=(64, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense3')\nnet = tl.layers.GaussianNoiseLayer(net, name='gaussian')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [64, 100]:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 2:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 2:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 78500:\n    raise Exception(\"params do not match\")\n\n## DropconnectDenseLayer\nx = tf.placeholder(tf.float32, shape=(64, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense4')\nnet = tl.layers.DropconnectDenseLayer(net, keep=0.8, name='dropconnect')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [64, 100]:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 2:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 4:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 88600:\n    raise Exception(\"params do not match\")\n",
        "source_code_len": 5232,
        "target_code": "\n\nclass Layer_Core_Test(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n\n        cls.batch_size = 8\n\n        # ============== DenseLayer ==============\n\n        x1 = tf.placeholder(tf.float32, shape=[None, 30])\n        net1 = tl.layers.InputLayer(x1, name='input')\n        net1 = tl.layers.DenseLayer(net1, n_units=10, name='dense')\n\n        net1.print_layers()\n        net1.print_params(False)\n\n        cls.net1_shape = net1.outputs.get_shape().as_list()\n        cls.net1_layers = net1.all_layers\n        cls.net1_params = net1.all_params\n        cls.net1_n_params = net1.count_params()\n\n        # ============== OneHotInputLayer ==============\n\n        x2 = tf.placeholder(tf.int32, shape=[None])\n        net2 = tl.layers.OneHotInputLayer(x2, depth=8, name='onehot')\n\n        net2.print_layers()\n        net2.print_params(False)\n\n        cls.net2_shape = net2.outputs.get_shape().as_list()\n        cls.net2_layers = net2.all_layers\n        cls.net2_params = net2.all_params\n        cls.net2_n_params = net2.count_params()\n\n        # ============== Word2vecEmbeddingInputlayer ==============\n\n        train_inputs = tf.placeholder(tf.int32, shape=cls.batch_size)\n        train_labels = tf.placeholder(tf.int32, shape=(cls.batch_size, 1))\n        net3 = tl.layers.Word2vecEmbeddingInputlayer(\n            inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\n\n        net3.print_layers()\n        net3.print_params(False)\n\n        cls.net3_shape = net3.outputs.get_shape().as_list()\n        cls.net3_layers = net3.all_layers\n        cls.net3_params = net3.all_params\n        cls.net3_n_params = net3.count_params()\n\n        # ============== EmbeddingInputlayer ==============\n\n        x4 = tf.placeholder(tf.int32, shape=(cls.batch_size, ))\n        net4 = tl.layers.EmbeddingInputlayer(inputs=x4, vocabulary_size=1000, embedding_size=50, name='embed')\n\n        net4.print_layers()\n        net4.print_params(False)\n\n        cls.net4_shape = net4.outputs.get_shape().as_list()\n        cls.net4_layers = net4.all_layers\n        cls.net4_params = net4.all_params\n        cls.net4_n_params = net4.count_params()\n\n        # ============== AverageEmbeddingInputlayer ==============\n\n        length = 5\n        x5 = tf.placeholder(tf.int32, shape=(cls.batch_size, length))\n        net5 = tl.layers.AverageEmbeddingInputlayer(inputs=x5, vocabulary_size=1000, embedding_size=50, name='avg')\n\n        net5.print_layers()\n        net5.print_params(False)\n\n        cls.net5_shape = net5.outputs.get_shape().as_list()\n        cls.net5_layers = net5.all_layers\n        cls.net5_params = net5.all_params\n        cls.net5_n_params = net5.count_params()\n\n        # ============== ReconLayer ==============\n\n        x6 = tf.placeholder(tf.float32, shape=(None, 784))\n        net6 = tl.layers.InputLayer(x6, name='input')\n        net6 = tl.layers.DenseLayer(net6, n_units=196, act=tf.nn.sigmoid, name='dense2')\n        net6 = tl.layers.ReconLayer(net6, x_recon=x6, n_units=784, act=tf.nn.sigmoid, name='recon')\n\n        # sess = tf.InteractiveSession()\n        # tl.layers.initialize_global_variables(sess)\n        # X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n        # net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n\n        net6.print_layers()\n        net6.print_params(False)\n\n        cls.net6_shape = net6.outputs.get_shape().as_list()\n        cls.net6_layers = net6.all_layers\n        cls.net6_params = net6.all_params\n        cls.net6_n_params = net6.count_params()\n\n        # ============== GaussianNoiseLayer ==============\n\n        x7 = tf.placeholder(tf.float32, shape=(64, 784))\n        net7 = tl.layers.InputLayer(x7, name='input')\n        net7 = tl.layers.DenseLayer(net7, n_units=100, act=tf.nn.relu, name='dense3')\n        net7 = tl.layers.GaussianNoiseLayer(net7, name='gaussian')\n\n        net7.print_layers()\n        net7.print_params(False)\n\n        cls.net7_shape = net7.outputs.get_shape().as_list()\n        cls.net7_layers = net7.all_layers\n        cls.net7_params = net7.all_params\n        cls.net7_n_params = net7.count_params()\n\n        # ============== DropconnectDenseLayer ==============\n\n        x8 = tf.placeholder(tf.float32, shape=(64, 784))\n        net8 = tl.layers.InputLayer(x8, name='input')\n        net8 = tl.layers.DenseLayer(net8, n_units=100, act=tf.nn.relu, name='dense4')\n        net8 = tl.layers.DropconnectDenseLayer(net8, keep=0.8, name='dropconnect')\n\n        net8.print_layers()\n        net8.print_params(False)\n\n        cls.net8_shape = net8.outputs.get_shape().as_list()\n        cls.net8_layers = net8.all_layers\n        cls.net8_params = net8.all_params\n        cls.net8_n_params = net8.count_params()\n\n    @classmethod\n    def tearDownClass(cls):\n        tf.reset_default_graph()\n\n    def test_net1(self):\n        self.assertEqual(self.net1_shape[-1], 10)\n        self.assertEqual(len(self.net1_layers), 1)\n        self.assertEqual(len(self.net1_params), 2)\n        self.assertEqual(self.net1_n_params, 310)\n\n    def test_net2(self):\n        self.assertEqual(self.net2_shape[-1], 8)\n        self.assertEqual(len(self.net2_layers), 0)\n        self.assertEqual(len(self.net2_params), 0)\n        self.assertEqual(self.net2_n_params, 0)\n\n    def test_net3(self):\n        self.assertEqual(self.net3_shape, [self.batch_size, 200])\n        self.assertEqual(len(self.net3_layers), 1)\n        self.assertEqual(len(self.net3_params), 3)\n        self.assertEqual(self.net3_n_params, 401000)\n\n    def test_net4(self):\n        self.assertEqual(self.net4_shape, [self.batch_size, 50])\n        self.assertEqual(len(self.net4_layers), 1)\n        self.assertEqual(len(self.net4_params), 1)\n        self.assertEqual(self.net4_n_params, 50000)\n\n    def test_net5(self):\n        self.assertEqual(self.net5_shape, [self.batch_size, 50])\n        self.assertEqual(len(self.net5_layers), 1)\n        self.assertEqual(len(self.net5_params), 1)\n        self.assertEqual(self.net5_n_params, 50000)\n\n    def test_net6(self):\n        self.assertEqual(self.net6_shape[-1], 784)\n        self.assertEqual(len(self.net6_layers), 2)\n        self.assertEqual(len(self.net6_params), 4)\n        self.assertEqual(self.net6_n_params, 308308)\n\n    def test_net7(self):\n        self.assertEqual(self.net7_shape, [64, 100])\n        self.assertEqual(len(self.net7_layers), 2)\n        self.assertEqual(len(self.net7_params), 2)\n        self.assertEqual(self.net7_n_params, 78500)\n\n    def test_net8(self):\n        self.assertEqual(self.net8_shape, [64, 100])\n        self.assertEqual(len(self.net8_layers), 2)\n        self.assertEqual(len(self.net8_params), 4)\n        self.assertEqual(self.net8_n_params, 88600)\n\n\nif __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_len": 6975,
        "diff_format": "@@ -3,180 +7,186 @@\n \n-## DenseLayer\n-x = tf.placeholder(tf.float32, shape=[None, 30])\n-net = tl.layers.InputLayer(x, name='input')\n-net = tl.layers.DenseLayer(net, n_units=10, name='dense')\n \n-net.print_layers()\n-net.print_params(False)\n+class Layer_Core_Test(unittest.TestCase):\n+    @classmethod\n+    def setUpClass(cls):\n \n-shape = net.outputs.get_shape().as_list()\n-if shape[-1] != 10:\n-    raise Exception(\"shape do not match\")\n+        cls.batch_size = 8\n \n-if len(net.all_layers) != 1:\n-    raise Exception(\"layers do not match\")\n+        # ============== DenseLayer ==============\n \n-if len(net.all_params) != 2:\n-    raise Exception(\"params do not match\")\n+        x1 = tf.placeholder(tf.float32, shape=[None, 30])\n+        net1 = tl.layers.InputLayer(x1, name='input')\n+        net1 = tl.layers.DenseLayer(net1, n_units=10, name='dense')\n \n-if net.count_params() != 310:\n-    raise Exception(\"params do not match\")\n+        net1.print_layers()\n+        net1.print_params(False)\n \n-## OneHotInputLayer\n-x = tf.placeholder(tf.int32, shape=[None])\n-net = tl.layers.OneHotInputLayer(x, depth=8, name='onehot')\n-print(net)\n+        cls.net1_shape = net1.outputs.get_shape().as_list()\n+        cls.net1_layers = net1.all_layers\n+        cls.net1_params = net1.all_params\n+        cls.net1_n_params = net1.count_params()\n \n-net.print_layers()\n-net.print_params(False)\n+        # ============== OneHotInputLayer ==============\n \n-shape = net.outputs.get_shape().as_list()\n-if shape[-1] != 8:\n-    raise Exception(\"shape do not match\")\n+        x2 = tf.placeholder(tf.int32, shape=[None])\n+        net2 = tl.layers.OneHotInputLayer(x2, depth=8, name='onehot')\n \n-if len(net.all_layers) != 0:\n-    raise Exception(\"layers do not match\")\n+        net2.print_layers()\n+        net2.print_params(False)\n \n-if len(net.all_params) != 0:\n-    raise Exception(\"params do not match\")\n+        cls.net2_shape = net2.outputs.get_shape().as_list()\n+        cls.net2_layers = net2.all_layers\n+        cls.net2_params = net2.all_params\n+        cls.net2_n_params = net2.count_params()\n \n-if net.count_params() != 0:\n-    raise Exception(\"params do not match\")\n+        # ============== Word2vecEmbeddingInputlayer ==============\n \n-## Word2vecEmbeddingInputlayer\n-batch_size = 8\n-train_inputs = tf.placeholder(tf.int32, shape=(batch_size))\n-train_labels = tf.placeholder(tf.int32, shape=(batch_size, 1))\n-net = tl.layers.Word2vecEmbeddingInputlayer(\n-    inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\n-cost = net.nce_cost\n-train_params = net.all_params\n+        train_inputs = tf.placeholder(tf.int32, shape=cls.batch_size)\n+        train_labels = tf.placeholder(tf.int32, shape=(cls.batch_size, 1))\n+        net3 = tl.layers.Word2vecEmbeddingInputlayer(\n+            inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\n \n-net.print_layers()\n-net.print_params(False)\n+        net3.print_layers()\n+        net3.print_params(False)\n \n-shape = net.outputs.get_shape().as_list()\n-if shape != [8, 200]:\n-    raise Exception(\"shape do not match\")\n+        cls.net3_shape = net3.outputs.get_shape().as_list()\n+        cls.net3_layers = net3.all_layers\n+        cls.net3_params = net3.all_params\n+        cls.net3_n_params = net3.count_params()\n \n-if len(net.all_layers) != 1:\n-    raise Exception(\"layers do not match\")\n+        # ============== EmbeddingInputlayer ==============\n \n-if len(net.all_params) != 3:\n-    raise Exception(\"params do not match\")\n+        x4 = tf.placeholder(tf.int32, shape=(cls.batch_size, ))\n+        net4 = tl.layers.EmbeddingInputlayer(inputs=x4, vocabulary_size=1000, embedding_size=50, name='embed')\n \n-if net.count_params() != 401000:\n-    raise Exception(\"params do not match\")\n+        net4.print_layers()\n+        net4.print_params(False)\n \n-## EmbeddingInputlayer\n-batch_size = 8\n-x = tf.placeholder(tf.int32, shape=(batch_size, ))\n-net = tl.layers.EmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='embed')\n+        cls.net4_shape = net4.outputs.get_shape().as_list()\n+        cls.net4_layers = net4.all_layers\n+        cls.net4_params = net4.all_params\n+        cls.net4_n_params = net4.count_params()\n \n-net.print_layers()\n-net.print_params(False)\n+        # ============== AverageEmbeddingInputlayer ==============\n \n-shape = net.outputs.get_shape().as_list()\n-if shape != [batch_size, 50]:  # (8, 50)\n-    raise Exception(\"shape do not match\")\n+        length = 5\n+        x5 = tf.placeholder(tf.int32, shape=(cls.batch_size, length))\n+        net5 = tl.layers.AverageEmbeddingInputlayer(inputs=x5, vocabulary_size=1000, embedding_size=50, name='avg')\n \n-if len(net.all_layers) != 1:\n-    raise Exception(\"layers do not match\")\n+        net5.print_layers()\n+        net5.print_params(False)\n \n-if len(net.all_params) != 1:\n-    raise Exception(\"params do not match\")\n+        cls.net5_shape = net5.outputs.get_shape().as_list()\n+        cls.net5_layers = net5.all_layers\n+        cls.net5_params = net5.all_params\n+        cls.net5_n_params = net5.count_params()\n \n-if net.count_params() != 50000:\n-    raise Exception(\"params do not match\")\n+        # ============== ReconLayer ==============\n \n-## AverageEmbeddingInputlayer\n-batch_size = 8\n-length = 5\n-x = tf.placeholder(tf.int32, shape=(batch_size, length))\n-net = tl.layers.AverageEmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='avg')\n+        x6 = tf.placeholder(tf.float32, shape=(None, 784))\n+        net6 = tl.layers.InputLayer(x6, name='input')\n+        net6 = tl.layers.DenseLayer(net6, n_units=196, act=tf.nn.sigmoid, name='dense2')\n+        net6 = tl.layers.ReconLayer(net6, x_recon=x6, n_units=784, act=tf.nn.sigmoid, name='recon')\n \n-net.print_layers()\n-net.print_params(False)\n+        # sess = tf.InteractiveSession()\n+        # tl.layers.initialize_global_variables(sess)\n+        # X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n+        # net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n \n-shape = net.outputs.get_shape().as_list()\n-if shape != [batch_size, 50]:  # (8, 50)\n-    raise Exception(\"shape do not match\")\n+        net6.print_layers()\n+        net6.print_params(False)\n \n-if len(net.all_layers) != 1:\n-    raise Exception(\"layers do not match\")\n+        cls.net6_shape = net6.outputs.get_shape().as_list()\n+        cls.net6_layers = net6.all_layers\n+        cls.net6_params = net6.all_params\n+        cls.net6_n_params = net6.count_params()\n \n-if len(net.all_params) != 1:\n-    raise Exception(\"params do not match\")\n+        # ============== GaussianNoiseLayer ==============\n \n-if net.count_params() != 50000:\n-    raise Exception(\"params do not match\")\n+        x7 = tf.placeholder(tf.float32, shape=(64, 784))\n+        net7 = tl.layers.InputLayer(x7, name='input')\n+        net7 = tl.layers.DenseLayer(net7, n_units=100, act=tf.nn.relu, name='dense3')\n+        net7 = tl.layers.GaussianNoiseLayer(net7, name='gaussian')\n \n-## ReconLayer\n-x = tf.placeholder(tf.float32, shape=(None, 784))\n-net = tl.layers.InputLayer(x, name='input')\n-net = tl.layers.DenseLayer(net, n_units=196, act=tf.nn.sigmoid, name='dense2')\n-net = tl.layers.ReconLayer(net, x_recon=x, n_units=784, act=tf.nn.sigmoid, name='recon')\n-# sess = tf.InteractiveSession()\n-# tl.layers.initialize_global_variables(sess)\n-# X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n-# net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n+        net7.print_layers()\n+        net7.print_params(False)\n \n-net.print_layers()\n-net.print_params(False)\n+        cls.net7_shape = net7.outputs.get_shape().as_list()\n+        cls.net7_layers = net7.all_layers\n+        cls.net7_params = net7.all_params\n+        cls.net7_n_params = net7.count_params()\n \n-shape = net.outputs.get_shape().as_list()\n-if shape[-1] != 784:\n-    raise Exception(\"shape do not match\")\n+        # ============== DropconnectDenseLayer ==============\n \n-if len(net.all_layers) != 2:\n-    raise Exception(\"layers do not match\")\n+        x8 = tf.placeholder(tf.float32, shape=(64, 784))\n+        net8 = tl.layers.InputLayer(x8, name='input')\n+        net8 = tl.layers.DenseLayer(net8, n_units=100, act=tf.nn.relu, name='dense4')\n+        net8 = tl.layers.DropconnectDenseLayer(net8, keep=0.8, name='dropconnect')\n \n-if len(net.all_params) != 4:\n-    raise Exception(\"params do not match\")\n+        net8.print_layers()\n+        net8.print_params(False)\n \n-if net.count_params() != 308308:\n-    raise Exception(\"params do not match\")\n+        cls.net8_shape = net8.outputs.get_shape().as_list()\n+        cls.net8_layers = net8.all_layers\n+        cls.net8_params = net8.all_params\n+        cls.net8_n_params = net8.count_params()\n \n-## GaussianNoiseLayer\n-x = tf.placeholder(tf.float32, shape=(64, 784))\n-net = tl.layers.InputLayer(x, name='input')\n-net = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense3')\n-net = tl.layers.GaussianNoiseLayer(net, name='gaussian')\n+    @classmethod\n+    def tearDownClass(cls):\n+        tf.reset_default_graph()\n \n-net.print_layers()\n-net.print_params(False)\n+    def test_net1(self):\n+        self.assertEqual(self.net1_shape[-1], 10)\n+        self.assertEqual(len(self.net1_layers), 1)\n+        self.assertEqual(len(self.net1_params), 2)\n+        self.assertEqual(self.net1_n_params, 310)\n \n-shape = net.outputs.get_shape().as_list()\n-if shape != [64, 100]:\n-    raise Exception(\"shape do not match\")\n+    def test_net2(self):\n+        self.assertEqual(self.net2_shape[-1], 8)\n+        self.assertEqual(len(self.net2_layers), 0)\n+        self.assertEqual(len(self.net2_params), 0)\n+        self.assertEqual(self.net2_n_params, 0)\n \n-if len(net.all_layers) != 2:\n-    raise Exception(\"layers do not match\")\n+    def test_net3(self):\n+        self.assertEqual(self.net3_shape, [self.batch_size, 200])\n+        self.assertEqual(len(self.net3_layers), 1)\n+        self.assertEqual(len(self.net3_params), 3)\n+        self.assertEqual(self.net3_n_params, 401000)\n \n-if len(net.all_params) != 2:\n-    raise Exception(\"params do not match\")\n+    def test_net4(self):\n+        self.assertEqual(self.net4_shape, [self.batch_size, 50])\n+        self.assertEqual(len(self.net4_layers), 1)\n+        self.assertEqual(len(self.net4_params), 1)\n+        self.assertEqual(self.net4_n_params, 50000)\n \n-if net.count_params() != 78500:\n-    raise Exception(\"params do not match\")\n+    def test_net5(self):\n+        self.assertEqual(self.net5_shape, [self.batch_size, 50])\n+        self.assertEqual(len(self.net5_layers), 1)\n+        self.assertEqual(len(self.net5_params), 1)\n+        self.assertEqual(self.net5_n_params, 50000)\n \n-## DropconnectDenseLayer\n-x = tf.placeholder(tf.float32, shape=(64, 784))\n-net = tl.layers.InputLayer(x, name='input')\n-net = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense4')\n-net = tl.layers.DropconnectDenseLayer(net, keep=0.8, name='dropconnect')\n+    def test_net6(self):\n+        self.assertEqual(self.net6_shape[-1], 784)\n+        self.assertEqual(len(self.net6_layers), 2)\n+        self.assertEqual(len(self.net6_params), 4)\n+        self.assertEqual(self.net6_n_params, 308308)\n \n-net.print_layers()\n-net.print_params(False)\n+    def test_net7(self):\n+        self.assertEqual(self.net7_shape, [64, 100])\n+        self.assertEqual(len(self.net7_layers), 2)\n+        self.assertEqual(len(self.net7_params), 2)\n+        self.assertEqual(self.net7_n_params, 78500)\n \n-shape = net.outputs.get_shape().as_list()\n-if shape != [64, 100]:\n-    raise Exception(\"shape do not match\")\n+    def test_net8(self):\n+        self.assertEqual(self.net8_shape, [64, 100])\n+        self.assertEqual(len(self.net8_layers), 2)\n+        self.assertEqual(len(self.net8_params), 4)\n+        self.assertEqual(self.net8_n_params, 88600)\n \n-if len(net.all_layers) != 2:\n-    raise Exception(\"layers do not match\")\n \n-if len(net.all_params) != 4:\n-    raise Exception(\"params do not match\")\n+if __name__ == '__main__':\n \n-if net.count_params() != 88600:\n-    raise Exception(\"params do not match\")\n+    # tf.logging.set_verbosity(tf.logging.INFO)\n+    tf.logging.set_verbosity(tf.logging.DEBUG)\n+\n+    unittest.main()\n",
        "source_code_with_indent": "\n## DenseLayer\nx = tf.placeholder(tf.float32, shape=[None, 30])\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=10, name='dense')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 10:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 1:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 2:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 310:\n    <IND>raise Exception(\"params do not match\")\n\n## OneHotInputLayer\n<DED>x = tf.placeholder(tf.int32, shape=[None])\nnet = tl.layers.OneHotInputLayer(x, depth=8, name='onehot')\nprint(net)\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 8:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 0:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 0:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 0:\n    <IND>raise Exception(\"params do not match\")\n\n## Word2vecEmbeddingInputlayer\n<DED>batch_size = 8\ntrain_inputs = tf.placeholder(tf.int32, shape=(batch_size))\ntrain_labels = tf.placeholder(tf.int32, shape=(batch_size, 1))\nnet = tl.layers.Word2vecEmbeddingInputlayer(\n    inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\ncost = net.nce_cost\ntrain_params = net.all_params\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [8, 200]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 1:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 3:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 401000:\n    <IND>raise Exception(\"params do not match\")\n\n## EmbeddingInputlayer\n<DED>batch_size = 8\nx = tf.placeholder(tf.int32, shape=(batch_size, ))\nnet = tl.layers.EmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='embed')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [batch_size, 50]:  # (8, 50)\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 1:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 1:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 50000:\n    <IND>raise Exception(\"params do not match\")\n\n## AverageEmbeddingInputlayer\n<DED>batch_size = 8\nlength = 5\nx = tf.placeholder(tf.int32, shape=(batch_size, length))\nnet = tl.layers.AverageEmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='avg')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [batch_size, 50]:  # (8, 50)\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 1:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 1:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 50000:\n    <IND>raise Exception(\"params do not match\")\n\n## ReconLayer\n<DED>x = tf.placeholder(tf.float32, shape=(None, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=196, act=tf.nn.sigmoid, name='dense2')\nnet = tl.layers.ReconLayer(net, x_recon=x, n_units=784, act=tf.nn.sigmoid, name='recon')\n# sess = tf.InteractiveSession()\n# tl.layers.initialize_global_variables(sess)\n# X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n# net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 784:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 2:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 4:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 308308:\n    <IND>raise Exception(\"params do not match\")\n\n## GaussianNoiseLayer\n<DED>x = tf.placeholder(tf.float32, shape=(64, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense3')\nnet = tl.layers.GaussianNoiseLayer(net, name='gaussian')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [64, 100]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 2:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 2:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 78500:\n    <IND>raise Exception(\"params do not match\")\n\n## DropconnectDenseLayer\n<DED>x = tf.placeholder(tf.float32, shape=(64, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense4')\nnet = tl.layers.DropconnectDenseLayer(net, keep=0.8, name='dropconnect')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [64, 100]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 2:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 4:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 88600:\n    <IND>raise Exception(\"params do not match\")\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n\nclass Layer_Core_Test(unittest.TestCase):\n    <IND>@classmethod\n    def setUpClass(cls):\n\n        <IND>cls.batch_size = 8\n\n        # ============== DenseLayer ==============\n\n        x1 = tf.placeholder(tf.float32, shape=[None, 30])\n        net1 = tl.layers.InputLayer(x1, name='input')\n        net1 = tl.layers.DenseLayer(net1, n_units=10, name='dense')\n\n        net1.print_layers()\n        net1.print_params(False)\n\n        cls.net1_shape = net1.outputs.get_shape().as_list()\n        cls.net1_layers = net1.all_layers\n        cls.net1_params = net1.all_params\n        cls.net1_n_params = net1.count_params()\n\n        # ============== OneHotInputLayer ==============\n\n        x2 = tf.placeholder(tf.int32, shape=[None])\n        net2 = tl.layers.OneHotInputLayer(x2, depth=8, name='onehot')\n\n        net2.print_layers()\n        net2.print_params(False)\n\n        cls.net2_shape = net2.outputs.get_shape().as_list()\n        cls.net2_layers = net2.all_layers\n        cls.net2_params = net2.all_params\n        cls.net2_n_params = net2.count_params()\n\n        # ============== Word2vecEmbeddingInputlayer ==============\n\n        train_inputs = tf.placeholder(tf.int32, shape=cls.batch_size)\n        train_labels = tf.placeholder(tf.int32, shape=(cls.batch_size, 1))\n        net3 = tl.layers.Word2vecEmbeddingInputlayer(\n            inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\n\n        net3.print_layers()\n        net3.print_params(False)\n\n        cls.net3_shape = net3.outputs.get_shape().as_list()\n        cls.net3_layers = net3.all_layers\n        cls.net3_params = net3.all_params\n        cls.net3_n_params = net3.count_params()\n\n        # ============== EmbeddingInputlayer ==============\n\n        x4 = tf.placeholder(tf.int32, shape=(cls.batch_size, ))\n        net4 = tl.layers.EmbeddingInputlayer(inputs=x4, vocabulary_size=1000, embedding_size=50, name='embed')\n\n        net4.print_layers()\n        net4.print_params(False)\n\n        cls.net4_shape = net4.outputs.get_shape().as_list()\n        cls.net4_layers = net4.all_layers\n        cls.net4_params = net4.all_params\n        cls.net4_n_params = net4.count_params()\n\n        # ============== AverageEmbeddingInputlayer ==============\n\n        length = 5\n        x5 = tf.placeholder(tf.int32, shape=(cls.batch_size, length))\n        net5 = tl.layers.AverageEmbeddingInputlayer(inputs=x5, vocabulary_size=1000, embedding_size=50, name='avg')\n\n        net5.print_layers()\n        net5.print_params(False)\n\n        cls.net5_shape = net5.outputs.get_shape().as_list()\n        cls.net5_layers = net5.all_layers\n        cls.net5_params = net5.all_params\n        cls.net5_n_params = net5.count_params()\n\n        # ============== ReconLayer ==============\n\n        x6 = tf.placeholder(tf.float32, shape=(None, 784))\n        net6 = tl.layers.InputLayer(x6, name='input')\n        net6 = tl.layers.DenseLayer(net6, n_units=196, act=tf.nn.sigmoid, name='dense2')\n        net6 = tl.layers.ReconLayer(net6, x_recon=x6, n_units=784, act=tf.nn.sigmoid, name='recon')\n\n        # sess = tf.InteractiveSession()\n        # tl.layers.initialize_global_variables(sess)\n        # X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n        # net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n\n        net6.print_layers()\n        net6.print_params(False)\n\n        cls.net6_shape = net6.outputs.get_shape().as_list()\n        cls.net6_layers = net6.all_layers\n        cls.net6_params = net6.all_params\n        cls.net6_n_params = net6.count_params()\n\n        # ============== GaussianNoiseLayer ==============\n\n        x7 = tf.placeholder(tf.float32, shape=(64, 784))\n        net7 = tl.layers.InputLayer(x7, name='input')\n        net7 = tl.layers.DenseLayer(net7, n_units=100, act=tf.nn.relu, name='dense3')\n        net7 = tl.layers.GaussianNoiseLayer(net7, name='gaussian')\n\n        net7.print_layers()\n        net7.print_params(False)\n\n        cls.net7_shape = net7.outputs.get_shape().as_list()\n        cls.net7_layers = net7.all_layers\n        cls.net7_params = net7.all_params\n        cls.net7_n_params = net7.count_params()\n\n        # ============== DropconnectDenseLayer ==============\n\n        x8 = tf.placeholder(tf.float32, shape=(64, 784))\n        net8 = tl.layers.InputLayer(x8, name='input')\n        net8 = tl.layers.DenseLayer(net8, n_units=100, act=tf.nn.relu, name='dense4')\n        net8 = tl.layers.DropconnectDenseLayer(net8, keep=0.8, name='dropconnect')\n\n        net8.print_layers()\n        net8.print_params(False)\n\n        cls.net8_shape = net8.outputs.get_shape().as_list()\n        cls.net8_layers = net8.all_layers\n        cls.net8_params = net8.all_params\n        cls.net8_n_params = net8.count_params()\n\n    <DED>@classmethod\n    def tearDownClass(cls):\n        <IND>tf.reset_default_graph()\n\n    <DED>def test_net1(self):\n        <IND>self.assertEqual(self.net1_shape[-1], 10)\n        self.assertEqual(len(self.net1_layers), 1)\n        self.assertEqual(len(self.net1_params), 2)\n        self.assertEqual(self.net1_n_params, 310)\n\n    <DED>def test_net2(self):\n        <IND>self.assertEqual(self.net2_shape[-1], 8)\n        self.assertEqual(len(self.net2_layers), 0)\n        self.assertEqual(len(self.net2_params), 0)\n        self.assertEqual(self.net2_n_params, 0)\n\n    <DED>def test_net3(self):\n        <IND>self.assertEqual(self.net3_shape, [self.batch_size, 200])\n        self.assertEqual(len(self.net3_layers), 1)\n        self.assertEqual(len(self.net3_params), 3)\n        self.assertEqual(self.net3_n_params, 401000)\n\n    <DED>def test_net4(self):\n        <IND>self.assertEqual(self.net4_shape, [self.batch_size, 50])\n        self.assertEqual(len(self.net4_layers), 1)\n        self.assertEqual(len(self.net4_params), 1)\n        self.assertEqual(self.net4_n_params, 50000)\n\n    <DED>def test_net5(self):\n        <IND>self.assertEqual(self.net5_shape, [self.batch_size, 50])\n        self.assertEqual(len(self.net5_layers), 1)\n        self.assertEqual(len(self.net5_params), 1)\n        self.assertEqual(self.net5_n_params, 50000)\n\n    <DED>def test_net6(self):\n        <IND>self.assertEqual(self.net6_shape[-1], 784)\n        self.assertEqual(len(self.net6_layers), 2)\n        self.assertEqual(len(self.net6_params), 4)\n        self.assertEqual(self.net6_n_params, 308308)\n\n    <DED>def test_net7(self):\n        <IND>self.assertEqual(self.net7_shape, [64, 100])\n        self.assertEqual(len(self.net7_layers), 2)\n        self.assertEqual(len(self.net7_params), 2)\n        self.assertEqual(self.net7_n_params, 78500)\n\n    <DED>def test_net8(self):\n        <IND>self.assertEqual(self.net8_shape, [64, 100])\n        self.assertEqual(len(self.net8_layers), 2)\n        self.assertEqual(len(self.net8_params), 4)\n        self.assertEqual(self.net8_n_params, 88600)\n\n\n<DED><DED>if __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    <IND>tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "tensorlayer/TensorLayer",
    "commit": "6f539ad2324ddccc18b6ac39e4a2f4aeb12173a2",
    "filename": "tests/test_layers_core.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/tensorlayer-TensorLayer/tests/test_layers_core.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "tests/test_layers_core.py:74:0 Incompatible variable type [9]: net is declared to have type `tl.layers.core.InputLayer` but is used as type `tl.layers.core.EmbeddingInputlayer`.",
    "message": " net is declared to have type `tl.layers.core.InputLayer` but is used as type `tl.layers.core.EmbeddingInputlayer`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 74,
    "warning_line": "net = tl.layers.EmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='embed')",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import tensorflow as tf\n",
        "source_code_len": 24,
        "target_code": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_len": 87,
        "diff_format": "@@ -1,1 +1,5 @@\n+#!/usr/bin/env python\n+# -*- coding: utf-8 -*-\n+import unittest\n+\n import tensorflow as tf\n",
        "source_code_with_indent": "import tensorflow as tf\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n## DenseLayer\nx = tf.placeholder(tf.float32, shape=[None, 30])\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=10, name='dense')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 10:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 1:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 2:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 310:\n    raise Exception(\"params do not match\")\n\n## OneHotInputLayer\nx = tf.placeholder(tf.int32, shape=[None])\nnet = tl.layers.OneHotInputLayer(x, depth=8, name='onehot')\nprint(net)\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 8:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 0:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 0:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 0:\n    raise Exception(\"params do not match\")\n\n## Word2vecEmbeddingInputlayer\nbatch_size = 8\ntrain_inputs = tf.placeholder(tf.int32, shape=(batch_size))\ntrain_labels = tf.placeholder(tf.int32, shape=(batch_size, 1))\nnet = tl.layers.Word2vecEmbeddingInputlayer(\n    inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\ncost = net.nce_cost\ntrain_params = net.all_params\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [8, 200]:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 1:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 3:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 401000:\n    raise Exception(\"params do not match\")\n\n## EmbeddingInputlayer\nbatch_size = 8\nx = tf.placeholder(tf.int32, shape=(batch_size, ))\nnet = tl.layers.EmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='embed')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [batch_size, 50]:  # (8, 50)\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 1:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 1:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 50000:\n    raise Exception(\"params do not match\")\n\n## AverageEmbeddingInputlayer\nbatch_size = 8\nlength = 5\nx = tf.placeholder(tf.int32, shape=(batch_size, length))\nnet = tl.layers.AverageEmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='avg')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [batch_size, 50]:  # (8, 50)\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 1:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 1:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 50000:\n    raise Exception(\"params do not match\")\n\n## ReconLayer\nx = tf.placeholder(tf.float32, shape=(None, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=196, act=tf.nn.sigmoid, name='dense2')\nnet = tl.layers.ReconLayer(net, x_recon=x, n_units=784, act=tf.nn.sigmoid, name='recon')\n# sess = tf.InteractiveSession()\n# tl.layers.initialize_global_variables(sess)\n# X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n# net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 784:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 2:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 4:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 308308:\n    raise Exception(\"params do not match\")\n\n## GaussianNoiseLayer\nx = tf.placeholder(tf.float32, shape=(64, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense3')\nnet = tl.layers.GaussianNoiseLayer(net, name='gaussian')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [64, 100]:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 2:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 2:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 78500:\n    raise Exception(\"params do not match\")\n\n## DropconnectDenseLayer\nx = tf.placeholder(tf.float32, shape=(64, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense4')\nnet = tl.layers.DropconnectDenseLayer(net, keep=0.8, name='dropconnect')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [64, 100]:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 2:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 4:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 88600:\n    raise Exception(\"params do not match\")\n",
        "source_code_len": 5232,
        "target_code": "\n\nclass Layer_Core_Test(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n\n        cls.batch_size = 8\n\n        # ============== DenseLayer ==============\n\n        x1 = tf.placeholder(tf.float32, shape=[None, 30])\n        net1 = tl.layers.InputLayer(x1, name='input')\n        net1 = tl.layers.DenseLayer(net1, n_units=10, name='dense')\n\n        net1.print_layers()\n        net1.print_params(False)\n\n        cls.net1_shape = net1.outputs.get_shape().as_list()\n        cls.net1_layers = net1.all_layers\n        cls.net1_params = net1.all_params\n        cls.net1_n_params = net1.count_params()\n\n        # ============== OneHotInputLayer ==============\n\n        x2 = tf.placeholder(tf.int32, shape=[None])\n        net2 = tl.layers.OneHotInputLayer(x2, depth=8, name='onehot')\n\n        net2.print_layers()\n        net2.print_params(False)\n\n        cls.net2_shape = net2.outputs.get_shape().as_list()\n        cls.net2_layers = net2.all_layers\n        cls.net2_params = net2.all_params\n        cls.net2_n_params = net2.count_params()\n\n        # ============== Word2vecEmbeddingInputlayer ==============\n\n        train_inputs = tf.placeholder(tf.int32, shape=cls.batch_size)\n        train_labels = tf.placeholder(tf.int32, shape=(cls.batch_size, 1))\n        net3 = tl.layers.Word2vecEmbeddingInputlayer(\n            inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\n\n        net3.print_layers()\n        net3.print_params(False)\n\n        cls.net3_shape = net3.outputs.get_shape().as_list()\n        cls.net3_layers = net3.all_layers\n        cls.net3_params = net3.all_params\n        cls.net3_n_params = net3.count_params()\n\n        # ============== EmbeddingInputlayer ==============\n\n        x4 = tf.placeholder(tf.int32, shape=(cls.batch_size, ))\n        net4 = tl.layers.EmbeddingInputlayer(inputs=x4, vocabulary_size=1000, embedding_size=50, name='embed')\n\n        net4.print_layers()\n        net4.print_params(False)\n\n        cls.net4_shape = net4.outputs.get_shape().as_list()\n        cls.net4_layers = net4.all_layers\n        cls.net4_params = net4.all_params\n        cls.net4_n_params = net4.count_params()\n\n        # ============== AverageEmbeddingInputlayer ==============\n\n        length = 5\n        x5 = tf.placeholder(tf.int32, shape=(cls.batch_size, length))\n        net5 = tl.layers.AverageEmbeddingInputlayer(inputs=x5, vocabulary_size=1000, embedding_size=50, name='avg')\n\n        net5.print_layers()\n        net5.print_params(False)\n\n        cls.net5_shape = net5.outputs.get_shape().as_list()\n        cls.net5_layers = net5.all_layers\n        cls.net5_params = net5.all_params\n        cls.net5_n_params = net5.count_params()\n\n        # ============== ReconLayer ==============\n\n        x6 = tf.placeholder(tf.float32, shape=(None, 784))\n        net6 = tl.layers.InputLayer(x6, name='input')\n        net6 = tl.layers.DenseLayer(net6, n_units=196, act=tf.nn.sigmoid, name='dense2')\n        net6 = tl.layers.ReconLayer(net6, x_recon=x6, n_units=784, act=tf.nn.sigmoid, name='recon')\n\n        # sess = tf.InteractiveSession()\n        # tl.layers.initialize_global_variables(sess)\n        # X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n        # net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n\n        net6.print_layers()\n        net6.print_params(False)\n\n        cls.net6_shape = net6.outputs.get_shape().as_list()\n        cls.net6_layers = net6.all_layers\n        cls.net6_params = net6.all_params\n        cls.net6_n_params = net6.count_params()\n\n        # ============== GaussianNoiseLayer ==============\n\n        x7 = tf.placeholder(tf.float32, shape=(64, 784))\n        net7 = tl.layers.InputLayer(x7, name='input')\n        net7 = tl.layers.DenseLayer(net7, n_units=100, act=tf.nn.relu, name='dense3')\n        net7 = tl.layers.GaussianNoiseLayer(net7, name='gaussian')\n\n        net7.print_layers()\n        net7.print_params(False)\n\n        cls.net7_shape = net7.outputs.get_shape().as_list()\n        cls.net7_layers = net7.all_layers\n        cls.net7_params = net7.all_params\n        cls.net7_n_params = net7.count_params()\n\n        # ============== DropconnectDenseLayer ==============\n\n        x8 = tf.placeholder(tf.float32, shape=(64, 784))\n        net8 = tl.layers.InputLayer(x8, name='input')\n        net8 = tl.layers.DenseLayer(net8, n_units=100, act=tf.nn.relu, name='dense4')\n        net8 = tl.layers.DropconnectDenseLayer(net8, keep=0.8, name='dropconnect')\n\n        net8.print_layers()\n        net8.print_params(False)\n\n        cls.net8_shape = net8.outputs.get_shape().as_list()\n        cls.net8_layers = net8.all_layers\n        cls.net8_params = net8.all_params\n        cls.net8_n_params = net8.count_params()\n\n    @classmethod\n    def tearDownClass(cls):\n        tf.reset_default_graph()\n\n    def test_net1(self):\n        self.assertEqual(self.net1_shape[-1], 10)\n        self.assertEqual(len(self.net1_layers), 1)\n        self.assertEqual(len(self.net1_params), 2)\n        self.assertEqual(self.net1_n_params, 310)\n\n    def test_net2(self):\n        self.assertEqual(self.net2_shape[-1], 8)\n        self.assertEqual(len(self.net2_layers), 0)\n        self.assertEqual(len(self.net2_params), 0)\n        self.assertEqual(self.net2_n_params, 0)\n\n    def test_net3(self):\n        self.assertEqual(self.net3_shape, [self.batch_size, 200])\n        self.assertEqual(len(self.net3_layers), 1)\n        self.assertEqual(len(self.net3_params), 3)\n        self.assertEqual(self.net3_n_params, 401000)\n\n    def test_net4(self):\n        self.assertEqual(self.net4_shape, [self.batch_size, 50])\n        self.assertEqual(len(self.net4_layers), 1)\n        self.assertEqual(len(self.net4_params), 1)\n        self.assertEqual(self.net4_n_params, 50000)\n\n    def test_net5(self):\n        self.assertEqual(self.net5_shape, [self.batch_size, 50])\n        self.assertEqual(len(self.net5_layers), 1)\n        self.assertEqual(len(self.net5_params), 1)\n        self.assertEqual(self.net5_n_params, 50000)\n\n    def test_net6(self):\n        self.assertEqual(self.net6_shape[-1], 784)\n        self.assertEqual(len(self.net6_layers), 2)\n        self.assertEqual(len(self.net6_params), 4)\n        self.assertEqual(self.net6_n_params, 308308)\n\n    def test_net7(self):\n        self.assertEqual(self.net7_shape, [64, 100])\n        self.assertEqual(len(self.net7_layers), 2)\n        self.assertEqual(len(self.net7_params), 2)\n        self.assertEqual(self.net7_n_params, 78500)\n\n    def test_net8(self):\n        self.assertEqual(self.net8_shape, [64, 100])\n        self.assertEqual(len(self.net8_layers), 2)\n        self.assertEqual(len(self.net8_params), 4)\n        self.assertEqual(self.net8_n_params, 88600)\n\n\nif __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_len": 6975,
        "diff_format": "@@ -3,180 +7,186 @@\n \n-## DenseLayer\n-x = tf.placeholder(tf.float32, shape=[None, 30])\n-net = tl.layers.InputLayer(x, name='input')\n-net = tl.layers.DenseLayer(net, n_units=10, name='dense')\n \n-net.print_layers()\n-net.print_params(False)\n+class Layer_Core_Test(unittest.TestCase):\n+    @classmethod\n+    def setUpClass(cls):\n \n-shape = net.outputs.get_shape().as_list()\n-if shape[-1] != 10:\n-    raise Exception(\"shape do not match\")\n+        cls.batch_size = 8\n \n-if len(net.all_layers) != 1:\n-    raise Exception(\"layers do not match\")\n+        # ============== DenseLayer ==============\n \n-if len(net.all_params) != 2:\n-    raise Exception(\"params do not match\")\n+        x1 = tf.placeholder(tf.float32, shape=[None, 30])\n+        net1 = tl.layers.InputLayer(x1, name='input')\n+        net1 = tl.layers.DenseLayer(net1, n_units=10, name='dense')\n \n-if net.count_params() != 310:\n-    raise Exception(\"params do not match\")\n+        net1.print_layers()\n+        net1.print_params(False)\n \n-## OneHotInputLayer\n-x = tf.placeholder(tf.int32, shape=[None])\n-net = tl.layers.OneHotInputLayer(x, depth=8, name='onehot')\n-print(net)\n+        cls.net1_shape = net1.outputs.get_shape().as_list()\n+        cls.net1_layers = net1.all_layers\n+        cls.net1_params = net1.all_params\n+        cls.net1_n_params = net1.count_params()\n \n-net.print_layers()\n-net.print_params(False)\n+        # ============== OneHotInputLayer ==============\n \n-shape = net.outputs.get_shape().as_list()\n-if shape[-1] != 8:\n-    raise Exception(\"shape do not match\")\n+        x2 = tf.placeholder(tf.int32, shape=[None])\n+        net2 = tl.layers.OneHotInputLayer(x2, depth=8, name='onehot')\n \n-if len(net.all_layers) != 0:\n-    raise Exception(\"layers do not match\")\n+        net2.print_layers()\n+        net2.print_params(False)\n \n-if len(net.all_params) != 0:\n-    raise Exception(\"params do not match\")\n+        cls.net2_shape = net2.outputs.get_shape().as_list()\n+        cls.net2_layers = net2.all_layers\n+        cls.net2_params = net2.all_params\n+        cls.net2_n_params = net2.count_params()\n \n-if net.count_params() != 0:\n-    raise Exception(\"params do not match\")\n+        # ============== Word2vecEmbeddingInputlayer ==============\n \n-## Word2vecEmbeddingInputlayer\n-batch_size = 8\n-train_inputs = tf.placeholder(tf.int32, shape=(batch_size))\n-train_labels = tf.placeholder(tf.int32, shape=(batch_size, 1))\n-net = tl.layers.Word2vecEmbeddingInputlayer(\n-    inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\n-cost = net.nce_cost\n-train_params = net.all_params\n+        train_inputs = tf.placeholder(tf.int32, shape=cls.batch_size)\n+        train_labels = tf.placeholder(tf.int32, shape=(cls.batch_size, 1))\n+        net3 = tl.layers.Word2vecEmbeddingInputlayer(\n+            inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\n \n-net.print_layers()\n-net.print_params(False)\n+        net3.print_layers()\n+        net3.print_params(False)\n \n-shape = net.outputs.get_shape().as_list()\n-if shape != [8, 200]:\n-    raise Exception(\"shape do not match\")\n+        cls.net3_shape = net3.outputs.get_shape().as_list()\n+        cls.net3_layers = net3.all_layers\n+        cls.net3_params = net3.all_params\n+        cls.net3_n_params = net3.count_params()\n \n-if len(net.all_layers) != 1:\n-    raise Exception(\"layers do not match\")\n+        # ============== EmbeddingInputlayer ==============\n \n-if len(net.all_params) != 3:\n-    raise Exception(\"params do not match\")\n+        x4 = tf.placeholder(tf.int32, shape=(cls.batch_size, ))\n+        net4 = tl.layers.EmbeddingInputlayer(inputs=x4, vocabulary_size=1000, embedding_size=50, name='embed')\n \n-if net.count_params() != 401000:\n-    raise Exception(\"params do not match\")\n+        net4.print_layers()\n+        net4.print_params(False)\n \n-## EmbeddingInputlayer\n-batch_size = 8\n-x = tf.placeholder(tf.int32, shape=(batch_size, ))\n-net = tl.layers.EmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='embed')\n+        cls.net4_shape = net4.outputs.get_shape().as_list()\n+        cls.net4_layers = net4.all_layers\n+        cls.net4_params = net4.all_params\n+        cls.net4_n_params = net4.count_params()\n \n-net.print_layers()\n-net.print_params(False)\n+        # ============== AverageEmbeddingInputlayer ==============\n \n-shape = net.outputs.get_shape().as_list()\n-if shape != [batch_size, 50]:  # (8, 50)\n-    raise Exception(\"shape do not match\")\n+        length = 5\n+        x5 = tf.placeholder(tf.int32, shape=(cls.batch_size, length))\n+        net5 = tl.layers.AverageEmbeddingInputlayer(inputs=x5, vocabulary_size=1000, embedding_size=50, name='avg')\n \n-if len(net.all_layers) != 1:\n-    raise Exception(\"layers do not match\")\n+        net5.print_layers()\n+        net5.print_params(False)\n \n-if len(net.all_params) != 1:\n-    raise Exception(\"params do not match\")\n+        cls.net5_shape = net5.outputs.get_shape().as_list()\n+        cls.net5_layers = net5.all_layers\n+        cls.net5_params = net5.all_params\n+        cls.net5_n_params = net5.count_params()\n \n-if net.count_params() != 50000:\n-    raise Exception(\"params do not match\")\n+        # ============== ReconLayer ==============\n \n-## AverageEmbeddingInputlayer\n-batch_size = 8\n-length = 5\n-x = tf.placeholder(tf.int32, shape=(batch_size, length))\n-net = tl.layers.AverageEmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='avg')\n+        x6 = tf.placeholder(tf.float32, shape=(None, 784))\n+        net6 = tl.layers.InputLayer(x6, name='input')\n+        net6 = tl.layers.DenseLayer(net6, n_units=196, act=tf.nn.sigmoid, name='dense2')\n+        net6 = tl.layers.ReconLayer(net6, x_recon=x6, n_units=784, act=tf.nn.sigmoid, name='recon')\n \n-net.print_layers()\n-net.print_params(False)\n+        # sess = tf.InteractiveSession()\n+        # tl.layers.initialize_global_variables(sess)\n+        # X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n+        # net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n \n-shape = net.outputs.get_shape().as_list()\n-if shape != [batch_size, 50]:  # (8, 50)\n-    raise Exception(\"shape do not match\")\n+        net6.print_layers()\n+        net6.print_params(False)\n \n-if len(net.all_layers) != 1:\n-    raise Exception(\"layers do not match\")\n+        cls.net6_shape = net6.outputs.get_shape().as_list()\n+        cls.net6_layers = net6.all_layers\n+        cls.net6_params = net6.all_params\n+        cls.net6_n_params = net6.count_params()\n \n-if len(net.all_params) != 1:\n-    raise Exception(\"params do not match\")\n+        # ============== GaussianNoiseLayer ==============\n \n-if net.count_params() != 50000:\n-    raise Exception(\"params do not match\")\n+        x7 = tf.placeholder(tf.float32, shape=(64, 784))\n+        net7 = tl.layers.InputLayer(x7, name='input')\n+        net7 = tl.layers.DenseLayer(net7, n_units=100, act=tf.nn.relu, name='dense3')\n+        net7 = tl.layers.GaussianNoiseLayer(net7, name='gaussian')\n \n-## ReconLayer\n-x = tf.placeholder(tf.float32, shape=(None, 784))\n-net = tl.layers.InputLayer(x, name='input')\n-net = tl.layers.DenseLayer(net, n_units=196, act=tf.nn.sigmoid, name='dense2')\n-net = tl.layers.ReconLayer(net, x_recon=x, n_units=784, act=tf.nn.sigmoid, name='recon')\n-# sess = tf.InteractiveSession()\n-# tl.layers.initialize_global_variables(sess)\n-# X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n-# net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n+        net7.print_layers()\n+        net7.print_params(False)\n \n-net.print_layers()\n-net.print_params(False)\n+        cls.net7_shape = net7.outputs.get_shape().as_list()\n+        cls.net7_layers = net7.all_layers\n+        cls.net7_params = net7.all_params\n+        cls.net7_n_params = net7.count_params()\n \n-shape = net.outputs.get_shape().as_list()\n-if shape[-1] != 784:\n-    raise Exception(\"shape do not match\")\n+        # ============== DropconnectDenseLayer ==============\n \n-if len(net.all_layers) != 2:\n-    raise Exception(\"layers do not match\")\n+        x8 = tf.placeholder(tf.float32, shape=(64, 784))\n+        net8 = tl.layers.InputLayer(x8, name='input')\n+        net8 = tl.layers.DenseLayer(net8, n_units=100, act=tf.nn.relu, name='dense4')\n+        net8 = tl.layers.DropconnectDenseLayer(net8, keep=0.8, name='dropconnect')\n \n-if len(net.all_params) != 4:\n-    raise Exception(\"params do not match\")\n+        net8.print_layers()\n+        net8.print_params(False)\n \n-if net.count_params() != 308308:\n-    raise Exception(\"params do not match\")\n+        cls.net8_shape = net8.outputs.get_shape().as_list()\n+        cls.net8_layers = net8.all_layers\n+        cls.net8_params = net8.all_params\n+        cls.net8_n_params = net8.count_params()\n \n-## GaussianNoiseLayer\n-x = tf.placeholder(tf.float32, shape=(64, 784))\n-net = tl.layers.InputLayer(x, name='input')\n-net = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense3')\n-net = tl.layers.GaussianNoiseLayer(net, name='gaussian')\n+    @classmethod\n+    def tearDownClass(cls):\n+        tf.reset_default_graph()\n \n-net.print_layers()\n-net.print_params(False)\n+    def test_net1(self):\n+        self.assertEqual(self.net1_shape[-1], 10)\n+        self.assertEqual(len(self.net1_layers), 1)\n+        self.assertEqual(len(self.net1_params), 2)\n+        self.assertEqual(self.net1_n_params, 310)\n \n-shape = net.outputs.get_shape().as_list()\n-if shape != [64, 100]:\n-    raise Exception(\"shape do not match\")\n+    def test_net2(self):\n+        self.assertEqual(self.net2_shape[-1], 8)\n+        self.assertEqual(len(self.net2_layers), 0)\n+        self.assertEqual(len(self.net2_params), 0)\n+        self.assertEqual(self.net2_n_params, 0)\n \n-if len(net.all_layers) != 2:\n-    raise Exception(\"layers do not match\")\n+    def test_net3(self):\n+        self.assertEqual(self.net3_shape, [self.batch_size, 200])\n+        self.assertEqual(len(self.net3_layers), 1)\n+        self.assertEqual(len(self.net3_params), 3)\n+        self.assertEqual(self.net3_n_params, 401000)\n \n-if len(net.all_params) != 2:\n-    raise Exception(\"params do not match\")\n+    def test_net4(self):\n+        self.assertEqual(self.net4_shape, [self.batch_size, 50])\n+        self.assertEqual(len(self.net4_layers), 1)\n+        self.assertEqual(len(self.net4_params), 1)\n+        self.assertEqual(self.net4_n_params, 50000)\n \n-if net.count_params() != 78500:\n-    raise Exception(\"params do not match\")\n+    def test_net5(self):\n+        self.assertEqual(self.net5_shape, [self.batch_size, 50])\n+        self.assertEqual(len(self.net5_layers), 1)\n+        self.assertEqual(len(self.net5_params), 1)\n+        self.assertEqual(self.net5_n_params, 50000)\n \n-## DropconnectDenseLayer\n-x = tf.placeholder(tf.float32, shape=(64, 784))\n-net = tl.layers.InputLayer(x, name='input')\n-net = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense4')\n-net = tl.layers.DropconnectDenseLayer(net, keep=0.8, name='dropconnect')\n+    def test_net6(self):\n+        self.assertEqual(self.net6_shape[-1], 784)\n+        self.assertEqual(len(self.net6_layers), 2)\n+        self.assertEqual(len(self.net6_params), 4)\n+        self.assertEqual(self.net6_n_params, 308308)\n \n-net.print_layers()\n-net.print_params(False)\n+    def test_net7(self):\n+        self.assertEqual(self.net7_shape, [64, 100])\n+        self.assertEqual(len(self.net7_layers), 2)\n+        self.assertEqual(len(self.net7_params), 2)\n+        self.assertEqual(self.net7_n_params, 78500)\n \n-shape = net.outputs.get_shape().as_list()\n-if shape != [64, 100]:\n-    raise Exception(\"shape do not match\")\n+    def test_net8(self):\n+        self.assertEqual(self.net8_shape, [64, 100])\n+        self.assertEqual(len(self.net8_layers), 2)\n+        self.assertEqual(len(self.net8_params), 4)\n+        self.assertEqual(self.net8_n_params, 88600)\n \n-if len(net.all_layers) != 2:\n-    raise Exception(\"layers do not match\")\n \n-if len(net.all_params) != 4:\n-    raise Exception(\"params do not match\")\n+if __name__ == '__main__':\n \n-if net.count_params() != 88600:\n-    raise Exception(\"params do not match\")\n+    # tf.logging.set_verbosity(tf.logging.INFO)\n+    tf.logging.set_verbosity(tf.logging.DEBUG)\n+\n+    unittest.main()\n",
        "source_code_with_indent": "\n## DenseLayer\nx = tf.placeholder(tf.float32, shape=[None, 30])\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=10, name='dense')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 10:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 1:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 2:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 310:\n    <IND>raise Exception(\"params do not match\")\n\n## OneHotInputLayer\n<DED>x = tf.placeholder(tf.int32, shape=[None])\nnet = tl.layers.OneHotInputLayer(x, depth=8, name='onehot')\nprint(net)\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 8:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 0:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 0:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 0:\n    <IND>raise Exception(\"params do not match\")\n\n## Word2vecEmbeddingInputlayer\n<DED>batch_size = 8\ntrain_inputs = tf.placeholder(tf.int32, shape=(batch_size))\ntrain_labels = tf.placeholder(tf.int32, shape=(batch_size, 1))\nnet = tl.layers.Word2vecEmbeddingInputlayer(\n    inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\ncost = net.nce_cost\ntrain_params = net.all_params\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [8, 200]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 1:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 3:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 401000:\n    <IND>raise Exception(\"params do not match\")\n\n## EmbeddingInputlayer\n<DED>batch_size = 8\nx = tf.placeholder(tf.int32, shape=(batch_size, ))\nnet = tl.layers.EmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='embed')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [batch_size, 50]:  # (8, 50)\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 1:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 1:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 50000:\n    <IND>raise Exception(\"params do not match\")\n\n## AverageEmbeddingInputlayer\n<DED>batch_size = 8\nlength = 5\nx = tf.placeholder(tf.int32, shape=(batch_size, length))\nnet = tl.layers.AverageEmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='avg')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [batch_size, 50]:  # (8, 50)\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 1:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 1:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 50000:\n    <IND>raise Exception(\"params do not match\")\n\n## ReconLayer\n<DED>x = tf.placeholder(tf.float32, shape=(None, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=196, act=tf.nn.sigmoid, name='dense2')\nnet = tl.layers.ReconLayer(net, x_recon=x, n_units=784, act=tf.nn.sigmoid, name='recon')\n# sess = tf.InteractiveSession()\n# tl.layers.initialize_global_variables(sess)\n# X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n# net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 784:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 2:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 4:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 308308:\n    <IND>raise Exception(\"params do not match\")\n\n## GaussianNoiseLayer\n<DED>x = tf.placeholder(tf.float32, shape=(64, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense3')\nnet = tl.layers.GaussianNoiseLayer(net, name='gaussian')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [64, 100]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 2:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 2:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 78500:\n    <IND>raise Exception(\"params do not match\")\n\n## DropconnectDenseLayer\n<DED>x = tf.placeholder(tf.float32, shape=(64, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense4')\nnet = tl.layers.DropconnectDenseLayer(net, keep=0.8, name='dropconnect')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [64, 100]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 2:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 4:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 88600:\n    <IND>raise Exception(\"params do not match\")\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n\nclass Layer_Core_Test(unittest.TestCase):\n    <IND>@classmethod\n    def setUpClass(cls):\n\n        <IND>cls.batch_size = 8\n\n        # ============== DenseLayer ==============\n\n        x1 = tf.placeholder(tf.float32, shape=[None, 30])\n        net1 = tl.layers.InputLayer(x1, name='input')\n        net1 = tl.layers.DenseLayer(net1, n_units=10, name='dense')\n\n        net1.print_layers()\n        net1.print_params(False)\n\n        cls.net1_shape = net1.outputs.get_shape().as_list()\n        cls.net1_layers = net1.all_layers\n        cls.net1_params = net1.all_params\n        cls.net1_n_params = net1.count_params()\n\n        # ============== OneHotInputLayer ==============\n\n        x2 = tf.placeholder(tf.int32, shape=[None])\n        net2 = tl.layers.OneHotInputLayer(x2, depth=8, name='onehot')\n\n        net2.print_layers()\n        net2.print_params(False)\n\n        cls.net2_shape = net2.outputs.get_shape().as_list()\n        cls.net2_layers = net2.all_layers\n        cls.net2_params = net2.all_params\n        cls.net2_n_params = net2.count_params()\n\n        # ============== Word2vecEmbeddingInputlayer ==============\n\n        train_inputs = tf.placeholder(tf.int32, shape=cls.batch_size)\n        train_labels = tf.placeholder(tf.int32, shape=(cls.batch_size, 1))\n        net3 = tl.layers.Word2vecEmbeddingInputlayer(\n            inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\n\n        net3.print_layers()\n        net3.print_params(False)\n\n        cls.net3_shape = net3.outputs.get_shape().as_list()\n        cls.net3_layers = net3.all_layers\n        cls.net3_params = net3.all_params\n        cls.net3_n_params = net3.count_params()\n\n        # ============== EmbeddingInputlayer ==============\n\n        x4 = tf.placeholder(tf.int32, shape=(cls.batch_size, ))\n        net4 = tl.layers.EmbeddingInputlayer(inputs=x4, vocabulary_size=1000, embedding_size=50, name='embed')\n\n        net4.print_layers()\n        net4.print_params(False)\n\n        cls.net4_shape = net4.outputs.get_shape().as_list()\n        cls.net4_layers = net4.all_layers\n        cls.net4_params = net4.all_params\n        cls.net4_n_params = net4.count_params()\n\n        # ============== AverageEmbeddingInputlayer ==============\n\n        length = 5\n        x5 = tf.placeholder(tf.int32, shape=(cls.batch_size, length))\n        net5 = tl.layers.AverageEmbeddingInputlayer(inputs=x5, vocabulary_size=1000, embedding_size=50, name='avg')\n\n        net5.print_layers()\n        net5.print_params(False)\n\n        cls.net5_shape = net5.outputs.get_shape().as_list()\n        cls.net5_layers = net5.all_layers\n        cls.net5_params = net5.all_params\n        cls.net5_n_params = net5.count_params()\n\n        # ============== ReconLayer ==============\n\n        x6 = tf.placeholder(tf.float32, shape=(None, 784))\n        net6 = tl.layers.InputLayer(x6, name='input')\n        net6 = tl.layers.DenseLayer(net6, n_units=196, act=tf.nn.sigmoid, name='dense2')\n        net6 = tl.layers.ReconLayer(net6, x_recon=x6, n_units=784, act=tf.nn.sigmoid, name='recon')\n\n        # sess = tf.InteractiveSession()\n        # tl.layers.initialize_global_variables(sess)\n        # X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n        # net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n\n        net6.print_layers()\n        net6.print_params(False)\n\n        cls.net6_shape = net6.outputs.get_shape().as_list()\n        cls.net6_layers = net6.all_layers\n        cls.net6_params = net6.all_params\n        cls.net6_n_params = net6.count_params()\n\n        # ============== GaussianNoiseLayer ==============\n\n        x7 = tf.placeholder(tf.float32, shape=(64, 784))\n        net7 = tl.layers.InputLayer(x7, name='input')\n        net7 = tl.layers.DenseLayer(net7, n_units=100, act=tf.nn.relu, name='dense3')\n        net7 = tl.layers.GaussianNoiseLayer(net7, name='gaussian')\n\n        net7.print_layers()\n        net7.print_params(False)\n\n        cls.net7_shape = net7.outputs.get_shape().as_list()\n        cls.net7_layers = net7.all_layers\n        cls.net7_params = net7.all_params\n        cls.net7_n_params = net7.count_params()\n\n        # ============== DropconnectDenseLayer ==============\n\n        x8 = tf.placeholder(tf.float32, shape=(64, 784))\n        net8 = tl.layers.InputLayer(x8, name='input')\n        net8 = tl.layers.DenseLayer(net8, n_units=100, act=tf.nn.relu, name='dense4')\n        net8 = tl.layers.DropconnectDenseLayer(net8, keep=0.8, name='dropconnect')\n\n        net8.print_layers()\n        net8.print_params(False)\n\n        cls.net8_shape = net8.outputs.get_shape().as_list()\n        cls.net8_layers = net8.all_layers\n        cls.net8_params = net8.all_params\n        cls.net8_n_params = net8.count_params()\n\n    <DED>@classmethod\n    def tearDownClass(cls):\n        <IND>tf.reset_default_graph()\n\n    <DED>def test_net1(self):\n        <IND>self.assertEqual(self.net1_shape[-1], 10)\n        self.assertEqual(len(self.net1_layers), 1)\n        self.assertEqual(len(self.net1_params), 2)\n        self.assertEqual(self.net1_n_params, 310)\n\n    <DED>def test_net2(self):\n        <IND>self.assertEqual(self.net2_shape[-1], 8)\n        self.assertEqual(len(self.net2_layers), 0)\n        self.assertEqual(len(self.net2_params), 0)\n        self.assertEqual(self.net2_n_params, 0)\n\n    <DED>def test_net3(self):\n        <IND>self.assertEqual(self.net3_shape, [self.batch_size, 200])\n        self.assertEqual(len(self.net3_layers), 1)\n        self.assertEqual(len(self.net3_params), 3)\n        self.assertEqual(self.net3_n_params, 401000)\n\n    <DED>def test_net4(self):\n        <IND>self.assertEqual(self.net4_shape, [self.batch_size, 50])\n        self.assertEqual(len(self.net4_layers), 1)\n        self.assertEqual(len(self.net4_params), 1)\n        self.assertEqual(self.net4_n_params, 50000)\n\n    <DED>def test_net5(self):\n        <IND>self.assertEqual(self.net5_shape, [self.batch_size, 50])\n        self.assertEqual(len(self.net5_layers), 1)\n        self.assertEqual(len(self.net5_params), 1)\n        self.assertEqual(self.net5_n_params, 50000)\n\n    <DED>def test_net6(self):\n        <IND>self.assertEqual(self.net6_shape[-1], 784)\n        self.assertEqual(len(self.net6_layers), 2)\n        self.assertEqual(len(self.net6_params), 4)\n        self.assertEqual(self.net6_n_params, 308308)\n\n    <DED>def test_net7(self):\n        <IND>self.assertEqual(self.net7_shape, [64, 100])\n        self.assertEqual(len(self.net7_layers), 2)\n        self.assertEqual(len(self.net7_params), 2)\n        self.assertEqual(self.net7_n_params, 78500)\n\n    <DED>def test_net8(self):\n        <IND>self.assertEqual(self.net8_shape, [64, 100])\n        self.assertEqual(len(self.net8_layers), 2)\n        self.assertEqual(len(self.net8_params), 4)\n        self.assertEqual(self.net8_n_params, 88600)\n\n\n<DED><DED>if __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    <IND>tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "tensorlayer/TensorLayer",
    "commit": "6f539ad2324ddccc18b6ac39e4a2f4aeb12173a2",
    "filename": "tests/test_layers_core.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/tensorlayer-TensorLayer/tests/test_layers_core.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "tests/test_layers_core.py:96:0 Incompatible variable type [9]: net is declared to have type `tl.layers.core.InputLayer` but is used as type `tl.layers.core.AverageEmbeddingInputlayer`.",
    "message": " net is declared to have type `tl.layers.core.InputLayer` but is used as type `tl.layers.core.AverageEmbeddingInputlayer`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 96,
    "warning_line": "net = tl.layers.AverageEmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='avg')",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import tensorflow as tf\n",
        "source_code_len": 24,
        "target_code": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_len": 87,
        "diff_format": "@@ -1,1 +1,5 @@\n+#!/usr/bin/env python\n+# -*- coding: utf-8 -*-\n+import unittest\n+\n import tensorflow as tf\n",
        "source_code_with_indent": "import tensorflow as tf\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n## DenseLayer\nx = tf.placeholder(tf.float32, shape=[None, 30])\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=10, name='dense')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 10:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 1:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 2:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 310:\n    raise Exception(\"params do not match\")\n\n## OneHotInputLayer\nx = tf.placeholder(tf.int32, shape=[None])\nnet = tl.layers.OneHotInputLayer(x, depth=8, name='onehot')\nprint(net)\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 8:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 0:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 0:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 0:\n    raise Exception(\"params do not match\")\n\n## Word2vecEmbeddingInputlayer\nbatch_size = 8\ntrain_inputs = tf.placeholder(tf.int32, shape=(batch_size))\ntrain_labels = tf.placeholder(tf.int32, shape=(batch_size, 1))\nnet = tl.layers.Word2vecEmbeddingInputlayer(\n    inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\ncost = net.nce_cost\ntrain_params = net.all_params\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [8, 200]:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 1:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 3:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 401000:\n    raise Exception(\"params do not match\")\n\n## EmbeddingInputlayer\nbatch_size = 8\nx = tf.placeholder(tf.int32, shape=(batch_size, ))\nnet = tl.layers.EmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='embed')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [batch_size, 50]:  # (8, 50)\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 1:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 1:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 50000:\n    raise Exception(\"params do not match\")\n\n## AverageEmbeddingInputlayer\nbatch_size = 8\nlength = 5\nx = tf.placeholder(tf.int32, shape=(batch_size, length))\nnet = tl.layers.AverageEmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='avg')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [batch_size, 50]:  # (8, 50)\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 1:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 1:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 50000:\n    raise Exception(\"params do not match\")\n\n## ReconLayer\nx = tf.placeholder(tf.float32, shape=(None, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=196, act=tf.nn.sigmoid, name='dense2')\nnet = tl.layers.ReconLayer(net, x_recon=x, n_units=784, act=tf.nn.sigmoid, name='recon')\n# sess = tf.InteractiveSession()\n# tl.layers.initialize_global_variables(sess)\n# X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n# net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 784:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 2:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 4:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 308308:\n    raise Exception(\"params do not match\")\n\n## GaussianNoiseLayer\nx = tf.placeholder(tf.float32, shape=(64, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense3')\nnet = tl.layers.GaussianNoiseLayer(net, name='gaussian')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [64, 100]:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 2:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 2:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 78500:\n    raise Exception(\"params do not match\")\n\n## DropconnectDenseLayer\nx = tf.placeholder(tf.float32, shape=(64, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense4')\nnet = tl.layers.DropconnectDenseLayer(net, keep=0.8, name='dropconnect')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [64, 100]:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 2:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 4:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 88600:\n    raise Exception(\"params do not match\")\n",
        "source_code_len": 5232,
        "target_code": "\n\nclass Layer_Core_Test(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n\n        cls.batch_size = 8\n\n        # ============== DenseLayer ==============\n\n        x1 = tf.placeholder(tf.float32, shape=[None, 30])\n        net1 = tl.layers.InputLayer(x1, name='input')\n        net1 = tl.layers.DenseLayer(net1, n_units=10, name='dense')\n\n        net1.print_layers()\n        net1.print_params(False)\n\n        cls.net1_shape = net1.outputs.get_shape().as_list()\n        cls.net1_layers = net1.all_layers\n        cls.net1_params = net1.all_params\n        cls.net1_n_params = net1.count_params()\n\n        # ============== OneHotInputLayer ==============\n\n        x2 = tf.placeholder(tf.int32, shape=[None])\n        net2 = tl.layers.OneHotInputLayer(x2, depth=8, name='onehot')\n\n        net2.print_layers()\n        net2.print_params(False)\n\n        cls.net2_shape = net2.outputs.get_shape().as_list()\n        cls.net2_layers = net2.all_layers\n        cls.net2_params = net2.all_params\n        cls.net2_n_params = net2.count_params()\n\n        # ============== Word2vecEmbeddingInputlayer ==============\n\n        train_inputs = tf.placeholder(tf.int32, shape=cls.batch_size)\n        train_labels = tf.placeholder(tf.int32, shape=(cls.batch_size, 1))\n        net3 = tl.layers.Word2vecEmbeddingInputlayer(\n            inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\n\n        net3.print_layers()\n        net3.print_params(False)\n\n        cls.net3_shape = net3.outputs.get_shape().as_list()\n        cls.net3_layers = net3.all_layers\n        cls.net3_params = net3.all_params\n        cls.net3_n_params = net3.count_params()\n\n        # ============== EmbeddingInputlayer ==============\n\n        x4 = tf.placeholder(tf.int32, shape=(cls.batch_size, ))\n        net4 = tl.layers.EmbeddingInputlayer(inputs=x4, vocabulary_size=1000, embedding_size=50, name='embed')\n\n        net4.print_layers()\n        net4.print_params(False)\n\n        cls.net4_shape = net4.outputs.get_shape().as_list()\n        cls.net4_layers = net4.all_layers\n        cls.net4_params = net4.all_params\n        cls.net4_n_params = net4.count_params()\n\n        # ============== AverageEmbeddingInputlayer ==============\n\n        length = 5\n        x5 = tf.placeholder(tf.int32, shape=(cls.batch_size, length))\n        net5 = tl.layers.AverageEmbeddingInputlayer(inputs=x5, vocabulary_size=1000, embedding_size=50, name='avg')\n\n        net5.print_layers()\n        net5.print_params(False)\n\n        cls.net5_shape = net5.outputs.get_shape().as_list()\n        cls.net5_layers = net5.all_layers\n        cls.net5_params = net5.all_params\n        cls.net5_n_params = net5.count_params()\n\n        # ============== ReconLayer ==============\n\n        x6 = tf.placeholder(tf.float32, shape=(None, 784))\n        net6 = tl.layers.InputLayer(x6, name='input')\n        net6 = tl.layers.DenseLayer(net6, n_units=196, act=tf.nn.sigmoid, name='dense2')\n        net6 = tl.layers.ReconLayer(net6, x_recon=x6, n_units=784, act=tf.nn.sigmoid, name='recon')\n\n        # sess = tf.InteractiveSession()\n        # tl.layers.initialize_global_variables(sess)\n        # X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n        # net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n\n        net6.print_layers()\n        net6.print_params(False)\n\n        cls.net6_shape = net6.outputs.get_shape().as_list()\n        cls.net6_layers = net6.all_layers\n        cls.net6_params = net6.all_params\n        cls.net6_n_params = net6.count_params()\n\n        # ============== GaussianNoiseLayer ==============\n\n        x7 = tf.placeholder(tf.float32, shape=(64, 784))\n        net7 = tl.layers.InputLayer(x7, name='input')\n        net7 = tl.layers.DenseLayer(net7, n_units=100, act=tf.nn.relu, name='dense3')\n        net7 = tl.layers.GaussianNoiseLayer(net7, name='gaussian')\n\n        net7.print_layers()\n        net7.print_params(False)\n\n        cls.net7_shape = net7.outputs.get_shape().as_list()\n        cls.net7_layers = net7.all_layers\n        cls.net7_params = net7.all_params\n        cls.net7_n_params = net7.count_params()\n\n        # ============== DropconnectDenseLayer ==============\n\n        x8 = tf.placeholder(tf.float32, shape=(64, 784))\n        net8 = tl.layers.InputLayer(x8, name='input')\n        net8 = tl.layers.DenseLayer(net8, n_units=100, act=tf.nn.relu, name='dense4')\n        net8 = tl.layers.DropconnectDenseLayer(net8, keep=0.8, name='dropconnect')\n\n        net8.print_layers()\n        net8.print_params(False)\n\n        cls.net8_shape = net8.outputs.get_shape().as_list()\n        cls.net8_layers = net8.all_layers\n        cls.net8_params = net8.all_params\n        cls.net8_n_params = net8.count_params()\n\n    @classmethod\n    def tearDownClass(cls):\n        tf.reset_default_graph()\n\n    def test_net1(self):\n        self.assertEqual(self.net1_shape[-1], 10)\n        self.assertEqual(len(self.net1_layers), 1)\n        self.assertEqual(len(self.net1_params), 2)\n        self.assertEqual(self.net1_n_params, 310)\n\n    def test_net2(self):\n        self.assertEqual(self.net2_shape[-1], 8)\n        self.assertEqual(len(self.net2_layers), 0)\n        self.assertEqual(len(self.net2_params), 0)\n        self.assertEqual(self.net2_n_params, 0)\n\n    def test_net3(self):\n        self.assertEqual(self.net3_shape, [self.batch_size, 200])\n        self.assertEqual(len(self.net3_layers), 1)\n        self.assertEqual(len(self.net3_params), 3)\n        self.assertEqual(self.net3_n_params, 401000)\n\n    def test_net4(self):\n        self.assertEqual(self.net4_shape, [self.batch_size, 50])\n        self.assertEqual(len(self.net4_layers), 1)\n        self.assertEqual(len(self.net4_params), 1)\n        self.assertEqual(self.net4_n_params, 50000)\n\n    def test_net5(self):\n        self.assertEqual(self.net5_shape, [self.batch_size, 50])\n        self.assertEqual(len(self.net5_layers), 1)\n        self.assertEqual(len(self.net5_params), 1)\n        self.assertEqual(self.net5_n_params, 50000)\n\n    def test_net6(self):\n        self.assertEqual(self.net6_shape[-1], 784)\n        self.assertEqual(len(self.net6_layers), 2)\n        self.assertEqual(len(self.net6_params), 4)\n        self.assertEqual(self.net6_n_params, 308308)\n\n    def test_net7(self):\n        self.assertEqual(self.net7_shape, [64, 100])\n        self.assertEqual(len(self.net7_layers), 2)\n        self.assertEqual(len(self.net7_params), 2)\n        self.assertEqual(self.net7_n_params, 78500)\n\n    def test_net8(self):\n        self.assertEqual(self.net8_shape, [64, 100])\n        self.assertEqual(len(self.net8_layers), 2)\n        self.assertEqual(len(self.net8_params), 4)\n        self.assertEqual(self.net8_n_params, 88600)\n\n\nif __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_len": 6975,
        "diff_format": "@@ -3,180 +7,186 @@\n \n-## DenseLayer\n-x = tf.placeholder(tf.float32, shape=[None, 30])\n-net = tl.layers.InputLayer(x, name='input')\n-net = tl.layers.DenseLayer(net, n_units=10, name='dense')\n \n-net.print_layers()\n-net.print_params(False)\n+class Layer_Core_Test(unittest.TestCase):\n+    @classmethod\n+    def setUpClass(cls):\n \n-shape = net.outputs.get_shape().as_list()\n-if shape[-1] != 10:\n-    raise Exception(\"shape do not match\")\n+        cls.batch_size = 8\n \n-if len(net.all_layers) != 1:\n-    raise Exception(\"layers do not match\")\n+        # ============== DenseLayer ==============\n \n-if len(net.all_params) != 2:\n-    raise Exception(\"params do not match\")\n+        x1 = tf.placeholder(tf.float32, shape=[None, 30])\n+        net1 = tl.layers.InputLayer(x1, name='input')\n+        net1 = tl.layers.DenseLayer(net1, n_units=10, name='dense')\n \n-if net.count_params() != 310:\n-    raise Exception(\"params do not match\")\n+        net1.print_layers()\n+        net1.print_params(False)\n \n-## OneHotInputLayer\n-x = tf.placeholder(tf.int32, shape=[None])\n-net = tl.layers.OneHotInputLayer(x, depth=8, name='onehot')\n-print(net)\n+        cls.net1_shape = net1.outputs.get_shape().as_list()\n+        cls.net1_layers = net1.all_layers\n+        cls.net1_params = net1.all_params\n+        cls.net1_n_params = net1.count_params()\n \n-net.print_layers()\n-net.print_params(False)\n+        # ============== OneHotInputLayer ==============\n \n-shape = net.outputs.get_shape().as_list()\n-if shape[-1] != 8:\n-    raise Exception(\"shape do not match\")\n+        x2 = tf.placeholder(tf.int32, shape=[None])\n+        net2 = tl.layers.OneHotInputLayer(x2, depth=8, name='onehot')\n \n-if len(net.all_layers) != 0:\n-    raise Exception(\"layers do not match\")\n+        net2.print_layers()\n+        net2.print_params(False)\n \n-if len(net.all_params) != 0:\n-    raise Exception(\"params do not match\")\n+        cls.net2_shape = net2.outputs.get_shape().as_list()\n+        cls.net2_layers = net2.all_layers\n+        cls.net2_params = net2.all_params\n+        cls.net2_n_params = net2.count_params()\n \n-if net.count_params() != 0:\n-    raise Exception(\"params do not match\")\n+        # ============== Word2vecEmbeddingInputlayer ==============\n \n-## Word2vecEmbeddingInputlayer\n-batch_size = 8\n-train_inputs = tf.placeholder(tf.int32, shape=(batch_size))\n-train_labels = tf.placeholder(tf.int32, shape=(batch_size, 1))\n-net = tl.layers.Word2vecEmbeddingInputlayer(\n-    inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\n-cost = net.nce_cost\n-train_params = net.all_params\n+        train_inputs = tf.placeholder(tf.int32, shape=cls.batch_size)\n+        train_labels = tf.placeholder(tf.int32, shape=(cls.batch_size, 1))\n+        net3 = tl.layers.Word2vecEmbeddingInputlayer(\n+            inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\n \n-net.print_layers()\n-net.print_params(False)\n+        net3.print_layers()\n+        net3.print_params(False)\n \n-shape = net.outputs.get_shape().as_list()\n-if shape != [8, 200]:\n-    raise Exception(\"shape do not match\")\n+        cls.net3_shape = net3.outputs.get_shape().as_list()\n+        cls.net3_layers = net3.all_layers\n+        cls.net3_params = net3.all_params\n+        cls.net3_n_params = net3.count_params()\n \n-if len(net.all_layers) != 1:\n-    raise Exception(\"layers do not match\")\n+        # ============== EmbeddingInputlayer ==============\n \n-if len(net.all_params) != 3:\n-    raise Exception(\"params do not match\")\n+        x4 = tf.placeholder(tf.int32, shape=(cls.batch_size, ))\n+        net4 = tl.layers.EmbeddingInputlayer(inputs=x4, vocabulary_size=1000, embedding_size=50, name='embed')\n \n-if net.count_params() != 401000:\n-    raise Exception(\"params do not match\")\n+        net4.print_layers()\n+        net4.print_params(False)\n \n-## EmbeddingInputlayer\n-batch_size = 8\n-x = tf.placeholder(tf.int32, shape=(batch_size, ))\n-net = tl.layers.EmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='embed')\n+        cls.net4_shape = net4.outputs.get_shape().as_list()\n+        cls.net4_layers = net4.all_layers\n+        cls.net4_params = net4.all_params\n+        cls.net4_n_params = net4.count_params()\n \n-net.print_layers()\n-net.print_params(False)\n+        # ============== AverageEmbeddingInputlayer ==============\n \n-shape = net.outputs.get_shape().as_list()\n-if shape != [batch_size, 50]:  # (8, 50)\n-    raise Exception(\"shape do not match\")\n+        length = 5\n+        x5 = tf.placeholder(tf.int32, shape=(cls.batch_size, length))\n+        net5 = tl.layers.AverageEmbeddingInputlayer(inputs=x5, vocabulary_size=1000, embedding_size=50, name='avg')\n \n-if len(net.all_layers) != 1:\n-    raise Exception(\"layers do not match\")\n+        net5.print_layers()\n+        net5.print_params(False)\n \n-if len(net.all_params) != 1:\n-    raise Exception(\"params do not match\")\n+        cls.net5_shape = net5.outputs.get_shape().as_list()\n+        cls.net5_layers = net5.all_layers\n+        cls.net5_params = net5.all_params\n+        cls.net5_n_params = net5.count_params()\n \n-if net.count_params() != 50000:\n-    raise Exception(\"params do not match\")\n+        # ============== ReconLayer ==============\n \n-## AverageEmbeddingInputlayer\n-batch_size = 8\n-length = 5\n-x = tf.placeholder(tf.int32, shape=(batch_size, length))\n-net = tl.layers.AverageEmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='avg')\n+        x6 = tf.placeholder(tf.float32, shape=(None, 784))\n+        net6 = tl.layers.InputLayer(x6, name='input')\n+        net6 = tl.layers.DenseLayer(net6, n_units=196, act=tf.nn.sigmoid, name='dense2')\n+        net6 = tl.layers.ReconLayer(net6, x_recon=x6, n_units=784, act=tf.nn.sigmoid, name='recon')\n \n-net.print_layers()\n-net.print_params(False)\n+        # sess = tf.InteractiveSession()\n+        # tl.layers.initialize_global_variables(sess)\n+        # X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n+        # net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n \n-shape = net.outputs.get_shape().as_list()\n-if shape != [batch_size, 50]:  # (8, 50)\n-    raise Exception(\"shape do not match\")\n+        net6.print_layers()\n+        net6.print_params(False)\n \n-if len(net.all_layers) != 1:\n-    raise Exception(\"layers do not match\")\n+        cls.net6_shape = net6.outputs.get_shape().as_list()\n+        cls.net6_layers = net6.all_layers\n+        cls.net6_params = net6.all_params\n+        cls.net6_n_params = net6.count_params()\n \n-if len(net.all_params) != 1:\n-    raise Exception(\"params do not match\")\n+        # ============== GaussianNoiseLayer ==============\n \n-if net.count_params() != 50000:\n-    raise Exception(\"params do not match\")\n+        x7 = tf.placeholder(tf.float32, shape=(64, 784))\n+        net7 = tl.layers.InputLayer(x7, name='input')\n+        net7 = tl.layers.DenseLayer(net7, n_units=100, act=tf.nn.relu, name='dense3')\n+        net7 = tl.layers.GaussianNoiseLayer(net7, name='gaussian')\n \n-## ReconLayer\n-x = tf.placeholder(tf.float32, shape=(None, 784))\n-net = tl.layers.InputLayer(x, name='input')\n-net = tl.layers.DenseLayer(net, n_units=196, act=tf.nn.sigmoid, name='dense2')\n-net = tl.layers.ReconLayer(net, x_recon=x, n_units=784, act=tf.nn.sigmoid, name='recon')\n-# sess = tf.InteractiveSession()\n-# tl.layers.initialize_global_variables(sess)\n-# X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n-# net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n+        net7.print_layers()\n+        net7.print_params(False)\n \n-net.print_layers()\n-net.print_params(False)\n+        cls.net7_shape = net7.outputs.get_shape().as_list()\n+        cls.net7_layers = net7.all_layers\n+        cls.net7_params = net7.all_params\n+        cls.net7_n_params = net7.count_params()\n \n-shape = net.outputs.get_shape().as_list()\n-if shape[-1] != 784:\n-    raise Exception(\"shape do not match\")\n+        # ============== DropconnectDenseLayer ==============\n \n-if len(net.all_layers) != 2:\n-    raise Exception(\"layers do not match\")\n+        x8 = tf.placeholder(tf.float32, shape=(64, 784))\n+        net8 = tl.layers.InputLayer(x8, name='input')\n+        net8 = tl.layers.DenseLayer(net8, n_units=100, act=tf.nn.relu, name='dense4')\n+        net8 = tl.layers.DropconnectDenseLayer(net8, keep=0.8, name='dropconnect')\n \n-if len(net.all_params) != 4:\n-    raise Exception(\"params do not match\")\n+        net8.print_layers()\n+        net8.print_params(False)\n \n-if net.count_params() != 308308:\n-    raise Exception(\"params do not match\")\n+        cls.net8_shape = net8.outputs.get_shape().as_list()\n+        cls.net8_layers = net8.all_layers\n+        cls.net8_params = net8.all_params\n+        cls.net8_n_params = net8.count_params()\n \n-## GaussianNoiseLayer\n-x = tf.placeholder(tf.float32, shape=(64, 784))\n-net = tl.layers.InputLayer(x, name='input')\n-net = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense3')\n-net = tl.layers.GaussianNoiseLayer(net, name='gaussian')\n+    @classmethod\n+    def tearDownClass(cls):\n+        tf.reset_default_graph()\n \n-net.print_layers()\n-net.print_params(False)\n+    def test_net1(self):\n+        self.assertEqual(self.net1_shape[-1], 10)\n+        self.assertEqual(len(self.net1_layers), 1)\n+        self.assertEqual(len(self.net1_params), 2)\n+        self.assertEqual(self.net1_n_params, 310)\n \n-shape = net.outputs.get_shape().as_list()\n-if shape != [64, 100]:\n-    raise Exception(\"shape do not match\")\n+    def test_net2(self):\n+        self.assertEqual(self.net2_shape[-1], 8)\n+        self.assertEqual(len(self.net2_layers), 0)\n+        self.assertEqual(len(self.net2_params), 0)\n+        self.assertEqual(self.net2_n_params, 0)\n \n-if len(net.all_layers) != 2:\n-    raise Exception(\"layers do not match\")\n+    def test_net3(self):\n+        self.assertEqual(self.net3_shape, [self.batch_size, 200])\n+        self.assertEqual(len(self.net3_layers), 1)\n+        self.assertEqual(len(self.net3_params), 3)\n+        self.assertEqual(self.net3_n_params, 401000)\n \n-if len(net.all_params) != 2:\n-    raise Exception(\"params do not match\")\n+    def test_net4(self):\n+        self.assertEqual(self.net4_shape, [self.batch_size, 50])\n+        self.assertEqual(len(self.net4_layers), 1)\n+        self.assertEqual(len(self.net4_params), 1)\n+        self.assertEqual(self.net4_n_params, 50000)\n \n-if net.count_params() != 78500:\n-    raise Exception(\"params do not match\")\n+    def test_net5(self):\n+        self.assertEqual(self.net5_shape, [self.batch_size, 50])\n+        self.assertEqual(len(self.net5_layers), 1)\n+        self.assertEqual(len(self.net5_params), 1)\n+        self.assertEqual(self.net5_n_params, 50000)\n \n-## DropconnectDenseLayer\n-x = tf.placeholder(tf.float32, shape=(64, 784))\n-net = tl.layers.InputLayer(x, name='input')\n-net = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense4')\n-net = tl.layers.DropconnectDenseLayer(net, keep=0.8, name='dropconnect')\n+    def test_net6(self):\n+        self.assertEqual(self.net6_shape[-1], 784)\n+        self.assertEqual(len(self.net6_layers), 2)\n+        self.assertEqual(len(self.net6_params), 4)\n+        self.assertEqual(self.net6_n_params, 308308)\n \n-net.print_layers()\n-net.print_params(False)\n+    def test_net7(self):\n+        self.assertEqual(self.net7_shape, [64, 100])\n+        self.assertEqual(len(self.net7_layers), 2)\n+        self.assertEqual(len(self.net7_params), 2)\n+        self.assertEqual(self.net7_n_params, 78500)\n \n-shape = net.outputs.get_shape().as_list()\n-if shape != [64, 100]:\n-    raise Exception(\"shape do not match\")\n+    def test_net8(self):\n+        self.assertEqual(self.net8_shape, [64, 100])\n+        self.assertEqual(len(self.net8_layers), 2)\n+        self.assertEqual(len(self.net8_params), 4)\n+        self.assertEqual(self.net8_n_params, 88600)\n \n-if len(net.all_layers) != 2:\n-    raise Exception(\"layers do not match\")\n \n-if len(net.all_params) != 4:\n-    raise Exception(\"params do not match\")\n+if __name__ == '__main__':\n \n-if net.count_params() != 88600:\n-    raise Exception(\"params do not match\")\n+    # tf.logging.set_verbosity(tf.logging.INFO)\n+    tf.logging.set_verbosity(tf.logging.DEBUG)\n+\n+    unittest.main()\n",
        "source_code_with_indent": "\n## DenseLayer\nx = tf.placeholder(tf.float32, shape=[None, 30])\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=10, name='dense')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 10:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 1:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 2:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 310:\n    <IND>raise Exception(\"params do not match\")\n\n## OneHotInputLayer\n<DED>x = tf.placeholder(tf.int32, shape=[None])\nnet = tl.layers.OneHotInputLayer(x, depth=8, name='onehot')\nprint(net)\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 8:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 0:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 0:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 0:\n    <IND>raise Exception(\"params do not match\")\n\n## Word2vecEmbeddingInputlayer\n<DED>batch_size = 8\ntrain_inputs = tf.placeholder(tf.int32, shape=(batch_size))\ntrain_labels = tf.placeholder(tf.int32, shape=(batch_size, 1))\nnet = tl.layers.Word2vecEmbeddingInputlayer(\n    inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\ncost = net.nce_cost\ntrain_params = net.all_params\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [8, 200]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 1:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 3:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 401000:\n    <IND>raise Exception(\"params do not match\")\n\n## EmbeddingInputlayer\n<DED>batch_size = 8\nx = tf.placeholder(tf.int32, shape=(batch_size, ))\nnet = tl.layers.EmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='embed')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [batch_size, 50]:  # (8, 50)\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 1:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 1:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 50000:\n    <IND>raise Exception(\"params do not match\")\n\n## AverageEmbeddingInputlayer\n<DED>batch_size = 8\nlength = 5\nx = tf.placeholder(tf.int32, shape=(batch_size, length))\nnet = tl.layers.AverageEmbeddingInputlayer(inputs=x, vocabulary_size=1000, embedding_size=50, name='avg')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [batch_size, 50]:  # (8, 50)\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 1:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 1:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 50000:\n    <IND>raise Exception(\"params do not match\")\n\n## ReconLayer\n<DED>x = tf.placeholder(tf.float32, shape=(None, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=196, act=tf.nn.sigmoid, name='dense2')\nnet = tl.layers.ReconLayer(net, x_recon=x, n_units=784, act=tf.nn.sigmoid, name='recon')\n# sess = tf.InteractiveSession()\n# tl.layers.initialize_global_variables(sess)\n# X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n# net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 784:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 2:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 4:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 308308:\n    <IND>raise Exception(\"params do not match\")\n\n## GaussianNoiseLayer\n<DED>x = tf.placeholder(tf.float32, shape=(64, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense3')\nnet = tl.layers.GaussianNoiseLayer(net, name='gaussian')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [64, 100]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 2:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 2:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 78500:\n    <IND>raise Exception(\"params do not match\")\n\n## DropconnectDenseLayer\n<DED>x = tf.placeholder(tf.float32, shape=(64, 784))\nnet = tl.layers.InputLayer(x, name='input')\nnet = tl.layers.DenseLayer(net, n_units=100, act=tf.nn.relu, name='dense4')\nnet = tl.layers.DropconnectDenseLayer(net, keep=0.8, name='dropconnect')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape != [64, 100]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 2:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 4:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 88600:\n    <IND>raise Exception(\"params do not match\")\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n\nclass Layer_Core_Test(unittest.TestCase):\n    <IND>@classmethod\n    def setUpClass(cls):\n\n        <IND>cls.batch_size = 8\n\n        # ============== DenseLayer ==============\n\n        x1 = tf.placeholder(tf.float32, shape=[None, 30])\n        net1 = tl.layers.InputLayer(x1, name='input')\n        net1 = tl.layers.DenseLayer(net1, n_units=10, name='dense')\n\n        net1.print_layers()\n        net1.print_params(False)\n\n        cls.net1_shape = net1.outputs.get_shape().as_list()\n        cls.net1_layers = net1.all_layers\n        cls.net1_params = net1.all_params\n        cls.net1_n_params = net1.count_params()\n\n        # ============== OneHotInputLayer ==============\n\n        x2 = tf.placeholder(tf.int32, shape=[None])\n        net2 = tl.layers.OneHotInputLayer(x2, depth=8, name='onehot')\n\n        net2.print_layers()\n        net2.print_params(False)\n\n        cls.net2_shape = net2.outputs.get_shape().as_list()\n        cls.net2_layers = net2.all_layers\n        cls.net2_params = net2.all_params\n        cls.net2_n_params = net2.count_params()\n\n        # ============== Word2vecEmbeddingInputlayer ==============\n\n        train_inputs = tf.placeholder(tf.int32, shape=cls.batch_size)\n        train_labels = tf.placeholder(tf.int32, shape=(cls.batch_size, 1))\n        net3 = tl.layers.Word2vecEmbeddingInputlayer(\n            inputs=train_inputs, train_labels=train_labels, vocabulary_size=1000, embedding_size=200, num_sampled=64, name='word2vec')\n\n        net3.print_layers()\n        net3.print_params(False)\n\n        cls.net3_shape = net3.outputs.get_shape().as_list()\n        cls.net3_layers = net3.all_layers\n        cls.net3_params = net3.all_params\n        cls.net3_n_params = net3.count_params()\n\n        # ============== EmbeddingInputlayer ==============\n\n        x4 = tf.placeholder(tf.int32, shape=(cls.batch_size, ))\n        net4 = tl.layers.EmbeddingInputlayer(inputs=x4, vocabulary_size=1000, embedding_size=50, name='embed')\n\n        net4.print_layers()\n        net4.print_params(False)\n\n        cls.net4_shape = net4.outputs.get_shape().as_list()\n        cls.net4_layers = net4.all_layers\n        cls.net4_params = net4.all_params\n        cls.net4_n_params = net4.count_params()\n\n        # ============== AverageEmbeddingInputlayer ==============\n\n        length = 5\n        x5 = tf.placeholder(tf.int32, shape=(cls.batch_size, length))\n        net5 = tl.layers.AverageEmbeddingInputlayer(inputs=x5, vocabulary_size=1000, embedding_size=50, name='avg')\n\n        net5.print_layers()\n        net5.print_params(False)\n\n        cls.net5_shape = net5.outputs.get_shape().as_list()\n        cls.net5_layers = net5.all_layers\n        cls.net5_params = net5.all_params\n        cls.net5_n_params = net5.count_params()\n\n        # ============== ReconLayer ==============\n\n        x6 = tf.placeholder(tf.float32, shape=(None, 784))\n        net6 = tl.layers.InputLayer(x6, name='input')\n        net6 = tl.layers.DenseLayer(net6, n_units=196, act=tf.nn.sigmoid, name='dense2')\n        net6 = tl.layers.ReconLayer(net6, x_recon=x6, n_units=784, act=tf.nn.sigmoid, name='recon')\n\n        # sess = tf.InteractiveSession()\n        # tl.layers.initialize_global_variables(sess)\n        # X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 784))\n        # net.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=1, batch_size=128, print_freq=1, save=True, save_name='w1pre_')\n\n        net6.print_layers()\n        net6.print_params(False)\n\n        cls.net6_shape = net6.outputs.get_shape().as_list()\n        cls.net6_layers = net6.all_layers\n        cls.net6_params = net6.all_params\n        cls.net6_n_params = net6.count_params()\n\n        # ============== GaussianNoiseLayer ==============\n\n        x7 = tf.placeholder(tf.float32, shape=(64, 784))\n        net7 = tl.layers.InputLayer(x7, name='input')\n        net7 = tl.layers.DenseLayer(net7, n_units=100, act=tf.nn.relu, name='dense3')\n        net7 = tl.layers.GaussianNoiseLayer(net7, name='gaussian')\n\n        net7.print_layers()\n        net7.print_params(False)\n\n        cls.net7_shape = net7.outputs.get_shape().as_list()\n        cls.net7_layers = net7.all_layers\n        cls.net7_params = net7.all_params\n        cls.net7_n_params = net7.count_params()\n\n        # ============== DropconnectDenseLayer ==============\n\n        x8 = tf.placeholder(tf.float32, shape=(64, 784))\n        net8 = tl.layers.InputLayer(x8, name='input')\n        net8 = tl.layers.DenseLayer(net8, n_units=100, act=tf.nn.relu, name='dense4')\n        net8 = tl.layers.DropconnectDenseLayer(net8, keep=0.8, name='dropconnect')\n\n        net8.print_layers()\n        net8.print_params(False)\n\n        cls.net8_shape = net8.outputs.get_shape().as_list()\n        cls.net8_layers = net8.all_layers\n        cls.net8_params = net8.all_params\n        cls.net8_n_params = net8.count_params()\n\n    <DED>@classmethod\n    def tearDownClass(cls):\n        <IND>tf.reset_default_graph()\n\n    <DED>def test_net1(self):\n        <IND>self.assertEqual(self.net1_shape[-1], 10)\n        self.assertEqual(len(self.net1_layers), 1)\n        self.assertEqual(len(self.net1_params), 2)\n        self.assertEqual(self.net1_n_params, 310)\n\n    <DED>def test_net2(self):\n        <IND>self.assertEqual(self.net2_shape[-1], 8)\n        self.assertEqual(len(self.net2_layers), 0)\n        self.assertEqual(len(self.net2_params), 0)\n        self.assertEqual(self.net2_n_params, 0)\n\n    <DED>def test_net3(self):\n        <IND>self.assertEqual(self.net3_shape, [self.batch_size, 200])\n        self.assertEqual(len(self.net3_layers), 1)\n        self.assertEqual(len(self.net3_params), 3)\n        self.assertEqual(self.net3_n_params, 401000)\n\n    <DED>def test_net4(self):\n        <IND>self.assertEqual(self.net4_shape, [self.batch_size, 50])\n        self.assertEqual(len(self.net4_layers), 1)\n        self.assertEqual(len(self.net4_params), 1)\n        self.assertEqual(self.net4_n_params, 50000)\n\n    <DED>def test_net5(self):\n        <IND>self.assertEqual(self.net5_shape, [self.batch_size, 50])\n        self.assertEqual(len(self.net5_layers), 1)\n        self.assertEqual(len(self.net5_params), 1)\n        self.assertEqual(self.net5_n_params, 50000)\n\n    <DED>def test_net6(self):\n        <IND>self.assertEqual(self.net6_shape[-1], 784)\n        self.assertEqual(len(self.net6_layers), 2)\n        self.assertEqual(len(self.net6_params), 4)\n        self.assertEqual(self.net6_n_params, 308308)\n\n    <DED>def test_net7(self):\n        <IND>self.assertEqual(self.net7_shape, [64, 100])\n        self.assertEqual(len(self.net7_layers), 2)\n        self.assertEqual(len(self.net7_params), 2)\n        self.assertEqual(self.net7_n_params, 78500)\n\n    <DED>def test_net8(self):\n        <IND>self.assertEqual(self.net8_shape, [64, 100])\n        self.assertEqual(len(self.net8_layers), 2)\n        self.assertEqual(len(self.net8_params), 4)\n        self.assertEqual(self.net8_n_params, 88600)\n\n\n<DED><DED>if __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    <IND>tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "tensorlayer/TensorLayer",
    "commit": "6f539ad2324ddccc18b6ac39e4a2f4aeb12173a2",
    "filename": "tests/test_layers_merge.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/tensorlayer-TensorLayer/tests/test_layers_merge.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "tests/test_layers_merge.py:27:0 Incompatible variable type [9]: net is declared to have type `tl.layers.merge.ConcatLayer` but is used as type `tl.layers.merge.ElementwiseLayer`.",
    "message": " net is declared to have type `tl.layers.merge.ConcatLayer` but is used as type `tl.layers.merge.ElementwiseLayer`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 27,
    "warning_line": "net = tl.layers.ElementwiseLayer([net_0, net_1], combine_fn=tf.minimum, name='minimum')",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import tensorflow as tf\n",
        "source_code_len": 24,
        "target_code": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_len": 87,
        "diff_format": "@@ -1,1 +1,5 @@\n+#!/usr/bin/env python\n+# -*- coding: utf-8 -*-\n+import unittest\n+\n import tensorflow as tf\n",
        "source_code_with_indent": "import tensorflow as tf\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\nsess = tf.InteractiveSession()\n\n## vector\nx = tf.placeholder(tf.float32, shape=[None, 784])\ninputs = tl.layers.InputLayer(x, name='input_layer')\nnet1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu1_1')\nnet2 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu2_1')\nnet = tl.layers.ConcatLayer([net1, net2], concat_dim=1, name='concat_layer')\n\nnet.print_params(False)\nnet.print_layers()\n\nif len(net.all_layers) != 3:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 4:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 157000:\n    raise Exception(\"params do not match\")\n\nnet_0 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_0')\nnet_1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_1')\nnet = tl.layers.ElementwiseLayer([net_0, net_1], combine_fn=tf.minimum, name='minimum')\n\nnet.print_params(False)\nnet.print_layers()\n\nif len(net.all_layers) != 3:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 4:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 157000:\n    raise Exception(\"params do not match\")\n\n## image\nx = tf.placeholder(tf.float32, shape=[None, 100, 100, 3])\ninputs = tl.layers.InputLayer(x, name='input')\nnet1 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c1')\nnet2 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c2')\nnet = tl.layers.ConcatLayer([net1, net2], concat_dim=-1, name='concat')\n\nnet.print_params(False)\nnet.print_layers()\n\nshape = net.outputs.get_shape().as_list()\nif shape[1:] != [50, 50, 64]:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 3:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 4:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 1792:\n    raise Exception(\"params do not match\")\n\nnet = tl.layers.ElementwiseLayer([net1, net2], combine_fn=tf.minimum, name='minimum2')\nnet.print_params(False)\nnet.print_layers()\n\nshape = net.outputs.get_shape().as_list()\nif shape[1:] != [50, 50, 32]:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 3:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 4:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 1792:\n    raise Exception(\"params do not match\")\n",
        "source_code_len": 2418,
        "target_code": "\n\nclass Layer_Merge_Test(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n\n        cls.data = dict()\n\n        ##############\n        #   vector   #\n        ##############\n\n        x = tf.placeholder(tf.float32, shape=[None, 784])\n        inputs = tl.layers.InputLayer(x, name='input_layer')\n\n        net_v1_1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu1_1')\n        net_v1_2 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu2_1')\n        net_v1 = tl.layers.ConcatLayer([net_v1_1, net_v1_2], concat_dim=1, name='concat_layer')\n\n        net_v1.print_params(False)\n        net_v1.print_layers()\n\n        cls.data[\"net_vector1\"] = dict()\n        cls.data[\"net_vector1\"][\"layers\"] = net_v1.all_layers\n        cls.data[\"net_vector1\"][\"params\"] = net_v1.all_params\n        cls.data[\"net_vector1\"][\"n_params\"] = net_v1.count_params()\n\n        net_v2_1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_0')\n        net_v2_2 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_1')\n        net_v2 = tl.layers.ElementwiseLayer([net_v2_1, net_v2_2], combine_fn=tf.minimum, name='minimum')\n\n        net_v2.print_params(False)\n        net_v2.print_layers()\n\n        cls.data[\"net_vector2\"] = dict()\n        cls.data[\"net_vector2\"][\"layers\"] = net_v2.all_layers\n        cls.data[\"net_vector2\"][\"params\"] = net_v2.all_params\n        cls.data[\"net_vector2\"][\"n_params\"] = net_v2.count_params()\n\n        #############\n        #   Image   #\n        #############\n\n        x = tf.placeholder(tf.float32, shape=[None, 100, 100, 3])\n        inputs = tl.layers.InputLayer(x, name='input')\n\n        net_im1_1 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c1')\n        net_im1_2 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c2')\n        net_im1 = tl.layers.ConcatLayer([net_im1_1, net_im1_2], concat_dim=-1, name='concat')\n\n        net_im1.print_params(False)\n        net_im1.print_layers()\n\n        cls.data[\"net_image1\"] = dict()\n        cls.data[\"net_image1\"][\"shape\"] = net_im1.outputs.get_shape().as_list()\n        cls.data[\"net_image1\"][\"layers\"] = net_im1.all_layers\n        cls.data[\"net_image1\"][\"params\"] = net_im1.all_params\n        cls.data[\"net_image1\"][\"n_params\"] = net_im1.count_params()\n\n        net_im2 = tl.layers.ElementwiseLayer([net_im1_1, net_im1_2], combine_fn=tf.minimum, name='minimum2')\n\n        net_im2.print_params(False)\n        net_im2.print_layers()\n\n        cls.data[\"net_image2\"] = dict()\n        cls.data[\"net_image2\"][\"shape\"] = net_im2.outputs.get_shape().as_list()\n        cls.data[\"net_image2\"][\"layers\"] = net_im2.all_layers\n        cls.data[\"net_image2\"][\"params\"] = net_im2.all_params\n        cls.data[\"net_image2\"][\"n_params\"] = net_im2.count_params()\n\n    @classmethod\n    def tearDownClass(cls):\n        tf.reset_default_graph()\n\n    def test_net_vector1(self):\n        self.assertEqual(len(self.data[\"net_vector1\"][\"layers\"]), 3)\n        self.assertEqual(len(self.data[\"net_vector1\"][\"params\"]), 4)\n        self.assertEqual(self.data[\"net_vector1\"][\"n_params\"], 157000)\n\n    def test_net_vector2(self):\n        self.assertEqual(len(self.data[\"net_vector2\"][\"layers\"]), 3)\n        self.assertEqual(len(self.data[\"net_vector2\"][\"params\"]), 4)\n        self.assertEqual(self.data[\"net_vector2\"][\"n_params\"], 157000)\n\n    def test_net_image1(self):\n        self.assertEqual(self.data[\"net_image1\"][\"shape\"][1:], [50, 50, 64])\n        self.assertEqual(len(self.data[\"net_image1\"][\"layers\"]), 3)\n        self.assertEqual(len(self.data[\"net_image1\"][\"params\"]), 4)\n        self.assertEqual(self.data[\"net_image1\"][\"n_params\"], 1792)\n\n    def test_net_image2(self):\n        self.assertEqual(self.data[\"net_image2\"][\"shape\"][1:], [50, 50, 32])\n        self.assertEqual(len(self.data[\"net_image2\"][\"layers\"]), 3)\n        self.assertEqual(len(self.data[\"net_image2\"][\"params\"]), 4)\n        self.assertEqual(self.data[\"net_image2\"][\"n_params\"], 1792)\n\n\nif __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_len": 4208,
        "diff_format": "@@ -3,77 +7,103 @@\n \n-sess = tf.InteractiveSession()\n \n-## vector\n-x = tf.placeholder(tf.float32, shape=[None, 784])\n-inputs = tl.layers.InputLayer(x, name='input_layer')\n-net1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu1_1')\n-net2 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu2_1')\n-net = tl.layers.ConcatLayer([net1, net2], concat_dim=1, name='concat_layer')\n+class Layer_Merge_Test(unittest.TestCase):\n+    @classmethod\n+    def setUpClass(cls):\n \n-net.print_params(False)\n-net.print_layers()\n+        cls.data = dict()\n \n-if len(net.all_layers) != 3:\n-    raise Exception(\"layers do not match\")\n+        ##############\n+        #   vector   #\n+        ##############\n \n-if len(net.all_params) != 4:\n-    raise Exception(\"params do not match\")\n+        x = tf.placeholder(tf.float32, shape=[None, 784])\n+        inputs = tl.layers.InputLayer(x, name='input_layer')\n \n-if net.count_params() != 157000:\n-    raise Exception(\"params do not match\")\n+        net_v1_1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu1_1')\n+        net_v1_2 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu2_1')\n+        net_v1 = tl.layers.ConcatLayer([net_v1_1, net_v1_2], concat_dim=1, name='concat_layer')\n \n-net_0 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_0')\n-net_1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_1')\n-net = tl.layers.ElementwiseLayer([net_0, net_1], combine_fn=tf.minimum, name='minimum')\n+        net_v1.print_params(False)\n+        net_v1.print_layers()\n \n-net.print_params(False)\n-net.print_layers()\n+        cls.data[\"net_vector1\"] = dict()\n+        cls.data[\"net_vector1\"][\"layers\"] = net_v1.all_layers\n+        cls.data[\"net_vector1\"][\"params\"] = net_v1.all_params\n+        cls.data[\"net_vector1\"][\"n_params\"] = net_v1.count_params()\n \n-if len(net.all_layers) != 3:\n-    raise Exception(\"layers do not match\")\n+        net_v2_1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_0')\n+        net_v2_2 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_1')\n+        net_v2 = tl.layers.ElementwiseLayer([net_v2_1, net_v2_2], combine_fn=tf.minimum, name='minimum')\n \n-if len(net.all_params) != 4:\n-    raise Exception(\"params do not match\")\n+        net_v2.print_params(False)\n+        net_v2.print_layers()\n \n-if net.count_params() != 157000:\n-    raise Exception(\"params do not match\")\n+        cls.data[\"net_vector2\"] = dict()\n+        cls.data[\"net_vector2\"][\"layers\"] = net_v2.all_layers\n+        cls.data[\"net_vector2\"][\"params\"] = net_v2.all_params\n+        cls.data[\"net_vector2\"][\"n_params\"] = net_v2.count_params()\n \n-## image\n-x = tf.placeholder(tf.float32, shape=[None, 100, 100, 3])\n-inputs = tl.layers.InputLayer(x, name='input')\n-net1 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c1')\n-net2 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c2')\n-net = tl.layers.ConcatLayer([net1, net2], concat_dim=-1, name='concat')\n+        #############\n+        #   Image   #\n+        #############\n \n-net.print_params(False)\n-net.print_layers()\n+        x = tf.placeholder(tf.float32, shape=[None, 100, 100, 3])\n+        inputs = tl.layers.InputLayer(x, name='input')\n \n-shape = net.outputs.get_shape().as_list()\n-if shape[1:] != [50, 50, 64]:\n-    raise Exception(\"shape do not match\")\n+        net_im1_1 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c1')\n+        net_im1_2 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c2')\n+        net_im1 = tl.layers.ConcatLayer([net_im1_1, net_im1_2], concat_dim=-1, name='concat')\n \n-if len(net.all_layers) != 3:\n-    raise Exception(\"layers do not match\")\n+        net_im1.print_params(False)\n+        net_im1.print_layers()\n \n-if len(net.all_params) != 4:\n-    raise Exception(\"params do not match\")\n+        cls.data[\"net_image1\"] = dict()\n+        cls.data[\"net_image1\"][\"shape\"] = net_im1.outputs.get_shape().as_list()\n+        cls.data[\"net_image1\"][\"layers\"] = net_im1.all_layers\n+        cls.data[\"net_image1\"][\"params\"] = net_im1.all_params\n+        cls.data[\"net_image1\"][\"n_params\"] = net_im1.count_params()\n \n-if net.count_params() != 1792:\n-    raise Exception(\"params do not match\")\n+        net_im2 = tl.layers.ElementwiseLayer([net_im1_1, net_im1_2], combine_fn=tf.minimum, name='minimum2')\n \n-net = tl.layers.ElementwiseLayer([net1, net2], combine_fn=tf.minimum, name='minimum2')\n-net.print_params(False)\n-net.print_layers()\n+        net_im2.print_params(False)\n+        net_im2.print_layers()\n \n-shape = net.outputs.get_shape().as_list()\n-if shape[1:] != [50, 50, 32]:\n-    raise Exception(\"shape do not match\")\n+        cls.data[\"net_image2\"] = dict()\n+        cls.data[\"net_image2\"][\"shape\"] = net_im2.outputs.get_shape().as_list()\n+        cls.data[\"net_image2\"][\"layers\"] = net_im2.all_layers\n+        cls.data[\"net_image2\"][\"params\"] = net_im2.all_params\n+        cls.data[\"net_image2\"][\"n_params\"] = net_im2.count_params()\n \n-if len(net.all_layers) != 3:\n-    raise Exception(\"layers do not match\")\n+    @classmethod\n+    def tearDownClass(cls):\n+        tf.reset_default_graph()\n \n-if len(net.all_params) != 4:\n-    raise Exception(\"params do not match\")\n+    def test_net_vector1(self):\n+        self.assertEqual(len(self.data[\"net_vector1\"][\"layers\"]), 3)\n+        self.assertEqual(len(self.data[\"net_vector1\"][\"params\"]), 4)\n+        self.assertEqual(self.data[\"net_vector1\"][\"n_params\"], 157000)\n \n-if net.count_params() != 1792:\n-    raise Exception(\"params do not match\")\n+    def test_net_vector2(self):\n+        self.assertEqual(len(self.data[\"net_vector2\"][\"layers\"]), 3)\n+        self.assertEqual(len(self.data[\"net_vector2\"][\"params\"]), 4)\n+        self.assertEqual(self.data[\"net_vector2\"][\"n_params\"], 157000)\n+\n+    def test_net_image1(self):\n+        self.assertEqual(self.data[\"net_image1\"][\"shape\"][1:], [50, 50, 64])\n+        self.assertEqual(len(self.data[\"net_image1\"][\"layers\"]), 3)\n+        self.assertEqual(len(self.data[\"net_image1\"][\"params\"]), 4)\n+        self.assertEqual(self.data[\"net_image1\"][\"n_params\"], 1792)\n+\n+    def test_net_image2(self):\n+        self.assertEqual(self.data[\"net_image2\"][\"shape\"][1:], [50, 50, 32])\n+        self.assertEqual(len(self.data[\"net_image2\"][\"layers\"]), 3)\n+        self.assertEqual(len(self.data[\"net_image2\"][\"params\"]), 4)\n+        self.assertEqual(self.data[\"net_image2\"][\"n_params\"], 1792)\n+\n+\n+if __name__ == '__main__':\n+\n+    # tf.logging.set_verbosity(tf.logging.INFO)\n+    tf.logging.set_verbosity(tf.logging.DEBUG)\n+\n+    unittest.main()\n",
        "source_code_with_indent": "\nsess = tf.InteractiveSession()\n\n## vector\nx = tf.placeholder(tf.float32, shape=[None, 784])\ninputs = tl.layers.InputLayer(x, name='input_layer')\nnet1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu1_1')\nnet2 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu2_1')\nnet = tl.layers.ConcatLayer([net1, net2], concat_dim=1, name='concat_layer')\n\nnet.print_params(False)\nnet.print_layers()\n\nif len(net.all_layers) != 3:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 4:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 157000:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>net_0 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_0')\nnet_1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_1')\nnet = tl.layers.ElementwiseLayer([net_0, net_1], combine_fn=tf.minimum, name='minimum')\n\nnet.print_params(False)\nnet.print_layers()\n\nif len(net.all_layers) != 3:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 4:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 157000:\n    <IND>raise Exception(\"params do not match\")\n\n## image\n<DED>x = tf.placeholder(tf.float32, shape=[None, 100, 100, 3])\ninputs = tl.layers.InputLayer(x, name='input')\nnet1 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c1')\nnet2 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c2')\nnet = tl.layers.ConcatLayer([net1, net2], concat_dim=-1, name='concat')\n\nnet.print_params(False)\nnet.print_layers()\n\nshape = net.outputs.get_shape().as_list()\nif shape[1:] != [50, 50, 64]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 3:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 4:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 1792:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>net = tl.layers.ElementwiseLayer([net1, net2], combine_fn=tf.minimum, name='minimum2')\nnet.print_params(False)\nnet.print_layers()\n\nshape = net.outputs.get_shape().as_list()\nif shape[1:] != [50, 50, 32]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 3:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 4:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 1792:\n    <IND>raise Exception(\"params do not match\")\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n\nclass Layer_Merge_Test(unittest.TestCase):\n    <IND>@classmethod\n    def setUpClass(cls):\n\n        <IND>cls.data = dict()\n\n        ##############\n        #   vector   #\n        ##############\n\n        x = tf.placeholder(tf.float32, shape=[None, 784])\n        inputs = tl.layers.InputLayer(x, name='input_layer')\n\n        net_v1_1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu1_1')\n        net_v1_2 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu2_1')\n        net_v1 = tl.layers.ConcatLayer([net_v1_1, net_v1_2], concat_dim=1, name='concat_layer')\n\n        net_v1.print_params(False)\n        net_v1.print_layers()\n\n        cls.data[\"net_vector1\"] = dict()\n        cls.data[\"net_vector1\"][\"layers\"] = net_v1.all_layers\n        cls.data[\"net_vector1\"][\"params\"] = net_v1.all_params\n        cls.data[\"net_vector1\"][\"n_params\"] = net_v1.count_params()\n\n        net_v2_1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_0')\n        net_v2_2 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_1')\n        net_v2 = tl.layers.ElementwiseLayer([net_v2_1, net_v2_2], combine_fn=tf.minimum, name='minimum')\n\n        net_v2.print_params(False)\n        net_v2.print_layers()\n\n        cls.data[\"net_vector2\"] = dict()\n        cls.data[\"net_vector2\"][\"layers\"] = net_v2.all_layers\n        cls.data[\"net_vector2\"][\"params\"] = net_v2.all_params\n        cls.data[\"net_vector2\"][\"n_params\"] = net_v2.count_params()\n\n        #############\n        #   Image   #\n        #############\n\n        x = tf.placeholder(tf.float32, shape=[None, 100, 100, 3])\n        inputs = tl.layers.InputLayer(x, name='input')\n\n        net_im1_1 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c1')\n        net_im1_2 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c2')\n        net_im1 = tl.layers.ConcatLayer([net_im1_1, net_im1_2], concat_dim=-1, name='concat')\n\n        net_im1.print_params(False)\n        net_im1.print_layers()\n\n        cls.data[\"net_image1\"] = dict()\n        cls.data[\"net_image1\"][\"shape\"] = net_im1.outputs.get_shape().as_list()\n        cls.data[\"net_image1\"][\"layers\"] = net_im1.all_layers\n        cls.data[\"net_image1\"][\"params\"] = net_im1.all_params\n        cls.data[\"net_image1\"][\"n_params\"] = net_im1.count_params()\n\n        net_im2 = tl.layers.ElementwiseLayer([net_im1_1, net_im1_2], combine_fn=tf.minimum, name='minimum2')\n\n        net_im2.print_params(False)\n        net_im2.print_layers()\n\n        cls.data[\"net_image2\"] = dict()\n        cls.data[\"net_image2\"][\"shape\"] = net_im2.outputs.get_shape().as_list()\n        cls.data[\"net_image2\"][\"layers\"] = net_im2.all_layers\n        cls.data[\"net_image2\"][\"params\"] = net_im2.all_params\n        cls.data[\"net_image2\"][\"n_params\"] = net_im2.count_params()\n\n    <DED>@classmethod\n    def tearDownClass(cls):\n        <IND>tf.reset_default_graph()\n\n    <DED>def test_net_vector1(self):\n        <IND>self.assertEqual(len(self.data[\"net_vector1\"][\"layers\"]), 3)\n        self.assertEqual(len(self.data[\"net_vector1\"][\"params\"]), 4)\n        self.assertEqual(self.data[\"net_vector1\"][\"n_params\"], 157000)\n\n    <DED>def test_net_vector2(self):\n        <IND>self.assertEqual(len(self.data[\"net_vector2\"][\"layers\"]), 3)\n        self.assertEqual(len(self.data[\"net_vector2\"][\"params\"]), 4)\n        self.assertEqual(self.data[\"net_vector2\"][\"n_params\"], 157000)\n\n    <DED>def test_net_image1(self):\n        <IND>self.assertEqual(self.data[\"net_image1\"][\"shape\"][1:], [50, 50, 64])\n        self.assertEqual(len(self.data[\"net_image1\"][\"layers\"]), 3)\n        self.assertEqual(len(self.data[\"net_image1\"][\"params\"]), 4)\n        self.assertEqual(self.data[\"net_image1\"][\"n_params\"], 1792)\n\n    <DED>def test_net_image2(self):\n        <IND>self.assertEqual(self.data[\"net_image2\"][\"shape\"][1:], [50, 50, 32])\n        self.assertEqual(len(self.data[\"net_image2\"][\"layers\"]), 3)\n        self.assertEqual(len(self.data[\"net_image2\"][\"params\"]), 4)\n        self.assertEqual(self.data[\"net_image2\"][\"n_params\"], 1792)\n\n\n<DED><DED>if __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    <IND>tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "tensorlayer/TensorLayer",
    "commit": "6f539ad2324ddccc18b6ac39e4a2f4aeb12173a2",
    "filename": "tests/test_layers_merge.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/tensorlayer-TensorLayer/tests/test_layers_merge.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "tests/test_layers_merge.py:64:0 Incompatible variable type [9]: net is declared to have type `tl.layers.merge.ConcatLayer` but is used as type `tl.layers.merge.ElementwiseLayer`.",
    "message": " net is declared to have type `tl.layers.merge.ConcatLayer` but is used as type `tl.layers.merge.ElementwiseLayer`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 64,
    "warning_line": "net = tl.layers.ElementwiseLayer([net1, net2], combine_fn=tf.minimum, name='minimum2')",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import tensorflow as tf\n",
        "source_code_len": 24,
        "target_code": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_len": 87,
        "diff_format": "@@ -1,1 +1,5 @@\n+#!/usr/bin/env python\n+# -*- coding: utf-8 -*-\n+import unittest\n+\n import tensorflow as tf\n",
        "source_code_with_indent": "import tensorflow as tf\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\nsess = tf.InteractiveSession()\n\n## vector\nx = tf.placeholder(tf.float32, shape=[None, 784])\ninputs = tl.layers.InputLayer(x, name='input_layer')\nnet1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu1_1')\nnet2 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu2_1')\nnet = tl.layers.ConcatLayer([net1, net2], concat_dim=1, name='concat_layer')\n\nnet.print_params(False)\nnet.print_layers()\n\nif len(net.all_layers) != 3:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 4:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 157000:\n    raise Exception(\"params do not match\")\n\nnet_0 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_0')\nnet_1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_1')\nnet = tl.layers.ElementwiseLayer([net_0, net_1], combine_fn=tf.minimum, name='minimum')\n\nnet.print_params(False)\nnet.print_layers()\n\nif len(net.all_layers) != 3:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 4:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 157000:\n    raise Exception(\"params do not match\")\n\n## image\nx = tf.placeholder(tf.float32, shape=[None, 100, 100, 3])\ninputs = tl.layers.InputLayer(x, name='input')\nnet1 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c1')\nnet2 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c2')\nnet = tl.layers.ConcatLayer([net1, net2], concat_dim=-1, name='concat')\n\nnet.print_params(False)\nnet.print_layers()\n\nshape = net.outputs.get_shape().as_list()\nif shape[1:] != [50, 50, 64]:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 3:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 4:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 1792:\n    raise Exception(\"params do not match\")\n\nnet = tl.layers.ElementwiseLayer([net1, net2], combine_fn=tf.minimum, name='minimum2')\nnet.print_params(False)\nnet.print_layers()\n\nshape = net.outputs.get_shape().as_list()\nif shape[1:] != [50, 50, 32]:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 3:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 4:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 1792:\n    raise Exception(\"params do not match\")\n",
        "source_code_len": 2418,
        "target_code": "\n\nclass Layer_Merge_Test(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n\n        cls.data = dict()\n\n        ##############\n        #   vector   #\n        ##############\n\n        x = tf.placeholder(tf.float32, shape=[None, 784])\n        inputs = tl.layers.InputLayer(x, name='input_layer')\n\n        net_v1_1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu1_1')\n        net_v1_2 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu2_1')\n        net_v1 = tl.layers.ConcatLayer([net_v1_1, net_v1_2], concat_dim=1, name='concat_layer')\n\n        net_v1.print_params(False)\n        net_v1.print_layers()\n\n        cls.data[\"net_vector1\"] = dict()\n        cls.data[\"net_vector1\"][\"layers\"] = net_v1.all_layers\n        cls.data[\"net_vector1\"][\"params\"] = net_v1.all_params\n        cls.data[\"net_vector1\"][\"n_params\"] = net_v1.count_params()\n\n        net_v2_1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_0')\n        net_v2_2 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_1')\n        net_v2 = tl.layers.ElementwiseLayer([net_v2_1, net_v2_2], combine_fn=tf.minimum, name='minimum')\n\n        net_v2.print_params(False)\n        net_v2.print_layers()\n\n        cls.data[\"net_vector2\"] = dict()\n        cls.data[\"net_vector2\"][\"layers\"] = net_v2.all_layers\n        cls.data[\"net_vector2\"][\"params\"] = net_v2.all_params\n        cls.data[\"net_vector2\"][\"n_params\"] = net_v2.count_params()\n\n        #############\n        #   Image   #\n        #############\n\n        x = tf.placeholder(tf.float32, shape=[None, 100, 100, 3])\n        inputs = tl.layers.InputLayer(x, name='input')\n\n        net_im1_1 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c1')\n        net_im1_2 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c2')\n        net_im1 = tl.layers.ConcatLayer([net_im1_1, net_im1_2], concat_dim=-1, name='concat')\n\n        net_im1.print_params(False)\n        net_im1.print_layers()\n\n        cls.data[\"net_image1\"] = dict()\n        cls.data[\"net_image1\"][\"shape\"] = net_im1.outputs.get_shape().as_list()\n        cls.data[\"net_image1\"][\"layers\"] = net_im1.all_layers\n        cls.data[\"net_image1\"][\"params\"] = net_im1.all_params\n        cls.data[\"net_image1\"][\"n_params\"] = net_im1.count_params()\n\n        net_im2 = tl.layers.ElementwiseLayer([net_im1_1, net_im1_2], combine_fn=tf.minimum, name='minimum2')\n\n        net_im2.print_params(False)\n        net_im2.print_layers()\n\n        cls.data[\"net_image2\"] = dict()\n        cls.data[\"net_image2\"][\"shape\"] = net_im2.outputs.get_shape().as_list()\n        cls.data[\"net_image2\"][\"layers\"] = net_im2.all_layers\n        cls.data[\"net_image2\"][\"params\"] = net_im2.all_params\n        cls.data[\"net_image2\"][\"n_params\"] = net_im2.count_params()\n\n    @classmethod\n    def tearDownClass(cls):\n        tf.reset_default_graph()\n\n    def test_net_vector1(self):\n        self.assertEqual(len(self.data[\"net_vector1\"][\"layers\"]), 3)\n        self.assertEqual(len(self.data[\"net_vector1\"][\"params\"]), 4)\n        self.assertEqual(self.data[\"net_vector1\"][\"n_params\"], 157000)\n\n    def test_net_vector2(self):\n        self.assertEqual(len(self.data[\"net_vector2\"][\"layers\"]), 3)\n        self.assertEqual(len(self.data[\"net_vector2\"][\"params\"]), 4)\n        self.assertEqual(self.data[\"net_vector2\"][\"n_params\"], 157000)\n\n    def test_net_image1(self):\n        self.assertEqual(self.data[\"net_image1\"][\"shape\"][1:], [50, 50, 64])\n        self.assertEqual(len(self.data[\"net_image1\"][\"layers\"]), 3)\n        self.assertEqual(len(self.data[\"net_image1\"][\"params\"]), 4)\n        self.assertEqual(self.data[\"net_image1\"][\"n_params\"], 1792)\n\n    def test_net_image2(self):\n        self.assertEqual(self.data[\"net_image2\"][\"shape\"][1:], [50, 50, 32])\n        self.assertEqual(len(self.data[\"net_image2\"][\"layers\"]), 3)\n        self.assertEqual(len(self.data[\"net_image2\"][\"params\"]), 4)\n        self.assertEqual(self.data[\"net_image2\"][\"n_params\"], 1792)\n\n\nif __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_len": 4208,
        "diff_format": "@@ -3,77 +7,103 @@\n \n-sess = tf.InteractiveSession()\n \n-## vector\n-x = tf.placeholder(tf.float32, shape=[None, 784])\n-inputs = tl.layers.InputLayer(x, name='input_layer')\n-net1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu1_1')\n-net2 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu2_1')\n-net = tl.layers.ConcatLayer([net1, net2], concat_dim=1, name='concat_layer')\n+class Layer_Merge_Test(unittest.TestCase):\n+    @classmethod\n+    def setUpClass(cls):\n \n-net.print_params(False)\n-net.print_layers()\n+        cls.data = dict()\n \n-if len(net.all_layers) != 3:\n-    raise Exception(\"layers do not match\")\n+        ##############\n+        #   vector   #\n+        ##############\n \n-if len(net.all_params) != 4:\n-    raise Exception(\"params do not match\")\n+        x = tf.placeholder(tf.float32, shape=[None, 784])\n+        inputs = tl.layers.InputLayer(x, name='input_layer')\n \n-if net.count_params() != 157000:\n-    raise Exception(\"params do not match\")\n+        net_v1_1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu1_1')\n+        net_v1_2 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu2_1')\n+        net_v1 = tl.layers.ConcatLayer([net_v1_1, net_v1_2], concat_dim=1, name='concat_layer')\n \n-net_0 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_0')\n-net_1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_1')\n-net = tl.layers.ElementwiseLayer([net_0, net_1], combine_fn=tf.minimum, name='minimum')\n+        net_v1.print_params(False)\n+        net_v1.print_layers()\n \n-net.print_params(False)\n-net.print_layers()\n+        cls.data[\"net_vector1\"] = dict()\n+        cls.data[\"net_vector1\"][\"layers\"] = net_v1.all_layers\n+        cls.data[\"net_vector1\"][\"params\"] = net_v1.all_params\n+        cls.data[\"net_vector1\"][\"n_params\"] = net_v1.count_params()\n \n-if len(net.all_layers) != 3:\n-    raise Exception(\"layers do not match\")\n+        net_v2_1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_0')\n+        net_v2_2 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_1')\n+        net_v2 = tl.layers.ElementwiseLayer([net_v2_1, net_v2_2], combine_fn=tf.minimum, name='minimum')\n \n-if len(net.all_params) != 4:\n-    raise Exception(\"params do not match\")\n+        net_v2.print_params(False)\n+        net_v2.print_layers()\n \n-if net.count_params() != 157000:\n-    raise Exception(\"params do not match\")\n+        cls.data[\"net_vector2\"] = dict()\n+        cls.data[\"net_vector2\"][\"layers\"] = net_v2.all_layers\n+        cls.data[\"net_vector2\"][\"params\"] = net_v2.all_params\n+        cls.data[\"net_vector2\"][\"n_params\"] = net_v2.count_params()\n \n-## image\n-x = tf.placeholder(tf.float32, shape=[None, 100, 100, 3])\n-inputs = tl.layers.InputLayer(x, name='input')\n-net1 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c1')\n-net2 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c2')\n-net = tl.layers.ConcatLayer([net1, net2], concat_dim=-1, name='concat')\n+        #############\n+        #   Image   #\n+        #############\n \n-net.print_params(False)\n-net.print_layers()\n+        x = tf.placeholder(tf.float32, shape=[None, 100, 100, 3])\n+        inputs = tl.layers.InputLayer(x, name='input')\n \n-shape = net.outputs.get_shape().as_list()\n-if shape[1:] != [50, 50, 64]:\n-    raise Exception(\"shape do not match\")\n+        net_im1_1 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c1')\n+        net_im1_2 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c2')\n+        net_im1 = tl.layers.ConcatLayer([net_im1_1, net_im1_2], concat_dim=-1, name='concat')\n \n-if len(net.all_layers) != 3:\n-    raise Exception(\"layers do not match\")\n+        net_im1.print_params(False)\n+        net_im1.print_layers()\n \n-if len(net.all_params) != 4:\n-    raise Exception(\"params do not match\")\n+        cls.data[\"net_image1\"] = dict()\n+        cls.data[\"net_image1\"][\"shape\"] = net_im1.outputs.get_shape().as_list()\n+        cls.data[\"net_image1\"][\"layers\"] = net_im1.all_layers\n+        cls.data[\"net_image1\"][\"params\"] = net_im1.all_params\n+        cls.data[\"net_image1\"][\"n_params\"] = net_im1.count_params()\n \n-if net.count_params() != 1792:\n-    raise Exception(\"params do not match\")\n+        net_im2 = tl.layers.ElementwiseLayer([net_im1_1, net_im1_2], combine_fn=tf.minimum, name='minimum2')\n \n-net = tl.layers.ElementwiseLayer([net1, net2], combine_fn=tf.minimum, name='minimum2')\n-net.print_params(False)\n-net.print_layers()\n+        net_im2.print_params(False)\n+        net_im2.print_layers()\n \n-shape = net.outputs.get_shape().as_list()\n-if shape[1:] != [50, 50, 32]:\n-    raise Exception(\"shape do not match\")\n+        cls.data[\"net_image2\"] = dict()\n+        cls.data[\"net_image2\"][\"shape\"] = net_im2.outputs.get_shape().as_list()\n+        cls.data[\"net_image2\"][\"layers\"] = net_im2.all_layers\n+        cls.data[\"net_image2\"][\"params\"] = net_im2.all_params\n+        cls.data[\"net_image2\"][\"n_params\"] = net_im2.count_params()\n \n-if len(net.all_layers) != 3:\n-    raise Exception(\"layers do not match\")\n+    @classmethod\n+    def tearDownClass(cls):\n+        tf.reset_default_graph()\n \n-if len(net.all_params) != 4:\n-    raise Exception(\"params do not match\")\n+    def test_net_vector1(self):\n+        self.assertEqual(len(self.data[\"net_vector1\"][\"layers\"]), 3)\n+        self.assertEqual(len(self.data[\"net_vector1\"][\"params\"]), 4)\n+        self.assertEqual(self.data[\"net_vector1\"][\"n_params\"], 157000)\n \n-if net.count_params() != 1792:\n-    raise Exception(\"params do not match\")\n+    def test_net_vector2(self):\n+        self.assertEqual(len(self.data[\"net_vector2\"][\"layers\"]), 3)\n+        self.assertEqual(len(self.data[\"net_vector2\"][\"params\"]), 4)\n+        self.assertEqual(self.data[\"net_vector2\"][\"n_params\"], 157000)\n+\n+    def test_net_image1(self):\n+        self.assertEqual(self.data[\"net_image1\"][\"shape\"][1:], [50, 50, 64])\n+        self.assertEqual(len(self.data[\"net_image1\"][\"layers\"]), 3)\n+        self.assertEqual(len(self.data[\"net_image1\"][\"params\"]), 4)\n+        self.assertEqual(self.data[\"net_image1\"][\"n_params\"], 1792)\n+\n+    def test_net_image2(self):\n+        self.assertEqual(self.data[\"net_image2\"][\"shape\"][1:], [50, 50, 32])\n+        self.assertEqual(len(self.data[\"net_image2\"][\"layers\"]), 3)\n+        self.assertEqual(len(self.data[\"net_image2\"][\"params\"]), 4)\n+        self.assertEqual(self.data[\"net_image2\"][\"n_params\"], 1792)\n+\n+\n+if __name__ == '__main__':\n+\n+    # tf.logging.set_verbosity(tf.logging.INFO)\n+    tf.logging.set_verbosity(tf.logging.DEBUG)\n+\n+    unittest.main()\n",
        "source_code_with_indent": "\nsess = tf.InteractiveSession()\n\n## vector\nx = tf.placeholder(tf.float32, shape=[None, 784])\ninputs = tl.layers.InputLayer(x, name='input_layer')\nnet1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu1_1')\nnet2 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu2_1')\nnet = tl.layers.ConcatLayer([net1, net2], concat_dim=1, name='concat_layer')\n\nnet.print_params(False)\nnet.print_layers()\n\nif len(net.all_layers) != 3:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 4:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 157000:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>net_0 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_0')\nnet_1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_1')\nnet = tl.layers.ElementwiseLayer([net_0, net_1], combine_fn=tf.minimum, name='minimum')\n\nnet.print_params(False)\nnet.print_layers()\n\nif len(net.all_layers) != 3:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 4:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 157000:\n    <IND>raise Exception(\"params do not match\")\n\n## image\n<DED>x = tf.placeholder(tf.float32, shape=[None, 100, 100, 3])\ninputs = tl.layers.InputLayer(x, name='input')\nnet1 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c1')\nnet2 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c2')\nnet = tl.layers.ConcatLayer([net1, net2], concat_dim=-1, name='concat')\n\nnet.print_params(False)\nnet.print_layers()\n\nshape = net.outputs.get_shape().as_list()\nif shape[1:] != [50, 50, 64]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 3:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 4:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 1792:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>net = tl.layers.ElementwiseLayer([net1, net2], combine_fn=tf.minimum, name='minimum2')\nnet.print_params(False)\nnet.print_layers()\n\nshape = net.outputs.get_shape().as_list()\nif shape[1:] != [50, 50, 32]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 3:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 4:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 1792:\n    <IND>raise Exception(\"params do not match\")\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n\nclass Layer_Merge_Test(unittest.TestCase):\n    <IND>@classmethod\n    def setUpClass(cls):\n\n        <IND>cls.data = dict()\n\n        ##############\n        #   vector   #\n        ##############\n\n        x = tf.placeholder(tf.float32, shape=[None, 784])\n        inputs = tl.layers.InputLayer(x, name='input_layer')\n\n        net_v1_1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu1_1')\n        net_v1_2 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='relu2_1')\n        net_v1 = tl.layers.ConcatLayer([net_v1_1, net_v1_2], concat_dim=1, name='concat_layer')\n\n        net_v1.print_params(False)\n        net_v1.print_layers()\n\n        cls.data[\"net_vector1\"] = dict()\n        cls.data[\"net_vector1\"][\"layers\"] = net_v1.all_layers\n        cls.data[\"net_vector1\"][\"params\"] = net_v1.all_params\n        cls.data[\"net_vector1\"][\"n_params\"] = net_v1.count_params()\n\n        net_v2_1 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_0')\n        net_v2_2 = tl.layers.DenseLayer(inputs, n_units=100, act=tf.nn.relu, name='net_1')\n        net_v2 = tl.layers.ElementwiseLayer([net_v2_1, net_v2_2], combine_fn=tf.minimum, name='minimum')\n\n        net_v2.print_params(False)\n        net_v2.print_layers()\n\n        cls.data[\"net_vector2\"] = dict()\n        cls.data[\"net_vector2\"][\"layers\"] = net_v2.all_layers\n        cls.data[\"net_vector2\"][\"params\"] = net_v2.all_params\n        cls.data[\"net_vector2\"][\"n_params\"] = net_v2.count_params()\n\n        #############\n        #   Image   #\n        #############\n\n        x = tf.placeholder(tf.float32, shape=[None, 100, 100, 3])\n        inputs = tl.layers.InputLayer(x, name='input')\n\n        net_im1_1 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c1')\n        net_im1_2 = tl.layers.Conv2d(inputs, n_filter=32, filter_size=(3, 3), strides=(2, 2), act=tf.nn.relu, name='c2')\n        net_im1 = tl.layers.ConcatLayer([net_im1_1, net_im1_2], concat_dim=-1, name='concat')\n\n        net_im1.print_params(False)\n        net_im1.print_layers()\n\n        cls.data[\"net_image1\"] = dict()\n        cls.data[\"net_image1\"][\"shape\"] = net_im1.outputs.get_shape().as_list()\n        cls.data[\"net_image1\"][\"layers\"] = net_im1.all_layers\n        cls.data[\"net_image1\"][\"params\"] = net_im1.all_params\n        cls.data[\"net_image1\"][\"n_params\"] = net_im1.count_params()\n\n        net_im2 = tl.layers.ElementwiseLayer([net_im1_1, net_im1_2], combine_fn=tf.minimum, name='minimum2')\n\n        net_im2.print_params(False)\n        net_im2.print_layers()\n\n        cls.data[\"net_image2\"] = dict()\n        cls.data[\"net_image2\"][\"shape\"] = net_im2.outputs.get_shape().as_list()\n        cls.data[\"net_image2\"][\"layers\"] = net_im2.all_layers\n        cls.data[\"net_image2\"][\"params\"] = net_im2.all_params\n        cls.data[\"net_image2\"][\"n_params\"] = net_im2.count_params()\n\n    <DED>@classmethod\n    def tearDownClass(cls):\n        <IND>tf.reset_default_graph()\n\n    <DED>def test_net_vector1(self):\n        <IND>self.assertEqual(len(self.data[\"net_vector1\"][\"layers\"]), 3)\n        self.assertEqual(len(self.data[\"net_vector1\"][\"params\"]), 4)\n        self.assertEqual(self.data[\"net_vector1\"][\"n_params\"], 157000)\n\n    <DED>def test_net_vector2(self):\n        <IND>self.assertEqual(len(self.data[\"net_vector2\"][\"layers\"]), 3)\n        self.assertEqual(len(self.data[\"net_vector2\"][\"params\"]), 4)\n        self.assertEqual(self.data[\"net_vector2\"][\"n_params\"], 157000)\n\n    <DED>def test_net_image1(self):\n        <IND>self.assertEqual(self.data[\"net_image1\"][\"shape\"][1:], [50, 50, 64])\n        self.assertEqual(len(self.data[\"net_image1\"][\"layers\"]), 3)\n        self.assertEqual(len(self.data[\"net_image1\"][\"params\"]), 4)\n        self.assertEqual(self.data[\"net_image1\"][\"n_params\"], 1792)\n\n    <DED>def test_net_image2(self):\n        <IND>self.assertEqual(self.data[\"net_image2\"][\"shape\"][1:], [50, 50, 32])\n        self.assertEqual(len(self.data[\"net_image2\"][\"layers\"]), 3)\n        self.assertEqual(len(self.data[\"net_image2\"][\"params\"]), 4)\n        self.assertEqual(self.data[\"net_image2\"][\"n_params\"], 1792)\n\n\n<DED><DED>if __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    <IND>tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "tensorlayer/TensorLayer",
    "commit": "6f539ad2324ddccc18b6ac39e4a2f4aeb12173a2",
    "filename": "tests/test_layers_padding.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/tensorlayer-TensorLayer/tests/test_layers_padding.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "tests/test_layers_padding.py:43:0 Incompatible variable type [9]: n1 is declared to have type `tl.layers.padding.ZeroPad1d` but is used as type `tl.layers.padding.ZeroPad3d`.",
    "message": " n1 is declared to have type `tl.layers.padding.ZeroPad1d` but is used as type `tl.layers.padding.ZeroPad3d`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 43,
    "warning_line": "n1 = tl.layers.ZeroPad3d(n, padding=2)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import tensorflow as tf\n",
        "source_code_len": 24,
        "target_code": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_len": 87,
        "diff_format": "@@ -1,1 +1,5 @@\n+#!/usr/bin/env python\n+# -*- coding: utf-8 -*-\n+import unittest\n+\n import tensorflow as tf\n",
        "source_code_with_indent": "import tensorflow as tf\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n## 1D\nx = tf.placeholder(tf.float32, (None, 100, 1))\nn = tl.layers.InputLayer(x)\nn1 = tl.layers.ZeroPad1d(n, padding=1)\nn1.print_layers()\nshape = n1.outputs.get_shape().as_list()\nif shape[1:] != [102, 1]:\n    raise Exception(\"shape do not match\")\n\nn2 = tl.layers.ZeroPad1d(n, padding=(2, 3))\nn2.print_layers()\nshape = n2.outputs.get_shape().as_list()\nif shape[1:] != [105, 1]:\n    raise Exception(\"shape do not match\")\n\n## 2D\nx = tf.placeholder(tf.float32, (None, 100, 100, 3))\nn = tl.layers.InputLayer(x)\nn1 = tl.layers.ZeroPad2d(n, padding=2)\nn1.print_layers()\nshape = n1.outputs.get_shape().as_list()\nif shape[1:] != [104, 104, 3]:\n    raise Exception(\"shape do not match\")\n\nn2 = tl.layers.ZeroPad2d(n, padding=(2, 3))\nn2.print_layers()\nshape = n2.outputs.get_shape().as_list()\nif shape[1:] != [104, 106, 3]:\n    raise Exception(\"shape do not match\")\n\nn3 = tl.layers.ZeroPad2d(n, padding=((3, 3), (4, 4)))\nn3.print_layers()\nshape = n3.outputs.get_shape().as_list()\nif shape[1:] != [106, 108, 3]:\n    raise Exception(\"shape do not match\")\n\n## 3D\nx = tf.placeholder(tf.float32, (None, 100, 100, 100, 3))\nn = tl.layers.InputLayer(x)\nn1 = tl.layers.ZeroPad3d(n, padding=2)\nn1.print_layers()\nshape = n1.outputs.get_shape().as_list()\nif shape[1:] != [104, 104, 104, 3]:\n    raise Exception(\"shape do not match\")\n\nn2 = tl.layers.ZeroPad3d(n, padding=(2, 3, 4))\nn2.print_layers()\nshape = n2.outputs.get_shape().as_list()\nif shape[1:] != [104, 106, 108, 3]:\n    raise Exception(\"shape do not match\")\n\nn3 = tl.layers.ZeroPad3d(n, padding=((3, 3), (4, 4), (5, 5)))\nn3.print_layers()\nshape = n3.outputs.get_shape().as_list()\nif shape[1:] != [106, 108, 110, 3]:\n    raise Exception(\"shape do not match\")\n",
        "source_code_len": 1695,
        "target_code": "\n\nclass Layer_Padding_Test(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n\n        ## 1D\n        x = tf.placeholder(tf.float32, (None, 100, 1))\n        n = tl.layers.InputLayer(x)\n\n        n1 = tl.layers.ZeroPad1d(n, padding=1)\n        n2 = tl.layers.ZeroPad1d(n, padding=(2, 3))\n\n        n1.print_layers()\n        n2.print_layers()\n\n        cls.n1_shape = n1.outputs.get_shape().as_list()\n        cls.n2_shape = n2.outputs.get_shape().as_list()\n\n        ## 2D\n        x = tf.placeholder(tf.float32, (None, 100, 100, 3))\n        n = tl.layers.InputLayer(x)\n\n        n3 = tl.layers.ZeroPad2d(n, padding=2)\n        n4 = tl.layers.ZeroPad2d(n, padding=(2, 3))\n        n5 = tl.layers.ZeroPad2d(n, padding=((3, 3), (4, 4)))\n\n        n3.print_layers()\n        n4.print_layers()\n        n5.print_layers()\n\n        cls.n3_shape = n3.outputs.get_shape().as_list()\n        cls.n4_shape = n4.outputs.get_shape().as_list()\n        cls.n5_shape = n5.outputs.get_shape().as_list()\n\n        ## 3D\n        x = tf.placeholder(tf.float32, (None, 100, 100, 100, 3))\n        n = tl.layers.InputLayer(x)\n\n        n6 = tl.layers.ZeroPad3d(n, padding=2)\n        n7 = tl.layers.ZeroPad3d(n, padding=(2, 3, 4))\n        n8 = tl.layers.ZeroPad3d(n, padding=((3, 3), (4, 4), (5, 5)))\n\n        n6.print_layers()\n        n7.print_layers()\n        n8.print_layers()\n\n        cls.n6_shape = n6.outputs.get_shape().as_list()\n        cls.n7_shape = n7.outputs.get_shape().as_list()\n        cls.n8_shape = n8.outputs.get_shape().as_list()\n\n    @classmethod\n    def tearDownClass(cls):\n        tf.reset_default_graph()\n\n    def test_n1_shape(self):\n        self.assertEqual(self.n1_shape[1:], [102, 1])\n\n    def test_n2_shape(self):\n        self.assertEqual(self.n2_shape[1:], [105, 1])\n\n    def test_n3_shape(self):\n        self.assertEqual(self.n3_shape[1:], [104, 104, 3])\n\n    def test_n4_shape(self):\n        self.assertEqual(self.n4_shape[1:], [104, 106, 3])\n\n    def test_n5_shape(self):\n        self.assertEqual(self.n5_shape[1:], [106, 108, 3])\n\n    def test_n6_shape(self):\n        self.assertEqual(self.n6_shape[1:], [104, 104, 104, 3])\n\n    def test_n7_shape(self):\n        self.assertEqual(self.n7_shape[1:], [104, 106, 108, 3])\n\n    def test_n8_shape(self):\n        self.assertEqual(self.n8_shape[1:], [106, 108, 110, 3])\n\n\nif __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_len": 2461,
        "diff_format": "@@ -3,57 +7,86 @@\n \n-## 1D\n-x = tf.placeholder(tf.float32, (None, 100, 1))\n-n = tl.layers.InputLayer(x)\n-n1 = tl.layers.ZeroPad1d(n, padding=1)\n-n1.print_layers()\n-shape = n1.outputs.get_shape().as_list()\n-if shape[1:] != [102, 1]:\n-    raise Exception(\"shape do not match\")\n \n-n2 = tl.layers.ZeroPad1d(n, padding=(2, 3))\n-n2.print_layers()\n-shape = n2.outputs.get_shape().as_list()\n-if shape[1:] != [105, 1]:\n-    raise Exception(\"shape do not match\")\n+class Layer_Padding_Test(unittest.TestCase):\n+    @classmethod\n+    def setUpClass(cls):\n \n-## 2D\n-x = tf.placeholder(tf.float32, (None, 100, 100, 3))\n-n = tl.layers.InputLayer(x)\n-n1 = tl.layers.ZeroPad2d(n, padding=2)\n-n1.print_layers()\n-shape = n1.outputs.get_shape().as_list()\n-if shape[1:] != [104, 104, 3]:\n-    raise Exception(\"shape do not match\")\n+        ## 1D\n+        x = tf.placeholder(tf.float32, (None, 100, 1))\n+        n = tl.layers.InputLayer(x)\n \n-n2 = tl.layers.ZeroPad2d(n, padding=(2, 3))\n-n2.print_layers()\n-shape = n2.outputs.get_shape().as_list()\n-if shape[1:] != [104, 106, 3]:\n-    raise Exception(\"shape do not match\")\n+        n1 = tl.layers.ZeroPad1d(n, padding=1)\n+        n2 = tl.layers.ZeroPad1d(n, padding=(2, 3))\n \n-n3 = tl.layers.ZeroPad2d(n, padding=((3, 3), (4, 4)))\n-n3.print_layers()\n-shape = n3.outputs.get_shape().as_list()\n-if shape[1:] != [106, 108, 3]:\n-    raise Exception(\"shape do not match\")\n+        n1.print_layers()\n+        n2.print_layers()\n \n-## 3D\n-x = tf.placeholder(tf.float32, (None, 100, 100, 100, 3))\n-n = tl.layers.InputLayer(x)\n-n1 = tl.layers.ZeroPad3d(n, padding=2)\n-n1.print_layers()\n-shape = n1.outputs.get_shape().as_list()\n-if shape[1:] != [104, 104, 104, 3]:\n-    raise Exception(\"shape do not match\")\n+        cls.n1_shape = n1.outputs.get_shape().as_list()\n+        cls.n2_shape = n2.outputs.get_shape().as_list()\n \n-n2 = tl.layers.ZeroPad3d(n, padding=(2, 3, 4))\n-n2.print_layers()\n-shape = n2.outputs.get_shape().as_list()\n-if shape[1:] != [104, 106, 108, 3]:\n-    raise Exception(\"shape do not match\")\n+        ## 2D\n+        x = tf.placeholder(tf.float32, (None, 100, 100, 3))\n+        n = tl.layers.InputLayer(x)\n \n-n3 = tl.layers.ZeroPad3d(n, padding=((3, 3), (4, 4), (5, 5)))\n-n3.print_layers()\n-shape = n3.outputs.get_shape().as_list()\n-if shape[1:] != [106, 108, 110, 3]:\n-    raise Exception(\"shape do not match\")\n+        n3 = tl.layers.ZeroPad2d(n, padding=2)\n+        n4 = tl.layers.ZeroPad2d(n, padding=(2, 3))\n+        n5 = tl.layers.ZeroPad2d(n, padding=((3, 3), (4, 4)))\n+\n+        n3.print_layers()\n+        n4.print_layers()\n+        n5.print_layers()\n+\n+        cls.n3_shape = n3.outputs.get_shape().as_list()\n+        cls.n4_shape = n4.outputs.get_shape().as_list()\n+        cls.n5_shape = n5.outputs.get_shape().as_list()\n+\n+        ## 3D\n+        x = tf.placeholder(tf.float32, (None, 100, 100, 100, 3))\n+        n = tl.layers.InputLayer(x)\n+\n+        n6 = tl.layers.ZeroPad3d(n, padding=2)\n+        n7 = tl.layers.ZeroPad3d(n, padding=(2, 3, 4))\n+        n8 = tl.layers.ZeroPad3d(n, padding=((3, 3), (4, 4), (5, 5)))\n+\n+        n6.print_layers()\n+        n7.print_layers()\n+        n8.print_layers()\n+\n+        cls.n6_shape = n6.outputs.get_shape().as_list()\n+        cls.n7_shape = n7.outputs.get_shape().as_list()\n+        cls.n8_shape = n8.outputs.get_shape().as_list()\n+\n+    @classmethod\n+    def tearDownClass(cls):\n+        tf.reset_default_graph()\n+\n+    def test_n1_shape(self):\n+        self.assertEqual(self.n1_shape[1:], [102, 1])\n+\n+    def test_n2_shape(self):\n+        self.assertEqual(self.n2_shape[1:], [105, 1])\n+\n+    def test_n3_shape(self):\n+        self.assertEqual(self.n3_shape[1:], [104, 104, 3])\n+\n+    def test_n4_shape(self):\n+        self.assertEqual(self.n4_shape[1:], [104, 106, 3])\n+\n+    def test_n5_shape(self):\n+        self.assertEqual(self.n5_shape[1:], [106, 108, 3])\n+\n+    def test_n6_shape(self):\n+        self.assertEqual(self.n6_shape[1:], [104, 104, 104, 3])\n+\n+    def test_n7_shape(self):\n+        self.assertEqual(self.n7_shape[1:], [104, 106, 108, 3])\n+\n+    def test_n8_shape(self):\n+        self.assertEqual(self.n8_shape[1:], [106, 108, 110, 3])\n+\n+\n+if __name__ == '__main__':\n+\n+    # tf.logging.set_verbosity(tf.logging.INFO)\n+    tf.logging.set_verbosity(tf.logging.DEBUG)\n+\n+    unittest.main()\n",
        "source_code_with_indent": "\n## 1D\nx = tf.placeholder(tf.float32, (None, 100, 1))\nn = tl.layers.InputLayer(x)\nn1 = tl.layers.ZeroPad1d(n, padding=1)\nn1.print_layers()\nshape = n1.outputs.get_shape().as_list()\nif shape[1:] != [102, 1]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>n2 = tl.layers.ZeroPad1d(n, padding=(2, 3))\nn2.print_layers()\nshape = n2.outputs.get_shape().as_list()\nif shape[1:] != [105, 1]:\n    <IND>raise Exception(\"shape do not match\")\n\n## 2D\n<DED>x = tf.placeholder(tf.float32, (None, 100, 100, 3))\nn = tl.layers.InputLayer(x)\nn1 = tl.layers.ZeroPad2d(n, padding=2)\nn1.print_layers()\nshape = n1.outputs.get_shape().as_list()\nif shape[1:] != [104, 104, 3]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>n2 = tl.layers.ZeroPad2d(n, padding=(2, 3))\nn2.print_layers()\nshape = n2.outputs.get_shape().as_list()\nif shape[1:] != [104, 106, 3]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>n3 = tl.layers.ZeroPad2d(n, padding=((3, 3), (4, 4)))\nn3.print_layers()\nshape = n3.outputs.get_shape().as_list()\nif shape[1:] != [106, 108, 3]:\n    <IND>raise Exception(\"shape do not match\")\n\n## 3D\n<DED>x = tf.placeholder(tf.float32, (None, 100, 100, 100, 3))\nn = tl.layers.InputLayer(x)\nn1 = tl.layers.ZeroPad3d(n, padding=2)\nn1.print_layers()\nshape = n1.outputs.get_shape().as_list()\nif shape[1:] != [104, 104, 104, 3]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>n2 = tl.layers.ZeroPad3d(n, padding=(2, 3, 4))\nn2.print_layers()\nshape = n2.outputs.get_shape().as_list()\nif shape[1:] != [104, 106, 108, 3]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>n3 = tl.layers.ZeroPad3d(n, padding=((3, 3), (4, 4), (5, 5)))\nn3.print_layers()\nshape = n3.outputs.get_shape().as_list()\nif shape[1:] != [106, 108, 110, 3]:\n    <IND>raise Exception(\"shape do not match\")\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n\nclass Layer_Padding_Test(unittest.TestCase):\n    <IND>@classmethod\n    def setUpClass(cls):\n\n        ## 1D\n        <IND>x = tf.placeholder(tf.float32, (None, 100, 1))\n        n = tl.layers.InputLayer(x)\n\n        n1 = tl.layers.ZeroPad1d(n, padding=1)\n        n2 = tl.layers.ZeroPad1d(n, padding=(2, 3))\n\n        n1.print_layers()\n        n2.print_layers()\n\n        cls.n1_shape = n1.outputs.get_shape().as_list()\n        cls.n2_shape = n2.outputs.get_shape().as_list()\n\n        ## 2D\n        x = tf.placeholder(tf.float32, (None, 100, 100, 3))\n        n = tl.layers.InputLayer(x)\n\n        n3 = tl.layers.ZeroPad2d(n, padding=2)\n        n4 = tl.layers.ZeroPad2d(n, padding=(2, 3))\n        n5 = tl.layers.ZeroPad2d(n, padding=((3, 3), (4, 4)))\n\n        n3.print_layers()\n        n4.print_layers()\n        n5.print_layers()\n\n        cls.n3_shape = n3.outputs.get_shape().as_list()\n        cls.n4_shape = n4.outputs.get_shape().as_list()\n        cls.n5_shape = n5.outputs.get_shape().as_list()\n\n        ## 3D\n        x = tf.placeholder(tf.float32, (None, 100, 100, 100, 3))\n        n = tl.layers.InputLayer(x)\n\n        n6 = tl.layers.ZeroPad3d(n, padding=2)\n        n7 = tl.layers.ZeroPad3d(n, padding=(2, 3, 4))\n        n8 = tl.layers.ZeroPad3d(n, padding=((3, 3), (4, 4), (5, 5)))\n\n        n6.print_layers()\n        n7.print_layers()\n        n8.print_layers()\n\n        cls.n6_shape = n6.outputs.get_shape().as_list()\n        cls.n7_shape = n7.outputs.get_shape().as_list()\n        cls.n8_shape = n8.outputs.get_shape().as_list()\n\n    <DED>@classmethod\n    def tearDownClass(cls):\n        <IND>tf.reset_default_graph()\n\n    <DED>def test_n1_shape(self):\n        <IND>self.assertEqual(self.n1_shape[1:], [102, 1])\n\n    <DED>def test_n2_shape(self):\n        <IND>self.assertEqual(self.n2_shape[1:], [105, 1])\n\n    <DED>def test_n3_shape(self):\n        <IND>self.assertEqual(self.n3_shape[1:], [104, 104, 3])\n\n    <DED>def test_n4_shape(self):\n        <IND>self.assertEqual(self.n4_shape[1:], [104, 106, 3])\n\n    <DED>def test_n5_shape(self):\n        <IND>self.assertEqual(self.n5_shape[1:], [106, 108, 3])\n\n    <DED>def test_n6_shape(self):\n        <IND>self.assertEqual(self.n6_shape[1:], [104, 104, 104, 3])\n\n    <DED>def test_n7_shape(self):\n        <IND>self.assertEqual(self.n7_shape[1:], [104, 106, 108, 3])\n\n    <DED>def test_n8_shape(self):\n        <IND>self.assertEqual(self.n8_shape[1:], [106, 108, 110, 3])\n\n\n<DED><DED>if __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    <IND>tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "tensorlayer/TensorLayer",
    "commit": "6f539ad2324ddccc18b6ac39e4a2f4aeb12173a2",
    "filename": "tests/test_layers_padding.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/tensorlayer-TensorLayer/tests/test_layers_padding.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "tests/test_layers_padding.py:49:0 Incompatible variable type [9]: n2 is declared to have type `tl.layers.padding.ZeroPad1d` but is used as type `tl.layers.padding.ZeroPad3d`.",
    "message": " n2 is declared to have type `tl.layers.padding.ZeroPad1d` but is used as type `tl.layers.padding.ZeroPad3d`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 49,
    "warning_line": "n2 = tl.layers.ZeroPad3d(n, padding=(2, 3, 4))",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import tensorflow as tf\n",
        "source_code_len": 24,
        "target_code": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_len": 87,
        "diff_format": "@@ -1,1 +1,5 @@\n+#!/usr/bin/env python\n+# -*- coding: utf-8 -*-\n+import unittest\n+\n import tensorflow as tf\n",
        "source_code_with_indent": "import tensorflow as tf\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n## 1D\nx = tf.placeholder(tf.float32, (None, 100, 1))\nn = tl.layers.InputLayer(x)\nn1 = tl.layers.ZeroPad1d(n, padding=1)\nn1.print_layers()\nshape = n1.outputs.get_shape().as_list()\nif shape[1:] != [102, 1]:\n    raise Exception(\"shape do not match\")\n\nn2 = tl.layers.ZeroPad1d(n, padding=(2, 3))\nn2.print_layers()\nshape = n2.outputs.get_shape().as_list()\nif shape[1:] != [105, 1]:\n    raise Exception(\"shape do not match\")\n\n## 2D\nx = tf.placeholder(tf.float32, (None, 100, 100, 3))\nn = tl.layers.InputLayer(x)\nn1 = tl.layers.ZeroPad2d(n, padding=2)\nn1.print_layers()\nshape = n1.outputs.get_shape().as_list()\nif shape[1:] != [104, 104, 3]:\n    raise Exception(\"shape do not match\")\n\nn2 = tl.layers.ZeroPad2d(n, padding=(2, 3))\nn2.print_layers()\nshape = n2.outputs.get_shape().as_list()\nif shape[1:] != [104, 106, 3]:\n    raise Exception(\"shape do not match\")\n\nn3 = tl.layers.ZeroPad2d(n, padding=((3, 3), (4, 4)))\nn3.print_layers()\nshape = n3.outputs.get_shape().as_list()\nif shape[1:] != [106, 108, 3]:\n    raise Exception(\"shape do not match\")\n\n## 3D\nx = tf.placeholder(tf.float32, (None, 100, 100, 100, 3))\nn = tl.layers.InputLayer(x)\nn1 = tl.layers.ZeroPad3d(n, padding=2)\nn1.print_layers()\nshape = n1.outputs.get_shape().as_list()\nif shape[1:] != [104, 104, 104, 3]:\n    raise Exception(\"shape do not match\")\n\nn2 = tl.layers.ZeroPad3d(n, padding=(2, 3, 4))\nn2.print_layers()\nshape = n2.outputs.get_shape().as_list()\nif shape[1:] != [104, 106, 108, 3]:\n    raise Exception(\"shape do not match\")\n\nn3 = tl.layers.ZeroPad3d(n, padding=((3, 3), (4, 4), (5, 5)))\nn3.print_layers()\nshape = n3.outputs.get_shape().as_list()\nif shape[1:] != [106, 108, 110, 3]:\n    raise Exception(\"shape do not match\")\n",
        "source_code_len": 1695,
        "target_code": "\n\nclass Layer_Padding_Test(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n\n        ## 1D\n        x = tf.placeholder(tf.float32, (None, 100, 1))\n        n = tl.layers.InputLayer(x)\n\n        n1 = tl.layers.ZeroPad1d(n, padding=1)\n        n2 = tl.layers.ZeroPad1d(n, padding=(2, 3))\n\n        n1.print_layers()\n        n2.print_layers()\n\n        cls.n1_shape = n1.outputs.get_shape().as_list()\n        cls.n2_shape = n2.outputs.get_shape().as_list()\n\n        ## 2D\n        x = tf.placeholder(tf.float32, (None, 100, 100, 3))\n        n = tl.layers.InputLayer(x)\n\n        n3 = tl.layers.ZeroPad2d(n, padding=2)\n        n4 = tl.layers.ZeroPad2d(n, padding=(2, 3))\n        n5 = tl.layers.ZeroPad2d(n, padding=((3, 3), (4, 4)))\n\n        n3.print_layers()\n        n4.print_layers()\n        n5.print_layers()\n\n        cls.n3_shape = n3.outputs.get_shape().as_list()\n        cls.n4_shape = n4.outputs.get_shape().as_list()\n        cls.n5_shape = n5.outputs.get_shape().as_list()\n\n        ## 3D\n        x = tf.placeholder(tf.float32, (None, 100, 100, 100, 3))\n        n = tl.layers.InputLayer(x)\n\n        n6 = tl.layers.ZeroPad3d(n, padding=2)\n        n7 = tl.layers.ZeroPad3d(n, padding=(2, 3, 4))\n        n8 = tl.layers.ZeroPad3d(n, padding=((3, 3), (4, 4), (5, 5)))\n\n        n6.print_layers()\n        n7.print_layers()\n        n8.print_layers()\n\n        cls.n6_shape = n6.outputs.get_shape().as_list()\n        cls.n7_shape = n7.outputs.get_shape().as_list()\n        cls.n8_shape = n8.outputs.get_shape().as_list()\n\n    @classmethod\n    def tearDownClass(cls):\n        tf.reset_default_graph()\n\n    def test_n1_shape(self):\n        self.assertEqual(self.n1_shape[1:], [102, 1])\n\n    def test_n2_shape(self):\n        self.assertEqual(self.n2_shape[1:], [105, 1])\n\n    def test_n3_shape(self):\n        self.assertEqual(self.n3_shape[1:], [104, 104, 3])\n\n    def test_n4_shape(self):\n        self.assertEqual(self.n4_shape[1:], [104, 106, 3])\n\n    def test_n5_shape(self):\n        self.assertEqual(self.n5_shape[1:], [106, 108, 3])\n\n    def test_n6_shape(self):\n        self.assertEqual(self.n6_shape[1:], [104, 104, 104, 3])\n\n    def test_n7_shape(self):\n        self.assertEqual(self.n7_shape[1:], [104, 106, 108, 3])\n\n    def test_n8_shape(self):\n        self.assertEqual(self.n8_shape[1:], [106, 108, 110, 3])\n\n\nif __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_len": 2461,
        "diff_format": "@@ -3,57 +7,86 @@\n \n-## 1D\n-x = tf.placeholder(tf.float32, (None, 100, 1))\n-n = tl.layers.InputLayer(x)\n-n1 = tl.layers.ZeroPad1d(n, padding=1)\n-n1.print_layers()\n-shape = n1.outputs.get_shape().as_list()\n-if shape[1:] != [102, 1]:\n-    raise Exception(\"shape do not match\")\n \n-n2 = tl.layers.ZeroPad1d(n, padding=(2, 3))\n-n2.print_layers()\n-shape = n2.outputs.get_shape().as_list()\n-if shape[1:] != [105, 1]:\n-    raise Exception(\"shape do not match\")\n+class Layer_Padding_Test(unittest.TestCase):\n+    @classmethod\n+    def setUpClass(cls):\n \n-## 2D\n-x = tf.placeholder(tf.float32, (None, 100, 100, 3))\n-n = tl.layers.InputLayer(x)\n-n1 = tl.layers.ZeroPad2d(n, padding=2)\n-n1.print_layers()\n-shape = n1.outputs.get_shape().as_list()\n-if shape[1:] != [104, 104, 3]:\n-    raise Exception(\"shape do not match\")\n+        ## 1D\n+        x = tf.placeholder(tf.float32, (None, 100, 1))\n+        n = tl.layers.InputLayer(x)\n \n-n2 = tl.layers.ZeroPad2d(n, padding=(2, 3))\n-n2.print_layers()\n-shape = n2.outputs.get_shape().as_list()\n-if shape[1:] != [104, 106, 3]:\n-    raise Exception(\"shape do not match\")\n+        n1 = tl.layers.ZeroPad1d(n, padding=1)\n+        n2 = tl.layers.ZeroPad1d(n, padding=(2, 3))\n \n-n3 = tl.layers.ZeroPad2d(n, padding=((3, 3), (4, 4)))\n-n3.print_layers()\n-shape = n3.outputs.get_shape().as_list()\n-if shape[1:] != [106, 108, 3]:\n-    raise Exception(\"shape do not match\")\n+        n1.print_layers()\n+        n2.print_layers()\n \n-## 3D\n-x = tf.placeholder(tf.float32, (None, 100, 100, 100, 3))\n-n = tl.layers.InputLayer(x)\n-n1 = tl.layers.ZeroPad3d(n, padding=2)\n-n1.print_layers()\n-shape = n1.outputs.get_shape().as_list()\n-if shape[1:] != [104, 104, 104, 3]:\n-    raise Exception(\"shape do not match\")\n+        cls.n1_shape = n1.outputs.get_shape().as_list()\n+        cls.n2_shape = n2.outputs.get_shape().as_list()\n \n-n2 = tl.layers.ZeroPad3d(n, padding=(2, 3, 4))\n-n2.print_layers()\n-shape = n2.outputs.get_shape().as_list()\n-if shape[1:] != [104, 106, 108, 3]:\n-    raise Exception(\"shape do not match\")\n+        ## 2D\n+        x = tf.placeholder(tf.float32, (None, 100, 100, 3))\n+        n = tl.layers.InputLayer(x)\n \n-n3 = tl.layers.ZeroPad3d(n, padding=((3, 3), (4, 4), (5, 5)))\n-n3.print_layers()\n-shape = n3.outputs.get_shape().as_list()\n-if shape[1:] != [106, 108, 110, 3]:\n-    raise Exception(\"shape do not match\")\n+        n3 = tl.layers.ZeroPad2d(n, padding=2)\n+        n4 = tl.layers.ZeroPad2d(n, padding=(2, 3))\n+        n5 = tl.layers.ZeroPad2d(n, padding=((3, 3), (4, 4)))\n+\n+        n3.print_layers()\n+        n4.print_layers()\n+        n5.print_layers()\n+\n+        cls.n3_shape = n3.outputs.get_shape().as_list()\n+        cls.n4_shape = n4.outputs.get_shape().as_list()\n+        cls.n5_shape = n5.outputs.get_shape().as_list()\n+\n+        ## 3D\n+        x = tf.placeholder(tf.float32, (None, 100, 100, 100, 3))\n+        n = tl.layers.InputLayer(x)\n+\n+        n6 = tl.layers.ZeroPad3d(n, padding=2)\n+        n7 = tl.layers.ZeroPad3d(n, padding=(2, 3, 4))\n+        n8 = tl.layers.ZeroPad3d(n, padding=((3, 3), (4, 4), (5, 5)))\n+\n+        n6.print_layers()\n+        n7.print_layers()\n+        n8.print_layers()\n+\n+        cls.n6_shape = n6.outputs.get_shape().as_list()\n+        cls.n7_shape = n7.outputs.get_shape().as_list()\n+        cls.n8_shape = n8.outputs.get_shape().as_list()\n+\n+    @classmethod\n+    def tearDownClass(cls):\n+        tf.reset_default_graph()\n+\n+    def test_n1_shape(self):\n+        self.assertEqual(self.n1_shape[1:], [102, 1])\n+\n+    def test_n2_shape(self):\n+        self.assertEqual(self.n2_shape[1:], [105, 1])\n+\n+    def test_n3_shape(self):\n+        self.assertEqual(self.n3_shape[1:], [104, 104, 3])\n+\n+    def test_n4_shape(self):\n+        self.assertEqual(self.n4_shape[1:], [104, 106, 3])\n+\n+    def test_n5_shape(self):\n+        self.assertEqual(self.n5_shape[1:], [106, 108, 3])\n+\n+    def test_n6_shape(self):\n+        self.assertEqual(self.n6_shape[1:], [104, 104, 104, 3])\n+\n+    def test_n7_shape(self):\n+        self.assertEqual(self.n7_shape[1:], [104, 106, 108, 3])\n+\n+    def test_n8_shape(self):\n+        self.assertEqual(self.n8_shape[1:], [106, 108, 110, 3])\n+\n+\n+if __name__ == '__main__':\n+\n+    # tf.logging.set_verbosity(tf.logging.INFO)\n+    tf.logging.set_verbosity(tf.logging.DEBUG)\n+\n+    unittest.main()\n",
        "source_code_with_indent": "\n## 1D\nx = tf.placeholder(tf.float32, (None, 100, 1))\nn = tl.layers.InputLayer(x)\nn1 = tl.layers.ZeroPad1d(n, padding=1)\nn1.print_layers()\nshape = n1.outputs.get_shape().as_list()\nif shape[1:] != [102, 1]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>n2 = tl.layers.ZeroPad1d(n, padding=(2, 3))\nn2.print_layers()\nshape = n2.outputs.get_shape().as_list()\nif shape[1:] != [105, 1]:\n    <IND>raise Exception(\"shape do not match\")\n\n## 2D\n<DED>x = tf.placeholder(tf.float32, (None, 100, 100, 3))\nn = tl.layers.InputLayer(x)\nn1 = tl.layers.ZeroPad2d(n, padding=2)\nn1.print_layers()\nshape = n1.outputs.get_shape().as_list()\nif shape[1:] != [104, 104, 3]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>n2 = tl.layers.ZeroPad2d(n, padding=(2, 3))\nn2.print_layers()\nshape = n2.outputs.get_shape().as_list()\nif shape[1:] != [104, 106, 3]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>n3 = tl.layers.ZeroPad2d(n, padding=((3, 3), (4, 4)))\nn3.print_layers()\nshape = n3.outputs.get_shape().as_list()\nif shape[1:] != [106, 108, 3]:\n    <IND>raise Exception(\"shape do not match\")\n\n## 3D\n<DED>x = tf.placeholder(tf.float32, (None, 100, 100, 100, 3))\nn = tl.layers.InputLayer(x)\nn1 = tl.layers.ZeroPad3d(n, padding=2)\nn1.print_layers()\nshape = n1.outputs.get_shape().as_list()\nif shape[1:] != [104, 104, 104, 3]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>n2 = tl.layers.ZeroPad3d(n, padding=(2, 3, 4))\nn2.print_layers()\nshape = n2.outputs.get_shape().as_list()\nif shape[1:] != [104, 106, 108, 3]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>n3 = tl.layers.ZeroPad3d(n, padding=((3, 3), (4, 4), (5, 5)))\nn3.print_layers()\nshape = n3.outputs.get_shape().as_list()\nif shape[1:] != [106, 108, 110, 3]:\n    <IND>raise Exception(\"shape do not match\")\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n\nclass Layer_Padding_Test(unittest.TestCase):\n    <IND>@classmethod\n    def setUpClass(cls):\n\n        ## 1D\n        <IND>x = tf.placeholder(tf.float32, (None, 100, 1))\n        n = tl.layers.InputLayer(x)\n\n        n1 = tl.layers.ZeroPad1d(n, padding=1)\n        n2 = tl.layers.ZeroPad1d(n, padding=(2, 3))\n\n        n1.print_layers()\n        n2.print_layers()\n\n        cls.n1_shape = n1.outputs.get_shape().as_list()\n        cls.n2_shape = n2.outputs.get_shape().as_list()\n\n        ## 2D\n        x = tf.placeholder(tf.float32, (None, 100, 100, 3))\n        n = tl.layers.InputLayer(x)\n\n        n3 = tl.layers.ZeroPad2d(n, padding=2)\n        n4 = tl.layers.ZeroPad2d(n, padding=(2, 3))\n        n5 = tl.layers.ZeroPad2d(n, padding=((3, 3), (4, 4)))\n\n        n3.print_layers()\n        n4.print_layers()\n        n5.print_layers()\n\n        cls.n3_shape = n3.outputs.get_shape().as_list()\n        cls.n4_shape = n4.outputs.get_shape().as_list()\n        cls.n5_shape = n5.outputs.get_shape().as_list()\n\n        ## 3D\n        x = tf.placeholder(tf.float32, (None, 100, 100, 100, 3))\n        n = tl.layers.InputLayer(x)\n\n        n6 = tl.layers.ZeroPad3d(n, padding=2)\n        n7 = tl.layers.ZeroPad3d(n, padding=(2, 3, 4))\n        n8 = tl.layers.ZeroPad3d(n, padding=((3, 3), (4, 4), (5, 5)))\n\n        n6.print_layers()\n        n7.print_layers()\n        n8.print_layers()\n\n        cls.n6_shape = n6.outputs.get_shape().as_list()\n        cls.n7_shape = n7.outputs.get_shape().as_list()\n        cls.n8_shape = n8.outputs.get_shape().as_list()\n\n    <DED>@classmethod\n    def tearDownClass(cls):\n        <IND>tf.reset_default_graph()\n\n    <DED>def test_n1_shape(self):\n        <IND>self.assertEqual(self.n1_shape[1:], [102, 1])\n\n    <DED>def test_n2_shape(self):\n        <IND>self.assertEqual(self.n2_shape[1:], [105, 1])\n\n    <DED>def test_n3_shape(self):\n        <IND>self.assertEqual(self.n3_shape[1:], [104, 104, 3])\n\n    <DED>def test_n4_shape(self):\n        <IND>self.assertEqual(self.n4_shape[1:], [104, 106, 3])\n\n    <DED>def test_n5_shape(self):\n        <IND>self.assertEqual(self.n5_shape[1:], [106, 108, 3])\n\n    <DED>def test_n6_shape(self):\n        <IND>self.assertEqual(self.n6_shape[1:], [104, 104, 104, 3])\n\n    <DED>def test_n7_shape(self):\n        <IND>self.assertEqual(self.n7_shape[1:], [104, 106, 108, 3])\n\n    <DED>def test_n8_shape(self):\n        <IND>self.assertEqual(self.n8_shape[1:], [106, 108, 110, 3])\n\n\n<DED><DED>if __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    <IND>tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "tensorlayer/TensorLayer",
    "commit": "6f539ad2324ddccc18b6ac39e4a2f4aeb12173a2",
    "filename": "tests/test_layers_padding.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/tensorlayer-TensorLayer/tests/test_layers_padding.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "tests/test_layers_padding.py:55:0 Incompatible variable type [9]: n3 is declared to have type `tl.layers.padding.ZeroPad2d` but is used as type `tl.layers.padding.ZeroPad3d`.",
    "message": " n3 is declared to have type `tl.layers.padding.ZeroPad2d` but is used as type `tl.layers.padding.ZeroPad3d`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 55,
    "warning_line": "n3 = tl.layers.ZeroPad3d(n, padding=((3, 3), (4, 4), (5, 5)))",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import tensorflow as tf\n",
        "source_code_len": 24,
        "target_code": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_len": 87,
        "diff_format": "@@ -1,1 +1,5 @@\n+#!/usr/bin/env python\n+# -*- coding: utf-8 -*-\n+import unittest\n+\n import tensorflow as tf\n",
        "source_code_with_indent": "import tensorflow as tf\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n## 1D\nx = tf.placeholder(tf.float32, (None, 100, 1))\nn = tl.layers.InputLayer(x)\nn1 = tl.layers.ZeroPad1d(n, padding=1)\nn1.print_layers()\nshape = n1.outputs.get_shape().as_list()\nif shape[1:] != [102, 1]:\n    raise Exception(\"shape do not match\")\n\nn2 = tl.layers.ZeroPad1d(n, padding=(2, 3))\nn2.print_layers()\nshape = n2.outputs.get_shape().as_list()\nif shape[1:] != [105, 1]:\n    raise Exception(\"shape do not match\")\n\n## 2D\nx = tf.placeholder(tf.float32, (None, 100, 100, 3))\nn = tl.layers.InputLayer(x)\nn1 = tl.layers.ZeroPad2d(n, padding=2)\nn1.print_layers()\nshape = n1.outputs.get_shape().as_list()\nif shape[1:] != [104, 104, 3]:\n    raise Exception(\"shape do not match\")\n\nn2 = tl.layers.ZeroPad2d(n, padding=(2, 3))\nn2.print_layers()\nshape = n2.outputs.get_shape().as_list()\nif shape[1:] != [104, 106, 3]:\n    raise Exception(\"shape do not match\")\n\nn3 = tl.layers.ZeroPad2d(n, padding=((3, 3), (4, 4)))\nn3.print_layers()\nshape = n3.outputs.get_shape().as_list()\nif shape[1:] != [106, 108, 3]:\n    raise Exception(\"shape do not match\")\n\n## 3D\nx = tf.placeholder(tf.float32, (None, 100, 100, 100, 3))\nn = tl.layers.InputLayer(x)\nn1 = tl.layers.ZeroPad3d(n, padding=2)\nn1.print_layers()\nshape = n1.outputs.get_shape().as_list()\nif shape[1:] != [104, 104, 104, 3]:\n    raise Exception(\"shape do not match\")\n\nn2 = tl.layers.ZeroPad3d(n, padding=(2, 3, 4))\nn2.print_layers()\nshape = n2.outputs.get_shape().as_list()\nif shape[1:] != [104, 106, 108, 3]:\n    raise Exception(\"shape do not match\")\n\nn3 = tl.layers.ZeroPad3d(n, padding=((3, 3), (4, 4), (5, 5)))\nn3.print_layers()\nshape = n3.outputs.get_shape().as_list()\nif shape[1:] != [106, 108, 110, 3]:\n    raise Exception(\"shape do not match\")\n",
        "source_code_len": 1695,
        "target_code": "\n\nclass Layer_Padding_Test(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n\n        ## 1D\n        x = tf.placeholder(tf.float32, (None, 100, 1))\n        n = tl.layers.InputLayer(x)\n\n        n1 = tl.layers.ZeroPad1d(n, padding=1)\n        n2 = tl.layers.ZeroPad1d(n, padding=(2, 3))\n\n        n1.print_layers()\n        n2.print_layers()\n\n        cls.n1_shape = n1.outputs.get_shape().as_list()\n        cls.n2_shape = n2.outputs.get_shape().as_list()\n\n        ## 2D\n        x = tf.placeholder(tf.float32, (None, 100, 100, 3))\n        n = tl.layers.InputLayer(x)\n\n        n3 = tl.layers.ZeroPad2d(n, padding=2)\n        n4 = tl.layers.ZeroPad2d(n, padding=(2, 3))\n        n5 = tl.layers.ZeroPad2d(n, padding=((3, 3), (4, 4)))\n\n        n3.print_layers()\n        n4.print_layers()\n        n5.print_layers()\n\n        cls.n3_shape = n3.outputs.get_shape().as_list()\n        cls.n4_shape = n4.outputs.get_shape().as_list()\n        cls.n5_shape = n5.outputs.get_shape().as_list()\n\n        ## 3D\n        x = tf.placeholder(tf.float32, (None, 100, 100, 100, 3))\n        n = tl.layers.InputLayer(x)\n\n        n6 = tl.layers.ZeroPad3d(n, padding=2)\n        n7 = tl.layers.ZeroPad3d(n, padding=(2, 3, 4))\n        n8 = tl.layers.ZeroPad3d(n, padding=((3, 3), (4, 4), (5, 5)))\n\n        n6.print_layers()\n        n7.print_layers()\n        n8.print_layers()\n\n        cls.n6_shape = n6.outputs.get_shape().as_list()\n        cls.n7_shape = n7.outputs.get_shape().as_list()\n        cls.n8_shape = n8.outputs.get_shape().as_list()\n\n    @classmethod\n    def tearDownClass(cls):\n        tf.reset_default_graph()\n\n    def test_n1_shape(self):\n        self.assertEqual(self.n1_shape[1:], [102, 1])\n\n    def test_n2_shape(self):\n        self.assertEqual(self.n2_shape[1:], [105, 1])\n\n    def test_n3_shape(self):\n        self.assertEqual(self.n3_shape[1:], [104, 104, 3])\n\n    def test_n4_shape(self):\n        self.assertEqual(self.n4_shape[1:], [104, 106, 3])\n\n    def test_n5_shape(self):\n        self.assertEqual(self.n5_shape[1:], [106, 108, 3])\n\n    def test_n6_shape(self):\n        self.assertEqual(self.n6_shape[1:], [104, 104, 104, 3])\n\n    def test_n7_shape(self):\n        self.assertEqual(self.n7_shape[1:], [104, 106, 108, 3])\n\n    def test_n8_shape(self):\n        self.assertEqual(self.n8_shape[1:], [106, 108, 110, 3])\n\n\nif __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_len": 2461,
        "diff_format": "@@ -3,57 +7,86 @@\n \n-## 1D\n-x = tf.placeholder(tf.float32, (None, 100, 1))\n-n = tl.layers.InputLayer(x)\n-n1 = tl.layers.ZeroPad1d(n, padding=1)\n-n1.print_layers()\n-shape = n1.outputs.get_shape().as_list()\n-if shape[1:] != [102, 1]:\n-    raise Exception(\"shape do not match\")\n \n-n2 = tl.layers.ZeroPad1d(n, padding=(2, 3))\n-n2.print_layers()\n-shape = n2.outputs.get_shape().as_list()\n-if shape[1:] != [105, 1]:\n-    raise Exception(\"shape do not match\")\n+class Layer_Padding_Test(unittest.TestCase):\n+    @classmethod\n+    def setUpClass(cls):\n \n-## 2D\n-x = tf.placeholder(tf.float32, (None, 100, 100, 3))\n-n = tl.layers.InputLayer(x)\n-n1 = tl.layers.ZeroPad2d(n, padding=2)\n-n1.print_layers()\n-shape = n1.outputs.get_shape().as_list()\n-if shape[1:] != [104, 104, 3]:\n-    raise Exception(\"shape do not match\")\n+        ## 1D\n+        x = tf.placeholder(tf.float32, (None, 100, 1))\n+        n = tl.layers.InputLayer(x)\n \n-n2 = tl.layers.ZeroPad2d(n, padding=(2, 3))\n-n2.print_layers()\n-shape = n2.outputs.get_shape().as_list()\n-if shape[1:] != [104, 106, 3]:\n-    raise Exception(\"shape do not match\")\n+        n1 = tl.layers.ZeroPad1d(n, padding=1)\n+        n2 = tl.layers.ZeroPad1d(n, padding=(2, 3))\n \n-n3 = tl.layers.ZeroPad2d(n, padding=((3, 3), (4, 4)))\n-n3.print_layers()\n-shape = n3.outputs.get_shape().as_list()\n-if shape[1:] != [106, 108, 3]:\n-    raise Exception(\"shape do not match\")\n+        n1.print_layers()\n+        n2.print_layers()\n \n-## 3D\n-x = tf.placeholder(tf.float32, (None, 100, 100, 100, 3))\n-n = tl.layers.InputLayer(x)\n-n1 = tl.layers.ZeroPad3d(n, padding=2)\n-n1.print_layers()\n-shape = n1.outputs.get_shape().as_list()\n-if shape[1:] != [104, 104, 104, 3]:\n-    raise Exception(\"shape do not match\")\n+        cls.n1_shape = n1.outputs.get_shape().as_list()\n+        cls.n2_shape = n2.outputs.get_shape().as_list()\n \n-n2 = tl.layers.ZeroPad3d(n, padding=(2, 3, 4))\n-n2.print_layers()\n-shape = n2.outputs.get_shape().as_list()\n-if shape[1:] != [104, 106, 108, 3]:\n-    raise Exception(\"shape do not match\")\n+        ## 2D\n+        x = tf.placeholder(tf.float32, (None, 100, 100, 3))\n+        n = tl.layers.InputLayer(x)\n \n-n3 = tl.layers.ZeroPad3d(n, padding=((3, 3), (4, 4), (5, 5)))\n-n3.print_layers()\n-shape = n3.outputs.get_shape().as_list()\n-if shape[1:] != [106, 108, 110, 3]:\n-    raise Exception(\"shape do not match\")\n+        n3 = tl.layers.ZeroPad2d(n, padding=2)\n+        n4 = tl.layers.ZeroPad2d(n, padding=(2, 3))\n+        n5 = tl.layers.ZeroPad2d(n, padding=((3, 3), (4, 4)))\n+\n+        n3.print_layers()\n+        n4.print_layers()\n+        n5.print_layers()\n+\n+        cls.n3_shape = n3.outputs.get_shape().as_list()\n+        cls.n4_shape = n4.outputs.get_shape().as_list()\n+        cls.n5_shape = n5.outputs.get_shape().as_list()\n+\n+        ## 3D\n+        x = tf.placeholder(tf.float32, (None, 100, 100, 100, 3))\n+        n = tl.layers.InputLayer(x)\n+\n+        n6 = tl.layers.ZeroPad3d(n, padding=2)\n+        n7 = tl.layers.ZeroPad3d(n, padding=(2, 3, 4))\n+        n8 = tl.layers.ZeroPad3d(n, padding=((3, 3), (4, 4), (5, 5)))\n+\n+        n6.print_layers()\n+        n7.print_layers()\n+        n8.print_layers()\n+\n+        cls.n6_shape = n6.outputs.get_shape().as_list()\n+        cls.n7_shape = n7.outputs.get_shape().as_list()\n+        cls.n8_shape = n8.outputs.get_shape().as_list()\n+\n+    @classmethod\n+    def tearDownClass(cls):\n+        tf.reset_default_graph()\n+\n+    def test_n1_shape(self):\n+        self.assertEqual(self.n1_shape[1:], [102, 1])\n+\n+    def test_n2_shape(self):\n+        self.assertEqual(self.n2_shape[1:], [105, 1])\n+\n+    def test_n3_shape(self):\n+        self.assertEqual(self.n3_shape[1:], [104, 104, 3])\n+\n+    def test_n4_shape(self):\n+        self.assertEqual(self.n4_shape[1:], [104, 106, 3])\n+\n+    def test_n5_shape(self):\n+        self.assertEqual(self.n5_shape[1:], [106, 108, 3])\n+\n+    def test_n6_shape(self):\n+        self.assertEqual(self.n6_shape[1:], [104, 104, 104, 3])\n+\n+    def test_n7_shape(self):\n+        self.assertEqual(self.n7_shape[1:], [104, 106, 108, 3])\n+\n+    def test_n8_shape(self):\n+        self.assertEqual(self.n8_shape[1:], [106, 108, 110, 3])\n+\n+\n+if __name__ == '__main__':\n+\n+    # tf.logging.set_verbosity(tf.logging.INFO)\n+    tf.logging.set_verbosity(tf.logging.DEBUG)\n+\n+    unittest.main()\n",
        "source_code_with_indent": "\n## 1D\nx = tf.placeholder(tf.float32, (None, 100, 1))\nn = tl.layers.InputLayer(x)\nn1 = tl.layers.ZeroPad1d(n, padding=1)\nn1.print_layers()\nshape = n1.outputs.get_shape().as_list()\nif shape[1:] != [102, 1]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>n2 = tl.layers.ZeroPad1d(n, padding=(2, 3))\nn2.print_layers()\nshape = n2.outputs.get_shape().as_list()\nif shape[1:] != [105, 1]:\n    <IND>raise Exception(\"shape do not match\")\n\n## 2D\n<DED>x = tf.placeholder(tf.float32, (None, 100, 100, 3))\nn = tl.layers.InputLayer(x)\nn1 = tl.layers.ZeroPad2d(n, padding=2)\nn1.print_layers()\nshape = n1.outputs.get_shape().as_list()\nif shape[1:] != [104, 104, 3]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>n2 = tl.layers.ZeroPad2d(n, padding=(2, 3))\nn2.print_layers()\nshape = n2.outputs.get_shape().as_list()\nif shape[1:] != [104, 106, 3]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>n3 = tl.layers.ZeroPad2d(n, padding=((3, 3), (4, 4)))\nn3.print_layers()\nshape = n3.outputs.get_shape().as_list()\nif shape[1:] != [106, 108, 3]:\n    <IND>raise Exception(\"shape do not match\")\n\n## 3D\n<DED>x = tf.placeholder(tf.float32, (None, 100, 100, 100, 3))\nn = tl.layers.InputLayer(x)\nn1 = tl.layers.ZeroPad3d(n, padding=2)\nn1.print_layers()\nshape = n1.outputs.get_shape().as_list()\nif shape[1:] != [104, 104, 104, 3]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>n2 = tl.layers.ZeroPad3d(n, padding=(2, 3, 4))\nn2.print_layers()\nshape = n2.outputs.get_shape().as_list()\nif shape[1:] != [104, 106, 108, 3]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>n3 = tl.layers.ZeroPad3d(n, padding=((3, 3), (4, 4), (5, 5)))\nn3.print_layers()\nshape = n3.outputs.get_shape().as_list()\nif shape[1:] != [106, 108, 110, 3]:\n    <IND>raise Exception(\"shape do not match\")\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n\nclass Layer_Padding_Test(unittest.TestCase):\n    <IND>@classmethod\n    def setUpClass(cls):\n\n        ## 1D\n        <IND>x = tf.placeholder(tf.float32, (None, 100, 1))\n        n = tl.layers.InputLayer(x)\n\n        n1 = tl.layers.ZeroPad1d(n, padding=1)\n        n2 = tl.layers.ZeroPad1d(n, padding=(2, 3))\n\n        n1.print_layers()\n        n2.print_layers()\n\n        cls.n1_shape = n1.outputs.get_shape().as_list()\n        cls.n2_shape = n2.outputs.get_shape().as_list()\n\n        ## 2D\n        x = tf.placeholder(tf.float32, (None, 100, 100, 3))\n        n = tl.layers.InputLayer(x)\n\n        n3 = tl.layers.ZeroPad2d(n, padding=2)\n        n4 = tl.layers.ZeroPad2d(n, padding=(2, 3))\n        n5 = tl.layers.ZeroPad2d(n, padding=((3, 3), (4, 4)))\n\n        n3.print_layers()\n        n4.print_layers()\n        n5.print_layers()\n\n        cls.n3_shape = n3.outputs.get_shape().as_list()\n        cls.n4_shape = n4.outputs.get_shape().as_list()\n        cls.n5_shape = n5.outputs.get_shape().as_list()\n\n        ## 3D\n        x = tf.placeholder(tf.float32, (None, 100, 100, 100, 3))\n        n = tl.layers.InputLayer(x)\n\n        n6 = tl.layers.ZeroPad3d(n, padding=2)\n        n7 = tl.layers.ZeroPad3d(n, padding=(2, 3, 4))\n        n8 = tl.layers.ZeroPad3d(n, padding=((3, 3), (4, 4), (5, 5)))\n\n        n6.print_layers()\n        n7.print_layers()\n        n8.print_layers()\n\n        cls.n6_shape = n6.outputs.get_shape().as_list()\n        cls.n7_shape = n7.outputs.get_shape().as_list()\n        cls.n8_shape = n8.outputs.get_shape().as_list()\n\n    <DED>@classmethod\n    def tearDownClass(cls):\n        <IND>tf.reset_default_graph()\n\n    <DED>def test_n1_shape(self):\n        <IND>self.assertEqual(self.n1_shape[1:], [102, 1])\n\n    <DED>def test_n2_shape(self):\n        <IND>self.assertEqual(self.n2_shape[1:], [105, 1])\n\n    <DED>def test_n3_shape(self):\n        <IND>self.assertEqual(self.n3_shape[1:], [104, 104, 3])\n\n    <DED>def test_n4_shape(self):\n        <IND>self.assertEqual(self.n4_shape[1:], [104, 106, 3])\n\n    <DED>def test_n5_shape(self):\n        <IND>self.assertEqual(self.n5_shape[1:], [106, 108, 3])\n\n    <DED>def test_n6_shape(self):\n        <IND>self.assertEqual(self.n6_shape[1:], [104, 104, 104, 3])\n\n    <DED>def test_n7_shape(self):\n        <IND>self.assertEqual(self.n7_shape[1:], [104, 106, 108, 3])\n\n    <DED>def test_n8_shape(self):\n        <IND>self.assertEqual(self.n8_shape[1:], [106, 108, 110, 3])\n\n\n<DED><DED>if __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    <IND>tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "tensorlayer/TensorLayer",
    "commit": "6f539ad2324ddccc18b6ac39e4a2f4aeb12173a2",
    "filename": "tests/test_layers_recurrent.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/tensorlayer-TensorLayer/tests/test_layers_recurrent.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "tests/test_layers_recurrent.py:40:0 Incompatible variable type [9]: net is declared to have type `tl.layers.core.EmbeddingInputlayer` but is used as type `tl.layers.core.InputLayer`.",
    "message": " net is declared to have type `tl.layers.core.EmbeddingInputlayer` but is used as type `tl.layers.core.InputLayer`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 40,
    "warning_line": "net = tl.layers.InputLayer(x, name='in')",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import tensorflow as tf\n",
        "source_code_len": 24,
        "target_code": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_len": 87,
        "diff_format": "@@ -1,1 +1,5 @@\n+#!/usr/bin/env python\n+# -*- coding: utf-8 -*-\n+import unittest\n+\n import tensorflow as tf\n",
        "source_code_with_indent": "import tensorflow as tf\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n## RNN encoder ====================================================\nbatch_size = 32\nnum_steps = 5\nvocab_size = 30\nhidden_size = 20\nkeep_prob = 0.8\nis_train = True\ninput_data = tf.placeholder(tf.int32, [batch_size, num_steps])\nnet = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=vocab_size, embedding_size=hidden_size, name='embed')\nnet = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_train, name='drop1')\nnet = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, return_last=False, name='lstm1')\nlstm1 = net\nnet = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_train, name='drop2')\nnet = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, return_last=True, name='lstm2')\nlstm2 = net\nnet = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_train, name='drop3')\nnet = tl.layers.DenseLayer(net, n_units=vocab_size, name='output')\n\nnet.print_layers()\nnet.print_params(False)\n\nif len(net.all_layers) != 7:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 7:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 7790:\n    raise Exception(\"params do not match\")\n\n## CNN+RNN encoder ====================================================\nimage_size = 100\nbatch_size = 10\nnum_steps = 5\n\nx = tf.placeholder(tf.float32, shape=[batch_size, image_size, image_size, 1])\nnet = tl.layers.InputLayer(x, name='in')\nnet = tl.layers.Conv2d(net, n_filter=32, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn1')\nnet = tl.layers.MaxPool2d(net, filter_size=(2, 2), strides=(2, 2), name='pool1')\nnet = tl.layers.Conv2d(net, n_filter=10, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn2')\nnet = tl.layers.MaxPool2d(net, filter_size=(2, 2), strides=(2, 2), name='pool2')\nnet = tl.layers.FlattenLayer(net, name='flatten')\nnet = tl.layers.ReshapeLayer(net, shape=(-1, num_steps, int(net.outputs._shape[-1])))\nrnn = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=200, n_steps=num_steps, return_last=False, return_seq_2d=True, name='rnn')\nnet = tl.layers.DenseLayer(rnn, n_units=3, name='out')\n\nnet.print_layers()\nnet.print_params(False)\n\nif len(net.all_layers) != 8:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 8:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 562245:\n    raise Exception(\"params do not match\")\n\n## Bidirectional Synced input and output\nbatch_size = 10\nnum_steps = 5\nvocab_size = 30\nhidden_size = 20\ninput_data = tf.placeholder(tf.int32, [batch_size, num_steps])\nnet = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=vocab_size, embedding_size=hidden_size, name='emb')\nnet = tl.layers.BiRNNLayer(\n    net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, return_last=False, return_seq_2d=False, name='birnn')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[1:3] != [num_steps, hidden_size * 2]:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 2:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 5:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 7160:\n    raise Exception(\"params do not match\")\n\n# n_layer=2\nnet = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=vocab_size, embedding_size=hidden_size, name='emb2')\nnet = tl.layers.BiRNNLayer(\n    net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, n_layer=2, return_last=False, return_seq_2d=False, name='birnn2')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[1:3] != [num_steps, hidden_size * 2]:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 2:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 9:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 13720:\n    raise Exception(\"params do not match\")\n\n## ConvLSTMLayer TODO\n# image_size = 100\n# batch_size = 10\n# num_steps = 5\n# x = tf.placeholder(tf.float32, shape=[batch_size, num_steps, image_size, image_size, 3])\n# net = tl.layers.InputLayer(x, name='in2')\n# net = tl.layers.ConvLSTMLayer(net,\n#             feature_map=1,\n#             filter_size=(3, 3),\n#             cell_fn=tl.layers.BasicConvLSTMCell,\n#             initializer=tf.random_uniform_initializer(-0.1, 0.1),\n#             n_steps=num_steps,\n#             initial_state=None,\n#             return_last=False,\n#             return_seq_2d=False,\n#             name='convlstm')\n\n## Dynamic Synced input and output\nbatch_size = 32\nnum_steps = 5\nvocab_size = 30\nembedding_size = 20\nkeep_prob = 0.8\nis_train = True\ninput_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"input\")\nnin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=vocab_size, embedding_size=embedding_size, name='seq_embedding')\nrnn = tl.layers.DynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=(keep_prob if is_train else None),\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    return_last=False,\n    return_seq_2d=True,\n    name='dynamicrnn')\nnet = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o\")\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = rnn.outputs.get_shape().as_list()\nif shape[-1] != embedding_size:\n    raise Exception(\"shape do not match\")\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != vocab_size:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 3:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 5:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 4510:\n    raise Exception(\"params do not match\")\n\n# n_layer=3\nnin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=vocab_size, embedding_size=embedding_size, name='seq_embedding2')\nrnn = tl.layers.DynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=(keep_prob if is_train else None),\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    n_layer=3,\n    return_last=False,\n    return_seq_2d=True,\n    name='dynamicrnn2')\nnet = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o2\")\n\nshape = rnn.outputs.get_shape().as_list()\nif (shape[-1] != embedding_size) or (len(shape) != 2):\n    raise Exception(\"shape do not match\")\n\nnet = tl.layers.DynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=None,\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    n_layer=3,\n    return_last=False,\n    return_seq_2d=False,\n    name='dynamicrnn3')\n# net = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o3\")\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif (shape[-1] != embedding_size) or (len(shape) != 3):\n    raise Exception(\"shape do not match\")\n\nnet = tl.layers.DynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=None,\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    n_layer=1,\n    return_last=True,\n    return_seq_2d=False,\n    name='dynamicrnn4')\nnet.print_layers()\nnet.print_params(False)\nshape = net.outputs.get_shape().as_list()\nif (shape[-1] != embedding_size) or (len(shape) != 2):\n    raise Exception(\"shape do not match\")\n\nnet = tl.layers.DynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=None,\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    n_layer=1,\n    return_last=True,\n    return_seq_2d=True,\n    name='dynamicrnn5')\nnet.print_layers()\nnet.print_params(False)\nshape = net.outputs.get_shape().as_list()\nif (shape[-1] != embedding_size) or (len(shape) != 2):\n    raise Exception(\"shape do not match\")\n\n## BiDynamic Synced input and output\nrnn = tl.layers.BiDynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=(keep_prob if is_train else None),\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    return_last=False,\n    return_seq_2d=True,\n    name='bidynamicrnn')\nnet = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o4\")\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = rnn.outputs.get_shape().as_list()\nif shape[-1] != embedding_size * 2:\n    raise Exception(\"shape do not match\")\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != vocab_size:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 3:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 7:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 8390:\n    raise Exception(\"params do not match\")\n\n# n_layer=2\nrnn = tl.layers.BiDynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=(keep_prob if is_train else None),\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    n_layer=2,\n    return_last=False,\n    return_seq_2d=True,\n    name='bidynamicrnn2')\nnet = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o5\")\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = rnn.outputs.get_shape().as_list()\nif shape[-1] != embedding_size * 2:\n    raise Exception(\"shape do not match\")\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != vocab_size:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 3:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 11:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 18150:\n    raise Exception(\"params do not match\")\n\n## Seq2Seq\nfrom tensorlayer.layers import EmbeddingInputlayer, Seq2Seq, retrieve_seq_length_op2, DenseLayer\nbatch_size = 32\nencode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"encode_seqs\")\ndecode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"decode_seqs\")\ntarget_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_seqs\")\ntarget_mask = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_mask\")  # tl.prepro.sequences_get_mask()\nwith tf.variable_scope(\"model\"):\n    # for chatbot, you can use the same embedding layer,\n    # for translation, you may want to use 2 seperated embedding layers\n    with tf.variable_scope(\"embedding\") as vs:\n        net_encode = EmbeddingInputlayer(inputs=encode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n        vs.reuse_variables()\n        # tl.layers.set_name_reuse(True)\n        net_decode = EmbeddingInputlayer(inputs=decode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n    net = Seq2Seq(\n        net_encode,\n        net_decode,\n        cell_fn=tf.contrib.rnn.BasicLSTMCell,\n        n_hidden=200,\n        initializer=tf.random_uniform_initializer(-0.1, 0.1),\n        encode_sequence_length=retrieve_seq_length_op2(encode_seqs),\n        decode_sequence_length=retrieve_seq_length_op2(decode_seqs),\n        initial_state_encode=None,\n        dropout=None,\n        n_layer=2,\n        return_seq_2d=True,\n        name='Seq2seq')\nnet = DenseLayer(net, n_units=10000, act=tf.identity, name='oo')\ne_loss = tl.cost.cross_entropy_seq_with_mask(logits=net.outputs, target_seqs=target_seqs, input_mask=target_mask, return_details=False, name='cost')\ny = tf.nn.softmax(net.outputs)\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 10000:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 5:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 11:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 5293200:\n    raise Exception(\"params do not match\")\n",
        "source_code_len": 11934,
        "target_code": "\n\nclass Layer_Recurrent_Test(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n\n        cls.net1_batch_size = 32\n        cls.net2_batch_size = 10\n        cls.net3_batch_size = 10\n        cls.net5_batch_size = 32\n        cls.net11_batch_size = 32\n\n        cls.vocab_size = 30\n        cls.hidden_size = 20\n        cls.image_size = 100\n        cls.embedding_size = 20\n\n        cls.num_steps = 5\n\n        cls.keep_prob = 0.8\n        cls.is_train = True\n\n        # =============================== RNN encoder ===============================\n\n        input_data = tf.placeholder(tf.int32, [cls.net1_batch_size, cls.num_steps])\n\n        net1 = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=cls.vocab_size, embedding_size=cls.hidden_size, name='embed')\n        net1 = tl.layers.DropoutLayer(net1, keep=cls.keep_prob, is_fix=True, is_train=cls.is_train, name='drop1')\n        net1 = tl.layers.RNNLayer(net1, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=cls.hidden_size, n_steps=cls.num_steps, return_last=False, name='lstm1')\n\n        # lstm1 = net1\n\n        net1 = tl.layers.DropoutLayer(net1, keep=cls.keep_prob, is_fix=True, is_train=cls.is_train, name='drop2')\n        net1 = tl.layers.RNNLayer(net1, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=cls.hidden_size, n_steps=cls.num_steps, return_last=True, name='lstm2')\n\n        # lstm2 = net1\n\n        net1 = tl.layers.DropoutLayer(net1, keep=cls.keep_prob, is_fix=True, is_train=cls.is_train, name='drop3')\n        net1 = tl.layers.DenseLayer(net1, n_units=cls.vocab_size, name='output')\n\n        net1.print_layers()\n        net1.print_params(False)\n\n        cls.net1_shape = net1.outputs.get_shape().as_list()\n        cls.net1_layers = net1.all_layers\n        cls.net1_params = net1.all_params\n        cls.net1_n_params = net1.count_params()\n\n        # =============================== CNN+RNN encoder ===============================\n\n        x2 = tf.placeholder(tf.float32, shape=[cls.net2_batch_size, cls.image_size, cls.image_size, 1])\n        net2 = tl.layers.InputLayer(x2, name='in')\n\n        net2 = tl.layers.Conv2d(net2, n_filter=32, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn1')\n        net2 = tl.layers.MaxPool2d(net2, filter_size=(2, 2), strides=(2, 2), name='pool1')\n        net2 = tl.layers.Conv2d(net2, n_filter=10, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn2')\n        net2 = tl.layers.MaxPool2d(net2, filter_size=(2, 2), strides=(2, 2), name='pool2')\n\n        net2 = tl.layers.FlattenLayer(net2, name='flatten')\n        net2 = tl.layers.ReshapeLayer(net2, shape=(-1, cls.num_steps, int(net2.outputs._shape[-1])))\n\n        rnn = tl.layers.RNNLayer(\n            net2, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=200, n_steps=cls.num_steps, return_last=False, return_seq_2d=True, name='rnn')\n\n        net2 = tl.layers.DenseLayer(rnn, n_units=3, name='out')\n\n        net2.print_layers()\n        net2.print_params(False)\n\n        cls.net2_shape = net2.outputs.get_shape().as_list()\n        cls.net2_layers = net2.all_layers\n        cls.net2_params = net2.all_params\n        cls.net2_n_params = net2.count_params()\n\n        # =============================== Bidirectional Synced input and output ===============================\n\n        x3 = tf.placeholder(tf.int32, [cls.net3_batch_size, cls.num_steps])\n\n        net3 = tl.layers.EmbeddingInputlayer(inputs=x3, vocabulary_size=cls.vocab_size, embedding_size=cls.hidden_size, name='emb')\n        net3 = tl.layers.BiRNNLayer(\n            net3, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=cls.hidden_size, n_steps=cls.num_steps, return_last=False, return_seq_2d=False, name='birnn')\n\n        net3.print_layers()\n        net3.print_params(False)\n\n        cls.net3_shape = net3.outputs.get_shape().as_list()\n        cls.net3_layers = net3.all_layers\n        cls.net3_params = net3.all_params\n        cls.net3_n_params = net3.count_params()\n\n        # n_layer=2\n        net4 = tl.layers.EmbeddingInputlayer(inputs=x3, vocabulary_size=cls.vocab_size, embedding_size=cls.hidden_size, name='emb2')\n        net4 = tl.layers.BiRNNLayer(\n            net4,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.hidden_size,\n            n_steps=cls.num_steps,\n            n_layer=2,\n            return_last=False,\n            return_seq_2d=False,\n            name='birnn2')\n\n        net4.print_layers()\n        net4.print_params(False)\n\n        cls.net4_shape = net4.outputs.get_shape().as_list()\n        cls.net4_layers = net4.all_layers\n        cls.net4_params = net4.all_params\n        cls.net4_n_params = net4.count_params()\n\n        ## TODO: ConvLSTMLayer\n        # image_size = 100\n        # batch_size = 10\n        # num_steps = 5\n        # x = tf.placeholder(tf.float32, shape=[batch_size, num_steps, image_size, image_size, 3])\n        # net = tl.layers.InputLayer(x, name='in2')\n        # net = tl.layers.ConvLSTMLayer(net,\n        #             feature_map=1,\n        #             filter_size=(3, 3),\n        #             cell_fn=tl.layers.BasicConvLSTMCell,\n        #             initializer=tf.random_uniform_initializer(-0.1, 0.1),\n        #             n_steps=num_steps,\n        #             initial_state=None,\n        #             return_last=False,\n        #             return_seq_2d=False,\n        #             name='convlstm')\n\n        # =============================== Dynamic Synced input and output ===============================\n\n        input_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net5_batch_size, None], name=\"input\")\n        nin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=cls.vocab_size, embedding_size=cls.embedding_size, name='seq_embedding')\n\n        rnn = tl.layers.DynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=(cls.keep_prob if cls.is_train else None),\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            return_last=False,\n            return_seq_2d=True,\n            name='dynamicrnn')\n\n        net5 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o\")\n\n        net5.print_layers()\n        net5.print_params(False)\n\n        cls.net5_shape = net5.outputs.get_shape().as_list()\n        cls.net5_rnn_shape = rnn.outputs.get_shape().as_list()\n        cls.net5_layers = net5.all_layers\n        cls.net5_params = net5.all_params\n        cls.net5_n_params = net5.count_params()\n\n        # n_layer=3\n        nin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=cls.vocab_size, embedding_size=cls.embedding_size, name='seq_embedding2')\n        rnn = tl.layers.DynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=(cls.keep_prob if cls.is_train else None),\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            n_layer=3,\n            return_last=False,\n            return_seq_2d=True,\n            name='dynamicrnn2')\n\n        # net6 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o2\")\n\n        net6 = tl.layers.DynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=None,\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            n_layer=3,\n            return_last=False,\n            return_seq_2d=False,\n            name='dynamicrnn3')\n\n        # net6 = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o3\")\n\n        net6.print_layers()\n        net6.print_params(False)\n\n        cls.net6_shape = net6.outputs.get_shape().as_list()\n        cls.net6_rnn_shape = rnn.outputs.get_shape().as_list()\n\n        net7 = tl.layers.DynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=None,\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            n_layer=1,\n            return_last=True,\n            return_seq_2d=False,\n            name='dynamicrnn4')\n\n        net7.print_layers()\n        net7.print_params(False)\n\n        cls.net7_shape = net7.outputs.get_shape().as_list()\n\n        net8 = tl.layers.DynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=None,\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            n_layer=1,\n            return_last=True,\n            return_seq_2d=True,\n            name='dynamicrnn5')\n\n        net8.print_layers()\n        net8.print_params(False)\n\n        cls.net8_shape = net8.outputs.get_shape().as_list()\n\n        # =============================== BiDynamic Synced input and output ===============================\n\n        rnn = tl.layers.BiDynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=(cls.keep_prob if cls.is_train else None),\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            return_last=False,\n            return_seq_2d=True,\n            name='bidynamicrnn')\n\n        net9 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o4\")\n\n        net9.print_layers()\n        net9.print_params(False)\n\n        cls.net9_shape = net9.outputs.get_shape().as_list()\n        cls.net9_rnn_shape = rnn.outputs.get_shape().as_list()\n        cls.net9_layers = net9.all_layers\n        cls.net9_params = net9.all_params\n        cls.net9_n_params = net9.count_params()\n\n        # n_layer=2\n        rnn = tl.layers.BiDynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=(cls.keep_prob if cls.is_train else None),\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            n_layer=2,\n            return_last=False,\n            return_seq_2d=True,\n            name='bidynamicrnn2')\n\n        net10 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o5\")\n\n        net10.print_layers()\n        net10.print_params(False)\n\n        cls.net10_shape = net10.outputs.get_shape().as_list()\n        cls.net10_rnn_shape = rnn.outputs.get_shape().as_list()\n        cls.net10_layers = net10.all_layers\n        cls.net10_params = net10.all_params\n        cls.net10_n_params = net10.count_params()\n\n        # =============================== Seq2Seq ===============================\n\n        encode_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"encode_seqs\")\n        decode_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"decode_seqs\")\n        # target_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"target_seqs\")\n        # target_mask = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"target_mask\")  # tl.prepro.sequences_get_mask()\n\n        with tf.variable_scope(\"model\"):\n            # for chatbot, you can use the same embedding layer,\n            # for translation, you may want to use 2 seperated embedding layers\n\n            with tf.variable_scope(\"embedding\") as vs:\n                net_encode = tl.layers.EmbeddingInputlayer(inputs=encode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n                vs.reuse_variables()\n                # tl.layers.set_name_reuse(True)\n                net_decode = tl.layers.EmbeddingInputlayer(inputs=decode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n\n            net11 = tl.layers.Seq2Seq(\n                net_encode,\n                net_decode,\n                cell_fn=tf.contrib.rnn.BasicLSTMCell,\n                n_hidden=200,\n                initializer=tf.random_uniform_initializer(-0.1, 0.1),\n                encode_sequence_length=tl.layers.retrieve_seq_length_op2(encode_seqs),\n                decode_sequence_length=tl.layers.retrieve_seq_length_op2(decode_seqs),\n                initial_state_encode=None,\n                dropout=None,\n                n_layer=2,\n                return_seq_2d=True,\n                name='Seq2seq')\n\n        net11 = tl.layers.DenseLayer(net11, n_units=10000, act=tf.identity, name='oo')\n\n        # e_loss = tl.cost.cross_entropy_seq_with_mask(logits=net11.outputs, target_seqs=target_seqs, input_mask=target_mask, return_details=False, name='cost')\n        # y = tf.nn.softmax(net11.outputs)\n\n        net11.print_layers()\n        net11.print_params(False)\n\n        cls.net11_shape = net11.outputs.get_shape().as_list()\n        cls.net11_layers = net11.all_layers\n        cls.net11_params = net11.all_params\n        cls.net11_n_params = net11.count_params()\n\n    @classmethod\n    def tearDownClass(cls):\n        tf.reset_default_graph()\n\n    def test_net1(self):\n        self.assertEqual(self.net1_shape, [self.net1_batch_size, self.vocab_size])\n        self.assertEqual(len(self.net1_layers), 7)\n        self.assertEqual(len(self.net1_params), 7)\n        self.assertEqual(self.net1_n_params, 7790)\n\n    def test_net2(self):\n        self.assertEqual(self.net2_shape, [self.net2_batch_size, 3])\n        self.assertEqual(len(self.net2_layers), 8)\n        self.assertEqual(len(self.net2_params), 8)\n        self.assertEqual(self.net2_n_params, 562245)\n\n    def test_net3(self):\n        self.assertEqual(self.net3_shape[1:3], [self.num_steps, self.hidden_size * 2])\n        self.assertEqual(len(self.net3_layers), 2)\n        self.assertEqual(len(self.net3_params), 5)\n        self.assertEqual(self.net3_n_params, 7160)\n\n    def test_net4(self):\n        self.assertEqual(self.net4_shape[1:3], [self.num_steps, self.hidden_size * 2])\n        self.assertEqual(len(self.net4_layers), 2)\n        self.assertEqual(len(self.net4_params), 9)\n        self.assertEqual(self.net4_n_params, 13720)\n\n    def test_net5(self):\n        self.assertEqual(self.net5_shape[-1], self.vocab_size)\n        self.assertEqual(self.net5_rnn_shape[-1], self.embedding_size)\n        self.assertEqual(len(self.net5_layers), 3)\n        self.assertEqual(len(self.net5_params), 5)\n        self.assertEqual(self.net5_n_params, 4510)\n\n    def test_net6(self):\n        self.assertEqual(self.net6_shape[-1], self.embedding_size)\n        self.assertEqual(self.net6_rnn_shape[-1], self.embedding_size)\n\n    def test_net7(self):\n        self.assertEqual(self.net7_shape[-1], self.embedding_size)\n\n    def test_net8(self):\n        self.assertEqual(self.net8_shape[-1], self.embedding_size)\n\n    def test_net9(self):\n        self.assertEqual(self.net9_shape[-1], self.vocab_size)\n        self.assertEqual(self.net9_rnn_shape[-1], self.embedding_size * 2)\n        self.assertEqual(len(self.net9_layers), 3)\n        self.assertEqual(len(self.net9_params), 7)\n        self.assertEqual(self.net9_n_params, 8390)\n\n    def test_net10(self):\n        self.assertEqual(self.net10_shape[-1], self.vocab_size)\n        self.assertEqual(self.net10_rnn_shape[-1], self.embedding_size * 2)\n        self.assertEqual(len(self.net10_layers), 3)\n        self.assertEqual(len(self.net10_params), 11)\n        self.assertEqual(self.net10_n_params, 18150)\n\n    def test_net11(self):\n        self.assertEqual(self.net11_shape[-1], 10000)\n        self.assertEqual(len(self.net11_layers), 5)\n        self.assertEqual(len(self.net11_params), 11)\n        self.assertEqual(self.net11_n_params, 5293200)\n\n\nif __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_len": 15618,
        "diff_format": "@@ -3,344 +7,381 @@\n \n-## RNN encoder ====================================================\n-batch_size = 32\n-num_steps = 5\n-vocab_size = 30\n-hidden_size = 20\n-keep_prob = 0.8\n-is_train = True\n-input_data = tf.placeholder(tf.int32, [batch_size, num_steps])\n-net = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=vocab_size, embedding_size=hidden_size, name='embed')\n-net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_train, name='drop1')\n-net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, return_last=False, name='lstm1')\n-lstm1 = net\n-net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_train, name='drop2')\n-net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, return_last=True, name='lstm2')\n-lstm2 = net\n-net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_train, name='drop3')\n-net = tl.layers.DenseLayer(net, n_units=vocab_size, name='output')\n-\n-net.print_layers()\n-net.print_params(False)\n-\n-if len(net.all_layers) != 7:\n-    raise Exception(\"layers do not match\")\n-\n-if len(net.all_params) != 7:\n-    raise Exception(\"params do not match\")\n-\n-if net.count_params() != 7790:\n-    raise Exception(\"params do not match\")\n-\n-## CNN+RNN encoder ====================================================\n-image_size = 100\n-batch_size = 10\n-num_steps = 5\n-\n-x = tf.placeholder(tf.float32, shape=[batch_size, image_size, image_size, 1])\n-net = tl.layers.InputLayer(x, name='in')\n-net = tl.layers.Conv2d(net, n_filter=32, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn1')\n-net = tl.layers.MaxPool2d(net, filter_size=(2, 2), strides=(2, 2), name='pool1')\n-net = tl.layers.Conv2d(net, n_filter=10, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn2')\n-net = tl.layers.MaxPool2d(net, filter_size=(2, 2), strides=(2, 2), name='pool2')\n-net = tl.layers.FlattenLayer(net, name='flatten')\n-net = tl.layers.ReshapeLayer(net, shape=(-1, num_steps, int(net.outputs._shape[-1])))\n-rnn = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=200, n_steps=num_steps, return_last=False, return_seq_2d=True, name='rnn')\n-net = tl.layers.DenseLayer(rnn, n_units=3, name='out')\n-\n-net.print_layers()\n-net.print_params(False)\n-\n-if len(net.all_layers) != 8:\n-    raise Exception(\"layers do not match\")\n-\n-if len(net.all_params) != 8:\n-    raise Exception(\"params do not match\")\n-\n-if net.count_params() != 562245:\n-    raise Exception(\"params do not match\")\n-\n-## Bidirectional Synced input and output\n-batch_size = 10\n-num_steps = 5\n-vocab_size = 30\n-hidden_size = 20\n-input_data = tf.placeholder(tf.int32, [batch_size, num_steps])\n-net = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=vocab_size, embedding_size=hidden_size, name='emb')\n-net = tl.layers.BiRNNLayer(\n-    net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, return_last=False, return_seq_2d=False, name='birnn')\n-\n-net.print_layers()\n-net.print_params(False)\n-\n-shape = net.outputs.get_shape().as_list()\n-if shape[1:3] != [num_steps, hidden_size * 2]:\n-    raise Exception(\"shape do not match\")\n-\n-if len(net.all_layers) != 2:\n-    raise Exception(\"layers do not match\")\n-\n-if len(net.all_params) != 5:\n-    raise Exception(\"params do not match\")\n-\n-if net.count_params() != 7160:\n-    raise Exception(\"params do not match\")\n-\n-# n_layer=2\n-net = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=vocab_size, embedding_size=hidden_size, name='emb2')\n-net = tl.layers.BiRNNLayer(\n-    net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, n_layer=2, return_last=False, return_seq_2d=False, name='birnn2')\n-\n-net.print_layers()\n-net.print_params(False)\n-\n-shape = net.outputs.get_shape().as_list()\n-if shape[1:3] != [num_steps, hidden_size * 2]:\n-    raise Exception(\"shape do not match\")\n-\n-if len(net.all_layers) != 2:\n-    raise Exception(\"layers do not match\")\n-\n-if len(net.all_params) != 9:\n-    raise Exception(\"params do not match\")\n-\n-if net.count_params() != 13720:\n-    raise Exception(\"params do not match\")\n-\n-## ConvLSTMLayer TODO\n-# image_size = 100\n-# batch_size = 10\n-# num_steps = 5\n-# x = tf.placeholder(tf.float32, shape=[batch_size, num_steps, image_size, image_size, 3])\n-# net = tl.layers.InputLayer(x, name='in2')\n-# net = tl.layers.ConvLSTMLayer(net,\n-#             feature_map=1,\n-#             filter_size=(3, 3),\n-#             cell_fn=tl.layers.BasicConvLSTMCell,\n-#             initializer=tf.random_uniform_initializer(-0.1, 0.1),\n-#             n_steps=num_steps,\n-#             initial_state=None,\n-#             return_last=False,\n-#             return_seq_2d=False,\n-#             name='convlstm')\n-\n-## Dynamic Synced input and output\n-batch_size = 32\n-num_steps = 5\n-vocab_size = 30\n-embedding_size = 20\n-keep_prob = 0.8\n-is_train = True\n-input_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"input\")\n-nin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=vocab_size, embedding_size=embedding_size, name='seq_embedding')\n-rnn = tl.layers.DynamicRNNLayer(\n-    nin,\n-    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n-    n_hidden=embedding_size,\n-    dropout=(keep_prob if is_train else None),\n-    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n-    return_last=False,\n-    return_seq_2d=True,\n-    name='dynamicrnn')\n-net = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o\")\n-\n-net.print_layers()\n-net.print_params(False)\n-\n-shape = rnn.outputs.get_shape().as_list()\n-if shape[-1] != embedding_size:\n-    raise Exception(\"shape do not match\")\n-\n-shape = net.outputs.get_shape().as_list()\n-if shape[-1] != vocab_size:\n-    raise Exception(\"shape do not match\")\n-\n-if len(net.all_layers) != 3:\n-    raise Exception(\"layers do not match\")\n-\n-if len(net.all_params) != 5:\n-    raise Exception(\"params do not match\")\n-\n-if net.count_params() != 4510:\n-    raise Exception(\"params do not match\")\n-\n-# n_layer=3\n-nin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=vocab_size, embedding_size=embedding_size, name='seq_embedding2')\n-rnn = tl.layers.DynamicRNNLayer(\n-    nin,\n-    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n-    n_hidden=embedding_size,\n-    dropout=(keep_prob if is_train else None),\n-    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n-    n_layer=3,\n-    return_last=False,\n-    return_seq_2d=True,\n-    name='dynamicrnn2')\n-net = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o2\")\n-\n-shape = rnn.outputs.get_shape().as_list()\n-if (shape[-1] != embedding_size) or (len(shape) != 2):\n-    raise Exception(\"shape do not match\")\n-\n-net = tl.layers.DynamicRNNLayer(\n-    nin,\n-    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n-    n_hidden=embedding_size,\n-    dropout=None,\n-    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n-    n_layer=3,\n-    return_last=False,\n-    return_seq_2d=False,\n-    name='dynamicrnn3')\n-# net = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o3\")\n-\n-net.print_layers()\n-net.print_params(False)\n-\n-shape = net.outputs.get_shape().as_list()\n-if (shape[-1] != embedding_size) or (len(shape) != 3):\n-    raise Exception(\"shape do not match\")\n-\n-net = tl.layers.DynamicRNNLayer(\n-    nin,\n-    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n-    n_hidden=embedding_size,\n-    dropout=None,\n-    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n-    n_layer=1,\n-    return_last=True,\n-    return_seq_2d=False,\n-    name='dynamicrnn4')\n-net.print_layers()\n-net.print_params(False)\n-shape = net.outputs.get_shape().as_list()\n-if (shape[-1] != embedding_size) or (len(shape) != 2):\n-    raise Exception(\"shape do not match\")\n-\n-net = tl.layers.DynamicRNNLayer(\n-    nin,\n-    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n-    n_hidden=embedding_size,\n-    dropout=None,\n-    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n-    n_layer=1,\n-    return_last=True,\n-    return_seq_2d=True,\n-    name='dynamicrnn5')\n-net.print_layers()\n-net.print_params(False)\n-shape = net.outputs.get_shape().as_list()\n-if (shape[-1] != embedding_size) or (len(shape) != 2):\n-    raise Exception(\"shape do not match\")\n-\n-## BiDynamic Synced input and output\n-rnn = tl.layers.BiDynamicRNNLayer(\n-    nin,\n-    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n-    n_hidden=embedding_size,\n-    dropout=(keep_prob if is_train else None),\n-    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n-    return_last=False,\n-    return_seq_2d=True,\n-    name='bidynamicrnn')\n-net = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o4\")\n-\n-net.print_layers()\n-net.print_params(False)\n-\n-shape = rnn.outputs.get_shape().as_list()\n-if shape[-1] != embedding_size * 2:\n-    raise Exception(\"shape do not match\")\n-\n-shape = net.outputs.get_shape().as_list()\n-if shape[-1] != vocab_size:\n-    raise Exception(\"shape do not match\")\n-\n-if len(net.all_layers) != 3:\n-    raise Exception(\"layers do not match\")\n-\n-if len(net.all_params) != 7:\n-    raise Exception(\"params do not match\")\n-\n-if net.count_params() != 8390:\n-    raise Exception(\"params do not match\")\n-\n-# n_layer=2\n-rnn = tl.layers.BiDynamicRNNLayer(\n-    nin,\n-    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n-    n_hidden=embedding_size,\n-    dropout=(keep_prob if is_train else None),\n-    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n-    n_layer=2,\n-    return_last=False,\n-    return_seq_2d=True,\n-    name='bidynamicrnn2')\n-net = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o5\")\n-\n-net.print_layers()\n-net.print_params(False)\n-\n-shape = rnn.outputs.get_shape().as_list()\n-if shape[-1] != embedding_size * 2:\n-    raise Exception(\"shape do not match\")\n-\n-shape = net.outputs.get_shape().as_list()\n-if shape[-1] != vocab_size:\n-    raise Exception(\"shape do not match\")\n-\n-if len(net.all_layers) != 3:\n-    raise Exception(\"layers do not match\")\n-\n-if len(net.all_params) != 11:\n-    raise Exception(\"params do not match\")\n-\n-if net.count_params() != 18150:\n-    raise Exception(\"params do not match\")\n-\n-## Seq2Seq\n-from tensorlayer.layers import EmbeddingInputlayer, Seq2Seq, retrieve_seq_length_op2, DenseLayer\n-batch_size = 32\n-encode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"encode_seqs\")\n-decode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"decode_seqs\")\n-target_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_seqs\")\n-target_mask = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_mask\")  # tl.prepro.sequences_get_mask()\n-with tf.variable_scope(\"model\"):\n-    # for chatbot, you can use the same embedding layer,\n-    # for translation, you may want to use 2 seperated embedding layers\n-    with tf.variable_scope(\"embedding\") as vs:\n-        net_encode = EmbeddingInputlayer(inputs=encode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n-        vs.reuse_variables()\n-        # tl.layers.set_name_reuse(True)\n-        net_decode = EmbeddingInputlayer(inputs=decode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n-    net = Seq2Seq(\n-        net_encode,\n-        net_decode,\n-        cell_fn=tf.contrib.rnn.BasicLSTMCell,\n-        n_hidden=200,\n-        initializer=tf.random_uniform_initializer(-0.1, 0.1),\n-        encode_sequence_length=retrieve_seq_length_op2(encode_seqs),\n-        decode_sequence_length=retrieve_seq_length_op2(decode_seqs),\n-        initial_state_encode=None,\n-        dropout=None,\n-        n_layer=2,\n-        return_seq_2d=True,\n-        name='Seq2seq')\n-net = DenseLayer(net, n_units=10000, act=tf.identity, name='oo')\n-e_loss = tl.cost.cross_entropy_seq_with_mask(logits=net.outputs, target_seqs=target_seqs, input_mask=target_mask, return_details=False, name='cost')\n-y = tf.nn.softmax(net.outputs)\n-\n-net.print_layers()\n-net.print_params(False)\n-\n-shape = net.outputs.get_shape().as_list()\n-if shape[-1] != 10000:\n-    raise Exception(\"shape do not match\")\n-\n-if len(net.all_layers) != 5:\n-    raise Exception(\"layers do not match\")\n-\n-if len(net.all_params) != 11:\n-    raise Exception(\"params do not match\")\n-\n-if net.count_params() != 5293200:\n-    raise Exception(\"params do not match\")\n+\n+class Layer_Recurrent_Test(unittest.TestCase):\n+    @classmethod\n+    def setUpClass(cls):\n+\n+        cls.net1_batch_size = 32\n+        cls.net2_batch_size = 10\n+        cls.net3_batch_size = 10\n+        cls.net5_batch_size = 32\n+        cls.net11_batch_size = 32\n+\n+        cls.vocab_size = 30\n+        cls.hidden_size = 20\n+        cls.image_size = 100\n+        cls.embedding_size = 20\n+\n+        cls.num_steps = 5\n+\n+        cls.keep_prob = 0.8\n+        cls.is_train = True\n+\n+        # =============================== RNN encoder ===============================\n+\n+        input_data = tf.placeholder(tf.int32, [cls.net1_batch_size, cls.num_steps])\n+\n+        net1 = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=cls.vocab_size, embedding_size=cls.hidden_size, name='embed')\n+        net1 = tl.layers.DropoutLayer(net1, keep=cls.keep_prob, is_fix=True, is_train=cls.is_train, name='drop1')\n+        net1 = tl.layers.RNNLayer(net1, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=cls.hidden_size, n_steps=cls.num_steps, return_last=False, name='lstm1')\n+\n+        # lstm1 = net1\n+\n+        net1 = tl.layers.DropoutLayer(net1, keep=cls.keep_prob, is_fix=True, is_train=cls.is_train, name='drop2')\n+        net1 = tl.layers.RNNLayer(net1, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=cls.hidden_size, n_steps=cls.num_steps, return_last=True, name='lstm2')\n+\n+        # lstm2 = net1\n+\n+        net1 = tl.layers.DropoutLayer(net1, keep=cls.keep_prob, is_fix=True, is_train=cls.is_train, name='drop3')\n+        net1 = tl.layers.DenseLayer(net1, n_units=cls.vocab_size, name='output')\n+\n+        net1.print_layers()\n+        net1.print_params(False)\n+\n+        cls.net1_shape = net1.outputs.get_shape().as_list()\n+        cls.net1_layers = net1.all_layers\n+        cls.net1_params = net1.all_params\n+        cls.net1_n_params = net1.count_params()\n+\n+        # =============================== CNN+RNN encoder ===============================\n+\n+        x2 = tf.placeholder(tf.float32, shape=[cls.net2_batch_size, cls.image_size, cls.image_size, 1])\n+        net2 = tl.layers.InputLayer(x2, name='in')\n+\n+        net2 = tl.layers.Conv2d(net2, n_filter=32, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn1')\n+        net2 = tl.layers.MaxPool2d(net2, filter_size=(2, 2), strides=(2, 2), name='pool1')\n+        net2 = tl.layers.Conv2d(net2, n_filter=10, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn2')\n+        net2 = tl.layers.MaxPool2d(net2, filter_size=(2, 2), strides=(2, 2), name='pool2')\n+\n+        net2 = tl.layers.FlattenLayer(net2, name='flatten')\n+        net2 = tl.layers.ReshapeLayer(net2, shape=(-1, cls.num_steps, int(net2.outputs._shape[-1])))\n+\n+        rnn = tl.layers.RNNLayer(\n+            net2, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=200, n_steps=cls.num_steps, return_last=False, return_seq_2d=True, name='rnn')\n+\n+        net2 = tl.layers.DenseLayer(rnn, n_units=3, name='out')\n+\n+        net2.print_layers()\n+        net2.print_params(False)\n+\n+        cls.net2_shape = net2.outputs.get_shape().as_list()\n+        cls.net2_layers = net2.all_layers\n+        cls.net2_params = net2.all_params\n+        cls.net2_n_params = net2.count_params()\n+\n+        # =============================== Bidirectional Synced input and output ===============================\n+\n+        x3 = tf.placeholder(tf.int32, [cls.net3_batch_size, cls.num_steps])\n+\n+        net3 = tl.layers.EmbeddingInputlayer(inputs=x3, vocabulary_size=cls.vocab_size, embedding_size=cls.hidden_size, name='emb')\n+        net3 = tl.layers.BiRNNLayer(\n+            net3, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=cls.hidden_size, n_steps=cls.num_steps, return_last=False, return_seq_2d=False, name='birnn')\n+\n+        net3.print_layers()\n+        net3.print_params(False)\n+\n+        cls.net3_shape = net3.outputs.get_shape().as_list()\n+        cls.net3_layers = net3.all_layers\n+        cls.net3_params = net3.all_params\n+        cls.net3_n_params = net3.count_params()\n+\n+        # n_layer=2\n+        net4 = tl.layers.EmbeddingInputlayer(inputs=x3, vocabulary_size=cls.vocab_size, embedding_size=cls.hidden_size, name='emb2')\n+        net4 = tl.layers.BiRNNLayer(\n+            net4,\n+            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n+            n_hidden=cls.hidden_size,\n+            n_steps=cls.num_steps,\n+            n_layer=2,\n+            return_last=False,\n+            return_seq_2d=False,\n+            name='birnn2')\n+\n+        net4.print_layers()\n+        net4.print_params(False)\n+\n+        cls.net4_shape = net4.outputs.get_shape().as_list()\n+        cls.net4_layers = net4.all_layers\n+        cls.net4_params = net4.all_params\n+        cls.net4_n_params = net4.count_params()\n+\n+        ## TODO: ConvLSTMLayer\n+        # image_size = 100\n+        # batch_size = 10\n+        # num_steps = 5\n+        # x = tf.placeholder(tf.float32, shape=[batch_size, num_steps, image_size, image_size, 3])\n+        # net = tl.layers.InputLayer(x, name='in2')\n+        # net = tl.layers.ConvLSTMLayer(net,\n+        #             feature_map=1,\n+        #             filter_size=(3, 3),\n+        #             cell_fn=tl.layers.BasicConvLSTMCell,\n+        #             initializer=tf.random_uniform_initializer(-0.1, 0.1),\n+        #             n_steps=num_steps,\n+        #             initial_state=None,\n+        #             return_last=False,\n+        #             return_seq_2d=False,\n+        #             name='convlstm')\n+\n+        # =============================== Dynamic Synced input and output ===============================\n+\n+        input_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net5_batch_size, None], name=\"input\")\n+        nin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=cls.vocab_size, embedding_size=cls.embedding_size, name='seq_embedding')\n+\n+        rnn = tl.layers.DynamicRNNLayer(\n+            nin,\n+            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n+            n_hidden=cls.embedding_size,\n+            dropout=(cls.keep_prob if cls.is_train else None),\n+            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n+            return_last=False,\n+            return_seq_2d=True,\n+            name='dynamicrnn')\n+\n+        net5 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o\")\n+\n+        net5.print_layers()\n+        net5.print_params(False)\n+\n+        cls.net5_shape = net5.outputs.get_shape().as_list()\n+        cls.net5_rnn_shape = rnn.outputs.get_shape().as_list()\n+        cls.net5_layers = net5.all_layers\n+        cls.net5_params = net5.all_params\n+        cls.net5_n_params = net5.count_params()\n+\n+        # n_layer=3\n+        nin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=cls.vocab_size, embedding_size=cls.embedding_size, name='seq_embedding2')\n+        rnn = tl.layers.DynamicRNNLayer(\n+            nin,\n+            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n+            n_hidden=cls.embedding_size,\n+            dropout=(cls.keep_prob if cls.is_train else None),\n+            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n+            n_layer=3,\n+            return_last=False,\n+            return_seq_2d=True,\n+            name='dynamicrnn2')\n+\n+        # net6 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o2\")\n+\n+        net6 = tl.layers.DynamicRNNLayer(\n+            nin,\n+            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n+            n_hidden=cls.embedding_size,\n+            dropout=None,\n+            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n+            n_layer=3,\n+            return_last=False,\n+            return_seq_2d=False,\n+            name='dynamicrnn3')\n+\n+        # net6 = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o3\")\n+\n+        net6.print_layers()\n+        net6.print_params(False)\n+\n+        cls.net6_shape = net6.outputs.get_shape().as_list()\n+        cls.net6_rnn_shape = rnn.outputs.get_shape().as_list()\n+\n+        net7 = tl.layers.DynamicRNNLayer(\n+            nin,\n+            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n+            n_hidden=cls.embedding_size,\n+            dropout=None,\n+            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n+            n_layer=1,\n+            return_last=True,\n+            return_seq_2d=False,\n+            name='dynamicrnn4')\n+\n+        net7.print_layers()\n+        net7.print_params(False)\n+\n+        cls.net7_shape = net7.outputs.get_shape().as_list()\n+\n+        net8 = tl.layers.DynamicRNNLayer(\n+            nin,\n+            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n+            n_hidden=cls.embedding_size,\n+            dropout=None,\n+            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n+            n_layer=1,\n+            return_last=True,\n+            return_seq_2d=True,\n+            name='dynamicrnn5')\n+\n+        net8.print_layers()\n+        net8.print_params(False)\n+\n+        cls.net8_shape = net8.outputs.get_shape().as_list()\n+\n+        # =============================== BiDynamic Synced input and output ===============================\n+\n+        rnn = tl.layers.BiDynamicRNNLayer(\n+            nin,\n+            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n+            n_hidden=cls.embedding_size,\n+            dropout=(cls.keep_prob if cls.is_train else None),\n+            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n+            return_last=False,\n+            return_seq_2d=True,\n+            name='bidynamicrnn')\n+\n+        net9 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o4\")\n+\n+        net9.print_layers()\n+        net9.print_params(False)\n+\n+        cls.net9_shape = net9.outputs.get_shape().as_list()\n+        cls.net9_rnn_shape = rnn.outputs.get_shape().as_list()\n+        cls.net9_layers = net9.all_layers\n+        cls.net9_params = net9.all_params\n+        cls.net9_n_params = net9.count_params()\n+\n+        # n_layer=2\n+        rnn = tl.layers.BiDynamicRNNLayer(\n+            nin,\n+            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n+            n_hidden=cls.embedding_size,\n+            dropout=(cls.keep_prob if cls.is_train else None),\n+            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n+            n_layer=2,\n+            return_last=False,\n+            return_seq_2d=True,\n+            name='bidynamicrnn2')\n+\n+        net10 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o5\")\n+\n+        net10.print_layers()\n+        net10.print_params(False)\n+\n+        cls.net10_shape = net10.outputs.get_shape().as_list()\n+        cls.net10_rnn_shape = rnn.outputs.get_shape().as_list()\n+        cls.net10_layers = net10.all_layers\n+        cls.net10_params = net10.all_params\n+        cls.net10_n_params = net10.count_params()\n+\n+        # =============================== Seq2Seq ===============================\n+\n+        encode_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"encode_seqs\")\n+        decode_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"decode_seqs\")\n+        # target_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"target_seqs\")\n+        # target_mask = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"target_mask\")  # tl.prepro.sequences_get_mask()\n+\n+        with tf.variable_scope(\"model\"):\n+            # for chatbot, you can use the same embedding layer,\n+            # for translation, you may want to use 2 seperated embedding layers\n+\n+            with tf.variable_scope(\"embedding\") as vs:\n+                net_encode = tl.layers.EmbeddingInputlayer(inputs=encode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n+                vs.reuse_variables()\n+                # tl.layers.set_name_reuse(True)\n+                net_decode = tl.layers.EmbeddingInputlayer(inputs=decode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n+\n+            net11 = tl.layers.Seq2Seq(\n+                net_encode,\n+                net_decode,\n+                cell_fn=tf.contrib.rnn.BasicLSTMCell,\n+                n_hidden=200,\n+                initializer=tf.random_uniform_initializer(-0.1, 0.1),\n+                encode_sequence_length=tl.layers.retrieve_seq_length_op2(encode_seqs),\n+                decode_sequence_length=tl.layers.retrieve_seq_length_op2(decode_seqs),\n+                initial_state_encode=None,\n+                dropout=None,\n+                n_layer=2,\n+                return_seq_2d=True,\n+                name='Seq2seq')\n+\n+        net11 = tl.layers.DenseLayer(net11, n_units=10000, act=tf.identity, name='oo')\n+\n+        # e_loss = tl.cost.cross_entropy_seq_with_mask(logits=net11.outputs, target_seqs=target_seqs, input_mask=target_mask, return_details=False, name='cost')\n+        # y = tf.nn.softmax(net11.outputs)\n+\n+        net11.print_layers()\n+        net11.print_params(False)\n+\n+        cls.net11_shape = net11.outputs.get_shape().as_list()\n+        cls.net11_layers = net11.all_layers\n+        cls.net11_params = net11.all_params\n+        cls.net11_n_params = net11.count_params()\n+\n+    @classmethod\n+    def tearDownClass(cls):\n+        tf.reset_default_graph()\n+\n+    def test_net1(self):\n+        self.assertEqual(self.net1_shape, [self.net1_batch_size, self.vocab_size])\n+        self.assertEqual(len(self.net1_layers), 7)\n+        self.assertEqual(len(self.net1_params), 7)\n+        self.assertEqual(self.net1_n_params, 7790)\n+\n+    def test_net2(self):\n+        self.assertEqual(self.net2_shape, [self.net2_batch_size, 3])\n+        self.assertEqual(len(self.net2_layers), 8)\n+        self.assertEqual(len(self.net2_params), 8)\n+        self.assertEqual(self.net2_n_params, 562245)\n+\n+    def test_net3(self):\n+        self.assertEqual(self.net3_shape[1:3], [self.num_steps, self.hidden_size * 2])\n+        self.assertEqual(len(self.net3_layers), 2)\n+        self.assertEqual(len(self.net3_params), 5)\n+        self.assertEqual(self.net3_n_params, 7160)\n+\n+    def test_net4(self):\n+        self.assertEqual(self.net4_shape[1:3], [self.num_steps, self.hidden_size * 2])\n+        self.assertEqual(len(self.net4_layers), 2)\n+        self.assertEqual(len(self.net4_params), 9)\n+        self.assertEqual(self.net4_n_params, 13720)\n+\n+    def test_net5(self):\n+        self.assertEqual(self.net5_shape[-1], self.vocab_size)\n+        self.assertEqual(self.net5_rnn_shape[-1], self.embedding_size)\n+        self.assertEqual(len(self.net5_layers), 3)\n+        self.assertEqual(len(self.net5_params), 5)\n+        self.assertEqual(self.net5_n_params, 4510)\n+\n+    def test_net6(self):\n+        self.assertEqual(self.net6_shape[-1], self.embedding_size)\n+        self.assertEqual(self.net6_rnn_shape[-1], self.embedding_size)\n+\n+    def test_net7(self):\n+        self.assertEqual(self.net7_shape[-1], self.embedding_size)\n+\n+    def test_net8(self):\n+        self.assertEqual(self.net8_shape[-1], self.embedding_size)\n+\n+    def test_net9(self):\n+        self.assertEqual(self.net9_shape[-1], self.vocab_size)\n+        self.assertEqual(self.net9_rnn_shape[-1], self.embedding_size * 2)\n+        self.assertEqual(len(self.net9_layers), 3)\n+        self.assertEqual(len(self.net9_params), 7)\n+        self.assertEqual(self.net9_n_params, 8390)\n+\n+    def test_net10(self):\n+        self.assertEqual(self.net10_shape[-1], self.vocab_size)\n+        self.assertEqual(self.net10_rnn_shape[-1], self.embedding_size * 2)\n+        self.assertEqual(len(self.net10_layers), 3)\n+        self.assertEqual(len(self.net10_params), 11)\n+        self.assertEqual(self.net10_n_params, 18150)\n+\n+    def test_net11(self):\n+        self.assertEqual(self.net11_shape[-1], 10000)\n+        self.assertEqual(len(self.net11_layers), 5)\n+        self.assertEqual(len(self.net11_params), 11)\n+        self.assertEqual(self.net11_n_params, 5293200)\n+\n+\n+if __name__ == '__main__':\n+\n+    # tf.logging.set_verbosity(tf.logging.INFO)\n+    tf.logging.set_verbosity(tf.logging.DEBUG)\n+\n+    unittest.main()\n",
        "source_code_with_indent": "\n## RNN encoder ====================================================\nbatch_size = 32\nnum_steps = 5\nvocab_size = 30\nhidden_size = 20\nkeep_prob = 0.8\nis_train = True\ninput_data = tf.placeholder(tf.int32, [batch_size, num_steps])\nnet = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=vocab_size, embedding_size=hidden_size, name='embed')\nnet = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_train, name='drop1')\nnet = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, return_last=False, name='lstm1')\nlstm1 = net\nnet = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_train, name='drop2')\nnet = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, return_last=True, name='lstm2')\nlstm2 = net\nnet = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_train, name='drop3')\nnet = tl.layers.DenseLayer(net, n_units=vocab_size, name='output')\n\nnet.print_layers()\nnet.print_params(False)\n\nif len(net.all_layers) != 7:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 7:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 7790:\n    <IND>raise Exception(\"params do not match\")\n\n## CNN+RNN encoder ====================================================\n<DED>image_size = 100\nbatch_size = 10\nnum_steps = 5\n\nx = tf.placeholder(tf.float32, shape=[batch_size, image_size, image_size, 1])\nnet = tl.layers.InputLayer(x, name='in')\nnet = tl.layers.Conv2d(net, n_filter=32, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn1')\nnet = tl.layers.MaxPool2d(net, filter_size=(2, 2), strides=(2, 2), name='pool1')\nnet = tl.layers.Conv2d(net, n_filter=10, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn2')\nnet = tl.layers.MaxPool2d(net, filter_size=(2, 2), strides=(2, 2), name='pool2')\nnet = tl.layers.FlattenLayer(net, name='flatten')\nnet = tl.layers.ReshapeLayer(net, shape=(-1, num_steps, int(net.outputs._shape[-1])))\nrnn = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=200, n_steps=num_steps, return_last=False, return_seq_2d=True, name='rnn')\nnet = tl.layers.DenseLayer(rnn, n_units=3, name='out')\n\nnet.print_layers()\nnet.print_params(False)\n\nif len(net.all_layers) != 8:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 8:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 562245:\n    <IND>raise Exception(\"params do not match\")\n\n## Bidirectional Synced input and output\n<DED>batch_size = 10\nnum_steps = 5\nvocab_size = 30\nhidden_size = 20\ninput_data = tf.placeholder(tf.int32, [batch_size, num_steps])\nnet = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=vocab_size, embedding_size=hidden_size, name='emb')\nnet = tl.layers.BiRNNLayer(\n    net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, return_last=False, return_seq_2d=False, name='birnn')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[1:3] != [num_steps, hidden_size * 2]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 2:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 5:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 7160:\n    <IND>raise Exception(\"params do not match\")\n\n# n_layer=2\n<DED>net = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=vocab_size, embedding_size=hidden_size, name='emb2')\nnet = tl.layers.BiRNNLayer(\n    net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, n_layer=2, return_last=False, return_seq_2d=False, name='birnn2')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[1:3] != [num_steps, hidden_size * 2]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 2:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 9:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 13720:\n    <IND>raise Exception(\"params do not match\")\n\n## ConvLSTMLayer TODO\n# image_size = 100\n# batch_size = 10\n# num_steps = 5\n# x = tf.placeholder(tf.float32, shape=[batch_size, num_steps, image_size, image_size, 3])\n# net = tl.layers.InputLayer(x, name='in2')\n# net = tl.layers.ConvLSTMLayer(net,\n#             feature_map=1,\n#             filter_size=(3, 3),\n#             cell_fn=tl.layers.BasicConvLSTMCell,\n#             initializer=tf.random_uniform_initializer(-0.1, 0.1),\n#             n_steps=num_steps,\n#             initial_state=None,\n#             return_last=False,\n#             return_seq_2d=False,\n#             name='convlstm')\n\n## Dynamic Synced input and output\n<DED>batch_size = 32\nnum_steps = 5\nvocab_size = 30\nembedding_size = 20\nkeep_prob = 0.8\nis_train = True\ninput_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"input\")\nnin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=vocab_size, embedding_size=embedding_size, name='seq_embedding')\nrnn = tl.layers.DynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=(keep_prob if is_train else None),\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    return_last=False,\n    return_seq_2d=True,\n    name='dynamicrnn')\nnet = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o\")\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = rnn.outputs.get_shape().as_list()\nif shape[-1] != embedding_size:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>shape = net.outputs.get_shape().as_list()\nif shape[-1] != vocab_size:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 3:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 5:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 4510:\n    <IND>raise Exception(\"params do not match\")\n\n# n_layer=3\n<DED>nin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=vocab_size, embedding_size=embedding_size, name='seq_embedding2')\nrnn = tl.layers.DynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=(keep_prob if is_train else None),\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    n_layer=3,\n    return_last=False,\n    return_seq_2d=True,\n    name='dynamicrnn2')\nnet = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o2\")\n\nshape = rnn.outputs.get_shape().as_list()\nif (shape[-1] != embedding_size) or (len(shape) != 2):\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>net = tl.layers.DynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=None,\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    n_layer=3,\n    return_last=False,\n    return_seq_2d=False,\n    name='dynamicrnn3')\n# net = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o3\")\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif (shape[-1] != embedding_size) or (len(shape) != 3):\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>net = tl.layers.DynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=None,\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    n_layer=1,\n    return_last=True,\n    return_seq_2d=False,\n    name='dynamicrnn4')\nnet.print_layers()\nnet.print_params(False)\nshape = net.outputs.get_shape().as_list()\nif (shape[-1] != embedding_size) or (len(shape) != 2):\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>net = tl.layers.DynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=None,\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    n_layer=1,\n    return_last=True,\n    return_seq_2d=True,\n    name='dynamicrnn5')\nnet.print_layers()\nnet.print_params(False)\nshape = net.outputs.get_shape().as_list()\nif (shape[-1] != embedding_size) or (len(shape) != 2):\n    <IND>raise Exception(\"shape do not match\")\n\n## BiDynamic Synced input and output\n<DED>rnn = tl.layers.BiDynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=(keep_prob if is_train else None),\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    return_last=False,\n    return_seq_2d=True,\n    name='bidynamicrnn')\nnet = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o4\")\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = rnn.outputs.get_shape().as_list()\nif shape[-1] != embedding_size * 2:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>shape = net.outputs.get_shape().as_list()\nif shape[-1] != vocab_size:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 3:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 7:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 8390:\n    <IND>raise Exception(\"params do not match\")\n\n# n_layer=2\n<DED>rnn = tl.layers.BiDynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=(keep_prob if is_train else None),\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    n_layer=2,\n    return_last=False,\n    return_seq_2d=True,\n    name='bidynamicrnn2')\nnet = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o5\")\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = rnn.outputs.get_shape().as_list()\nif shape[-1] != embedding_size * 2:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>shape = net.outputs.get_shape().as_list()\nif shape[-1] != vocab_size:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 3:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 11:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 18150:\n    <IND>raise Exception(\"params do not match\")\n\n## Seq2Seq\n<DED>from tensorlayer.layers import EmbeddingInputlayer, Seq2Seq, retrieve_seq_length_op2, DenseLayer\nbatch_size = 32\nencode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"encode_seqs\")\ndecode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"decode_seqs\")\ntarget_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_seqs\")\ntarget_mask = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_mask\")  # tl.prepro.sequences_get_mask()\nwith tf.variable_scope(\"model\"):\n    # for chatbot, you can use the same embedding layer,\n    # for translation, you may want to use 2 seperated embedding layers\n    <IND>with tf.variable_scope(\"embedding\") as vs:\n        <IND>net_encode = EmbeddingInputlayer(inputs=encode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n        vs.reuse_variables()\n        # tl.layers.set_name_reuse(True)\n        net_decode = EmbeddingInputlayer(inputs=decode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n    <DED>net = Seq2Seq(\n        net_encode,\n        net_decode,\n        cell_fn=tf.contrib.rnn.BasicLSTMCell,\n        n_hidden=200,\n        initializer=tf.random_uniform_initializer(-0.1, 0.1),\n        encode_sequence_length=retrieve_seq_length_op2(encode_seqs),\n        decode_sequence_length=retrieve_seq_length_op2(decode_seqs),\n        initial_state_encode=None,\n        dropout=None,\n        n_layer=2,\n        return_seq_2d=True,\n        name='Seq2seq')\n<DED>net = DenseLayer(net, n_units=10000, act=tf.identity, name='oo')\ne_loss = tl.cost.cross_entropy_seq_with_mask(logits=net.outputs, target_seqs=target_seqs, input_mask=target_mask, return_details=False, name='cost')\ny = tf.nn.softmax(net.outputs)\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 10000:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 5:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 11:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 5293200:\n    <IND>raise Exception(\"params do not match\")\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n\nclass Layer_Recurrent_Test(unittest.TestCase):\n    <IND>@classmethod\n    def setUpClass(cls):\n\n        <IND>cls.net1_batch_size = 32\n        cls.net2_batch_size = 10\n        cls.net3_batch_size = 10\n        cls.net5_batch_size = 32\n        cls.net11_batch_size = 32\n\n        cls.vocab_size = 30\n        cls.hidden_size = 20\n        cls.image_size = 100\n        cls.embedding_size = 20\n\n        cls.num_steps = 5\n\n        cls.keep_prob = 0.8\n        cls.is_train = True\n\n        # =============================== RNN encoder ===============================\n\n        input_data = tf.placeholder(tf.int32, [cls.net1_batch_size, cls.num_steps])\n\n        net1 = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=cls.vocab_size, embedding_size=cls.hidden_size, name='embed')\n        net1 = tl.layers.DropoutLayer(net1, keep=cls.keep_prob, is_fix=True, is_train=cls.is_train, name='drop1')\n        net1 = tl.layers.RNNLayer(net1, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=cls.hidden_size, n_steps=cls.num_steps, return_last=False, name='lstm1')\n\n        # lstm1 = net1\n\n        net1 = tl.layers.DropoutLayer(net1, keep=cls.keep_prob, is_fix=True, is_train=cls.is_train, name='drop2')\n        net1 = tl.layers.RNNLayer(net1, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=cls.hidden_size, n_steps=cls.num_steps, return_last=True, name='lstm2')\n\n        # lstm2 = net1\n\n        net1 = tl.layers.DropoutLayer(net1, keep=cls.keep_prob, is_fix=True, is_train=cls.is_train, name='drop3')\n        net1 = tl.layers.DenseLayer(net1, n_units=cls.vocab_size, name='output')\n\n        net1.print_layers()\n        net1.print_params(False)\n\n        cls.net1_shape = net1.outputs.get_shape().as_list()\n        cls.net1_layers = net1.all_layers\n        cls.net1_params = net1.all_params\n        cls.net1_n_params = net1.count_params()\n\n        # =============================== CNN+RNN encoder ===============================\n\n        x2 = tf.placeholder(tf.float32, shape=[cls.net2_batch_size, cls.image_size, cls.image_size, 1])\n        net2 = tl.layers.InputLayer(x2, name='in')\n\n        net2 = tl.layers.Conv2d(net2, n_filter=32, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn1')\n        net2 = tl.layers.MaxPool2d(net2, filter_size=(2, 2), strides=(2, 2), name='pool1')\n        net2 = tl.layers.Conv2d(net2, n_filter=10, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn2')\n        net2 = tl.layers.MaxPool2d(net2, filter_size=(2, 2), strides=(2, 2), name='pool2')\n\n        net2 = tl.layers.FlattenLayer(net2, name='flatten')\n        net2 = tl.layers.ReshapeLayer(net2, shape=(-1, cls.num_steps, int(net2.outputs._shape[-1])))\n\n        rnn = tl.layers.RNNLayer(\n            net2, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=200, n_steps=cls.num_steps, return_last=False, return_seq_2d=True, name='rnn')\n\n        net2 = tl.layers.DenseLayer(rnn, n_units=3, name='out')\n\n        net2.print_layers()\n        net2.print_params(False)\n\n        cls.net2_shape = net2.outputs.get_shape().as_list()\n        cls.net2_layers = net2.all_layers\n        cls.net2_params = net2.all_params\n        cls.net2_n_params = net2.count_params()\n\n        # =============================== Bidirectional Synced input and output ===============================\n\n        x3 = tf.placeholder(tf.int32, [cls.net3_batch_size, cls.num_steps])\n\n        net3 = tl.layers.EmbeddingInputlayer(inputs=x3, vocabulary_size=cls.vocab_size, embedding_size=cls.hidden_size, name='emb')\n        net3 = tl.layers.BiRNNLayer(\n            net3, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=cls.hidden_size, n_steps=cls.num_steps, return_last=False, return_seq_2d=False, name='birnn')\n\n        net3.print_layers()\n        net3.print_params(False)\n\n        cls.net3_shape = net3.outputs.get_shape().as_list()\n        cls.net3_layers = net3.all_layers\n        cls.net3_params = net3.all_params\n        cls.net3_n_params = net3.count_params()\n\n        # n_layer=2\n        net4 = tl.layers.EmbeddingInputlayer(inputs=x3, vocabulary_size=cls.vocab_size, embedding_size=cls.hidden_size, name='emb2')\n        net4 = tl.layers.BiRNNLayer(\n            net4,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.hidden_size,\n            n_steps=cls.num_steps,\n            n_layer=2,\n            return_last=False,\n            return_seq_2d=False,\n            name='birnn2')\n\n        net4.print_layers()\n        net4.print_params(False)\n\n        cls.net4_shape = net4.outputs.get_shape().as_list()\n        cls.net4_layers = net4.all_layers\n        cls.net4_params = net4.all_params\n        cls.net4_n_params = net4.count_params()\n\n        ## TODO: ConvLSTMLayer\n        # image_size = 100\n        # batch_size = 10\n        # num_steps = 5\n        # x = tf.placeholder(tf.float32, shape=[batch_size, num_steps, image_size, image_size, 3])\n        # net = tl.layers.InputLayer(x, name='in2')\n        # net = tl.layers.ConvLSTMLayer(net,\n        #             feature_map=1,\n        #             filter_size=(3, 3),\n        #             cell_fn=tl.layers.BasicConvLSTMCell,\n        #             initializer=tf.random_uniform_initializer(-0.1, 0.1),\n        #             n_steps=num_steps,\n        #             initial_state=None,\n        #             return_last=False,\n        #             return_seq_2d=False,\n        #             name='convlstm')\n\n        # =============================== Dynamic Synced input and output ===============================\n\n        input_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net5_batch_size, None], name=\"input\")\n        nin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=cls.vocab_size, embedding_size=cls.embedding_size, name='seq_embedding')\n\n        rnn = tl.layers.DynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=(cls.keep_prob if cls.is_train else None),\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            return_last=False,\n            return_seq_2d=True,\n            name='dynamicrnn')\n\n        net5 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o\")\n\n        net5.print_layers()\n        net5.print_params(False)\n\n        cls.net5_shape = net5.outputs.get_shape().as_list()\n        cls.net5_rnn_shape = rnn.outputs.get_shape().as_list()\n        cls.net5_layers = net5.all_layers\n        cls.net5_params = net5.all_params\n        cls.net5_n_params = net5.count_params()\n\n        # n_layer=3\n        nin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=cls.vocab_size, embedding_size=cls.embedding_size, name='seq_embedding2')\n        rnn = tl.layers.DynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=(cls.keep_prob if cls.is_train else None),\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            n_layer=3,\n            return_last=False,\n            return_seq_2d=True,\n            name='dynamicrnn2')\n\n        # net6 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o2\")\n\n        net6 = tl.layers.DynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=None,\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            n_layer=3,\n            return_last=False,\n            return_seq_2d=False,\n            name='dynamicrnn3')\n\n        # net6 = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o3\")\n\n        net6.print_layers()\n        net6.print_params(False)\n\n        cls.net6_shape = net6.outputs.get_shape().as_list()\n        cls.net6_rnn_shape = rnn.outputs.get_shape().as_list()\n\n        net7 = tl.layers.DynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=None,\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            n_layer=1,\n            return_last=True,\n            return_seq_2d=False,\n            name='dynamicrnn4')\n\n        net7.print_layers()\n        net7.print_params(False)\n\n        cls.net7_shape = net7.outputs.get_shape().as_list()\n\n        net8 = tl.layers.DynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=None,\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            n_layer=1,\n            return_last=True,\n            return_seq_2d=True,\n            name='dynamicrnn5')\n\n        net8.print_layers()\n        net8.print_params(False)\n\n        cls.net8_shape = net8.outputs.get_shape().as_list()\n\n        # =============================== BiDynamic Synced input and output ===============================\n\n        rnn = tl.layers.BiDynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=(cls.keep_prob if cls.is_train else None),\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            return_last=False,\n            return_seq_2d=True,\n            name='bidynamicrnn')\n\n        net9 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o4\")\n\n        net9.print_layers()\n        net9.print_params(False)\n\n        cls.net9_shape = net9.outputs.get_shape().as_list()\n        cls.net9_rnn_shape = rnn.outputs.get_shape().as_list()\n        cls.net9_layers = net9.all_layers\n        cls.net9_params = net9.all_params\n        cls.net9_n_params = net9.count_params()\n\n        # n_layer=2\n        rnn = tl.layers.BiDynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=(cls.keep_prob if cls.is_train else None),\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            n_layer=2,\n            return_last=False,\n            return_seq_2d=True,\n            name='bidynamicrnn2')\n\n        net10 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o5\")\n\n        net10.print_layers()\n        net10.print_params(False)\n\n        cls.net10_shape = net10.outputs.get_shape().as_list()\n        cls.net10_rnn_shape = rnn.outputs.get_shape().as_list()\n        cls.net10_layers = net10.all_layers\n        cls.net10_params = net10.all_params\n        cls.net10_n_params = net10.count_params()\n\n        # =============================== Seq2Seq ===============================\n\n        encode_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"encode_seqs\")\n        decode_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"decode_seqs\")\n        # target_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"target_seqs\")\n        # target_mask = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"target_mask\")  # tl.prepro.sequences_get_mask()\n\n        with tf.variable_scope(\"model\"):\n            # for chatbot, you can use the same embedding layer,\n            # for translation, you may want to use 2 seperated embedding layers\n\n            <IND>with tf.variable_scope(\"embedding\") as vs:\n                <IND>net_encode = tl.layers.EmbeddingInputlayer(inputs=encode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n                vs.reuse_variables()\n                # tl.layers.set_name_reuse(True)\n                net_decode = tl.layers.EmbeddingInputlayer(inputs=decode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n\n            <DED>net11 = tl.layers.Seq2Seq(\n                net_encode,\n                net_decode,\n                cell_fn=tf.contrib.rnn.BasicLSTMCell,\n                n_hidden=200,\n                initializer=tf.random_uniform_initializer(-0.1, 0.1),\n                encode_sequence_length=tl.layers.retrieve_seq_length_op2(encode_seqs),\n                decode_sequence_length=tl.layers.retrieve_seq_length_op2(decode_seqs),\n                initial_state_encode=None,\n                dropout=None,\n                n_layer=2,\n                return_seq_2d=True,\n                name='Seq2seq')\n\n        <DED>net11 = tl.layers.DenseLayer(net11, n_units=10000, act=tf.identity, name='oo')\n\n        # e_loss = tl.cost.cross_entropy_seq_with_mask(logits=net11.outputs, target_seqs=target_seqs, input_mask=target_mask, return_details=False, name='cost')\n        # y = tf.nn.softmax(net11.outputs)\n\n        net11.print_layers()\n        net11.print_params(False)\n\n        cls.net11_shape = net11.outputs.get_shape().as_list()\n        cls.net11_layers = net11.all_layers\n        cls.net11_params = net11.all_params\n        cls.net11_n_params = net11.count_params()\n\n    <DED>@classmethod\n    def tearDownClass(cls):\n        <IND>tf.reset_default_graph()\n\n    <DED>def test_net1(self):\n        <IND>self.assertEqual(self.net1_shape, [self.net1_batch_size, self.vocab_size])\n        self.assertEqual(len(self.net1_layers), 7)\n        self.assertEqual(len(self.net1_params), 7)\n        self.assertEqual(self.net1_n_params, 7790)\n\n    <DED>def test_net2(self):\n        <IND>self.assertEqual(self.net2_shape, [self.net2_batch_size, 3])\n        self.assertEqual(len(self.net2_layers), 8)\n        self.assertEqual(len(self.net2_params), 8)\n        self.assertEqual(self.net2_n_params, 562245)\n\n    <DED>def test_net3(self):\n        <IND>self.assertEqual(self.net3_shape[1:3], [self.num_steps, self.hidden_size * 2])\n        self.assertEqual(len(self.net3_layers), 2)\n        self.assertEqual(len(self.net3_params), 5)\n        self.assertEqual(self.net3_n_params, 7160)\n\n    <DED>def test_net4(self):\n        <IND>self.assertEqual(self.net4_shape[1:3], [self.num_steps, self.hidden_size * 2])\n        self.assertEqual(len(self.net4_layers), 2)\n        self.assertEqual(len(self.net4_params), 9)\n        self.assertEqual(self.net4_n_params, 13720)\n\n    <DED>def test_net5(self):\n        <IND>self.assertEqual(self.net5_shape[-1], self.vocab_size)\n        self.assertEqual(self.net5_rnn_shape[-1], self.embedding_size)\n        self.assertEqual(len(self.net5_layers), 3)\n        self.assertEqual(len(self.net5_params), 5)\n        self.assertEqual(self.net5_n_params, 4510)\n\n    <DED>def test_net6(self):\n        <IND>self.assertEqual(self.net6_shape[-1], self.embedding_size)\n        self.assertEqual(self.net6_rnn_shape[-1], self.embedding_size)\n\n    <DED>def test_net7(self):\n        <IND>self.assertEqual(self.net7_shape[-1], self.embedding_size)\n\n    <DED>def test_net8(self):\n        <IND>self.assertEqual(self.net8_shape[-1], self.embedding_size)\n\n    <DED>def test_net9(self):\n        <IND>self.assertEqual(self.net9_shape[-1], self.vocab_size)\n        self.assertEqual(self.net9_rnn_shape[-1], self.embedding_size * 2)\n        self.assertEqual(len(self.net9_layers), 3)\n        self.assertEqual(len(self.net9_params), 7)\n        self.assertEqual(self.net9_n_params, 8390)\n\n    <DED>def test_net10(self):\n        <IND>self.assertEqual(self.net10_shape[-1], self.vocab_size)\n        self.assertEqual(self.net10_rnn_shape[-1], self.embedding_size * 2)\n        self.assertEqual(len(self.net10_layers), 3)\n        self.assertEqual(len(self.net10_params), 11)\n        self.assertEqual(self.net10_n_params, 18150)\n\n    <DED>def test_net11(self):\n        <IND>self.assertEqual(self.net11_shape[-1], 10000)\n        self.assertEqual(len(self.net11_layers), 5)\n        self.assertEqual(len(self.net11_params), 11)\n        self.assertEqual(self.net11_n_params, 5293200)\n\n\n<DED><DED>if __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    <IND>tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "tensorlayer/TensorLayer",
    "commit": "6f539ad2324ddccc18b6ac39e4a2f4aeb12173a2",
    "filename": "tests/test_layers_recurrent.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/tensorlayer-TensorLayer/tests/test_layers_recurrent.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "tests/test_layers_recurrent.py:315:4 Incompatible variable type [9]: net is declared to have type `tl.layers.core.EmbeddingInputlayer` but is used as type `tl.layers.recurrent.Seq2Seq`.",
    "message": " net is declared to have type `tl.layers.core.EmbeddingInputlayer` but is used as type `tl.layers.recurrent.Seq2Seq`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 315,
    "warning_line": "    net = Seq2Seq(",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import tensorflow as tf\n",
        "source_code_len": 24,
        "target_code": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_len": 87,
        "diff_format": "@@ -1,1 +1,5 @@\n+#!/usr/bin/env python\n+# -*- coding: utf-8 -*-\n+import unittest\n+\n import tensorflow as tf\n",
        "source_code_with_indent": "import tensorflow as tf\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n## RNN encoder ====================================================\nbatch_size = 32\nnum_steps = 5\nvocab_size = 30\nhidden_size = 20\nkeep_prob = 0.8\nis_train = True\ninput_data = tf.placeholder(tf.int32, [batch_size, num_steps])\nnet = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=vocab_size, embedding_size=hidden_size, name='embed')\nnet = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_train, name='drop1')\nnet = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, return_last=False, name='lstm1')\nlstm1 = net\nnet = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_train, name='drop2')\nnet = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, return_last=True, name='lstm2')\nlstm2 = net\nnet = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_train, name='drop3')\nnet = tl.layers.DenseLayer(net, n_units=vocab_size, name='output')\n\nnet.print_layers()\nnet.print_params(False)\n\nif len(net.all_layers) != 7:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 7:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 7790:\n    raise Exception(\"params do not match\")\n\n## CNN+RNN encoder ====================================================\nimage_size = 100\nbatch_size = 10\nnum_steps = 5\n\nx = tf.placeholder(tf.float32, shape=[batch_size, image_size, image_size, 1])\nnet = tl.layers.InputLayer(x, name='in')\nnet = tl.layers.Conv2d(net, n_filter=32, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn1')\nnet = tl.layers.MaxPool2d(net, filter_size=(2, 2), strides=(2, 2), name='pool1')\nnet = tl.layers.Conv2d(net, n_filter=10, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn2')\nnet = tl.layers.MaxPool2d(net, filter_size=(2, 2), strides=(2, 2), name='pool2')\nnet = tl.layers.FlattenLayer(net, name='flatten')\nnet = tl.layers.ReshapeLayer(net, shape=(-1, num_steps, int(net.outputs._shape[-1])))\nrnn = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=200, n_steps=num_steps, return_last=False, return_seq_2d=True, name='rnn')\nnet = tl.layers.DenseLayer(rnn, n_units=3, name='out')\n\nnet.print_layers()\nnet.print_params(False)\n\nif len(net.all_layers) != 8:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 8:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 562245:\n    raise Exception(\"params do not match\")\n\n## Bidirectional Synced input and output\nbatch_size = 10\nnum_steps = 5\nvocab_size = 30\nhidden_size = 20\ninput_data = tf.placeholder(tf.int32, [batch_size, num_steps])\nnet = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=vocab_size, embedding_size=hidden_size, name='emb')\nnet = tl.layers.BiRNNLayer(\n    net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, return_last=False, return_seq_2d=False, name='birnn')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[1:3] != [num_steps, hidden_size * 2]:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 2:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 5:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 7160:\n    raise Exception(\"params do not match\")\n\n# n_layer=2\nnet = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=vocab_size, embedding_size=hidden_size, name='emb2')\nnet = tl.layers.BiRNNLayer(\n    net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, n_layer=2, return_last=False, return_seq_2d=False, name='birnn2')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[1:3] != [num_steps, hidden_size * 2]:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 2:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 9:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 13720:\n    raise Exception(\"params do not match\")\n\n## ConvLSTMLayer TODO\n# image_size = 100\n# batch_size = 10\n# num_steps = 5\n# x = tf.placeholder(tf.float32, shape=[batch_size, num_steps, image_size, image_size, 3])\n# net = tl.layers.InputLayer(x, name='in2')\n# net = tl.layers.ConvLSTMLayer(net,\n#             feature_map=1,\n#             filter_size=(3, 3),\n#             cell_fn=tl.layers.BasicConvLSTMCell,\n#             initializer=tf.random_uniform_initializer(-0.1, 0.1),\n#             n_steps=num_steps,\n#             initial_state=None,\n#             return_last=False,\n#             return_seq_2d=False,\n#             name='convlstm')\n\n## Dynamic Synced input and output\nbatch_size = 32\nnum_steps = 5\nvocab_size = 30\nembedding_size = 20\nkeep_prob = 0.8\nis_train = True\ninput_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"input\")\nnin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=vocab_size, embedding_size=embedding_size, name='seq_embedding')\nrnn = tl.layers.DynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=(keep_prob if is_train else None),\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    return_last=False,\n    return_seq_2d=True,\n    name='dynamicrnn')\nnet = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o\")\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = rnn.outputs.get_shape().as_list()\nif shape[-1] != embedding_size:\n    raise Exception(\"shape do not match\")\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != vocab_size:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 3:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 5:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 4510:\n    raise Exception(\"params do not match\")\n\n# n_layer=3\nnin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=vocab_size, embedding_size=embedding_size, name='seq_embedding2')\nrnn = tl.layers.DynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=(keep_prob if is_train else None),\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    n_layer=3,\n    return_last=False,\n    return_seq_2d=True,\n    name='dynamicrnn2')\nnet = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o2\")\n\nshape = rnn.outputs.get_shape().as_list()\nif (shape[-1] != embedding_size) or (len(shape) != 2):\n    raise Exception(\"shape do not match\")\n\nnet = tl.layers.DynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=None,\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    n_layer=3,\n    return_last=False,\n    return_seq_2d=False,\n    name='dynamicrnn3')\n# net = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o3\")\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif (shape[-1] != embedding_size) or (len(shape) != 3):\n    raise Exception(\"shape do not match\")\n\nnet = tl.layers.DynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=None,\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    n_layer=1,\n    return_last=True,\n    return_seq_2d=False,\n    name='dynamicrnn4')\nnet.print_layers()\nnet.print_params(False)\nshape = net.outputs.get_shape().as_list()\nif (shape[-1] != embedding_size) or (len(shape) != 2):\n    raise Exception(\"shape do not match\")\n\nnet = tl.layers.DynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=None,\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    n_layer=1,\n    return_last=True,\n    return_seq_2d=True,\n    name='dynamicrnn5')\nnet.print_layers()\nnet.print_params(False)\nshape = net.outputs.get_shape().as_list()\nif (shape[-1] != embedding_size) or (len(shape) != 2):\n    raise Exception(\"shape do not match\")\n\n## BiDynamic Synced input and output\nrnn = tl.layers.BiDynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=(keep_prob if is_train else None),\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    return_last=False,\n    return_seq_2d=True,\n    name='bidynamicrnn')\nnet = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o4\")\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = rnn.outputs.get_shape().as_list()\nif shape[-1] != embedding_size * 2:\n    raise Exception(\"shape do not match\")\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != vocab_size:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 3:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 7:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 8390:\n    raise Exception(\"params do not match\")\n\n# n_layer=2\nrnn = tl.layers.BiDynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=(keep_prob if is_train else None),\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    n_layer=2,\n    return_last=False,\n    return_seq_2d=True,\n    name='bidynamicrnn2')\nnet = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o5\")\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = rnn.outputs.get_shape().as_list()\nif shape[-1] != embedding_size * 2:\n    raise Exception(\"shape do not match\")\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != vocab_size:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 3:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 11:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 18150:\n    raise Exception(\"params do not match\")\n\n## Seq2Seq\nfrom tensorlayer.layers import EmbeddingInputlayer, Seq2Seq, retrieve_seq_length_op2, DenseLayer\nbatch_size = 32\nencode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"encode_seqs\")\ndecode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"decode_seqs\")\ntarget_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_seqs\")\ntarget_mask = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_mask\")  # tl.prepro.sequences_get_mask()\nwith tf.variable_scope(\"model\"):\n    # for chatbot, you can use the same embedding layer,\n    # for translation, you may want to use 2 seperated embedding layers\n    with tf.variable_scope(\"embedding\") as vs:\n        net_encode = EmbeddingInputlayer(inputs=encode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n        vs.reuse_variables()\n        # tl.layers.set_name_reuse(True)\n        net_decode = EmbeddingInputlayer(inputs=decode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n    net = Seq2Seq(\n        net_encode,\n        net_decode,\n        cell_fn=tf.contrib.rnn.BasicLSTMCell,\n        n_hidden=200,\n        initializer=tf.random_uniform_initializer(-0.1, 0.1),\n        encode_sequence_length=retrieve_seq_length_op2(encode_seqs),\n        decode_sequence_length=retrieve_seq_length_op2(decode_seqs),\n        initial_state_encode=None,\n        dropout=None,\n        n_layer=2,\n        return_seq_2d=True,\n        name='Seq2seq')\nnet = DenseLayer(net, n_units=10000, act=tf.identity, name='oo')\ne_loss = tl.cost.cross_entropy_seq_with_mask(logits=net.outputs, target_seqs=target_seqs, input_mask=target_mask, return_details=False, name='cost')\ny = tf.nn.softmax(net.outputs)\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 10000:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 5:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 11:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 5293200:\n    raise Exception(\"params do not match\")\n",
        "source_code_len": 11934,
        "target_code": "\n\nclass Layer_Recurrent_Test(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n\n        cls.net1_batch_size = 32\n        cls.net2_batch_size = 10\n        cls.net3_batch_size = 10\n        cls.net5_batch_size = 32\n        cls.net11_batch_size = 32\n\n        cls.vocab_size = 30\n        cls.hidden_size = 20\n        cls.image_size = 100\n        cls.embedding_size = 20\n\n        cls.num_steps = 5\n\n        cls.keep_prob = 0.8\n        cls.is_train = True\n\n        # =============================== RNN encoder ===============================\n\n        input_data = tf.placeholder(tf.int32, [cls.net1_batch_size, cls.num_steps])\n\n        net1 = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=cls.vocab_size, embedding_size=cls.hidden_size, name='embed')\n        net1 = tl.layers.DropoutLayer(net1, keep=cls.keep_prob, is_fix=True, is_train=cls.is_train, name='drop1')\n        net1 = tl.layers.RNNLayer(net1, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=cls.hidden_size, n_steps=cls.num_steps, return_last=False, name='lstm1')\n\n        # lstm1 = net1\n\n        net1 = tl.layers.DropoutLayer(net1, keep=cls.keep_prob, is_fix=True, is_train=cls.is_train, name='drop2')\n        net1 = tl.layers.RNNLayer(net1, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=cls.hidden_size, n_steps=cls.num_steps, return_last=True, name='lstm2')\n\n        # lstm2 = net1\n\n        net1 = tl.layers.DropoutLayer(net1, keep=cls.keep_prob, is_fix=True, is_train=cls.is_train, name='drop3')\n        net1 = tl.layers.DenseLayer(net1, n_units=cls.vocab_size, name='output')\n\n        net1.print_layers()\n        net1.print_params(False)\n\n        cls.net1_shape = net1.outputs.get_shape().as_list()\n        cls.net1_layers = net1.all_layers\n        cls.net1_params = net1.all_params\n        cls.net1_n_params = net1.count_params()\n\n        # =============================== CNN+RNN encoder ===============================\n\n        x2 = tf.placeholder(tf.float32, shape=[cls.net2_batch_size, cls.image_size, cls.image_size, 1])\n        net2 = tl.layers.InputLayer(x2, name='in')\n\n        net2 = tl.layers.Conv2d(net2, n_filter=32, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn1')\n        net2 = tl.layers.MaxPool2d(net2, filter_size=(2, 2), strides=(2, 2), name='pool1')\n        net2 = tl.layers.Conv2d(net2, n_filter=10, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn2')\n        net2 = tl.layers.MaxPool2d(net2, filter_size=(2, 2), strides=(2, 2), name='pool2')\n\n        net2 = tl.layers.FlattenLayer(net2, name='flatten')\n        net2 = tl.layers.ReshapeLayer(net2, shape=(-1, cls.num_steps, int(net2.outputs._shape[-1])))\n\n        rnn = tl.layers.RNNLayer(\n            net2, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=200, n_steps=cls.num_steps, return_last=False, return_seq_2d=True, name='rnn')\n\n        net2 = tl.layers.DenseLayer(rnn, n_units=3, name='out')\n\n        net2.print_layers()\n        net2.print_params(False)\n\n        cls.net2_shape = net2.outputs.get_shape().as_list()\n        cls.net2_layers = net2.all_layers\n        cls.net2_params = net2.all_params\n        cls.net2_n_params = net2.count_params()\n\n        # =============================== Bidirectional Synced input and output ===============================\n\n        x3 = tf.placeholder(tf.int32, [cls.net3_batch_size, cls.num_steps])\n\n        net3 = tl.layers.EmbeddingInputlayer(inputs=x3, vocabulary_size=cls.vocab_size, embedding_size=cls.hidden_size, name='emb')\n        net3 = tl.layers.BiRNNLayer(\n            net3, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=cls.hidden_size, n_steps=cls.num_steps, return_last=False, return_seq_2d=False, name='birnn')\n\n        net3.print_layers()\n        net3.print_params(False)\n\n        cls.net3_shape = net3.outputs.get_shape().as_list()\n        cls.net3_layers = net3.all_layers\n        cls.net3_params = net3.all_params\n        cls.net3_n_params = net3.count_params()\n\n        # n_layer=2\n        net4 = tl.layers.EmbeddingInputlayer(inputs=x3, vocabulary_size=cls.vocab_size, embedding_size=cls.hidden_size, name='emb2')\n        net4 = tl.layers.BiRNNLayer(\n            net4,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.hidden_size,\n            n_steps=cls.num_steps,\n            n_layer=2,\n            return_last=False,\n            return_seq_2d=False,\n            name='birnn2')\n\n        net4.print_layers()\n        net4.print_params(False)\n\n        cls.net4_shape = net4.outputs.get_shape().as_list()\n        cls.net4_layers = net4.all_layers\n        cls.net4_params = net4.all_params\n        cls.net4_n_params = net4.count_params()\n\n        ## TODO: ConvLSTMLayer\n        # image_size = 100\n        # batch_size = 10\n        # num_steps = 5\n        # x = tf.placeholder(tf.float32, shape=[batch_size, num_steps, image_size, image_size, 3])\n        # net = tl.layers.InputLayer(x, name='in2')\n        # net = tl.layers.ConvLSTMLayer(net,\n        #             feature_map=1,\n        #             filter_size=(3, 3),\n        #             cell_fn=tl.layers.BasicConvLSTMCell,\n        #             initializer=tf.random_uniform_initializer(-0.1, 0.1),\n        #             n_steps=num_steps,\n        #             initial_state=None,\n        #             return_last=False,\n        #             return_seq_2d=False,\n        #             name='convlstm')\n\n        # =============================== Dynamic Synced input and output ===============================\n\n        input_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net5_batch_size, None], name=\"input\")\n        nin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=cls.vocab_size, embedding_size=cls.embedding_size, name='seq_embedding')\n\n        rnn = tl.layers.DynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=(cls.keep_prob if cls.is_train else None),\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            return_last=False,\n            return_seq_2d=True,\n            name='dynamicrnn')\n\n        net5 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o\")\n\n        net5.print_layers()\n        net5.print_params(False)\n\n        cls.net5_shape = net5.outputs.get_shape().as_list()\n        cls.net5_rnn_shape = rnn.outputs.get_shape().as_list()\n        cls.net5_layers = net5.all_layers\n        cls.net5_params = net5.all_params\n        cls.net5_n_params = net5.count_params()\n\n        # n_layer=3\n        nin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=cls.vocab_size, embedding_size=cls.embedding_size, name='seq_embedding2')\n        rnn = tl.layers.DynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=(cls.keep_prob if cls.is_train else None),\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            n_layer=3,\n            return_last=False,\n            return_seq_2d=True,\n            name='dynamicrnn2')\n\n        # net6 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o2\")\n\n        net6 = tl.layers.DynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=None,\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            n_layer=3,\n            return_last=False,\n            return_seq_2d=False,\n            name='dynamicrnn3')\n\n        # net6 = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o3\")\n\n        net6.print_layers()\n        net6.print_params(False)\n\n        cls.net6_shape = net6.outputs.get_shape().as_list()\n        cls.net6_rnn_shape = rnn.outputs.get_shape().as_list()\n\n        net7 = tl.layers.DynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=None,\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            n_layer=1,\n            return_last=True,\n            return_seq_2d=False,\n            name='dynamicrnn4')\n\n        net7.print_layers()\n        net7.print_params(False)\n\n        cls.net7_shape = net7.outputs.get_shape().as_list()\n\n        net8 = tl.layers.DynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=None,\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            n_layer=1,\n            return_last=True,\n            return_seq_2d=True,\n            name='dynamicrnn5')\n\n        net8.print_layers()\n        net8.print_params(False)\n\n        cls.net8_shape = net8.outputs.get_shape().as_list()\n\n        # =============================== BiDynamic Synced input and output ===============================\n\n        rnn = tl.layers.BiDynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=(cls.keep_prob if cls.is_train else None),\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            return_last=False,\n            return_seq_2d=True,\n            name='bidynamicrnn')\n\n        net9 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o4\")\n\n        net9.print_layers()\n        net9.print_params(False)\n\n        cls.net9_shape = net9.outputs.get_shape().as_list()\n        cls.net9_rnn_shape = rnn.outputs.get_shape().as_list()\n        cls.net9_layers = net9.all_layers\n        cls.net9_params = net9.all_params\n        cls.net9_n_params = net9.count_params()\n\n        # n_layer=2\n        rnn = tl.layers.BiDynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=(cls.keep_prob if cls.is_train else None),\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            n_layer=2,\n            return_last=False,\n            return_seq_2d=True,\n            name='bidynamicrnn2')\n\n        net10 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o5\")\n\n        net10.print_layers()\n        net10.print_params(False)\n\n        cls.net10_shape = net10.outputs.get_shape().as_list()\n        cls.net10_rnn_shape = rnn.outputs.get_shape().as_list()\n        cls.net10_layers = net10.all_layers\n        cls.net10_params = net10.all_params\n        cls.net10_n_params = net10.count_params()\n\n        # =============================== Seq2Seq ===============================\n\n        encode_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"encode_seqs\")\n        decode_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"decode_seqs\")\n        # target_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"target_seqs\")\n        # target_mask = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"target_mask\")  # tl.prepro.sequences_get_mask()\n\n        with tf.variable_scope(\"model\"):\n            # for chatbot, you can use the same embedding layer,\n            # for translation, you may want to use 2 seperated embedding layers\n\n            with tf.variable_scope(\"embedding\") as vs:\n                net_encode = tl.layers.EmbeddingInputlayer(inputs=encode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n                vs.reuse_variables()\n                # tl.layers.set_name_reuse(True)\n                net_decode = tl.layers.EmbeddingInputlayer(inputs=decode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n\n            net11 = tl.layers.Seq2Seq(\n                net_encode,\n                net_decode,\n                cell_fn=tf.contrib.rnn.BasicLSTMCell,\n                n_hidden=200,\n                initializer=tf.random_uniform_initializer(-0.1, 0.1),\n                encode_sequence_length=tl.layers.retrieve_seq_length_op2(encode_seqs),\n                decode_sequence_length=tl.layers.retrieve_seq_length_op2(decode_seqs),\n                initial_state_encode=None,\n                dropout=None,\n                n_layer=2,\n                return_seq_2d=True,\n                name='Seq2seq')\n\n        net11 = tl.layers.DenseLayer(net11, n_units=10000, act=tf.identity, name='oo')\n\n        # e_loss = tl.cost.cross_entropy_seq_with_mask(logits=net11.outputs, target_seqs=target_seqs, input_mask=target_mask, return_details=False, name='cost')\n        # y = tf.nn.softmax(net11.outputs)\n\n        net11.print_layers()\n        net11.print_params(False)\n\n        cls.net11_shape = net11.outputs.get_shape().as_list()\n        cls.net11_layers = net11.all_layers\n        cls.net11_params = net11.all_params\n        cls.net11_n_params = net11.count_params()\n\n    @classmethod\n    def tearDownClass(cls):\n        tf.reset_default_graph()\n\n    def test_net1(self):\n        self.assertEqual(self.net1_shape, [self.net1_batch_size, self.vocab_size])\n        self.assertEqual(len(self.net1_layers), 7)\n        self.assertEqual(len(self.net1_params), 7)\n        self.assertEqual(self.net1_n_params, 7790)\n\n    def test_net2(self):\n        self.assertEqual(self.net2_shape, [self.net2_batch_size, 3])\n        self.assertEqual(len(self.net2_layers), 8)\n        self.assertEqual(len(self.net2_params), 8)\n        self.assertEqual(self.net2_n_params, 562245)\n\n    def test_net3(self):\n        self.assertEqual(self.net3_shape[1:3], [self.num_steps, self.hidden_size * 2])\n        self.assertEqual(len(self.net3_layers), 2)\n        self.assertEqual(len(self.net3_params), 5)\n        self.assertEqual(self.net3_n_params, 7160)\n\n    def test_net4(self):\n        self.assertEqual(self.net4_shape[1:3], [self.num_steps, self.hidden_size * 2])\n        self.assertEqual(len(self.net4_layers), 2)\n        self.assertEqual(len(self.net4_params), 9)\n        self.assertEqual(self.net4_n_params, 13720)\n\n    def test_net5(self):\n        self.assertEqual(self.net5_shape[-1], self.vocab_size)\n        self.assertEqual(self.net5_rnn_shape[-1], self.embedding_size)\n        self.assertEqual(len(self.net5_layers), 3)\n        self.assertEqual(len(self.net5_params), 5)\n        self.assertEqual(self.net5_n_params, 4510)\n\n    def test_net6(self):\n        self.assertEqual(self.net6_shape[-1], self.embedding_size)\n        self.assertEqual(self.net6_rnn_shape[-1], self.embedding_size)\n\n    def test_net7(self):\n        self.assertEqual(self.net7_shape[-1], self.embedding_size)\n\n    def test_net8(self):\n        self.assertEqual(self.net8_shape[-1], self.embedding_size)\n\n    def test_net9(self):\n        self.assertEqual(self.net9_shape[-1], self.vocab_size)\n        self.assertEqual(self.net9_rnn_shape[-1], self.embedding_size * 2)\n        self.assertEqual(len(self.net9_layers), 3)\n        self.assertEqual(len(self.net9_params), 7)\n        self.assertEqual(self.net9_n_params, 8390)\n\n    def test_net10(self):\n        self.assertEqual(self.net10_shape[-1], self.vocab_size)\n        self.assertEqual(self.net10_rnn_shape[-1], self.embedding_size * 2)\n        self.assertEqual(len(self.net10_layers), 3)\n        self.assertEqual(len(self.net10_params), 11)\n        self.assertEqual(self.net10_n_params, 18150)\n\n    def test_net11(self):\n        self.assertEqual(self.net11_shape[-1], 10000)\n        self.assertEqual(len(self.net11_layers), 5)\n        self.assertEqual(len(self.net11_params), 11)\n        self.assertEqual(self.net11_n_params, 5293200)\n\n\nif __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_len": 15618,
        "diff_format": "@@ -3,344 +7,381 @@\n \n-## RNN encoder ====================================================\n-batch_size = 32\n-num_steps = 5\n-vocab_size = 30\n-hidden_size = 20\n-keep_prob = 0.8\n-is_train = True\n-input_data = tf.placeholder(tf.int32, [batch_size, num_steps])\n-net = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=vocab_size, embedding_size=hidden_size, name='embed')\n-net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_train, name='drop1')\n-net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, return_last=False, name='lstm1')\n-lstm1 = net\n-net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_train, name='drop2')\n-net = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, return_last=True, name='lstm2')\n-lstm2 = net\n-net = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_train, name='drop3')\n-net = tl.layers.DenseLayer(net, n_units=vocab_size, name='output')\n-\n-net.print_layers()\n-net.print_params(False)\n-\n-if len(net.all_layers) != 7:\n-    raise Exception(\"layers do not match\")\n-\n-if len(net.all_params) != 7:\n-    raise Exception(\"params do not match\")\n-\n-if net.count_params() != 7790:\n-    raise Exception(\"params do not match\")\n-\n-## CNN+RNN encoder ====================================================\n-image_size = 100\n-batch_size = 10\n-num_steps = 5\n-\n-x = tf.placeholder(tf.float32, shape=[batch_size, image_size, image_size, 1])\n-net = tl.layers.InputLayer(x, name='in')\n-net = tl.layers.Conv2d(net, n_filter=32, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn1')\n-net = tl.layers.MaxPool2d(net, filter_size=(2, 2), strides=(2, 2), name='pool1')\n-net = tl.layers.Conv2d(net, n_filter=10, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn2')\n-net = tl.layers.MaxPool2d(net, filter_size=(2, 2), strides=(2, 2), name='pool2')\n-net = tl.layers.FlattenLayer(net, name='flatten')\n-net = tl.layers.ReshapeLayer(net, shape=(-1, num_steps, int(net.outputs._shape[-1])))\n-rnn = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=200, n_steps=num_steps, return_last=False, return_seq_2d=True, name='rnn')\n-net = tl.layers.DenseLayer(rnn, n_units=3, name='out')\n-\n-net.print_layers()\n-net.print_params(False)\n-\n-if len(net.all_layers) != 8:\n-    raise Exception(\"layers do not match\")\n-\n-if len(net.all_params) != 8:\n-    raise Exception(\"params do not match\")\n-\n-if net.count_params() != 562245:\n-    raise Exception(\"params do not match\")\n-\n-## Bidirectional Synced input and output\n-batch_size = 10\n-num_steps = 5\n-vocab_size = 30\n-hidden_size = 20\n-input_data = tf.placeholder(tf.int32, [batch_size, num_steps])\n-net = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=vocab_size, embedding_size=hidden_size, name='emb')\n-net = tl.layers.BiRNNLayer(\n-    net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, return_last=False, return_seq_2d=False, name='birnn')\n-\n-net.print_layers()\n-net.print_params(False)\n-\n-shape = net.outputs.get_shape().as_list()\n-if shape[1:3] != [num_steps, hidden_size * 2]:\n-    raise Exception(\"shape do not match\")\n-\n-if len(net.all_layers) != 2:\n-    raise Exception(\"layers do not match\")\n-\n-if len(net.all_params) != 5:\n-    raise Exception(\"params do not match\")\n-\n-if net.count_params() != 7160:\n-    raise Exception(\"params do not match\")\n-\n-# n_layer=2\n-net = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=vocab_size, embedding_size=hidden_size, name='emb2')\n-net = tl.layers.BiRNNLayer(\n-    net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, n_layer=2, return_last=False, return_seq_2d=False, name='birnn2')\n-\n-net.print_layers()\n-net.print_params(False)\n-\n-shape = net.outputs.get_shape().as_list()\n-if shape[1:3] != [num_steps, hidden_size * 2]:\n-    raise Exception(\"shape do not match\")\n-\n-if len(net.all_layers) != 2:\n-    raise Exception(\"layers do not match\")\n-\n-if len(net.all_params) != 9:\n-    raise Exception(\"params do not match\")\n-\n-if net.count_params() != 13720:\n-    raise Exception(\"params do not match\")\n-\n-## ConvLSTMLayer TODO\n-# image_size = 100\n-# batch_size = 10\n-# num_steps = 5\n-# x = tf.placeholder(tf.float32, shape=[batch_size, num_steps, image_size, image_size, 3])\n-# net = tl.layers.InputLayer(x, name='in2')\n-# net = tl.layers.ConvLSTMLayer(net,\n-#             feature_map=1,\n-#             filter_size=(3, 3),\n-#             cell_fn=tl.layers.BasicConvLSTMCell,\n-#             initializer=tf.random_uniform_initializer(-0.1, 0.1),\n-#             n_steps=num_steps,\n-#             initial_state=None,\n-#             return_last=False,\n-#             return_seq_2d=False,\n-#             name='convlstm')\n-\n-## Dynamic Synced input and output\n-batch_size = 32\n-num_steps = 5\n-vocab_size = 30\n-embedding_size = 20\n-keep_prob = 0.8\n-is_train = True\n-input_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"input\")\n-nin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=vocab_size, embedding_size=embedding_size, name='seq_embedding')\n-rnn = tl.layers.DynamicRNNLayer(\n-    nin,\n-    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n-    n_hidden=embedding_size,\n-    dropout=(keep_prob if is_train else None),\n-    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n-    return_last=False,\n-    return_seq_2d=True,\n-    name='dynamicrnn')\n-net = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o\")\n-\n-net.print_layers()\n-net.print_params(False)\n-\n-shape = rnn.outputs.get_shape().as_list()\n-if shape[-1] != embedding_size:\n-    raise Exception(\"shape do not match\")\n-\n-shape = net.outputs.get_shape().as_list()\n-if shape[-1] != vocab_size:\n-    raise Exception(\"shape do not match\")\n-\n-if len(net.all_layers) != 3:\n-    raise Exception(\"layers do not match\")\n-\n-if len(net.all_params) != 5:\n-    raise Exception(\"params do not match\")\n-\n-if net.count_params() != 4510:\n-    raise Exception(\"params do not match\")\n-\n-# n_layer=3\n-nin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=vocab_size, embedding_size=embedding_size, name='seq_embedding2')\n-rnn = tl.layers.DynamicRNNLayer(\n-    nin,\n-    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n-    n_hidden=embedding_size,\n-    dropout=(keep_prob if is_train else None),\n-    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n-    n_layer=3,\n-    return_last=False,\n-    return_seq_2d=True,\n-    name='dynamicrnn2')\n-net = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o2\")\n-\n-shape = rnn.outputs.get_shape().as_list()\n-if (shape[-1] != embedding_size) or (len(shape) != 2):\n-    raise Exception(\"shape do not match\")\n-\n-net = tl.layers.DynamicRNNLayer(\n-    nin,\n-    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n-    n_hidden=embedding_size,\n-    dropout=None,\n-    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n-    n_layer=3,\n-    return_last=False,\n-    return_seq_2d=False,\n-    name='dynamicrnn3')\n-# net = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o3\")\n-\n-net.print_layers()\n-net.print_params(False)\n-\n-shape = net.outputs.get_shape().as_list()\n-if (shape[-1] != embedding_size) or (len(shape) != 3):\n-    raise Exception(\"shape do not match\")\n-\n-net = tl.layers.DynamicRNNLayer(\n-    nin,\n-    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n-    n_hidden=embedding_size,\n-    dropout=None,\n-    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n-    n_layer=1,\n-    return_last=True,\n-    return_seq_2d=False,\n-    name='dynamicrnn4')\n-net.print_layers()\n-net.print_params(False)\n-shape = net.outputs.get_shape().as_list()\n-if (shape[-1] != embedding_size) or (len(shape) != 2):\n-    raise Exception(\"shape do not match\")\n-\n-net = tl.layers.DynamicRNNLayer(\n-    nin,\n-    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n-    n_hidden=embedding_size,\n-    dropout=None,\n-    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n-    n_layer=1,\n-    return_last=True,\n-    return_seq_2d=True,\n-    name='dynamicrnn5')\n-net.print_layers()\n-net.print_params(False)\n-shape = net.outputs.get_shape().as_list()\n-if (shape[-1] != embedding_size) or (len(shape) != 2):\n-    raise Exception(\"shape do not match\")\n-\n-## BiDynamic Synced input and output\n-rnn = tl.layers.BiDynamicRNNLayer(\n-    nin,\n-    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n-    n_hidden=embedding_size,\n-    dropout=(keep_prob if is_train else None),\n-    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n-    return_last=False,\n-    return_seq_2d=True,\n-    name='bidynamicrnn')\n-net = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o4\")\n-\n-net.print_layers()\n-net.print_params(False)\n-\n-shape = rnn.outputs.get_shape().as_list()\n-if shape[-1] != embedding_size * 2:\n-    raise Exception(\"shape do not match\")\n-\n-shape = net.outputs.get_shape().as_list()\n-if shape[-1] != vocab_size:\n-    raise Exception(\"shape do not match\")\n-\n-if len(net.all_layers) != 3:\n-    raise Exception(\"layers do not match\")\n-\n-if len(net.all_params) != 7:\n-    raise Exception(\"params do not match\")\n-\n-if net.count_params() != 8390:\n-    raise Exception(\"params do not match\")\n-\n-# n_layer=2\n-rnn = tl.layers.BiDynamicRNNLayer(\n-    nin,\n-    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n-    n_hidden=embedding_size,\n-    dropout=(keep_prob if is_train else None),\n-    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n-    n_layer=2,\n-    return_last=False,\n-    return_seq_2d=True,\n-    name='bidynamicrnn2')\n-net = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o5\")\n-\n-net.print_layers()\n-net.print_params(False)\n-\n-shape = rnn.outputs.get_shape().as_list()\n-if shape[-1] != embedding_size * 2:\n-    raise Exception(\"shape do not match\")\n-\n-shape = net.outputs.get_shape().as_list()\n-if shape[-1] != vocab_size:\n-    raise Exception(\"shape do not match\")\n-\n-if len(net.all_layers) != 3:\n-    raise Exception(\"layers do not match\")\n-\n-if len(net.all_params) != 11:\n-    raise Exception(\"params do not match\")\n-\n-if net.count_params() != 18150:\n-    raise Exception(\"params do not match\")\n-\n-## Seq2Seq\n-from tensorlayer.layers import EmbeddingInputlayer, Seq2Seq, retrieve_seq_length_op2, DenseLayer\n-batch_size = 32\n-encode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"encode_seqs\")\n-decode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"decode_seqs\")\n-target_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_seqs\")\n-target_mask = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_mask\")  # tl.prepro.sequences_get_mask()\n-with tf.variable_scope(\"model\"):\n-    # for chatbot, you can use the same embedding layer,\n-    # for translation, you may want to use 2 seperated embedding layers\n-    with tf.variable_scope(\"embedding\") as vs:\n-        net_encode = EmbeddingInputlayer(inputs=encode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n-        vs.reuse_variables()\n-        # tl.layers.set_name_reuse(True)\n-        net_decode = EmbeddingInputlayer(inputs=decode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n-    net = Seq2Seq(\n-        net_encode,\n-        net_decode,\n-        cell_fn=tf.contrib.rnn.BasicLSTMCell,\n-        n_hidden=200,\n-        initializer=tf.random_uniform_initializer(-0.1, 0.1),\n-        encode_sequence_length=retrieve_seq_length_op2(encode_seqs),\n-        decode_sequence_length=retrieve_seq_length_op2(decode_seqs),\n-        initial_state_encode=None,\n-        dropout=None,\n-        n_layer=2,\n-        return_seq_2d=True,\n-        name='Seq2seq')\n-net = DenseLayer(net, n_units=10000, act=tf.identity, name='oo')\n-e_loss = tl.cost.cross_entropy_seq_with_mask(logits=net.outputs, target_seqs=target_seqs, input_mask=target_mask, return_details=False, name='cost')\n-y = tf.nn.softmax(net.outputs)\n-\n-net.print_layers()\n-net.print_params(False)\n-\n-shape = net.outputs.get_shape().as_list()\n-if shape[-1] != 10000:\n-    raise Exception(\"shape do not match\")\n-\n-if len(net.all_layers) != 5:\n-    raise Exception(\"layers do not match\")\n-\n-if len(net.all_params) != 11:\n-    raise Exception(\"params do not match\")\n-\n-if net.count_params() != 5293200:\n-    raise Exception(\"params do not match\")\n+\n+class Layer_Recurrent_Test(unittest.TestCase):\n+    @classmethod\n+    def setUpClass(cls):\n+\n+        cls.net1_batch_size = 32\n+        cls.net2_batch_size = 10\n+        cls.net3_batch_size = 10\n+        cls.net5_batch_size = 32\n+        cls.net11_batch_size = 32\n+\n+        cls.vocab_size = 30\n+        cls.hidden_size = 20\n+        cls.image_size = 100\n+        cls.embedding_size = 20\n+\n+        cls.num_steps = 5\n+\n+        cls.keep_prob = 0.8\n+        cls.is_train = True\n+\n+        # =============================== RNN encoder ===============================\n+\n+        input_data = tf.placeholder(tf.int32, [cls.net1_batch_size, cls.num_steps])\n+\n+        net1 = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=cls.vocab_size, embedding_size=cls.hidden_size, name='embed')\n+        net1 = tl.layers.DropoutLayer(net1, keep=cls.keep_prob, is_fix=True, is_train=cls.is_train, name='drop1')\n+        net1 = tl.layers.RNNLayer(net1, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=cls.hidden_size, n_steps=cls.num_steps, return_last=False, name='lstm1')\n+\n+        # lstm1 = net1\n+\n+        net1 = tl.layers.DropoutLayer(net1, keep=cls.keep_prob, is_fix=True, is_train=cls.is_train, name='drop2')\n+        net1 = tl.layers.RNNLayer(net1, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=cls.hidden_size, n_steps=cls.num_steps, return_last=True, name='lstm2')\n+\n+        # lstm2 = net1\n+\n+        net1 = tl.layers.DropoutLayer(net1, keep=cls.keep_prob, is_fix=True, is_train=cls.is_train, name='drop3')\n+        net1 = tl.layers.DenseLayer(net1, n_units=cls.vocab_size, name='output')\n+\n+        net1.print_layers()\n+        net1.print_params(False)\n+\n+        cls.net1_shape = net1.outputs.get_shape().as_list()\n+        cls.net1_layers = net1.all_layers\n+        cls.net1_params = net1.all_params\n+        cls.net1_n_params = net1.count_params()\n+\n+        # =============================== CNN+RNN encoder ===============================\n+\n+        x2 = tf.placeholder(tf.float32, shape=[cls.net2_batch_size, cls.image_size, cls.image_size, 1])\n+        net2 = tl.layers.InputLayer(x2, name='in')\n+\n+        net2 = tl.layers.Conv2d(net2, n_filter=32, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn1')\n+        net2 = tl.layers.MaxPool2d(net2, filter_size=(2, 2), strides=(2, 2), name='pool1')\n+        net2 = tl.layers.Conv2d(net2, n_filter=10, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn2')\n+        net2 = tl.layers.MaxPool2d(net2, filter_size=(2, 2), strides=(2, 2), name='pool2')\n+\n+        net2 = tl.layers.FlattenLayer(net2, name='flatten')\n+        net2 = tl.layers.ReshapeLayer(net2, shape=(-1, cls.num_steps, int(net2.outputs._shape[-1])))\n+\n+        rnn = tl.layers.RNNLayer(\n+            net2, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=200, n_steps=cls.num_steps, return_last=False, return_seq_2d=True, name='rnn')\n+\n+        net2 = tl.layers.DenseLayer(rnn, n_units=3, name='out')\n+\n+        net2.print_layers()\n+        net2.print_params(False)\n+\n+        cls.net2_shape = net2.outputs.get_shape().as_list()\n+        cls.net2_layers = net2.all_layers\n+        cls.net2_params = net2.all_params\n+        cls.net2_n_params = net2.count_params()\n+\n+        # =============================== Bidirectional Synced input and output ===============================\n+\n+        x3 = tf.placeholder(tf.int32, [cls.net3_batch_size, cls.num_steps])\n+\n+        net3 = tl.layers.EmbeddingInputlayer(inputs=x3, vocabulary_size=cls.vocab_size, embedding_size=cls.hidden_size, name='emb')\n+        net3 = tl.layers.BiRNNLayer(\n+            net3, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=cls.hidden_size, n_steps=cls.num_steps, return_last=False, return_seq_2d=False, name='birnn')\n+\n+        net3.print_layers()\n+        net3.print_params(False)\n+\n+        cls.net3_shape = net3.outputs.get_shape().as_list()\n+        cls.net3_layers = net3.all_layers\n+        cls.net3_params = net3.all_params\n+        cls.net3_n_params = net3.count_params()\n+\n+        # n_layer=2\n+        net4 = tl.layers.EmbeddingInputlayer(inputs=x3, vocabulary_size=cls.vocab_size, embedding_size=cls.hidden_size, name='emb2')\n+        net4 = tl.layers.BiRNNLayer(\n+            net4,\n+            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n+            n_hidden=cls.hidden_size,\n+            n_steps=cls.num_steps,\n+            n_layer=2,\n+            return_last=False,\n+            return_seq_2d=False,\n+            name='birnn2')\n+\n+        net4.print_layers()\n+        net4.print_params(False)\n+\n+        cls.net4_shape = net4.outputs.get_shape().as_list()\n+        cls.net4_layers = net4.all_layers\n+        cls.net4_params = net4.all_params\n+        cls.net4_n_params = net4.count_params()\n+\n+        ## TODO: ConvLSTMLayer\n+        # image_size = 100\n+        # batch_size = 10\n+        # num_steps = 5\n+        # x = tf.placeholder(tf.float32, shape=[batch_size, num_steps, image_size, image_size, 3])\n+        # net = tl.layers.InputLayer(x, name='in2')\n+        # net = tl.layers.ConvLSTMLayer(net,\n+        #             feature_map=1,\n+        #             filter_size=(3, 3),\n+        #             cell_fn=tl.layers.BasicConvLSTMCell,\n+        #             initializer=tf.random_uniform_initializer(-0.1, 0.1),\n+        #             n_steps=num_steps,\n+        #             initial_state=None,\n+        #             return_last=False,\n+        #             return_seq_2d=False,\n+        #             name='convlstm')\n+\n+        # =============================== Dynamic Synced input and output ===============================\n+\n+        input_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net5_batch_size, None], name=\"input\")\n+        nin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=cls.vocab_size, embedding_size=cls.embedding_size, name='seq_embedding')\n+\n+        rnn = tl.layers.DynamicRNNLayer(\n+            nin,\n+            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n+            n_hidden=cls.embedding_size,\n+            dropout=(cls.keep_prob if cls.is_train else None),\n+            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n+            return_last=False,\n+            return_seq_2d=True,\n+            name='dynamicrnn')\n+\n+        net5 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o\")\n+\n+        net5.print_layers()\n+        net5.print_params(False)\n+\n+        cls.net5_shape = net5.outputs.get_shape().as_list()\n+        cls.net5_rnn_shape = rnn.outputs.get_shape().as_list()\n+        cls.net5_layers = net5.all_layers\n+        cls.net5_params = net5.all_params\n+        cls.net5_n_params = net5.count_params()\n+\n+        # n_layer=3\n+        nin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=cls.vocab_size, embedding_size=cls.embedding_size, name='seq_embedding2')\n+        rnn = tl.layers.DynamicRNNLayer(\n+            nin,\n+            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n+            n_hidden=cls.embedding_size,\n+            dropout=(cls.keep_prob if cls.is_train else None),\n+            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n+            n_layer=3,\n+            return_last=False,\n+            return_seq_2d=True,\n+            name='dynamicrnn2')\n+\n+        # net6 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o2\")\n+\n+        net6 = tl.layers.DynamicRNNLayer(\n+            nin,\n+            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n+            n_hidden=cls.embedding_size,\n+            dropout=None,\n+            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n+            n_layer=3,\n+            return_last=False,\n+            return_seq_2d=False,\n+            name='dynamicrnn3')\n+\n+        # net6 = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o3\")\n+\n+        net6.print_layers()\n+        net6.print_params(False)\n+\n+        cls.net6_shape = net6.outputs.get_shape().as_list()\n+        cls.net6_rnn_shape = rnn.outputs.get_shape().as_list()\n+\n+        net7 = tl.layers.DynamicRNNLayer(\n+            nin,\n+            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n+            n_hidden=cls.embedding_size,\n+            dropout=None,\n+            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n+            n_layer=1,\n+            return_last=True,\n+            return_seq_2d=False,\n+            name='dynamicrnn4')\n+\n+        net7.print_layers()\n+        net7.print_params(False)\n+\n+        cls.net7_shape = net7.outputs.get_shape().as_list()\n+\n+        net8 = tl.layers.DynamicRNNLayer(\n+            nin,\n+            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n+            n_hidden=cls.embedding_size,\n+            dropout=None,\n+            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n+            n_layer=1,\n+            return_last=True,\n+            return_seq_2d=True,\n+            name='dynamicrnn5')\n+\n+        net8.print_layers()\n+        net8.print_params(False)\n+\n+        cls.net8_shape = net8.outputs.get_shape().as_list()\n+\n+        # =============================== BiDynamic Synced input and output ===============================\n+\n+        rnn = tl.layers.BiDynamicRNNLayer(\n+            nin,\n+            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n+            n_hidden=cls.embedding_size,\n+            dropout=(cls.keep_prob if cls.is_train else None),\n+            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n+            return_last=False,\n+            return_seq_2d=True,\n+            name='bidynamicrnn')\n+\n+        net9 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o4\")\n+\n+        net9.print_layers()\n+        net9.print_params(False)\n+\n+        cls.net9_shape = net9.outputs.get_shape().as_list()\n+        cls.net9_rnn_shape = rnn.outputs.get_shape().as_list()\n+        cls.net9_layers = net9.all_layers\n+        cls.net9_params = net9.all_params\n+        cls.net9_n_params = net9.count_params()\n+\n+        # n_layer=2\n+        rnn = tl.layers.BiDynamicRNNLayer(\n+            nin,\n+            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n+            n_hidden=cls.embedding_size,\n+            dropout=(cls.keep_prob if cls.is_train else None),\n+            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n+            n_layer=2,\n+            return_last=False,\n+            return_seq_2d=True,\n+            name='bidynamicrnn2')\n+\n+        net10 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o5\")\n+\n+        net10.print_layers()\n+        net10.print_params(False)\n+\n+        cls.net10_shape = net10.outputs.get_shape().as_list()\n+        cls.net10_rnn_shape = rnn.outputs.get_shape().as_list()\n+        cls.net10_layers = net10.all_layers\n+        cls.net10_params = net10.all_params\n+        cls.net10_n_params = net10.count_params()\n+\n+        # =============================== Seq2Seq ===============================\n+\n+        encode_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"encode_seqs\")\n+        decode_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"decode_seqs\")\n+        # target_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"target_seqs\")\n+        # target_mask = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"target_mask\")  # tl.prepro.sequences_get_mask()\n+\n+        with tf.variable_scope(\"model\"):\n+            # for chatbot, you can use the same embedding layer,\n+            # for translation, you may want to use 2 seperated embedding layers\n+\n+            with tf.variable_scope(\"embedding\") as vs:\n+                net_encode = tl.layers.EmbeddingInputlayer(inputs=encode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n+                vs.reuse_variables()\n+                # tl.layers.set_name_reuse(True)\n+                net_decode = tl.layers.EmbeddingInputlayer(inputs=decode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n+\n+            net11 = tl.layers.Seq2Seq(\n+                net_encode,\n+                net_decode,\n+                cell_fn=tf.contrib.rnn.BasicLSTMCell,\n+                n_hidden=200,\n+                initializer=tf.random_uniform_initializer(-0.1, 0.1),\n+                encode_sequence_length=tl.layers.retrieve_seq_length_op2(encode_seqs),\n+                decode_sequence_length=tl.layers.retrieve_seq_length_op2(decode_seqs),\n+                initial_state_encode=None,\n+                dropout=None,\n+                n_layer=2,\n+                return_seq_2d=True,\n+                name='Seq2seq')\n+\n+        net11 = tl.layers.DenseLayer(net11, n_units=10000, act=tf.identity, name='oo')\n+\n+        # e_loss = tl.cost.cross_entropy_seq_with_mask(logits=net11.outputs, target_seqs=target_seqs, input_mask=target_mask, return_details=False, name='cost')\n+        # y = tf.nn.softmax(net11.outputs)\n+\n+        net11.print_layers()\n+        net11.print_params(False)\n+\n+        cls.net11_shape = net11.outputs.get_shape().as_list()\n+        cls.net11_layers = net11.all_layers\n+        cls.net11_params = net11.all_params\n+        cls.net11_n_params = net11.count_params()\n+\n+    @classmethod\n+    def tearDownClass(cls):\n+        tf.reset_default_graph()\n+\n+    def test_net1(self):\n+        self.assertEqual(self.net1_shape, [self.net1_batch_size, self.vocab_size])\n+        self.assertEqual(len(self.net1_layers), 7)\n+        self.assertEqual(len(self.net1_params), 7)\n+        self.assertEqual(self.net1_n_params, 7790)\n+\n+    def test_net2(self):\n+        self.assertEqual(self.net2_shape, [self.net2_batch_size, 3])\n+        self.assertEqual(len(self.net2_layers), 8)\n+        self.assertEqual(len(self.net2_params), 8)\n+        self.assertEqual(self.net2_n_params, 562245)\n+\n+    def test_net3(self):\n+        self.assertEqual(self.net3_shape[1:3], [self.num_steps, self.hidden_size * 2])\n+        self.assertEqual(len(self.net3_layers), 2)\n+        self.assertEqual(len(self.net3_params), 5)\n+        self.assertEqual(self.net3_n_params, 7160)\n+\n+    def test_net4(self):\n+        self.assertEqual(self.net4_shape[1:3], [self.num_steps, self.hidden_size * 2])\n+        self.assertEqual(len(self.net4_layers), 2)\n+        self.assertEqual(len(self.net4_params), 9)\n+        self.assertEqual(self.net4_n_params, 13720)\n+\n+    def test_net5(self):\n+        self.assertEqual(self.net5_shape[-1], self.vocab_size)\n+        self.assertEqual(self.net5_rnn_shape[-1], self.embedding_size)\n+        self.assertEqual(len(self.net5_layers), 3)\n+        self.assertEqual(len(self.net5_params), 5)\n+        self.assertEqual(self.net5_n_params, 4510)\n+\n+    def test_net6(self):\n+        self.assertEqual(self.net6_shape[-1], self.embedding_size)\n+        self.assertEqual(self.net6_rnn_shape[-1], self.embedding_size)\n+\n+    def test_net7(self):\n+        self.assertEqual(self.net7_shape[-1], self.embedding_size)\n+\n+    def test_net8(self):\n+        self.assertEqual(self.net8_shape[-1], self.embedding_size)\n+\n+    def test_net9(self):\n+        self.assertEqual(self.net9_shape[-1], self.vocab_size)\n+        self.assertEqual(self.net9_rnn_shape[-1], self.embedding_size * 2)\n+        self.assertEqual(len(self.net9_layers), 3)\n+        self.assertEqual(len(self.net9_params), 7)\n+        self.assertEqual(self.net9_n_params, 8390)\n+\n+    def test_net10(self):\n+        self.assertEqual(self.net10_shape[-1], self.vocab_size)\n+        self.assertEqual(self.net10_rnn_shape[-1], self.embedding_size * 2)\n+        self.assertEqual(len(self.net10_layers), 3)\n+        self.assertEqual(len(self.net10_params), 11)\n+        self.assertEqual(self.net10_n_params, 18150)\n+\n+    def test_net11(self):\n+        self.assertEqual(self.net11_shape[-1], 10000)\n+        self.assertEqual(len(self.net11_layers), 5)\n+        self.assertEqual(len(self.net11_params), 11)\n+        self.assertEqual(self.net11_n_params, 5293200)\n+\n+\n+if __name__ == '__main__':\n+\n+    # tf.logging.set_verbosity(tf.logging.INFO)\n+    tf.logging.set_verbosity(tf.logging.DEBUG)\n+\n+    unittest.main()\n",
        "source_code_with_indent": "\n## RNN encoder ====================================================\nbatch_size = 32\nnum_steps = 5\nvocab_size = 30\nhidden_size = 20\nkeep_prob = 0.8\nis_train = True\ninput_data = tf.placeholder(tf.int32, [batch_size, num_steps])\nnet = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=vocab_size, embedding_size=hidden_size, name='embed')\nnet = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_train, name='drop1')\nnet = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, return_last=False, name='lstm1')\nlstm1 = net\nnet = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_train, name='drop2')\nnet = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, return_last=True, name='lstm2')\nlstm2 = net\nnet = tl.layers.DropoutLayer(net, keep=keep_prob, is_fix=True, is_train=is_train, name='drop3')\nnet = tl.layers.DenseLayer(net, n_units=vocab_size, name='output')\n\nnet.print_layers()\nnet.print_params(False)\n\nif len(net.all_layers) != 7:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 7:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 7790:\n    <IND>raise Exception(\"params do not match\")\n\n## CNN+RNN encoder ====================================================\n<DED>image_size = 100\nbatch_size = 10\nnum_steps = 5\n\nx = tf.placeholder(tf.float32, shape=[batch_size, image_size, image_size, 1])\nnet = tl.layers.InputLayer(x, name='in')\nnet = tl.layers.Conv2d(net, n_filter=32, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn1')\nnet = tl.layers.MaxPool2d(net, filter_size=(2, 2), strides=(2, 2), name='pool1')\nnet = tl.layers.Conv2d(net, n_filter=10, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn2')\nnet = tl.layers.MaxPool2d(net, filter_size=(2, 2), strides=(2, 2), name='pool2')\nnet = tl.layers.FlattenLayer(net, name='flatten')\nnet = tl.layers.ReshapeLayer(net, shape=(-1, num_steps, int(net.outputs._shape[-1])))\nrnn = tl.layers.RNNLayer(net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=200, n_steps=num_steps, return_last=False, return_seq_2d=True, name='rnn')\nnet = tl.layers.DenseLayer(rnn, n_units=3, name='out')\n\nnet.print_layers()\nnet.print_params(False)\n\nif len(net.all_layers) != 8:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 8:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 562245:\n    <IND>raise Exception(\"params do not match\")\n\n## Bidirectional Synced input and output\n<DED>batch_size = 10\nnum_steps = 5\nvocab_size = 30\nhidden_size = 20\ninput_data = tf.placeholder(tf.int32, [batch_size, num_steps])\nnet = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=vocab_size, embedding_size=hidden_size, name='emb')\nnet = tl.layers.BiRNNLayer(\n    net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, return_last=False, return_seq_2d=False, name='birnn')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[1:3] != [num_steps, hidden_size * 2]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 2:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 5:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 7160:\n    <IND>raise Exception(\"params do not match\")\n\n# n_layer=2\n<DED>net = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=vocab_size, embedding_size=hidden_size, name='emb2')\nnet = tl.layers.BiRNNLayer(\n    net, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=hidden_size, n_steps=num_steps, n_layer=2, return_last=False, return_seq_2d=False, name='birnn2')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[1:3] != [num_steps, hidden_size * 2]:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 2:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 9:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 13720:\n    <IND>raise Exception(\"params do not match\")\n\n## ConvLSTMLayer TODO\n# image_size = 100\n# batch_size = 10\n# num_steps = 5\n# x = tf.placeholder(tf.float32, shape=[batch_size, num_steps, image_size, image_size, 3])\n# net = tl.layers.InputLayer(x, name='in2')\n# net = tl.layers.ConvLSTMLayer(net,\n#             feature_map=1,\n#             filter_size=(3, 3),\n#             cell_fn=tl.layers.BasicConvLSTMCell,\n#             initializer=tf.random_uniform_initializer(-0.1, 0.1),\n#             n_steps=num_steps,\n#             initial_state=None,\n#             return_last=False,\n#             return_seq_2d=False,\n#             name='convlstm')\n\n## Dynamic Synced input and output\n<DED>batch_size = 32\nnum_steps = 5\nvocab_size = 30\nembedding_size = 20\nkeep_prob = 0.8\nis_train = True\ninput_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"input\")\nnin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=vocab_size, embedding_size=embedding_size, name='seq_embedding')\nrnn = tl.layers.DynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=(keep_prob if is_train else None),\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    return_last=False,\n    return_seq_2d=True,\n    name='dynamicrnn')\nnet = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o\")\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = rnn.outputs.get_shape().as_list()\nif shape[-1] != embedding_size:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>shape = net.outputs.get_shape().as_list()\nif shape[-1] != vocab_size:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 3:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 5:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 4510:\n    <IND>raise Exception(\"params do not match\")\n\n# n_layer=3\n<DED>nin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=vocab_size, embedding_size=embedding_size, name='seq_embedding2')\nrnn = tl.layers.DynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=(keep_prob if is_train else None),\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    n_layer=3,\n    return_last=False,\n    return_seq_2d=True,\n    name='dynamicrnn2')\nnet = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o2\")\n\nshape = rnn.outputs.get_shape().as_list()\nif (shape[-1] != embedding_size) or (len(shape) != 2):\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>net = tl.layers.DynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=None,\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    n_layer=3,\n    return_last=False,\n    return_seq_2d=False,\n    name='dynamicrnn3')\n# net = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o3\")\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif (shape[-1] != embedding_size) or (len(shape) != 3):\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>net = tl.layers.DynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=None,\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    n_layer=1,\n    return_last=True,\n    return_seq_2d=False,\n    name='dynamicrnn4')\nnet.print_layers()\nnet.print_params(False)\nshape = net.outputs.get_shape().as_list()\nif (shape[-1] != embedding_size) or (len(shape) != 2):\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>net = tl.layers.DynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=None,\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    n_layer=1,\n    return_last=True,\n    return_seq_2d=True,\n    name='dynamicrnn5')\nnet.print_layers()\nnet.print_params(False)\nshape = net.outputs.get_shape().as_list()\nif (shape[-1] != embedding_size) or (len(shape) != 2):\n    <IND>raise Exception(\"shape do not match\")\n\n## BiDynamic Synced input and output\n<DED>rnn = tl.layers.BiDynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=(keep_prob if is_train else None),\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    return_last=False,\n    return_seq_2d=True,\n    name='bidynamicrnn')\nnet = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o4\")\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = rnn.outputs.get_shape().as_list()\nif shape[-1] != embedding_size * 2:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>shape = net.outputs.get_shape().as_list()\nif shape[-1] != vocab_size:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 3:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 7:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 8390:\n    <IND>raise Exception(\"params do not match\")\n\n# n_layer=2\n<DED>rnn = tl.layers.BiDynamicRNNLayer(\n    nin,\n    cell_fn=tf.contrib.rnn.BasicLSTMCell,\n    n_hidden=embedding_size,\n    dropout=(keep_prob if is_train else None),\n    sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n    n_layer=2,\n    return_last=False,\n    return_seq_2d=True,\n    name='bidynamicrnn2')\nnet = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o5\")\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = rnn.outputs.get_shape().as_list()\nif shape[-1] != embedding_size * 2:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>shape = net.outputs.get_shape().as_list()\nif shape[-1] != vocab_size:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 3:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 11:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 18150:\n    <IND>raise Exception(\"params do not match\")\n\n## Seq2Seq\n<DED>from tensorlayer.layers import EmbeddingInputlayer, Seq2Seq, retrieve_seq_length_op2, DenseLayer\nbatch_size = 32\nencode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"encode_seqs\")\ndecode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"decode_seqs\")\ntarget_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_seqs\")\ntarget_mask = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_mask\")  # tl.prepro.sequences_get_mask()\nwith tf.variable_scope(\"model\"):\n    # for chatbot, you can use the same embedding layer,\n    # for translation, you may want to use 2 seperated embedding layers\n    <IND>with tf.variable_scope(\"embedding\") as vs:\n        <IND>net_encode = EmbeddingInputlayer(inputs=encode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n        vs.reuse_variables()\n        # tl.layers.set_name_reuse(True)\n        net_decode = EmbeddingInputlayer(inputs=decode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n    <DED>net = Seq2Seq(\n        net_encode,\n        net_decode,\n        cell_fn=tf.contrib.rnn.BasicLSTMCell,\n        n_hidden=200,\n        initializer=tf.random_uniform_initializer(-0.1, 0.1),\n        encode_sequence_length=retrieve_seq_length_op2(encode_seqs),\n        decode_sequence_length=retrieve_seq_length_op2(decode_seqs),\n        initial_state_encode=None,\n        dropout=None,\n        n_layer=2,\n        return_seq_2d=True,\n        name='Seq2seq')\n<DED>net = DenseLayer(net, n_units=10000, act=tf.identity, name='oo')\ne_loss = tl.cost.cross_entropy_seq_with_mask(logits=net.outputs, target_seqs=target_seqs, input_mask=target_mask, return_details=False, name='cost')\ny = tf.nn.softmax(net.outputs)\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 10000:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 5:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 11:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 5293200:\n    <IND>raise Exception(\"params do not match\")\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n\nclass Layer_Recurrent_Test(unittest.TestCase):\n    <IND>@classmethod\n    def setUpClass(cls):\n\n        <IND>cls.net1_batch_size = 32\n        cls.net2_batch_size = 10\n        cls.net3_batch_size = 10\n        cls.net5_batch_size = 32\n        cls.net11_batch_size = 32\n\n        cls.vocab_size = 30\n        cls.hidden_size = 20\n        cls.image_size = 100\n        cls.embedding_size = 20\n\n        cls.num_steps = 5\n\n        cls.keep_prob = 0.8\n        cls.is_train = True\n\n        # =============================== RNN encoder ===============================\n\n        input_data = tf.placeholder(tf.int32, [cls.net1_batch_size, cls.num_steps])\n\n        net1 = tl.layers.EmbeddingInputlayer(inputs=input_data, vocabulary_size=cls.vocab_size, embedding_size=cls.hidden_size, name='embed')\n        net1 = tl.layers.DropoutLayer(net1, keep=cls.keep_prob, is_fix=True, is_train=cls.is_train, name='drop1')\n        net1 = tl.layers.RNNLayer(net1, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=cls.hidden_size, n_steps=cls.num_steps, return_last=False, name='lstm1')\n\n        # lstm1 = net1\n\n        net1 = tl.layers.DropoutLayer(net1, keep=cls.keep_prob, is_fix=True, is_train=cls.is_train, name='drop2')\n        net1 = tl.layers.RNNLayer(net1, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=cls.hidden_size, n_steps=cls.num_steps, return_last=True, name='lstm2')\n\n        # lstm2 = net1\n\n        net1 = tl.layers.DropoutLayer(net1, keep=cls.keep_prob, is_fix=True, is_train=cls.is_train, name='drop3')\n        net1 = tl.layers.DenseLayer(net1, n_units=cls.vocab_size, name='output')\n\n        net1.print_layers()\n        net1.print_params(False)\n\n        cls.net1_shape = net1.outputs.get_shape().as_list()\n        cls.net1_layers = net1.all_layers\n        cls.net1_params = net1.all_params\n        cls.net1_n_params = net1.count_params()\n\n        # =============================== CNN+RNN encoder ===============================\n\n        x2 = tf.placeholder(tf.float32, shape=[cls.net2_batch_size, cls.image_size, cls.image_size, 1])\n        net2 = tl.layers.InputLayer(x2, name='in')\n\n        net2 = tl.layers.Conv2d(net2, n_filter=32, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn1')\n        net2 = tl.layers.MaxPool2d(net2, filter_size=(2, 2), strides=(2, 2), name='pool1')\n        net2 = tl.layers.Conv2d(net2, n_filter=10, filter_size=(5, 5), strides=(2, 2), act=tf.nn.relu, name='cnn2')\n        net2 = tl.layers.MaxPool2d(net2, filter_size=(2, 2), strides=(2, 2), name='pool2')\n\n        net2 = tl.layers.FlattenLayer(net2, name='flatten')\n        net2 = tl.layers.ReshapeLayer(net2, shape=(-1, cls.num_steps, int(net2.outputs._shape[-1])))\n\n        rnn = tl.layers.RNNLayer(\n            net2, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=200, n_steps=cls.num_steps, return_last=False, return_seq_2d=True, name='rnn')\n\n        net2 = tl.layers.DenseLayer(rnn, n_units=3, name='out')\n\n        net2.print_layers()\n        net2.print_params(False)\n\n        cls.net2_shape = net2.outputs.get_shape().as_list()\n        cls.net2_layers = net2.all_layers\n        cls.net2_params = net2.all_params\n        cls.net2_n_params = net2.count_params()\n\n        # =============================== Bidirectional Synced input and output ===============================\n\n        x3 = tf.placeholder(tf.int32, [cls.net3_batch_size, cls.num_steps])\n\n        net3 = tl.layers.EmbeddingInputlayer(inputs=x3, vocabulary_size=cls.vocab_size, embedding_size=cls.hidden_size, name='emb')\n        net3 = tl.layers.BiRNNLayer(\n            net3, cell_fn=tf.contrib.rnn.BasicLSTMCell, n_hidden=cls.hidden_size, n_steps=cls.num_steps, return_last=False, return_seq_2d=False, name='birnn')\n\n        net3.print_layers()\n        net3.print_params(False)\n\n        cls.net3_shape = net3.outputs.get_shape().as_list()\n        cls.net3_layers = net3.all_layers\n        cls.net3_params = net3.all_params\n        cls.net3_n_params = net3.count_params()\n\n        # n_layer=2\n        net4 = tl.layers.EmbeddingInputlayer(inputs=x3, vocabulary_size=cls.vocab_size, embedding_size=cls.hidden_size, name='emb2')\n        net4 = tl.layers.BiRNNLayer(\n            net4,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.hidden_size,\n            n_steps=cls.num_steps,\n            n_layer=2,\n            return_last=False,\n            return_seq_2d=False,\n            name='birnn2')\n\n        net4.print_layers()\n        net4.print_params(False)\n\n        cls.net4_shape = net4.outputs.get_shape().as_list()\n        cls.net4_layers = net4.all_layers\n        cls.net4_params = net4.all_params\n        cls.net4_n_params = net4.count_params()\n\n        ## TODO: ConvLSTMLayer\n        # image_size = 100\n        # batch_size = 10\n        # num_steps = 5\n        # x = tf.placeholder(tf.float32, shape=[batch_size, num_steps, image_size, image_size, 3])\n        # net = tl.layers.InputLayer(x, name='in2')\n        # net = tl.layers.ConvLSTMLayer(net,\n        #             feature_map=1,\n        #             filter_size=(3, 3),\n        #             cell_fn=tl.layers.BasicConvLSTMCell,\n        #             initializer=tf.random_uniform_initializer(-0.1, 0.1),\n        #             n_steps=num_steps,\n        #             initial_state=None,\n        #             return_last=False,\n        #             return_seq_2d=False,\n        #             name='convlstm')\n\n        # =============================== Dynamic Synced input and output ===============================\n\n        input_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net5_batch_size, None], name=\"input\")\n        nin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=cls.vocab_size, embedding_size=cls.embedding_size, name='seq_embedding')\n\n        rnn = tl.layers.DynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=(cls.keep_prob if cls.is_train else None),\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            return_last=False,\n            return_seq_2d=True,\n            name='dynamicrnn')\n\n        net5 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o\")\n\n        net5.print_layers()\n        net5.print_params(False)\n\n        cls.net5_shape = net5.outputs.get_shape().as_list()\n        cls.net5_rnn_shape = rnn.outputs.get_shape().as_list()\n        cls.net5_layers = net5.all_layers\n        cls.net5_params = net5.all_params\n        cls.net5_n_params = net5.count_params()\n\n        # n_layer=3\n        nin = tl.layers.EmbeddingInputlayer(inputs=input_seqs, vocabulary_size=cls.vocab_size, embedding_size=cls.embedding_size, name='seq_embedding2')\n        rnn = tl.layers.DynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=(cls.keep_prob if cls.is_train else None),\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            n_layer=3,\n            return_last=False,\n            return_seq_2d=True,\n            name='dynamicrnn2')\n\n        # net6 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o2\")\n\n        net6 = tl.layers.DynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=None,\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            n_layer=3,\n            return_last=False,\n            return_seq_2d=False,\n            name='dynamicrnn3')\n\n        # net6 = tl.layers.DenseLayer(rnn, n_units=vocab_size, name=\"o3\")\n\n        net6.print_layers()\n        net6.print_params(False)\n\n        cls.net6_shape = net6.outputs.get_shape().as_list()\n        cls.net6_rnn_shape = rnn.outputs.get_shape().as_list()\n\n        net7 = tl.layers.DynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=None,\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            n_layer=1,\n            return_last=True,\n            return_seq_2d=False,\n            name='dynamicrnn4')\n\n        net7.print_layers()\n        net7.print_params(False)\n\n        cls.net7_shape = net7.outputs.get_shape().as_list()\n\n        net8 = tl.layers.DynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=None,\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            n_layer=1,\n            return_last=True,\n            return_seq_2d=True,\n            name='dynamicrnn5')\n\n        net8.print_layers()\n        net8.print_params(False)\n\n        cls.net8_shape = net8.outputs.get_shape().as_list()\n\n        # =============================== BiDynamic Synced input and output ===============================\n\n        rnn = tl.layers.BiDynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=(cls.keep_prob if cls.is_train else None),\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            return_last=False,\n            return_seq_2d=True,\n            name='bidynamicrnn')\n\n        net9 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o4\")\n\n        net9.print_layers()\n        net9.print_params(False)\n\n        cls.net9_shape = net9.outputs.get_shape().as_list()\n        cls.net9_rnn_shape = rnn.outputs.get_shape().as_list()\n        cls.net9_layers = net9.all_layers\n        cls.net9_params = net9.all_params\n        cls.net9_n_params = net9.count_params()\n\n        # n_layer=2\n        rnn = tl.layers.BiDynamicRNNLayer(\n            nin,\n            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n            n_hidden=cls.embedding_size,\n            dropout=(cls.keep_prob if cls.is_train else None),\n            sequence_length=tl.layers.retrieve_seq_length_op2(input_seqs),\n            n_layer=2,\n            return_last=False,\n            return_seq_2d=True,\n            name='bidynamicrnn2')\n\n        net10 = tl.layers.DenseLayer(rnn, n_units=cls.vocab_size, name=\"o5\")\n\n        net10.print_layers()\n        net10.print_params(False)\n\n        cls.net10_shape = net10.outputs.get_shape().as_list()\n        cls.net10_rnn_shape = rnn.outputs.get_shape().as_list()\n        cls.net10_layers = net10.all_layers\n        cls.net10_params = net10.all_params\n        cls.net10_n_params = net10.count_params()\n\n        # =============================== Seq2Seq ===============================\n\n        encode_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"encode_seqs\")\n        decode_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"decode_seqs\")\n        # target_seqs = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"target_seqs\")\n        # target_mask = tf.placeholder(dtype=tf.int64, shape=[cls.net11_batch_size, None], name=\"target_mask\")  # tl.prepro.sequences_get_mask()\n\n        with tf.variable_scope(\"model\"):\n            # for chatbot, you can use the same embedding layer,\n            # for translation, you may want to use 2 seperated embedding layers\n\n            <IND>with tf.variable_scope(\"embedding\") as vs:\n                <IND>net_encode = tl.layers.EmbeddingInputlayer(inputs=encode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n                vs.reuse_variables()\n                # tl.layers.set_name_reuse(True)\n                net_decode = tl.layers.EmbeddingInputlayer(inputs=decode_seqs, vocabulary_size=10000, embedding_size=200, name='seq_embed')\n\n            <DED>net11 = tl.layers.Seq2Seq(\n                net_encode,\n                net_decode,\n                cell_fn=tf.contrib.rnn.BasicLSTMCell,\n                n_hidden=200,\n                initializer=tf.random_uniform_initializer(-0.1, 0.1),\n                encode_sequence_length=tl.layers.retrieve_seq_length_op2(encode_seqs),\n                decode_sequence_length=tl.layers.retrieve_seq_length_op2(decode_seqs),\n                initial_state_encode=None,\n                dropout=None,\n                n_layer=2,\n                return_seq_2d=True,\n                name='Seq2seq')\n\n        <DED>net11 = tl.layers.DenseLayer(net11, n_units=10000, act=tf.identity, name='oo')\n\n        # e_loss = tl.cost.cross_entropy_seq_with_mask(logits=net11.outputs, target_seqs=target_seqs, input_mask=target_mask, return_details=False, name='cost')\n        # y = tf.nn.softmax(net11.outputs)\n\n        net11.print_layers()\n        net11.print_params(False)\n\n        cls.net11_shape = net11.outputs.get_shape().as_list()\n        cls.net11_layers = net11.all_layers\n        cls.net11_params = net11.all_params\n        cls.net11_n_params = net11.count_params()\n\n    <DED>@classmethod\n    def tearDownClass(cls):\n        <IND>tf.reset_default_graph()\n\n    <DED>def test_net1(self):\n        <IND>self.assertEqual(self.net1_shape, [self.net1_batch_size, self.vocab_size])\n        self.assertEqual(len(self.net1_layers), 7)\n        self.assertEqual(len(self.net1_params), 7)\n        self.assertEqual(self.net1_n_params, 7790)\n\n    <DED>def test_net2(self):\n        <IND>self.assertEqual(self.net2_shape, [self.net2_batch_size, 3])\n        self.assertEqual(len(self.net2_layers), 8)\n        self.assertEqual(len(self.net2_params), 8)\n        self.assertEqual(self.net2_n_params, 562245)\n\n    <DED>def test_net3(self):\n        <IND>self.assertEqual(self.net3_shape[1:3], [self.num_steps, self.hidden_size * 2])\n        self.assertEqual(len(self.net3_layers), 2)\n        self.assertEqual(len(self.net3_params), 5)\n        self.assertEqual(self.net3_n_params, 7160)\n\n    <DED>def test_net4(self):\n        <IND>self.assertEqual(self.net4_shape[1:3], [self.num_steps, self.hidden_size * 2])\n        self.assertEqual(len(self.net4_layers), 2)\n        self.assertEqual(len(self.net4_params), 9)\n        self.assertEqual(self.net4_n_params, 13720)\n\n    <DED>def test_net5(self):\n        <IND>self.assertEqual(self.net5_shape[-1], self.vocab_size)\n        self.assertEqual(self.net5_rnn_shape[-1], self.embedding_size)\n        self.assertEqual(len(self.net5_layers), 3)\n        self.assertEqual(len(self.net5_params), 5)\n        self.assertEqual(self.net5_n_params, 4510)\n\n    <DED>def test_net6(self):\n        <IND>self.assertEqual(self.net6_shape[-1], self.embedding_size)\n        self.assertEqual(self.net6_rnn_shape[-1], self.embedding_size)\n\n    <DED>def test_net7(self):\n        <IND>self.assertEqual(self.net7_shape[-1], self.embedding_size)\n\n    <DED>def test_net8(self):\n        <IND>self.assertEqual(self.net8_shape[-1], self.embedding_size)\n\n    <DED>def test_net9(self):\n        <IND>self.assertEqual(self.net9_shape[-1], self.vocab_size)\n        self.assertEqual(self.net9_rnn_shape[-1], self.embedding_size * 2)\n        self.assertEqual(len(self.net9_layers), 3)\n        self.assertEqual(len(self.net9_params), 7)\n        self.assertEqual(self.net9_n_params, 8390)\n\n    <DED>def test_net10(self):\n        <IND>self.assertEqual(self.net10_shape[-1], self.vocab_size)\n        self.assertEqual(self.net10_rnn_shape[-1], self.embedding_size * 2)\n        self.assertEqual(len(self.net10_layers), 3)\n        self.assertEqual(len(self.net10_params), 11)\n        self.assertEqual(self.net10_n_params, 18150)\n\n    <DED>def test_net11(self):\n        <IND>self.assertEqual(self.net11_shape[-1], 10000)\n        self.assertEqual(len(self.net11_layers), 5)\n        self.assertEqual(len(self.net11_params), 11)\n        self.assertEqual(self.net11_n_params, 5293200)\n\n\n<DED><DED>if __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    <IND>tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "tensorlayer/TensorLayer",
    "commit": "6f539ad2324ddccc18b6ac39e4a2f4aeb12173a2",
    "filename": "tests/test_layers_stack.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/tensorlayer-TensorLayer/tests/test_layers_stack.py",
    "file_hunks_size": 2,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "tests/test_layers_stack.py:9:0 Incompatible variable type [9]: net is declared to have type `tl.layers.core.InputLayer` but is used as type `tl.layers.stack.StackLayer`.",
    "message": " net is declared to have type `tl.layers.core.InputLayer` but is used as type `tl.layers.stack.StackLayer`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 9,
    "warning_line": "net = tl.layers.StackLayer([net1, net2, net3], axis=1, name='stack')",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import tensorflow as tf\n",
        "source_code_len": 24,
        "target_code": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_len": 87,
        "diff_format": "@@ -1,1 +1,5 @@\n+#!/usr/bin/env python\n+# -*- coding: utf-8 -*-\n+import unittest\n+\n import tensorflow as tf\n",
        "source_code_with_indent": "import tensorflow as tf\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\nimport unittest\n\nimport tensorflow as tf\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\nx = tf.placeholder(tf.float32, shape=[None, 30])\nnet = tl.layers.InputLayer(x, name='input')\nnet1 = tl.layers.DenseLayer(net, n_units=10, name='dense1')\nnet2 = tl.layers.DenseLayer(net, n_units=10, name='dense2')\nnet3 = tl.layers.DenseLayer(net, n_units=10, name='dense3')\nnet = tl.layers.StackLayer([net1, net2, net3], axis=1, name='stack')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 10:\n    raise Exception(\"shape do not match\")\n\nif len(net.all_layers) != 4:\n    raise Exception(\"layers do not match\")\n\nif len(net.all_params) != 6:\n    raise Exception(\"params do not match\")\n\nif net.count_params() != 930:\n    raise Exception(\"params do not match\")\n\nnet = tl.layers.UnStackLayer(net, axis=1, name='unstack')\nfor n in net:\n    print(n, n.outputs)\n    shape = n.outputs.get_shape().as_list()\n    if shape[-1] != 10:\n        raise Exception(\"shape do not match\")\n\n    # n.print_layers()\n    # n.print_params(False)\n\n    if len(n.all_layers) != 4:\n        raise Exception(\"layers do not match\")\n\n    if len(n.all_params) != 6:\n        raise Exception(\"params do not match\")\n\n    if n.count_params() != 930:\n        raise Exception(\"params do not match\")\n",
        "source_code_len": 1213,
        "target_code": "\n\nclass Layer_Stack_Test(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n\n        x = tf.placeholder(tf.float32, shape=[None, 30])\n        net = tl.layers.InputLayer(x, name='input')\n        net1 = tl.layers.DenseLayer(net, n_units=10, name='dense1')\n        net2 = tl.layers.DenseLayer(net, n_units=10, name='dense2')\n        net3 = tl.layers.DenseLayer(net, n_units=10, name='dense3')\n        net = tl.layers.StackLayer([net1, net2, net3], axis=1, name='stack')\n\n        net.print_layers()\n        net.print_params(False)\n\n        cls.net_shape = net.outputs.get_shape().as_list()\n        cls.layers = net.all_layers\n        cls.params = net.all_params\n        cls.n_params = net.count_params()\n\n        cls.net = tl.layers.UnStackLayer(net, axis=1, name='unstack')\n\n    @classmethod\n    def tearDownClass(cls):\n        tf.reset_default_graph()\n\n    def test_net_shape(self):\n        self.assertEqual(self.net_shape[-1], 10)\n\n    def test_layers(self):\n        self.assertEqual(len(self.layers), 4)\n\n    def test_params(self):\n        self.assertEqual(len(self.params), 6)\n        self.assertEqual(self.n_params, 930)\n\n    def test_unstack(self):\n\n        for n in self.net:\n            shape = n.outputs.get_shape().as_list()\n\n            self.assertEqual(shape[-1], 10)\n            self.assertEqual(len(n.all_layers), 4)\n            self.assertEqual(len(n.all_params), 6)\n            self.assertEqual(n.count_params(), 930)\n\n\nif __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_len": 1588,
        "diff_format": "@@ -3,42 +7,54 @@\n \n-x = tf.placeholder(tf.float32, shape=[None, 30])\n-net = tl.layers.InputLayer(x, name='input')\n-net1 = tl.layers.DenseLayer(net, n_units=10, name='dense1')\n-net2 = tl.layers.DenseLayer(net, n_units=10, name='dense2')\n-net3 = tl.layers.DenseLayer(net, n_units=10, name='dense3')\n-net = tl.layers.StackLayer([net1, net2, net3], axis=1, name='stack')\n \n-net.print_layers()\n-net.print_params(False)\n+class Layer_Stack_Test(unittest.TestCase):\n+    @classmethod\n+    def setUpClass(cls):\n \n-shape = net.outputs.get_shape().as_list()\n-if shape[-1] != 10:\n-    raise Exception(\"shape do not match\")\n+        x = tf.placeholder(tf.float32, shape=[None, 30])\n+        net = tl.layers.InputLayer(x, name='input')\n+        net1 = tl.layers.DenseLayer(net, n_units=10, name='dense1')\n+        net2 = tl.layers.DenseLayer(net, n_units=10, name='dense2')\n+        net3 = tl.layers.DenseLayer(net, n_units=10, name='dense3')\n+        net = tl.layers.StackLayer([net1, net2, net3], axis=1, name='stack')\n \n-if len(net.all_layers) != 4:\n-    raise Exception(\"layers do not match\")\n+        net.print_layers()\n+        net.print_params(False)\n \n-if len(net.all_params) != 6:\n-    raise Exception(\"params do not match\")\n+        cls.net_shape = net.outputs.get_shape().as_list()\n+        cls.layers = net.all_layers\n+        cls.params = net.all_params\n+        cls.n_params = net.count_params()\n \n-if net.count_params() != 930:\n-    raise Exception(\"params do not match\")\n+        cls.net = tl.layers.UnStackLayer(net, axis=1, name='unstack')\n \n-net = tl.layers.UnStackLayer(net, axis=1, name='unstack')\n-for n in net:\n-    print(n, n.outputs)\n-    shape = n.outputs.get_shape().as_list()\n-    if shape[-1] != 10:\n-        raise Exception(\"shape do not match\")\n+    @classmethod\n+    def tearDownClass(cls):\n+        tf.reset_default_graph()\n \n-    # n.print_layers()\n-    # n.print_params(False)\n+    def test_net_shape(self):\n+        self.assertEqual(self.net_shape[-1], 10)\n \n-    if len(n.all_layers) != 4:\n-        raise Exception(\"layers do not match\")\n+    def test_layers(self):\n+        self.assertEqual(len(self.layers), 4)\n \n-    if len(n.all_params) != 6:\n-        raise Exception(\"params do not match\")\n+    def test_params(self):\n+        self.assertEqual(len(self.params), 6)\n+        self.assertEqual(self.n_params, 930)\n \n-    if n.count_params() != 930:\n-        raise Exception(\"params do not match\")\n+    def test_unstack(self):\n+\n+        for n in self.net:\n+            shape = n.outputs.get_shape().as_list()\n+\n+            self.assertEqual(shape[-1], 10)\n+            self.assertEqual(len(n.all_layers), 4)\n+            self.assertEqual(len(n.all_params), 6)\n+            self.assertEqual(n.count_params(), 930)\n+\n+\n+if __name__ == '__main__':\n+\n+    # tf.logging.set_verbosity(tf.logging.INFO)\n+    tf.logging.set_verbosity(tf.logging.DEBUG)\n+\n+    unittest.main()\n",
        "source_code_with_indent": "\nx = tf.placeholder(tf.float32, shape=[None, 30])\nnet = tl.layers.InputLayer(x, name='input')\nnet1 = tl.layers.DenseLayer(net, n_units=10, name='dense1')\nnet2 = tl.layers.DenseLayer(net, n_units=10, name='dense2')\nnet3 = tl.layers.DenseLayer(net, n_units=10, name='dense3')\nnet = tl.layers.StackLayer([net1, net2, net3], axis=1, name='stack')\n\nnet.print_layers()\nnet.print_params(False)\n\nshape = net.outputs.get_shape().as_list()\nif shape[-1] != 10:\n    <IND>raise Exception(\"shape do not match\")\n\n<DED>if len(net.all_layers) != 4:\n    <IND>raise Exception(\"layers do not match\")\n\n<DED>if len(net.all_params) != 6:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>if net.count_params() != 930:\n    <IND>raise Exception(\"params do not match\")\n\n<DED>net = tl.layers.UnStackLayer(net, axis=1, name='unstack')\nfor n in net:\n    <IND>print(n, n.outputs)\n    shape = n.outputs.get_shape().as_list()\n    if shape[-1] != 10:\n        <IND>raise Exception(\"shape do not match\")\n\n    # n.print_layers()\n    # n.print_params(False)\n\n    <DED>if len(n.all_layers) != 4:\n        <IND>raise Exception(\"layers do not match\")\n\n    <DED>if len(n.all_params) != 6:\n        <IND>raise Exception(\"params do not match\")\n\n    <DED>if n.count_params() != 930:\n        <IND>raise Exception(\"params do not match\")\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n\nclass Layer_Stack_Test(unittest.TestCase):\n    <IND>@classmethod\n    def setUpClass(cls):\n\n        <IND>x = tf.placeholder(tf.float32, shape=[None, 30])\n        net = tl.layers.InputLayer(x, name='input')\n        net1 = tl.layers.DenseLayer(net, n_units=10, name='dense1')\n        net2 = tl.layers.DenseLayer(net, n_units=10, name='dense2')\n        net3 = tl.layers.DenseLayer(net, n_units=10, name='dense3')\n        net = tl.layers.StackLayer([net1, net2, net3], axis=1, name='stack')\n\n        net.print_layers()\n        net.print_params(False)\n\n        cls.net_shape = net.outputs.get_shape().as_list()\n        cls.layers = net.all_layers\n        cls.params = net.all_params\n        cls.n_params = net.count_params()\n\n        cls.net = tl.layers.UnStackLayer(net, axis=1, name='unstack')\n\n    <DED>@classmethod\n    def tearDownClass(cls):\n        <IND>tf.reset_default_graph()\n\n    <DED>def test_net_shape(self):\n        <IND>self.assertEqual(self.net_shape[-1], 10)\n\n    <DED>def test_layers(self):\n        <IND>self.assertEqual(len(self.layers), 4)\n\n    <DED>def test_params(self):\n        <IND>self.assertEqual(len(self.params), 6)\n        self.assertEqual(self.n_params, 930)\n\n    <DED>def test_unstack(self):\n\n        <IND>for n in self.net:\n            <IND>shape = n.outputs.get_shape().as_list()\n\n            self.assertEqual(shape[-1], 10)\n            self.assertEqual(len(n.all_layers), 4)\n            self.assertEqual(len(n.all_params), 6)\n            self.assertEqual(n.count_params(), 930)\n\n\n<DED><DED><DED>if __name__ == '__main__':\n\n    # tf.logging.set_verbosity(tf.logging.INFO)\n    <IND>tf.logging.set_verbosity(tf.logging.DEBUG)\n\n    unittest.main()\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  }
]