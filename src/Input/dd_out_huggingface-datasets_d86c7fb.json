[
  {
    "project": "huggingface/datasets",
    "commit": "d86c7fb53933f5b7558dd1ce202836d164becca5",
    "filename": "src/datasets/builder.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/huggingface-datasets/src/datasets/builder.py",
    "file_hunks_size": 16,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": true,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "src/datasets/builder.py:179:40 Incompatible parameter type [6]: Expected `str` for 1st positional only parameter to call `url_or_path_join` but got `Union[None, bool, str]`.",
    "message": " Expected `str` for 1st positional only parameter to call `url_or_path_join` but got `Union[None, bool, str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 179,
    "warning_line": "                return url_or_path_join(base_path, data_file) if is_relative_path(data_file) else data_file",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "\n        if self.data_files is not None:\n            m = Hasher()\n            if suffix:\n                m.update(suffix)\n            if isinstance(self.data_files, str):\n                data_files = {\"train\": [self.data_files]}\n            elif isinstance(self.data_files, (tuple, list)):\n                data_files = {\"train\": self.data_files}\n            elif isinstance(self.data_files, dict):\n                data_files = {\n                    str(key): files if isinstance(files, (tuple, list)) else [files]\n                    for key, files in self.data_files.items()\n                }\n            else:\n                raise ValueError(\"Please provide a valid `data_files` in `DatasetBuilder`\")\n\n            def abspath(data_file) -> str:\n                data_file = data_file.as_posix() if isinstance(data_file, PurePath) else str(data_file)\n                return url_or_path_join(base_path, data_file) if is_relative_path(data_file) else data_file\n\n            data_files: Dict[str, List[str]] = map_nested(abspath, data_files)\n            remote_urls = [\n                data_file for key in data_files for data_file in data_files[key] if is_remote_url(data_file)\n            ]\n            etags = dict(\n                zip(\n                    remote_urls,\n                    request_etags(\n                        remote_urls, use_auth_token=use_auth_token, tqdm_kwargs={\"desc\": \"Check remote data files\"}\n                    ),\n                )\n            )\n            for key in sorted(data_files.keys()):\n                m.update(key)\n                for data_file in data_files[key]:\n                    if is_remote_url(data_file):\n                        m.update(data_file)\n                        m.update(etags[data_file])\n                    else:\n                        m.update(os.path.abspath(data_file))\n                        m.update(str(os.path.getmtime(data_file)))\n            suffix = m.hexdigest()\n\n        if custom_features is not None:\n",
        "source_code_len": 1981,
        "target_code": "\n        if custom_features is not None:\n",
        "target_code_len": 41,
        "diff_format": "@@ -160,45 +154,2 @@\n \n-        if self.data_files is not None:\n-            m = Hasher()\n-            if suffix:\n-                m.update(suffix)\n-            if isinstance(self.data_files, str):\n-                data_files = {\"train\": [self.data_files]}\n-            elif isinstance(self.data_files, (tuple, list)):\n-                data_files = {\"train\": self.data_files}\n-            elif isinstance(self.data_files, dict):\n-                data_files = {\n-                    str(key): files if isinstance(files, (tuple, list)) else [files]\n-                    for key, files in self.data_files.items()\n-                }\n-            else:\n-                raise ValueError(\"Please provide a valid `data_files` in `DatasetBuilder`\")\n-\n-            def abspath(data_file) -> str:\n-                data_file = data_file.as_posix() if isinstance(data_file, PurePath) else str(data_file)\n-                return url_or_path_join(base_path, data_file) if is_relative_path(data_file) else data_file\n-\n-            data_files: Dict[str, List[str]] = map_nested(abspath, data_files)\n-            remote_urls = [\n-                data_file for key in data_files for data_file in data_files[key] if is_remote_url(data_file)\n-            ]\n-            etags = dict(\n-                zip(\n-                    remote_urls,\n-                    request_etags(\n-                        remote_urls, use_auth_token=use_auth_token, tqdm_kwargs={\"desc\": \"Check remote data files\"}\n-                    ),\n-                )\n-            )\n-            for key in sorted(data_files.keys()):\n-                m.update(key)\n-                for data_file in data_files[key]:\n-                    if is_remote_url(data_file):\n-                        m.update(data_file)\n-                        m.update(etags[data_file])\n-                    else:\n-                        m.update(os.path.abspath(data_file))\n-                        m.update(str(os.path.getmtime(data_file)))\n-            suffix = m.hexdigest()\n-\n         if custom_features is not None:\n",
        "source_code_with_indent": "\n        <DED><DED>if self.data_files is not None:\n            <IND>m = Hasher()\n            if suffix:\n                <IND>m.update(suffix)\n            <DED>if isinstance(self.data_files, str):\n                <IND>data_files = {\"train\": [self.data_files]}\n            <DED>elif isinstance(self.data_files, (tuple, list)):\n                <IND>data_files = {\"train\": self.data_files}\n            <DED>elif isinstance(self.data_files, dict):\n                <IND>data_files = {\n                    str(key): files if isinstance(files, (tuple, list)) else [files]\n                    for key, files in self.data_files.items()\n                }\n            <DED>else:\n                <IND>raise ValueError(\"Please provide a valid `data_files` in `DatasetBuilder`\")\n\n            <DED>def abspath(data_file) -> str:\n                <IND>data_file = data_file.as_posix() if isinstance(data_file, PurePath) else str(data_file)\n                return url_or_path_join(base_path, data_file) if is_relative_path(data_file) else data_file\n\n            <DED>data_files: Dict[str, List[str]] = map_nested(abspath, data_files)\n            remote_urls = [\n                data_file for key in data_files for data_file in data_files[key] if is_remote_url(data_file)\n            ]\n            etags = dict(\n                zip(\n                    remote_urls,\n                    request_etags(\n                        remote_urls, use_auth_token=use_auth_token, tqdm_kwargs={\"desc\": \"Check remote data files\"}\n                    ),\n                )\n            )\n            for key in sorted(data_files.keys()):\n                <IND>m.update(key)\n                for data_file in data_files[key]:\n                    <IND>if is_remote_url(data_file):\n                        <IND>m.update(data_file)\n                        m.update(etags[data_file])\n                    <DED>else:\n                        <IND>m.update(os.path.abspath(data_file))\n                        m.update(str(os.path.getmtime(data_file)))\n            <DED><DED><DED>suffix = m.hexdigest()\n\n        <DED>if custom_features is not None:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n        <DED><DED>if custom_features is not None:\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  }
]