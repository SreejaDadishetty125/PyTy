[
  {
    "project": "mjpost/sacrebleu",
    "commit": "c36e558e8717a9d6d395a9746924ad631a04cf1d",
    "filename": "sacrebleu/compat.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/mjpost-sacrebleu/sacrebleu/compat.py",
    "file_hunks_size": 1,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "sacrebleu/compat.py:37:4 Incompatible return type [7]: Expected `sacrebleu.metrics.bleu.BLEU` but got `sacrebleu.metrics.bleu.BLEUScore`.",
    "message": " Expected `sacrebleu.metrics.bleu.BLEU` but got `sacrebleu.metrics.bleu.BLEUScore`.",
    "rule_id": "Incompatible return type [7]",
    "warning_line_no": 37,
    "warning_line": "    return metric.corpus_score(",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "                tokenize=DEFAULT_TOKENIZER,\n                use_effective_order=False) -> BLEU:\n    \"\"\"Produces BLEU scores along with its sufficient statistics from a source against one or more references.\n",
        "source_code_len": 207,
        "target_code": "                tokenize=DEFAULT_TOKENIZER,\n                use_effective_order=False) -> BLEUScore:\n    \"\"\"Produces BLEU scores along with its sufficient statistics from a source against one or more references.\n",
        "target_code_len": 212,
        "diff_format": "@@ -19,3 +19,3 @@\n                 tokenize=DEFAULT_TOKENIZER,\n-                use_effective_order=False) -> BLEU:\n+                use_effective_order=False) -> BLEUScore:\n     \"\"\"Produces BLEU scores along with its sufficient statistics from a source against one or more references.\n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "                tokenize=DEFAULT_TOKENIZER,\n                use_effective_order=False) -> BLEU:\n    <IND>",
        "target_code_with_indent": "                tokenize=DEFAULT_TOKENIZER,\n                use_effective_order=False) -> BLEUScore:\n    <IND>"
      }
    ]
  },
  {
    "project": "mjpost/sacrebleu",
    "commit": "c36e558e8717a9d6d395a9746924ad631a04cf1d",
    "filename": "sacrebleu/compat.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/mjpost-sacrebleu/sacrebleu/compat.py",
    "file_hunks_size": 1,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "sacrebleu/compat.py:52:4 Incompatible return type [7]: Expected `sacrebleu.metrics.bleu.BLEUScore` but got `sacrebleu.metrics.bleu.BLEU`.",
    "message": " Expected `sacrebleu.metrics.bleu.BLEUScore` but got `sacrebleu.metrics.bleu.BLEU`.",
    "rule_id": "Incompatible return type [7]",
    "warning_line_no": 52,
    "warning_line": "    return corpus_bleu(",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "                tokenize=DEFAULT_TOKENIZER,\n                use_effective_order=False) -> BLEU:\n    \"\"\"Produces BLEU scores along with its sufficient statistics from a source against one or more references.\n",
        "source_code_len": 207,
        "target_code": "                tokenize=DEFAULT_TOKENIZER,\n                use_effective_order=False) -> BLEUScore:\n    \"\"\"Produces BLEU scores along with its sufficient statistics from a source against one or more references.\n",
        "target_code_len": 212,
        "diff_format": "@@ -19,3 +19,3 @@\n                 tokenize=DEFAULT_TOKENIZER,\n-                use_effective_order=False) -> BLEU:\n+                use_effective_order=False) -> BLEUScore:\n     \"\"\"Produces BLEU scores along with its sufficient statistics from a source against one or more references.\n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "                tokenize=DEFAULT_TOKENIZER,\n                use_effective_order=False) -> BLEU:\n    <IND>",
        "target_code_with_indent": "                tokenize=DEFAULT_TOKENIZER,\n                use_effective_order=False) -> BLEUScore:\n    <IND>"
      }
    ]
  }
]