[
  {
    "project": "deepmipt/DeepPavlov",
    "commit": "a277765bef2979a48bf1365782129d703834f1e9",
    "filename": "deeppavlov/core/models/keras_model.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/deepmipt-DeepPavlov/deeppavlov/core/models/keras_model.py",
    "file_hunks_size": 8,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "deeppavlov/core/models/keras_model.py:184:19 Incompatible variable type [9]: fname is declared to have type `str` but is used as type `None`.",
    "message": " fname is declared to have type `str` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 184,
    "warning_line": "    def save(self, fname: str = None) -> None:",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    def init_model_from_scratch(self, model_name: str):\n        \"\"\"\n        Initialize uncompiled model from scratch with given params\n\n        Args:\n            model_name: name of model function described as a method of this class\n\n        Returns:\n            compiled model with given network and learning parameters\n        \"\"\"\n        log.info(f'[initializing `{self.__class__.__name__}` from scratch as {model_name}]')\n        model_func = getattr(self, model_name, None)\n        if callable(model_func):\n            model = model_func(**self.opt)\n        else:\n            raise AttributeError(\"Model {} is not defined\".format(model_name))\n\n        return model\n\n    @overrides\n    def load(self, model_name: str):\n        \"\"\"\n        Initialize uncompiled model from saved params and weights\n\n        Args:\n            model_name: name of model function described as a method of this class\n\n        Returns:\n            model with loaded weights and network parameters from files\n            but compiled with given learning parameters\n        \"\"\"\n        if self.load_path:\n            if isinstance(self.load_path, Path) and not self.load_path.parent.is_dir():\n                raise ConfigError(\"Provided load path is incorrect!\")\n\n            opt_path = Path(\"{}_opt.json\".format(str(self.load_path.resolve())))\n            weights_path = Path(\"{}.h5\".format(str(self.load_path.resolve())))\n\n            if opt_path.exists() and weights_path.exists():\n\n                log.info(\"[initializing `{}` from saved]\".format(self.__class__.__name__))\n\n                self.opt = read_json(opt_path)\n\n                model_func = getattr(self, model_name, None)\n                if callable(model_func):\n                    model = model_func(**self.opt)\n                else:\n                    raise AttributeError(\"Model {} is not defined\".format(model_name))\n\n                log.info(\"[loading weights from {}]\".format(weights_path.name))\n                model.load_weights(str(weights_path))\n\n                return model\n            else:\n                return self.init_model_from_scratch(model_name)\n        else:\n            log.warning(\"No `load_path` is provided for {}\".format(self.__class__.__name__))\n            return self.init_model_from_scratch(model_name)\n\n    def compile(self, model: Model, optimizer_name: str, loss_name: str,\n                lear_rate: float = 0.01, lear_rate_decay: float = 0.):\n        \"\"\"\n        Compile model with given optimizer and loss\n\n        Args:\n            model: keras uncompiled model\n            optimizer_name: name of optimizer from keras.optimizers\n            loss_name: loss function name (from keras.losses)\n            lear_rate: learning rate.\n            lear_rate_decay: learning rate decay.\n\n        Returns:\n\n        \"\"\"\n        optimizer_func = getattr(keras.optimizers, optimizer_name, None)\n        if callable(optimizer_func):\n            if not (lear_rate is None):\n                if not (lear_rate_decay is None):\n                    self.optimizer = optimizer_func(lr=lear_rate, decay=lear_rate_decay)\n                else:\n                    self.optimizer = optimizer_func(lr=lear_rate)\n            elif not (lear_rate_decay is None):\n                self.optimizer = optimizer_func(decay=lear_rate_decay)\n            else:\n                self.optimizer = optimizer_func()\n        else:\n            raise AttributeError(\"Optimizer {} is not defined in `keras.optimizers`\".format(optimizer_name))\n\n        loss_func = getattr(keras.losses, loss_name, None)\n        if callable(loss_func):\n            loss = loss_func\n        else:\n            raise AttributeError(\"Loss {} is not defined\".format(loss_name))\n\n        model.compile(optimizer=self.optimizer,\n                      loss=loss)\n        return model\n\n    @overrides\n    def save(self, fname: str = None) -> None:\n        \"\"\"\n        Save the model parameters into <<fname>>_opt.json (or <<ser_file>>_opt.json)\n        and model weights into <<fname>>.h5 (or <<ser_file>>.h5)\n        Args:\n            fname: file_path to save model. If not explicitly given seld.opt[\"ser_file\"] will be used\n\n        Returns:\n            None\n        \"\"\"\n        if not fname:\n            fname = self.save_path\n        else:\n            fname = Path(fname).resolve()\n\n        if not fname.parent.is_dir():\n            raise ConfigError(\"Provided save path is incorrect!\")\n        else:\n            opt_path = f\"{fname}_opt.json\"\n            weights_path = f\"{fname}.h5\"\n            log.info(f\"[saving model to {opt_path}]\")\n            self.model.save_weights(weights_path)\n\n        # if model was loaded from one path and saved to another one\n        # then change load_path to save_path for config\n        self.opt[\"epochs_done\"] = self.epochs_done\n        self.opt[\"final_lear_rate\"] = K.eval(self.optimizer.lr) / (1. +\n                                                                   K.eval(self.optimizer.decay) * self.batches_seen)\n\n        if self.opt.get(\"load_path\") and self.opt.get(\"save_path\"):\n            if self.opt.get(\"save_path\") != self.opt.get(\"load_path\"):\n                self.opt[\"load_path\"] = str(self.opt[\"save_path\"])\n        save_json(self.opt, opt_path)\n\n    @abstractmethod\n    def reset(self):\n        pass\n\n    def process_event(self, event_name: str, data: dict):\n        \"\"\"\n",
        "source_code_len": 5344,
        "target_code": "\n    @abstractmethod\n    def load(self, *args, **kwargs) -> None:\n        pass\n\n    @abstractmethod\n    def save(self, *args, **kwargs) -> None:\n        pass\n\n    def process_event(self, event_name: str, data: dict) -> None:\n        \"\"\"\n",
        "target_code_len": 237,
        "diff_format": "@@ -83,141 +70,11 @@\n \n-    def init_model_from_scratch(self, model_name: str):\n-        \"\"\"\n-        Initialize uncompiled model from scratch with given params\n-\n-        Args:\n-            model_name: name of model function described as a method of this class\n-\n-        Returns:\n-            compiled model with given network and learning parameters\n-        \"\"\"\n-        log.info(f'[initializing `{self.__class__.__name__}` from scratch as {model_name}]')\n-        model_func = getattr(self, model_name, None)\n-        if callable(model_func):\n-            model = model_func(**self.opt)\n-        else:\n-            raise AttributeError(\"Model {} is not defined\".format(model_name))\n-\n-        return model\n-\n-    @overrides\n-    def load(self, model_name: str):\n-        \"\"\"\n-        Initialize uncompiled model from saved params and weights\n-\n-        Args:\n-            model_name: name of model function described as a method of this class\n-\n-        Returns:\n-            model with loaded weights and network parameters from files\n-            but compiled with given learning parameters\n-        \"\"\"\n-        if self.load_path:\n-            if isinstance(self.load_path, Path) and not self.load_path.parent.is_dir():\n-                raise ConfigError(\"Provided load path is incorrect!\")\n-\n-            opt_path = Path(\"{}_opt.json\".format(str(self.load_path.resolve())))\n-            weights_path = Path(\"{}.h5\".format(str(self.load_path.resolve())))\n-\n-            if opt_path.exists() and weights_path.exists():\n-\n-                log.info(\"[initializing `{}` from saved]\".format(self.__class__.__name__))\n-\n-                self.opt = read_json(opt_path)\n-\n-                model_func = getattr(self, model_name, None)\n-                if callable(model_func):\n-                    model = model_func(**self.opt)\n-                else:\n-                    raise AttributeError(\"Model {} is not defined\".format(model_name))\n-\n-                log.info(\"[loading weights from {}]\".format(weights_path.name))\n-                model.load_weights(str(weights_path))\n-\n-                return model\n-            else:\n-                return self.init_model_from_scratch(model_name)\n-        else:\n-            log.warning(\"No `load_path` is provided for {}\".format(self.__class__.__name__))\n-            return self.init_model_from_scratch(model_name)\n-\n-    def compile(self, model: Model, optimizer_name: str, loss_name: str,\n-                lear_rate: float = 0.01, lear_rate_decay: float = 0.):\n-        \"\"\"\n-        Compile model with given optimizer and loss\n-\n-        Args:\n-            model: keras uncompiled model\n-            optimizer_name: name of optimizer from keras.optimizers\n-            loss_name: loss function name (from keras.losses)\n-            lear_rate: learning rate.\n-            lear_rate_decay: learning rate decay.\n-\n-        Returns:\n-\n-        \"\"\"\n-        optimizer_func = getattr(keras.optimizers, optimizer_name, None)\n-        if callable(optimizer_func):\n-            if not (lear_rate is None):\n-                if not (lear_rate_decay is None):\n-                    self.optimizer = optimizer_func(lr=lear_rate, decay=lear_rate_decay)\n-                else:\n-                    self.optimizer = optimizer_func(lr=lear_rate)\n-            elif not (lear_rate_decay is None):\n-                self.optimizer = optimizer_func(decay=lear_rate_decay)\n-            else:\n-                self.optimizer = optimizer_func()\n-        else:\n-            raise AttributeError(\"Optimizer {} is not defined in `keras.optimizers`\".format(optimizer_name))\n-\n-        loss_func = getattr(keras.losses, loss_name, None)\n-        if callable(loss_func):\n-            loss = loss_func\n-        else:\n-            raise AttributeError(\"Loss {} is not defined\".format(loss_name))\n-\n-        model.compile(optimizer=self.optimizer,\n-                      loss=loss)\n-        return model\n-\n-    @overrides\n-    def save(self, fname: str = None) -> None:\n-        \"\"\"\n-        Save the model parameters into <<fname>>_opt.json (or <<ser_file>>_opt.json)\n-        and model weights into <<fname>>.h5 (or <<ser_file>>.h5)\n-        Args:\n-            fname: file_path to save model. If not explicitly given seld.opt[\"ser_file\"] will be used\n-\n-        Returns:\n-            None\n-        \"\"\"\n-        if not fname:\n-            fname = self.save_path\n-        else:\n-            fname = Path(fname).resolve()\n-\n-        if not fname.parent.is_dir():\n-            raise ConfigError(\"Provided save path is incorrect!\")\n-        else:\n-            opt_path = f\"{fname}_opt.json\"\n-            weights_path = f\"{fname}.h5\"\n-            log.info(f\"[saving model to {opt_path}]\")\n-            self.model.save_weights(weights_path)\n-\n-        # if model was loaded from one path and saved to another one\n-        # then change load_path to save_path for config\n-        self.opt[\"epochs_done\"] = self.epochs_done\n-        self.opt[\"final_lear_rate\"] = K.eval(self.optimizer.lr) / (1. +\n-                                                                   K.eval(self.optimizer.decay) * self.batches_seen)\n-\n-        if self.opt.get(\"load_path\") and self.opt.get(\"save_path\"):\n-            if self.opt.get(\"save_path\") != self.opt.get(\"load_path\"):\n-                self.opt[\"load_path\"] = str(self.opt[\"save_path\"])\n-        save_json(self.opt, opt_path)\n+    @abstractmethod\n+    def load(self, *args, **kwargs) -> None:\n+        pass\n \n     @abstractmethod\n-    def reset(self):\n+    def save(self, *args, **kwargs) -> None:\n         pass\n \n-    def process_event(self, event_name: str, data: dict):\n+    def process_event(self, event_name: str, data: dict) -> None:\n         \"\"\"\n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "\n    <DED>def init_model_from_scratch(self, model_name: str):\n        <IND>\"\"\"\n        Initialize uncompiled model from scratch with given params\n\n        Args:\n            model_name: name of model function described as a method of this class\n\n        Returns:\n            compiled model with given network and learning parameters\n        \"\"\"\n        log.info(f'[initializing `{self.__class__.__name__}` from scratch as {model_name}]')\n        model_func = getattr(self, model_name, None)\n        if callable(model_func):\n            <IND>model = model_func(**self.opt)\n        <DED>else:\n            <IND>raise AttributeError(\"Model {} is not defined\".format(model_name))\n\n        <DED>return model\n\n    <DED>@overrides\n    def load(self, model_name: str):\n        <IND>\"\"\"\n        Initialize uncompiled model from saved params and weights\n\n        Args:\n            model_name: name of model function described as a method of this class\n\n        Returns:\n            model with loaded weights and network parameters from files\n            but compiled with given learning parameters\n        \"\"\"\n        if self.load_path:\n            <IND>if isinstance(self.load_path, Path) and not self.load_path.parent.is_dir():\n                <IND>raise ConfigError(\"Provided load path is incorrect!\")\n\n            <DED>opt_path = Path(\"{}_opt.json\".format(str(self.load_path.resolve())))\n            weights_path = Path(\"{}.h5\".format(str(self.load_path.resolve())))\n\n            if opt_path.exists() and weights_path.exists():\n\n                <IND>log.info(\"[initializing `{}` from saved]\".format(self.__class__.__name__))\n\n                self.opt = read_json(opt_path)\n\n                model_func = getattr(self, model_name, None)\n                if callable(model_func):\n                    <IND>model = model_func(**self.opt)\n                <DED>else:\n                    <IND>raise AttributeError(\"Model {} is not defined\".format(model_name))\n\n                <DED>log.info(\"[loading weights from {}]\".format(weights_path.name))\n                model.load_weights(str(weights_path))\n\n                return model\n            <DED>else:\n                <IND>return self.init_model_from_scratch(model_name)\n        <DED><DED>else:\n            <IND>log.warning(\"No `load_path` is provided for {}\".format(self.__class__.__name__))\n            return self.init_model_from_scratch(model_name)\n\n    <DED><DED>def compile(self, model: Model, optimizer_name: str, loss_name: str,\n                lear_rate: float = 0.01, lear_rate_decay: float = 0.):\n        <IND>\"\"\"\n        Compile model with given optimizer and loss\n\n        Args:\n            model: keras uncompiled model\n            optimizer_name: name of optimizer from keras.optimizers\n            loss_name: loss function name (from keras.losses)\n            lear_rate: learning rate.\n            lear_rate_decay: learning rate decay.\n\n        Returns:\n\n        \"\"\"\n        optimizer_func = getattr(keras.optimizers, optimizer_name, None)\n        if callable(optimizer_func):\n            <IND>if not (lear_rate is None):\n                <IND>if not (lear_rate_decay is None):\n                    <IND>self.optimizer = optimizer_func(lr=lear_rate, decay=lear_rate_decay)\n                <DED>else:\n                    <IND>self.optimizer = optimizer_func(lr=lear_rate)\n            <DED><DED>elif not (lear_rate_decay is None):\n                <IND>self.optimizer = optimizer_func(decay=lear_rate_decay)\n            <DED>else:\n                <IND>self.optimizer = optimizer_func()\n        <DED><DED>else:\n            <IND>raise AttributeError(\"Optimizer {} is not defined in `keras.optimizers`\".format(optimizer_name))\n\n        <DED>loss_func = getattr(keras.losses, loss_name, None)\n        if callable(loss_func):\n            <IND>loss = loss_func\n        <DED>else:\n            <IND>raise AttributeError(\"Loss {} is not defined\".format(loss_name))\n\n        <DED>model.compile(optimizer=self.optimizer,\n                      loss=loss)\n        return model\n\n    <DED>@overrides\n    def save(self, fname: str = None) -> None:\n        <IND>\"\"\"\n        Save the model parameters into <<fname>>_opt.json (or <<ser_file>>_opt.json)\n        and model weights into <<fname>>.h5 (or <<ser_file>>.h5)\n        Args:\n            fname: file_path to save model. If not explicitly given seld.opt[\"ser_file\"] will be used\n\n        Returns:\n            None\n        \"\"\"\n        if not fname:\n            <IND>fname = self.save_path\n        <DED>else:\n            <IND>fname = Path(fname).resolve()\n\n        <DED>if not fname.parent.is_dir():\n            <IND>raise ConfigError(\"Provided save path is incorrect!\")\n        <DED>else:\n            <IND>opt_path = f\"{fname}_opt.json\"\n            weights_path = f\"{fname}.h5\"\n            log.info(f\"[saving model to {opt_path}]\")\n            self.model.save_weights(weights_path)\n\n        # if model was loaded from one path and saved to another one\n        # then change load_path to save_path for config\n        <DED>self.opt[\"epochs_done\"] = self.epochs_done\n        self.opt[\"final_lear_rate\"] = K.eval(self.optimizer.lr) / (1. +\n                                                                   K.eval(self.optimizer.decay) * self.batches_seen)\n\n        if self.opt.get(\"load_path\") and self.opt.get(\"save_path\"):\n            <IND>if self.opt.get(\"save_path\") != self.opt.get(\"load_path\"):\n                <IND>self.opt[\"load_path\"] = str(self.opt[\"save_path\"])\n        <DED><DED>save_json(self.opt, opt_path)\n\n    <DED>@abstractmethod\n    def reset(self):\n        <IND>pass\n\n    <DED>def process_event(self, event_name: str, data: dict):\n        <IND>",
        "target_code_with_indent": "\n    <DED>@abstractmethod\n    def load(self, *args, **kwargs) -> None:\n        <IND>pass\n\n    <DED>@abstractmethod\n    def save(self, *args, **kwargs) -> None:\n        <IND>pass\n\n    <DED>def process_event(self, event_name: str, data: dict) -> None:\n        <IND>"
      }
    ]
  },
  {
    "project": "deepmipt/DeepPavlov",
    "commit": "a277765bef2979a48bf1365782129d703834f1e9",
    "filename": "deeppavlov/core/models/keras_model.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/deepmipt-DeepPavlov/deeppavlov/core/models/keras_model.py",
    "file_hunks_size": 8,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "deeppavlov/core/models/keras_model.py:197:12 Incompatible variable type [9]: fname is declared to have type `str` but is used as type `Path`.",
    "message": " fname is declared to have type `str` but is used as type `Path`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 197,
    "warning_line": "            fname = Path(fname).resolve()",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    def init_model_from_scratch(self, model_name: str):\n        \"\"\"\n        Initialize uncompiled model from scratch with given params\n\n        Args:\n            model_name: name of model function described as a method of this class\n\n        Returns:\n            compiled model with given network and learning parameters\n        \"\"\"\n        log.info(f'[initializing `{self.__class__.__name__}` from scratch as {model_name}]')\n        model_func = getattr(self, model_name, None)\n        if callable(model_func):\n            model = model_func(**self.opt)\n        else:\n            raise AttributeError(\"Model {} is not defined\".format(model_name))\n\n        return model\n\n    @overrides\n    def load(self, model_name: str):\n        \"\"\"\n        Initialize uncompiled model from saved params and weights\n\n        Args:\n            model_name: name of model function described as a method of this class\n\n        Returns:\n            model with loaded weights and network parameters from files\n            but compiled with given learning parameters\n        \"\"\"\n        if self.load_path:\n            if isinstance(self.load_path, Path) and not self.load_path.parent.is_dir():\n                raise ConfigError(\"Provided load path is incorrect!\")\n\n            opt_path = Path(\"{}_opt.json\".format(str(self.load_path.resolve())))\n            weights_path = Path(\"{}.h5\".format(str(self.load_path.resolve())))\n\n            if opt_path.exists() and weights_path.exists():\n\n                log.info(\"[initializing `{}` from saved]\".format(self.__class__.__name__))\n\n                self.opt = read_json(opt_path)\n\n                model_func = getattr(self, model_name, None)\n                if callable(model_func):\n                    model = model_func(**self.opt)\n                else:\n                    raise AttributeError(\"Model {} is not defined\".format(model_name))\n\n                log.info(\"[loading weights from {}]\".format(weights_path.name))\n                model.load_weights(str(weights_path))\n\n                return model\n            else:\n                return self.init_model_from_scratch(model_name)\n        else:\n            log.warning(\"No `load_path` is provided for {}\".format(self.__class__.__name__))\n            return self.init_model_from_scratch(model_name)\n\n    def compile(self, model: Model, optimizer_name: str, loss_name: str,\n                lear_rate: float = 0.01, lear_rate_decay: float = 0.):\n        \"\"\"\n        Compile model with given optimizer and loss\n\n        Args:\n            model: keras uncompiled model\n            optimizer_name: name of optimizer from keras.optimizers\n            loss_name: loss function name (from keras.losses)\n            lear_rate: learning rate.\n            lear_rate_decay: learning rate decay.\n\n        Returns:\n\n        \"\"\"\n        optimizer_func = getattr(keras.optimizers, optimizer_name, None)\n        if callable(optimizer_func):\n            if not (lear_rate is None):\n                if not (lear_rate_decay is None):\n                    self.optimizer = optimizer_func(lr=lear_rate, decay=lear_rate_decay)\n                else:\n                    self.optimizer = optimizer_func(lr=lear_rate)\n            elif not (lear_rate_decay is None):\n                self.optimizer = optimizer_func(decay=lear_rate_decay)\n            else:\n                self.optimizer = optimizer_func()\n        else:\n            raise AttributeError(\"Optimizer {} is not defined in `keras.optimizers`\".format(optimizer_name))\n\n        loss_func = getattr(keras.losses, loss_name, None)\n        if callable(loss_func):\n            loss = loss_func\n        else:\n            raise AttributeError(\"Loss {} is not defined\".format(loss_name))\n\n        model.compile(optimizer=self.optimizer,\n                      loss=loss)\n        return model\n\n    @overrides\n    def save(self, fname: str = None) -> None:\n        \"\"\"\n        Save the model parameters into <<fname>>_opt.json (or <<ser_file>>_opt.json)\n        and model weights into <<fname>>.h5 (or <<ser_file>>.h5)\n        Args:\n            fname: file_path to save model. If not explicitly given seld.opt[\"ser_file\"] will be used\n\n        Returns:\n            None\n        \"\"\"\n        if not fname:\n            fname = self.save_path\n        else:\n            fname = Path(fname).resolve()\n\n        if not fname.parent.is_dir():\n            raise ConfigError(\"Provided save path is incorrect!\")\n        else:\n            opt_path = f\"{fname}_opt.json\"\n            weights_path = f\"{fname}.h5\"\n            log.info(f\"[saving model to {opt_path}]\")\n            self.model.save_weights(weights_path)\n\n        # if model was loaded from one path and saved to another one\n        # then change load_path to save_path for config\n        self.opt[\"epochs_done\"] = self.epochs_done\n        self.opt[\"final_lear_rate\"] = K.eval(self.optimizer.lr) / (1. +\n                                                                   K.eval(self.optimizer.decay) * self.batches_seen)\n\n        if self.opt.get(\"load_path\") and self.opt.get(\"save_path\"):\n            if self.opt.get(\"save_path\") != self.opt.get(\"load_path\"):\n                self.opt[\"load_path\"] = str(self.opt[\"save_path\"])\n        save_json(self.opt, opt_path)\n\n    @abstractmethod\n    def reset(self):\n        pass\n\n    def process_event(self, event_name: str, data: dict):\n        \"\"\"\n",
        "source_code_len": 5344,
        "target_code": "\n    @abstractmethod\n    def load(self, *args, **kwargs) -> None:\n        pass\n\n    @abstractmethod\n    def save(self, *args, **kwargs) -> None:\n        pass\n\n    def process_event(self, event_name: str, data: dict) -> None:\n        \"\"\"\n",
        "target_code_len": 237,
        "diff_format": "@@ -83,141 +70,11 @@\n \n-    def init_model_from_scratch(self, model_name: str):\n-        \"\"\"\n-        Initialize uncompiled model from scratch with given params\n-\n-        Args:\n-            model_name: name of model function described as a method of this class\n-\n-        Returns:\n-            compiled model with given network and learning parameters\n-        \"\"\"\n-        log.info(f'[initializing `{self.__class__.__name__}` from scratch as {model_name}]')\n-        model_func = getattr(self, model_name, None)\n-        if callable(model_func):\n-            model = model_func(**self.opt)\n-        else:\n-            raise AttributeError(\"Model {} is not defined\".format(model_name))\n-\n-        return model\n-\n-    @overrides\n-    def load(self, model_name: str):\n-        \"\"\"\n-        Initialize uncompiled model from saved params and weights\n-\n-        Args:\n-            model_name: name of model function described as a method of this class\n-\n-        Returns:\n-            model with loaded weights and network parameters from files\n-            but compiled with given learning parameters\n-        \"\"\"\n-        if self.load_path:\n-            if isinstance(self.load_path, Path) and not self.load_path.parent.is_dir():\n-                raise ConfigError(\"Provided load path is incorrect!\")\n-\n-            opt_path = Path(\"{}_opt.json\".format(str(self.load_path.resolve())))\n-            weights_path = Path(\"{}.h5\".format(str(self.load_path.resolve())))\n-\n-            if opt_path.exists() and weights_path.exists():\n-\n-                log.info(\"[initializing `{}` from saved]\".format(self.__class__.__name__))\n-\n-                self.opt = read_json(opt_path)\n-\n-                model_func = getattr(self, model_name, None)\n-                if callable(model_func):\n-                    model = model_func(**self.opt)\n-                else:\n-                    raise AttributeError(\"Model {} is not defined\".format(model_name))\n-\n-                log.info(\"[loading weights from {}]\".format(weights_path.name))\n-                model.load_weights(str(weights_path))\n-\n-                return model\n-            else:\n-                return self.init_model_from_scratch(model_name)\n-        else:\n-            log.warning(\"No `load_path` is provided for {}\".format(self.__class__.__name__))\n-            return self.init_model_from_scratch(model_name)\n-\n-    def compile(self, model: Model, optimizer_name: str, loss_name: str,\n-                lear_rate: float = 0.01, lear_rate_decay: float = 0.):\n-        \"\"\"\n-        Compile model with given optimizer and loss\n-\n-        Args:\n-            model: keras uncompiled model\n-            optimizer_name: name of optimizer from keras.optimizers\n-            loss_name: loss function name (from keras.losses)\n-            lear_rate: learning rate.\n-            lear_rate_decay: learning rate decay.\n-\n-        Returns:\n-\n-        \"\"\"\n-        optimizer_func = getattr(keras.optimizers, optimizer_name, None)\n-        if callable(optimizer_func):\n-            if not (lear_rate is None):\n-                if not (lear_rate_decay is None):\n-                    self.optimizer = optimizer_func(lr=lear_rate, decay=lear_rate_decay)\n-                else:\n-                    self.optimizer = optimizer_func(lr=lear_rate)\n-            elif not (lear_rate_decay is None):\n-                self.optimizer = optimizer_func(decay=lear_rate_decay)\n-            else:\n-                self.optimizer = optimizer_func()\n-        else:\n-            raise AttributeError(\"Optimizer {} is not defined in `keras.optimizers`\".format(optimizer_name))\n-\n-        loss_func = getattr(keras.losses, loss_name, None)\n-        if callable(loss_func):\n-            loss = loss_func\n-        else:\n-            raise AttributeError(\"Loss {} is not defined\".format(loss_name))\n-\n-        model.compile(optimizer=self.optimizer,\n-                      loss=loss)\n-        return model\n-\n-    @overrides\n-    def save(self, fname: str = None) -> None:\n-        \"\"\"\n-        Save the model parameters into <<fname>>_opt.json (or <<ser_file>>_opt.json)\n-        and model weights into <<fname>>.h5 (or <<ser_file>>.h5)\n-        Args:\n-            fname: file_path to save model. If not explicitly given seld.opt[\"ser_file\"] will be used\n-\n-        Returns:\n-            None\n-        \"\"\"\n-        if not fname:\n-            fname = self.save_path\n-        else:\n-            fname = Path(fname).resolve()\n-\n-        if not fname.parent.is_dir():\n-            raise ConfigError(\"Provided save path is incorrect!\")\n-        else:\n-            opt_path = f\"{fname}_opt.json\"\n-            weights_path = f\"{fname}.h5\"\n-            log.info(f\"[saving model to {opt_path}]\")\n-            self.model.save_weights(weights_path)\n-\n-        # if model was loaded from one path and saved to another one\n-        # then change load_path to save_path for config\n-        self.opt[\"epochs_done\"] = self.epochs_done\n-        self.opt[\"final_lear_rate\"] = K.eval(self.optimizer.lr) / (1. +\n-                                                                   K.eval(self.optimizer.decay) * self.batches_seen)\n-\n-        if self.opt.get(\"load_path\") and self.opt.get(\"save_path\"):\n-            if self.opt.get(\"save_path\") != self.opt.get(\"load_path\"):\n-                self.opt[\"load_path\"] = str(self.opt[\"save_path\"])\n-        save_json(self.opt, opt_path)\n+    @abstractmethod\n+    def load(self, *args, **kwargs) -> None:\n+        pass\n \n     @abstractmethod\n-    def reset(self):\n+    def save(self, *args, **kwargs) -> None:\n         pass\n \n-    def process_event(self, event_name: str, data: dict):\n+    def process_event(self, event_name: str, data: dict) -> None:\n         \"\"\"\n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "\n    <DED>def init_model_from_scratch(self, model_name: str):\n        <IND>\"\"\"\n        Initialize uncompiled model from scratch with given params\n\n        Args:\n            model_name: name of model function described as a method of this class\n\n        Returns:\n            compiled model with given network and learning parameters\n        \"\"\"\n        log.info(f'[initializing `{self.__class__.__name__}` from scratch as {model_name}]')\n        model_func = getattr(self, model_name, None)\n        if callable(model_func):\n            <IND>model = model_func(**self.opt)\n        <DED>else:\n            <IND>raise AttributeError(\"Model {} is not defined\".format(model_name))\n\n        <DED>return model\n\n    <DED>@overrides\n    def load(self, model_name: str):\n        <IND>\"\"\"\n        Initialize uncompiled model from saved params and weights\n\n        Args:\n            model_name: name of model function described as a method of this class\n\n        Returns:\n            model with loaded weights and network parameters from files\n            but compiled with given learning parameters\n        \"\"\"\n        if self.load_path:\n            <IND>if isinstance(self.load_path, Path) and not self.load_path.parent.is_dir():\n                <IND>raise ConfigError(\"Provided load path is incorrect!\")\n\n            <DED>opt_path = Path(\"{}_opt.json\".format(str(self.load_path.resolve())))\n            weights_path = Path(\"{}.h5\".format(str(self.load_path.resolve())))\n\n            if opt_path.exists() and weights_path.exists():\n\n                <IND>log.info(\"[initializing `{}` from saved]\".format(self.__class__.__name__))\n\n                self.opt = read_json(opt_path)\n\n                model_func = getattr(self, model_name, None)\n                if callable(model_func):\n                    <IND>model = model_func(**self.opt)\n                <DED>else:\n                    <IND>raise AttributeError(\"Model {} is not defined\".format(model_name))\n\n                <DED>log.info(\"[loading weights from {}]\".format(weights_path.name))\n                model.load_weights(str(weights_path))\n\n                return model\n            <DED>else:\n                <IND>return self.init_model_from_scratch(model_name)\n        <DED><DED>else:\n            <IND>log.warning(\"No `load_path` is provided for {}\".format(self.__class__.__name__))\n            return self.init_model_from_scratch(model_name)\n\n    <DED><DED>def compile(self, model: Model, optimizer_name: str, loss_name: str,\n                lear_rate: float = 0.01, lear_rate_decay: float = 0.):\n        <IND>\"\"\"\n        Compile model with given optimizer and loss\n\n        Args:\n            model: keras uncompiled model\n            optimizer_name: name of optimizer from keras.optimizers\n            loss_name: loss function name (from keras.losses)\n            lear_rate: learning rate.\n            lear_rate_decay: learning rate decay.\n\n        Returns:\n\n        \"\"\"\n        optimizer_func = getattr(keras.optimizers, optimizer_name, None)\n        if callable(optimizer_func):\n            <IND>if not (lear_rate is None):\n                <IND>if not (lear_rate_decay is None):\n                    <IND>self.optimizer = optimizer_func(lr=lear_rate, decay=lear_rate_decay)\n                <DED>else:\n                    <IND>self.optimizer = optimizer_func(lr=lear_rate)\n            <DED><DED>elif not (lear_rate_decay is None):\n                <IND>self.optimizer = optimizer_func(decay=lear_rate_decay)\n            <DED>else:\n                <IND>self.optimizer = optimizer_func()\n        <DED><DED>else:\n            <IND>raise AttributeError(\"Optimizer {} is not defined in `keras.optimizers`\".format(optimizer_name))\n\n        <DED>loss_func = getattr(keras.losses, loss_name, None)\n        if callable(loss_func):\n            <IND>loss = loss_func\n        <DED>else:\n            <IND>raise AttributeError(\"Loss {} is not defined\".format(loss_name))\n\n        <DED>model.compile(optimizer=self.optimizer,\n                      loss=loss)\n        return model\n\n    <DED>@overrides\n    def save(self, fname: str = None) -> None:\n        <IND>\"\"\"\n        Save the model parameters into <<fname>>_opt.json (or <<ser_file>>_opt.json)\n        and model weights into <<fname>>.h5 (or <<ser_file>>.h5)\n        Args:\n            fname: file_path to save model. If not explicitly given seld.opt[\"ser_file\"] will be used\n\n        Returns:\n            None\n        \"\"\"\n        if not fname:\n            <IND>fname = self.save_path\n        <DED>else:\n            <IND>fname = Path(fname).resolve()\n\n        <DED>if not fname.parent.is_dir():\n            <IND>raise ConfigError(\"Provided save path is incorrect!\")\n        <DED>else:\n            <IND>opt_path = f\"{fname}_opt.json\"\n            weights_path = f\"{fname}.h5\"\n            log.info(f\"[saving model to {opt_path}]\")\n            self.model.save_weights(weights_path)\n\n        # if model was loaded from one path and saved to another one\n        # then change load_path to save_path for config\n        <DED>self.opt[\"epochs_done\"] = self.epochs_done\n        self.opt[\"final_lear_rate\"] = K.eval(self.optimizer.lr) / (1. +\n                                                                   K.eval(self.optimizer.decay) * self.batches_seen)\n\n        if self.opt.get(\"load_path\") and self.opt.get(\"save_path\"):\n            <IND>if self.opt.get(\"save_path\") != self.opt.get(\"load_path\"):\n                <IND>self.opt[\"load_path\"] = str(self.opt[\"save_path\"])\n        <DED><DED>save_json(self.opt, opt_path)\n\n    <DED>@abstractmethod\n    def reset(self):\n        <IND>pass\n\n    <DED>def process_event(self, event_name: str, data: dict):\n        <IND>",
        "target_code_with_indent": "\n    <DED>@abstractmethod\n    def load(self, *args, **kwargs) -> None:\n        <IND>pass\n\n    <DED>@abstractmethod\n    def save(self, *args, **kwargs) -> None:\n        <IND>pass\n\n    <DED>def process_event(self, event_name: str, data: dict) -> None:\n        <IND>"
      }
    ]
  },
  {
    "project": "deepmipt/DeepPavlov",
    "commit": "a277765bef2979a48bf1365782129d703834f1e9",
    "filename": "deeppavlov/models/morpho_tagger/tagger.py",
    "min_patch_found": false,
    "full_warning_msg": "deeppavlov/models/morpho_tagger/tagger.py:40:23 Incompatible variable type [9]: save_path is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/deepmipt-DeepPavlov/deeppavlov/models/morpho_tagger/tagger.py'",
    "dd_fail": true
  },
  {
    "project": "deepmipt/DeepPavlov",
    "commit": "a277765bef2979a48bf1365782129d703834f1e9",
    "filename": "deeppavlov/models/morpho_tagger/tagger.py",
    "min_patch_found": false,
    "full_warning_msg": "deeppavlov/models/morpho_tagger/tagger.py:40:46 Incompatible variable type [9]: load_path is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/deepmipt-DeepPavlov/deeppavlov/models/morpho_tagger/tagger.py'",
    "dd_fail": true
  },
  {
    "project": "deepmipt/DeepPavlov",
    "commit": "a277765bef2979a48bf1365782129d703834f1e9",
    "filename": "deeppavlov/models/morpho_tagger/tagger.py",
    "min_patch_found": false,
    "full_warning_msg": "deeppavlov/models/morpho_tagger/tagger.py:40:69 Incompatible variable type [9]: mode is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/deepmipt-DeepPavlov/deeppavlov/models/morpho_tagger/tagger.py'",
    "dd_fail": true
  },
  {
    "project": "deepmipt/DeepPavlov",
    "commit": "a277765bef2979a48bf1365782129d703834f1e9",
    "filename": "deeppavlov/models/preprocessors/capitalization.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/deepmipt-DeepPavlov/deeppavlov/models/preprocessors/capitalization.py",
    "file_hunks_size": 5,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "deeppavlov/models/preprocessors/capitalization.py:77:17 Incompatible variable type [9]: append_case is declared to have type `str` but is used as type `None`.",
    "message": " append_case is declared to have type `str` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 77,
    "warning_line": "                 append_case: str = None) -> Tuple[str]:",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "import re\nfrom typing import Union, Tuple, List\n\n",
        "source_code_len": 49,
        "target_code": "import re\nfrom typing import Union, Tuple, List, Optional\n\n",
        "target_code_len": 59,
        "diff_format": "@@ -16,3 +16,3 @@\n import re\n-from typing import Union, Tuple, List\n+from typing import Union, Tuple, List, Optional\n \n",
        "source_code_with_indent": "import re\nfrom typing import Union, Tuple, List\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "import re\nfrom typing import Union, Tuple, List, Optional\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "def process_word(word: str, to_lower: bool = False,\n                 append_case: str = None) -> Tuple[str]:\n    \"\"\"Converts word to a tuple of symbols, optionally converts it to lowercase\n",
        "source_code_len": 189,
        "target_code": "def process_word(word: str, to_lower: bool = False,\n                 append_case: Optional[str] = None) -> Tuple[str]:\n    \"\"\"Converts word to a tuple of symbols, optionally converts it to lowercase\n",
        "target_code_len": 199,
        "diff_format": "@@ -76,3 +76,3 @@\n def process_word(word: str, to_lower: bool = False,\n-                 append_case: str = None) -> Tuple[str]:\n+                 append_case: Optional[str] = None) -> Tuple[str]:\n     \"\"\"Converts word to a tuple of symbols, optionally converts it to lowercase\n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "<DED><DED><DED>def process_word(word: str, to_lower: bool = False,\n                 append_case: str = None) -> Tuple[str]:\n    <IND>",
        "target_code_with_indent": "<DED><DED><DED>def process_word(word: str, to_lower: bool = False,\n                 append_case: Optional[str] = None) -> Tuple[str]:\n    <IND>"
      }
    ]
  },
  {
    "project": "deepmipt/DeepPavlov",
    "commit": "a277765bef2979a48bf1365782129d703834f1e9",
    "filename": "deeppavlov/models/ranking/keras_siamese_model.py",
    "min_patch_found": false,
    "full_warning_msg": "deeppavlov/models/ranking/keras_siamese_model.py:78:4 Inconsistent override [14]: `deeppavlov.models.ranking.keras_siamese_model.KerasSiameseModel.compile` overrides method defined in `KerasModel` inconsistently. Could not find parameter `lear_rate` in overriding signature.",
    "exception": "PatchSet should only have 1 Patch, but it has 0",
    "dd_fail": true
  },
  {
    "project": "deepmipt/DeepPavlov",
    "commit": "a277765bef2979a48bf1365782129d703834f1e9",
    "filename": "deeppavlov/models/ranking/keras_siamese_model.py",
    "min_patch_found": false,
    "full_warning_msg": "deeppavlov/models/ranking/keras_siamese_model.py:78:4 Inconsistent override [14]: `deeppavlov.models.ranking.keras_siamese_model.KerasSiameseModel.compile` overrides method defined in `KerasModel` inconsistently. Could not find parameter `lear_rate_decay` in overriding signature.",
    "exception": "PatchSet should only have 1 Patch, but it has 0",
    "dd_fail": true
  },
  {
    "project": "deepmipt/DeepPavlov",
    "commit": "a277765bef2979a48bf1365782129d703834f1e9",
    "filename": "deeppavlov/models/ranking/keras_siamese_model.py",
    "min_patch_found": false,
    "full_warning_msg": "deeppavlov/models/ranking/keras_siamese_model.py:78:4 Inconsistent override [14]: `deeppavlov.models.ranking.keras_siamese_model.KerasSiameseModel.compile` overrides method defined in `KerasModel` inconsistently. Could not find parameter `loss_name` in overriding signature.",
    "exception": "PatchSet should only have 1 Patch, but it has 0",
    "dd_fail": true
  },
  {
    "project": "deepmipt/DeepPavlov",
    "commit": "a277765bef2979a48bf1365782129d703834f1e9",
    "filename": "deeppavlov/models/ranking/keras_siamese_model.py",
    "min_patch_found": false,
    "full_warning_msg": "deeppavlov/models/ranking/keras_siamese_model.py:78:4 Inconsistent override [14]: `deeppavlov.models.ranking.keras_siamese_model.KerasSiameseModel.compile` overrides method defined in `KerasModel` inconsistently. Could not find parameter `model` in overriding signature.",
    "exception": "PatchSet should only have 1 Patch, but it has 0",
    "dd_fail": true
  },
  {
    "project": "deepmipt/DeepPavlov",
    "commit": "a277765bef2979a48bf1365782129d703834f1e9",
    "filename": "deeppavlov/models/ranking/keras_siamese_model.py",
    "min_patch_found": false,
    "full_warning_msg": "deeppavlov/models/ranking/keras_siamese_model.py:78:4 Inconsistent override [14]: `deeppavlov.models.ranking.keras_siamese_model.KerasSiameseModel.compile` overrides method defined in `KerasModel` inconsistently. Could not find parameter `optimizer_name` in overriding signature.",
    "exception": "PatchSet should only have 1 Patch, but it has 0",
    "dd_fail": true
  }
]