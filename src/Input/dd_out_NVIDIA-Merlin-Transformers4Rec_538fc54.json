[
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "merlin_standard_lib/schema/schema.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/merlin_standard_lib/schema/schema.py",
    "file_hunks_size": 19,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "merlin_standard_lib/schema/schema.py:393:27 Incompatible parameter type [6]: Expected `List[Feature]` for 1st positional only parameter to call `_Schema.__init__` but got `typing.Sequence[typing.Any]`.",
    "message": " Expected `List[Feature]` for 1st positional only parameter to call `_Schema.__init__` but got `typing.Sequence[typing.Any]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 393,
    "warning_line": "            other = Schema(other)"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "merlin_standard_lib/utils/proto_utils.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/merlin_standard_lib/utils/proto_utils.py",
    "file_hunks_size": 2,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "merlin_standard_lib/utils/proto_utils.py:33:58 Incompatible parameter type [6]: Expected `typing.Iterable[typing_extensions.SupportsIndex]` for 1st positional only parameter to call `bytes.__new__` but got `Variable[ProtoMessageType]`.",
    "message": " Expected `typing.Iterable[typing_extensions.SupportsIndex]` for 1st positional only parameter to call `bytes.__new__` but got `Variable[ProtoMessageType]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 33,
    "warning_line": "    output = better_proto_message.__class__().parse(bytes(better_proto_message))"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/config/trainer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/config/trainer.py",
    "file_hunks_size": 3,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/config/trainer.py:64:4 Incompatible attribute type [8]: Attribute `avg_session_length` declared in class `T4RecTrainingArguments` has type `int` but is used as type `None`.",
    "message": " Attribute `avg_session_length` declared in class `T4RecTrainingArguments` has type `int` but is used as type `None`.",
    "rule_id": "Incompatible attribute type [8]",
    "warning_line_no": 64,
    "warning_line": "    avg_session_length: int = field(",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from dataclasses import dataclass, field\n\n",
        "source_code_len": 42,
        "target_code": "from dataclasses import dataclass, field\nfrom typing import Optional\n\n",
        "target_code_len": 70,
        "diff_format": "@@ -17,2 +17,3 @@\n from dataclasses import dataclass, field\n+from typing import Optional\n \n",
        "source_code_with_indent": "from dataclasses import dataclass, field\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from dataclasses import dataclass, field\nfrom typing import Optional\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    avg_session_length: int = field(\n        default=None,\n",
        "source_code_len": 60,
        "target_code": "\n    avg_session_length: Optional[int] = field(\n        default=None,\n",
        "target_code_len": 70,
        "diff_format": "@@ -63,3 +64,3 @@\n \n-    avg_session_length: int = field(\n+    avg_session_length: Optional[int] = field(\n         default=None,\n",
        "source_code_with_indent": "\n    avg_session_length: int = field(\n        default=None,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    avg_session_length: Optional[int] = field(\n        default=None,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/config/trainer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/config/trainer.py",
    "file_hunks_size": 3,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/config/trainer.py:75:4 Incompatible attribute type [8]: Attribute `max_sequence_length` declared in class `T4RecTrainingArguments` has type `int` but is used as type `None`.",
    "message": " Attribute `max_sequence_length` declared in class `T4RecTrainingArguments` has type `int` but is used as type `None`.",
    "rule_id": "Incompatible attribute type [8]",
    "warning_line_no": 75,
    "warning_line": "    max_sequence_length: int = field(",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "from dataclasses import dataclass, field\n\n",
        "source_code_len": 42,
        "target_code": "from dataclasses import dataclass, field\nfrom typing import Optional\n\n",
        "target_code_len": 70,
        "diff_format": "@@ -17,2 +17,3 @@\n from dataclasses import dataclass, field\n+from typing import Optional\n \n",
        "source_code_with_indent": "from dataclasses import dataclass, field\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "from dataclasses import dataclass, field\nfrom typing import Optional\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    max_sequence_length: int = field(\n        default=None,\n",
        "source_code_len": 61,
        "target_code": "\n    max_sequence_length: Optional[int] = field(\n        default=None,\n",
        "target_code_len": 71,
        "diff_format": "@@ -74,3 +75,3 @@\n \n-    max_sequence_length: int = field(\n+    max_sequence_length: Optional[int] = field(\n         default=None,\n",
        "source_code_with_indent": "\n    max_sequence_length: int = field(\n        default=None,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    max_sequence_length: Optional[int] = field(\n        default=None,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/block/dlrm.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/block/dlrm.py",
    "file_hunks_size": 7,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/tf/block/dlrm.py:92:19 Incompatible parameter type [6]: Expected `Union[List[str], TabularBlock, merlin_standard_lib.schema.schema.Schema]` for 1st positional only parameter to call `DLRMBlock.__init__` but got `Optional[TabularBlock]`.",
    "message": " Expected `Union[List[str], TabularBlock, merlin_standard_lib.schema.schema.Schema]` for 1st positional only parameter to call `DLRMBlock.__init__` but got `Optional[TabularBlock]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 92,
    "warning_line": "        return cls(continuous_features, embedding_layer, bottom_mlp, top_mlp=top_mlp, **kwargs)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        self,\n        continuous_features: Union[List[str], Schema, TabularBlock],\n        embedding_layer: EmbeddingFeatures,\n",
        "source_code_len": 127,
        "target_code": "        self,\n        continuous_features: Union[List[str], Schema, Optional[TabularBlock]],\n        embedding_layer: EmbeddingFeatures,\n",
        "target_code_len": 137,
        "diff_format": "@@ -38,3 +37,3 @@\n         self,\n-        continuous_features: Union[List[str], Schema, TabularBlock],\n+        continuous_features: Union[List[str], Schema, Optional[TabularBlock]],\n         embedding_layer: EmbeddingFeatures,\n",
        "source_code_with_indent": "        self,\n        continuous_features: Union[List[str], Schema, TabularBlock],\n        embedding_layer: EmbeddingFeatures,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        self,\n        continuous_features: Union[List[str], Schema, Optional[TabularBlock]],\n        embedding_layer: EmbeddingFeatures,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/block/dlrm.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/block/dlrm.py",
    "file_hunks_size": 7,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/tf/block/dlrm.py:92:40 Incompatible parameter type [6]: Expected `EmbeddingFeatures` for 2nd positional only parameter to call `DLRMBlock.__init__` but got `Optional[EmbeddingFeatures]`.",
    "message": " Expected `EmbeddingFeatures` for 2nd positional only parameter to call `DLRMBlock.__init__` but got `Optional[EmbeddingFeatures]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 92,
    "warning_line": "        return cls(continuous_features, embedding_layer, bottom_mlp, top_mlp=top_mlp, **kwargs)"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/features/embedding.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/features/embedding.py",
    "file_hunks_size": 6,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/tf/features/embedding.py:110:24 Incompatible parameter type [6]: Expected `float` for 2nd positional only parameter to call `get_embedding_sizes_from_schema` but got `Optional[float]`.",
    "message": " Expected `float` for 2nd positional only parameter to call `get_embedding_sizes_from_schema` but got `Optional[float]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 110,
    "warning_line": "                schema, infer_embedding_sizes_multiplier"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/features/embedding.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/features/embedding.py",
    "file_hunks_size": 6,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/tf/features/embedding.py:160:4 Inconsistent override [14]: `transformers4rec.tf.features.embedding.EmbeddingFeatures.call` overrides method defined in `transformers4rec.tf.tabular.tabular.TabularBlock` inconsistently. Could not find parameter `x` in overriding signature.",
    "message": " `transformers4rec.tf.features.embedding.EmbeddingFeatures.call` overrides method defined in `transformers4rec.tf.tabular.tabular.TabularBlock` inconsistently. Could not find parameter `x` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 160,
    "warning_line": "    def call(self, inputs: TabularData, **kwargs) -> TabularData:"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/features/embedding.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/features/embedding.py",
    "file_hunks_size": 6,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/tf/features/embedding.py:160:4 Inconsistent override [14]: `transformers4rec.tf.features.embedding.EmbeddingFeatures.call` overrides method defined in `transformers4rec.tf.tabular.tabular.TabularBlock` inconsistently. Could not find parameter `Variable(unknown)` in overriding signature.",
    "message": " `transformers4rec.tf.features.embedding.EmbeddingFeatures.call` overrides method defined in `transformers4rec.tf.tabular.tabular.TabularBlock` inconsistently. Could not find parameter `Variable(unknown)` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 160,
    "warning_line": "    def call(self, inputs: TabularData, **kwargs) -> TabularData:"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/features/sequence.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/features/sequence.py",
    "file_hunks_size": 6,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "transformers4rec/tf/features/sequence.py:160:4 Inconsistent override [14]: `transformers4rec.tf.features.sequence.TabularSequenceFeatures.from_schema` overrides method defined in `TabularFeatures` inconsistently. Could not find parameter `max_text_length` in overriding signature.",
    "message": " `transformers4rec.tf.features.sequence.TabularSequenceFeatures.from_schema` overrides method defined in `TabularFeatures` inconsistently. Could not find parameter `max_text_length` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 160,
    "warning_line": "    def from_schema(",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "    @classmethod\n    def from_schema(\n        cls,\n",
        "source_code_len": 51,
        "target_code": "    @classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_len": 67,
        "diff_format": "@@ -159,3 +164,3 @@\n     @classmethod\n-    def from_schema(\n+    def from_schema(  # type: ignore\n         cls,\n",
        "source_code_with_indent": "    <DED>@classmethod\n    def from_schema(\n        cls,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED>@classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/features/sequence.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/features/sequence.py",
    "file_hunks_size": 6,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "transformers4rec/tf/features/sequence.py:160:4 Inconsistent override [14]: `transformers4rec.tf.features.sequence.TabularSequenceFeatures.from_schema` overrides method defined in `TabularFeatures` inconsistently. Could not find parameter `text_model` in overriding signature.",
    "message": " `transformers4rec.tf.features.sequence.TabularSequenceFeatures.from_schema` overrides method defined in `TabularFeatures` inconsistently. Could not find parameter `text_model` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 160,
    "warning_line": "    def from_schema(",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "    @classmethod\n    def from_schema(\n        cls,\n",
        "source_code_len": 51,
        "target_code": "    @classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_len": 67,
        "diff_format": "@@ -159,3 +164,3 @@\n     @classmethod\n-    def from_schema(\n+    def from_schema(  # type: ignore\n         cls,\n",
        "source_code_with_indent": "    <DED>@classmethod\n    def from_schema(\n        cls,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED>@classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/features/sequence.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/features/sequence.py",
    "file_hunks_size": 6,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "transformers4rec/tf/features/sequence.py:160:4 Inconsistent override [14]: `transformers4rec.tf.features.sequence.TabularSequenceFeatures.from_schema` overrides method defined in `TabularFeatures` inconsistently. Could not find parameter `text_tags` in overriding signature.",
    "message": " `transformers4rec.tf.features.sequence.TabularSequenceFeatures.from_schema` overrides method defined in `TabularFeatures` inconsistently. Could not find parameter `text_tags` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 160,
    "warning_line": "    def from_schema(",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "    @classmethod\n    def from_schema(\n        cls,\n",
        "source_code_len": 51,
        "target_code": "    @classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_len": 67,
        "diff_format": "@@ -159,3 +164,3 @@\n     @classmethod\n-    def from_schema(\n+    def from_schema(  # type: ignore\n         cls,\n",
        "source_code_with_indent": "    <DED>@classmethod\n    def from_schema(\n        cls,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED>@classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/features/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/features/tabular.py",
    "file_hunks_size": 10,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/tf/features/tabular.py:126:4 Inconsistent override [14]: `transformers4rec.tf.features.tabular.TabularFeatures.from_schema` overrides method defined in `transformers4rec.tf.tabular.tabular.TabularBlock` inconsistently. Could not find parameter `tags` in overriding signature.",
    "message": " `transformers4rec.tf.features.tabular.TabularFeatures.from_schema` overrides method defined in `transformers4rec.tf.tabular.tabular.TabularBlock` inconsistently. Could not find parameter `tags` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 126,
    "warning_line": "    def from_schema("
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/features/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/features/tabular.py",
    "file_hunks_size": 10,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/tf/features/tabular.py:129:8 Incompatible variable type [9]: continuous_tags is declared to have type `Union[None, List[typing.Any], merlin_standard_lib.schema.tag.Tag, str]` but is used as type `typing.Tuple[merlin_standard_lib.schema.tag.Tag]`.",
    "message": " continuous_tags is declared to have type `Union[None, List[typing.Any], merlin_standard_lib.schema.tag.Tag, str]` but is used as type `typing.Tuple[merlin_standard_lib.schema.tag.Tag]`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 129,
    "warning_line": "        continuous_tags: Optional[Union[Tag, list, str]] = (Tag.CONTINUOUS,),"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/features/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/features/tabular.py",
    "file_hunks_size": 10,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/tf/features/tabular.py:130:8 Incompatible variable type [9]: categorical_tags is declared to have type `Union[None, List[typing.Any], merlin_standard_lib.schema.tag.Tag, str]` but is used as type `typing.Tuple[merlin_standard_lib.schema.tag.Tag]`.",
    "message": " categorical_tags is declared to have type `Union[None, List[typing.Any], merlin_standard_lib.schema.tag.Tag, str]` but is used as type `typing.Tuple[merlin_standard_lib.schema.tag.Tag]`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 130,
    "warning_line": "        categorical_tags: Optional[Union[Tag, list, str]] = (Tag.CATEGORICAL,),"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/model/head.py",
    "min_patch_found": false,
    "full_warning_msg": "transformers4rec/tf/model/head.py:63:33 Incompatible parameter type [6]: Expected `typing.Iterable[Variable[_T1]]` for 1st positional only parameter to call `zip.__new__` but got `Union[List[PredictionTask], PredictionTask]`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/model/head.py'",
    "dd_fail": true
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/model/prediction_task.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/model/prediction_task.py",
    "file_hunks_size": 10,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/tf/model/prediction_task.py:119:4 Inconsistent override [14]: `transformers4rec.tf.model.prediction_task.PredictionTask.compute_loss` overrides method defined in `LossMixin` inconsistently. Could not find parameter `training` in overriding signature.",
    "message": " `transformers4rec.tf.model.prediction_task.PredictionTask.compute_loss` overrides method defined in `LossMixin` inconsistently. Could not find parameter `training` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 119,
    "warning_line": "    def compute_loss("
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/model/prediction_task.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/model/prediction_task.py",
    "file_hunks_size": 10,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/tf/model/prediction_task.py:130:22 Call error [29]: `PredictionTask` is not a function.",
    "message": " `PredictionTask` is not a function.",
    "rule_id": "Call error [29]",
    "warning_line_no": 130,
    "warning_line": "        predictions = self(inputs, **kwargs)"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/model/prediction_task.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/model/prediction_task.py",
    "file_hunks_size": 10,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "transformers4rec/tf/model/prediction_task.py:418:4 Inconsistent override [14]: `transformers4rec.tf.model.prediction_task.NextItemPredictionTask.compute_loss` overrides method defined in `PredictionTask` inconsistently. Could not find parameter `Keywords(unknown)` in overriding signature.",
    "message": " `transformers4rec.tf.model.prediction_task.NextItemPredictionTask.compute_loss` overrides method defined in `PredictionTask` inconsistently. Could not find parameter `Keywords(unknown)` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 418,
    "warning_line": "    def compute_loss(",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "\n    def compute_loss(\n        self,\n",
        "source_code_len": 37,
        "target_code": "\n    def compute_loss(  # type: ignore\n        self,\n",
        "target_code_len": 53,
        "diff_format": "@@ -417,3 +215,3 @@\n \n-    def compute_loss(\n+    def compute_loss(  # type: ignore\n         self,\n",
        "source_code_with_indent": "\n    <DED>def compute_loss(\n        self,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>def compute_loss(  # type: ignore\n        self,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/model/prediction_task.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/model/prediction_task.py",
    "file_hunks_size": 10,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/tf/model/prediction_task.py:485:29 Incompatible variable type [9]: mode is declared to have type `str` but is used as type `None`.",
    "message": " mode is declared to have type `str` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 485,
    "warning_line": "    def metric_results(self, mode: str = None) -> Dict[str, tf.Tensor]:"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/tabular/base.py",
    "file_hunks_size": 25,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/tf/tabular/tabular.py:130:15 Incompatible parameter type [6]: Expected `typing.Sized` for 1st positional only parameter to call `len` but got `Union[List[TabularTransformation], List[str], TabularTransformation, str]`.",
    "message": " Expected `typing.Sized` for 1st positional only parameter to call `len` but got `Union[List[TabularTransformation], List[str], TabularTransformation, str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 130,
    "warning_line": "        if len(transformation) == 1 and isinstance(transformation, list):"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/tabular/base.py",
    "file_hunks_size": 25,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/tf/tabular/tabular.py:194:21 Incompatible parameter type [6]: Expected `Union[List[TabularTransformation], List[str], TabularTransformation, str]` for 1st positional only parameter to call `TabularBlock.set_pre` but got `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]`.",
    "message": " Expected `Union[List[TabularTransformation], List[str], TabularTransformation, str]` for 1st positional only parameter to call `TabularBlock.set_pre` but got `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 194,
    "warning_line": "        self.set_pre(pre)"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/tabular/base.py",
    "file_hunks_size": 25,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/tf/tabular/tabular.py:195:22 Incompatible parameter type [6]: Expected `Union[List[TabularTransformation], List[str], TabularTransformation, str]` for 1st positional only parameter to call `TabularBlock.set_post` but got `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]`.",
    "message": " Expected `Union[List[TabularTransformation], List[str], TabularTransformation, str]` for 1st positional only parameter to call `TabularBlock.set_post` but got `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 195,
    "warning_line": "        self.set_post(post)"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/tabular/base.py",
    "file_hunks_size": 25,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "transformers4rec/tf/tabular/tabular.py:249:8 Incompatible variable type [9]: pre is declared to have type `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]` but is used as type `Union[List[Union[List[TabularTransformation], List[str], TabularTransformation, str]], FilterFeatures]`.",
    "message": " pre is declared to have type `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]` but is used as type `Union[List[Union[List[TabularTransformation], List[str], TabularTransformation, str]], FilterFeatures]`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 249,
    "warning_line": "        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "        \"\"\"\n        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)\n\n",
        "source_code_len": 96,
        "target_code": "        \"\"\"\n        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)  # type: ignore\n\n",
        "target_code_len": 112,
        "diff_format": "@@ -248,3 +251,3 @@\n         \"\"\"\n-        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)\n+        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)  # type: ignore\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "\n        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)\n\n",
        "target_code_with_indent": "\n        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)  # type: ignore\n\n"
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/tabular/base.py",
    "file_hunks_size": 25,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/tf/tabular/tabular.py:269:20 Incompatible parameter type [6]: Expected `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]` for 2nd parameter `transformations` to call `TabularBlock._maybe_apply_transformations` but got `Union[None, SequentialTabularTransformations, TabularAggregation, str]`.",
    "message": " Expected `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]` for 2nd parameter `transformations` to call `TabularBlock._maybe_apply_transformations` but got `Union[None, SequentialTabularTransformations, TabularAggregation, str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 269,
    "warning_line": "            inputs, transformations=transformations or self.pre"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/tabular/base.py",
    "file_hunks_size": 25,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/tf/tabular/tabular.py:279:8 Incompatible variable type [9]: merge_with is declared to have type `Union[List[TabularBlock], TabularBlock]` but is used as type `None`.",
    "message": " merge_with is declared to have type `Union[List[TabularBlock], TabularBlock]` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 279,
    "warning_line": "        merge_with: Union[\"TabularBlock\", List[\"TabularBlock\"]] = None,"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/tabular/base.py",
    "file_hunks_size": 25,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/tf/tabular/tabular.py:312:21 Incompatible parameter type [6]: Expected `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]` for 2nd parameter `transformations` to call `TabularBlock._maybe_apply_transformations` but got `Union[None, List[TabularTransformation], List[str], SequentialTabularTransformations, TabularTransformation, str]`.",
    "message": " Expected `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]` for 2nd parameter `transformations` to call `TabularBlock._maybe_apply_transformations` but got `Union[None, List[TabularTransformation], List[str], SequentialTabularTransformations, TabularTransformation, str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 312,
    "warning_line": "            outputs, transformations=transformations or self.post"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/tabular/base.py",
    "file_hunks_size": 25,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/tf/tabular/tabular.py:328:8 Incompatible variable type [9]: merge_with is declared to have type `Union[List[TabularBlock], TabularBlock]` but is used as type `None`.",
    "message": " merge_with is declared to have type `Union[List[TabularBlock], TabularBlock]` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 328,
    "warning_line": "        merge_with: Union[\"TabularBlock\", List[\"TabularBlock\"]] = None,"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/tabular/base.py",
    "file_hunks_size": 25,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/tf/tabular/tabular.py:353:39 Incompatible parameter type [6]: Expected `Union[None, TabularAggregation, str]` for 2nd parameter `transformations` to call `TabularBlock.pre_call` but got `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]`.",
    "message": " Expected `Union[None, TabularAggregation, str]` for 2nd parameter `transformations` to call `TabularBlock.pre_call` but got `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 353,
    "warning_line": "        inputs = self.pre_call(inputs, transformations=pre)"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/tf/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/tf/tabular/base.py",
    "file_hunks_size": 25,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/tf/tabular/tabular.py:595:12 Incompatible variable type [9]: Unable to unpack `Union[Dict[str, typing.Any], TabularBlock]`, expected a tuple.",
    "message": " Unable to unpack `Union[Dict[str, typing.Any], TabularBlock]`, expected a tuple.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 595,
    "warning_line": "            blocks_to_merge = reduce(lambda a, b: dict(a, **b), blocks_to_merge)"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/features/embedding.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/features/embedding.py",
    "file_hunks_size": 11,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": true,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/torch/features/embedding.py:76:23 Incompatible parameter type [6]: Expected `str` for 1st positional only parameter to call `dict.__setitem__` but got `Optional[str]`.",
    "message": " Expected `str` for 1st positional only parameter to call `dict.__setitem__` but got `Optional[str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 76,
    "warning_line": "                tables[table.name] = table",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "            features_dim[name] = table.dim\n            if table.name not in tables:\n                tables[table.name] = table\n\n",
        "source_code_len": 128,
        "target_code": "            features_dim[name] = table.dim\n            if name not in tables:\n                tables[name] = table\n\n",
        "target_code_len": 116,
        "diff_format": "@@ -74,4 +78,4 @@\n             features_dim[name] = table.dim\n-            if table.name not in tables:\n-                tables[table.name] = table\n+            if name not in tables:\n+                tables[name] = table\n \n",
        "source_code_with_indent": "            features_dim[name] = table.dim\n            if table.name not in tables:\n                <IND>tables[table.name] = table\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "            features_dim[name] = table.dim\n            if name not in tables:\n                <IND>tables[name] = table\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/features/embedding.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/features/embedding.py",
    "file_hunks_size": 11,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/torch/features/embedding.py:162:24 Incompatible parameter type [6]: Expected `float` for 2nd positional only parameter to call `get_embedding_sizes_from_schema` but got `Optional[float]`.",
    "message": " Expected `float` for 2nd positional only parameter to call `get_embedding_sizes_from_schema` but got `Optional[float]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 162,
    "warning_line": "                schema, infer_embedding_sizes_multiplier",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        embedding_dims: Optional[Dict[str, int]] = None,\n        embedding_dim_default: Optional[int] = 64,\n        infer_embedding_sizes: bool = False,\n        infer_embedding_sizes_multiplier: Optional[float] = 2.0,\n        embeddings_initializers: Optional[Dict[str, Callable[[Any], None]]] = None,\n        combiner: Optional[str] = \"mean\",\n        tags: Optional[Union[Tag, list, str]] = None,\n",
        "source_code_len": 398,
        "target_code": "        embedding_dims: Optional[Dict[str, int]] = None,\n        embedding_dim_default: int = 64,\n        infer_embedding_sizes: bool = False,\n        infer_embedding_sizes_multiplier: float = 2.0,\n        embeddings_initializers: Optional[Dict[str, Callable[[Any], None]]] = None,\n        combiner: str = \"mean\",\n        tags: Optional[Union[Tag, list, str]] = None,\n",
        "target_code_len": 368,
        "diff_format": "@@ -100,7 +104,7 @@\n         embedding_dims: Optional[Dict[str, int]] = None,\n-        embedding_dim_default: Optional[int] = 64,\n+        embedding_dim_default: int = 64,\n         infer_embedding_sizes: bool = False,\n-        infer_embedding_sizes_multiplier: Optional[float] = 2.0,\n+        infer_embedding_sizes_multiplier: float = 2.0,\n         embeddings_initializers: Optional[Dict[str, Callable[[Any], None]]] = None,\n-        combiner: Optional[str] = \"mean\",\n+        combiner: str = \"mean\",\n         tags: Optional[Union[Tag, list, str]] = None,\n",
        "source_code_with_indent": "        embedding_dims: Optional[Dict[str, int]] = None,\n        embedding_dim_default: Optional[int] = 64,\n        infer_embedding_sizes: bool = False,\n        infer_embedding_sizes_multiplier: Optional[float] = 2.0,\n        embeddings_initializers: Optional[Dict[str, Callable[[Any], None]]] = None,\n        combiner: Optional[str] = \"mean\",\n        tags: Optional[Union[Tag, list, str]] = None,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        embedding_dims: Optional[Dict[str, int]] = None,\n        embedding_dim_default: int = 64,\n        infer_embedding_sizes: bool = False,\n        infer_embedding_sizes_multiplier: float = 2.0,\n        embeddings_initializers: Optional[Dict[str, Callable[[Any], None]]] = None,\n        combiner: str = \"mean\",\n        tags: Optional[Union[Tag, list, str]] = None,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/features/embedding.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/features/embedding.py",
    "file_hunks_size": 11,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/torch/features/embedding.py:182:20 Incompatible parameter type [6]: Expected `str` for 4th parameter `combiner` to call `TableConfig.__init__` but got `Optional[str]`.",
    "message": " Expected `str` for 4th parameter `combiner` to call `TableConfig.__init__` but got `Optional[str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 182,
    "warning_line": "                    combiner=combiner,",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        embedding_dims: Optional[Dict[str, int]] = None,\n        embedding_dim_default: Optional[int] = 64,\n        infer_embedding_sizes: bool = False,\n        infer_embedding_sizes_multiplier: Optional[float] = 2.0,\n        embeddings_initializers: Optional[Dict[str, Callable[[Any], None]]] = None,\n        combiner: Optional[str] = \"mean\",\n        tags: Optional[Union[Tag, list, str]] = None,\n",
        "source_code_len": 398,
        "target_code": "        embedding_dims: Optional[Dict[str, int]] = None,\n        embedding_dim_default: int = 64,\n        infer_embedding_sizes: bool = False,\n        infer_embedding_sizes_multiplier: float = 2.0,\n        embeddings_initializers: Optional[Dict[str, Callable[[Any], None]]] = None,\n        combiner: str = \"mean\",\n        tags: Optional[Union[Tag, list, str]] = None,\n",
        "target_code_len": 368,
        "diff_format": "@@ -100,7 +104,7 @@\n         embedding_dims: Optional[Dict[str, int]] = None,\n-        embedding_dim_default: Optional[int] = 64,\n+        embedding_dim_default: int = 64,\n         infer_embedding_sizes: bool = False,\n-        infer_embedding_sizes_multiplier: Optional[float] = 2.0,\n+        infer_embedding_sizes_multiplier: float = 2.0,\n         embeddings_initializers: Optional[Dict[str, Callable[[Any], None]]] = None,\n-        combiner: Optional[str] = \"mean\",\n+        combiner: str = \"mean\",\n         tags: Optional[Union[Tag, list, str]] = None,\n",
        "source_code_with_indent": "        embedding_dims: Optional[Dict[str, int]] = None,\n        embedding_dim_default: Optional[int] = 64,\n        infer_embedding_sizes: bool = False,\n        infer_embedding_sizes_multiplier: Optional[float] = 2.0,\n        embeddings_initializers: Optional[Dict[str, Callable[[Any], None]]] = None,\n        combiner: Optional[str] = \"mean\",\n        tags: Optional[Union[Tag, list, str]] = None,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        embedding_dims: Optional[Dict[str, int]] = None,\n        embedding_dim_default: int = 64,\n        infer_embedding_sizes: bool = False,\n        infer_embedding_sizes_multiplier: float = 2.0,\n        embeddings_initializers: Optional[Dict[str, Callable[[Any], None]]] = None,\n        combiner: str = \"mean\",\n        tags: Optional[Union[Tag, list, str]] = None,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/features/embedding.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/features/embedding.py",
    "file_hunks_size": 11,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "transformers4rec/torch/features/embedding.py:286:4 Inconsistent override [14]: `transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.from_schema` overrides method defined in `EmbeddingFeatures` inconsistently. Could not find parameter `aggregation` in overriding signature.",
    "message": " `transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.from_schema` overrides method defined in `EmbeddingFeatures` inconsistently. Could not find parameter `aggregation` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 286,
    "warning_line": "    def from_schema(",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "    @classmethod\n    def from_schema(\n        cls,\n",
        "source_code_len": 51,
        "target_code": "    @classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_len": 67,
        "diff_format": "@@ -285,3 +289,3 @@\n     @classmethod\n-    def from_schema(\n+    def from_schema(  # type: ignore\n         cls,\n",
        "source_code_with_indent": "    <DED>@classmethod\n    def from_schema(\n        cls,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED>@classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/features/embedding.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/features/embedding.py",
    "file_hunks_size": 11,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "transformers4rec/torch/features/embedding.py:286:4 Inconsistent override [14]: `transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.from_schema` overrides method defined in `EmbeddingFeatures` inconsistently. Could not find parameter `embedding_dim_default` in overriding signature.",
    "message": " `transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.from_schema` overrides method defined in `EmbeddingFeatures` inconsistently. Could not find parameter `embedding_dim_default` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 286,
    "warning_line": "    def from_schema(",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "    @classmethod\n    def from_schema(\n        cls,\n",
        "source_code_len": 51,
        "target_code": "    @classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_len": 67,
        "diff_format": "@@ -285,3 +289,3 @@\n     @classmethod\n-    def from_schema(\n+    def from_schema(  # type: ignore\n         cls,\n",
        "source_code_with_indent": "    <DED>@classmethod\n    def from_schema(\n        cls,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED>@classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/features/embedding.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/features/embedding.py",
    "file_hunks_size": 11,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "transformers4rec/torch/features/embedding.py:286:4 Inconsistent override [14]: `transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.from_schema` overrides method defined in `EmbeddingFeatures` inconsistently. Could not find parameter `embedding_dims` in overriding signature.",
    "message": " `transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.from_schema` overrides method defined in `EmbeddingFeatures` inconsistently. Could not find parameter `embedding_dims` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 286,
    "warning_line": "    def from_schema(",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "    @classmethod\n    def from_schema(\n        cls,\n",
        "source_code_len": 51,
        "target_code": "    @classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_len": 67,
        "diff_format": "@@ -285,3 +289,3 @@\n     @classmethod\n-    def from_schema(\n+    def from_schema(  # type: ignore\n         cls,\n",
        "source_code_with_indent": "    <DED>@classmethod\n    def from_schema(\n        cls,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED>@classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/features/embedding.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/features/embedding.py",
    "file_hunks_size": 11,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "transformers4rec/torch/features/embedding.py:286:4 Inconsistent override [14]: `transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.from_schema` overrides method defined in `EmbeddingFeatures` inconsistently. Could not find parameter `infer_embedding_sizes` in overriding signature.",
    "message": " `transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.from_schema` overrides method defined in `EmbeddingFeatures` inconsistently. Could not find parameter `infer_embedding_sizes` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 286,
    "warning_line": "    def from_schema(",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "    @classmethod\n    def from_schema(\n        cls,\n",
        "source_code_len": 51,
        "target_code": "    @classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_len": 67,
        "diff_format": "@@ -285,3 +289,3 @@\n     @classmethod\n-    def from_schema(\n+    def from_schema(  # type: ignore\n         cls,\n",
        "source_code_with_indent": "    <DED>@classmethod\n    def from_schema(\n        cls,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED>@classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/features/embedding.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/features/embedding.py",
    "file_hunks_size": 11,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "transformers4rec/torch/features/embedding.py:286:4 Inconsistent override [14]: `transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.from_schema` overrides method defined in `EmbeddingFeatures` inconsistently. Could not find parameter `infer_embedding_sizes_multiplier` in overriding signature.",
    "message": " `transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.from_schema` overrides method defined in `EmbeddingFeatures` inconsistently. Could not find parameter `infer_embedding_sizes_multiplier` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 286,
    "warning_line": "    def from_schema(",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "    @classmethod\n    def from_schema(\n        cls,\n",
        "source_code_len": 51,
        "target_code": "    @classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_len": 67,
        "diff_format": "@@ -285,3 +289,3 @@\n     @classmethod\n-    def from_schema(\n+    def from_schema(  # type: ignore\n         cls,\n",
        "source_code_with_indent": "    <DED>@classmethod\n    def from_schema(\n        cls,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED>@classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/features/embedding.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/features/embedding.py",
    "file_hunks_size": 11,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "transformers4rec/torch/features/embedding.py:286:4 Inconsistent override [14]: `transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.from_schema` overrides method defined in `EmbeddingFeatures` inconsistently. Could not find parameter `item_id` in overriding signature.",
    "message": " `transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.from_schema` overrides method defined in `EmbeddingFeatures` inconsistently. Could not find parameter `item_id` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 286,
    "warning_line": "    def from_schema(",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "    @classmethod\n    def from_schema(\n        cls,\n",
        "source_code_len": 51,
        "target_code": "    @classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_len": 67,
        "diff_format": "@@ -285,3 +289,3 @@\n     @classmethod\n-    def from_schema(\n+    def from_schema(  # type: ignore\n         cls,\n",
        "source_code_with_indent": "    <DED>@classmethod\n    def from_schema(\n        cls,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED>@classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/features/embedding.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/features/embedding.py",
    "file_hunks_size": 11,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "transformers4rec/torch/features/embedding.py:286:4 Inconsistent override [14]: `transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.from_schema` overrides method defined in `EmbeddingFeatures` inconsistently. Could not find parameter `post` in overriding signature.",
    "message": " `transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.from_schema` overrides method defined in `EmbeddingFeatures` inconsistently. Could not find parameter `post` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 286,
    "warning_line": "    def from_schema(",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "    @classmethod\n    def from_schema(\n        cls,\n",
        "source_code_len": 51,
        "target_code": "    @classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_len": 67,
        "diff_format": "@@ -285,3 +289,3 @@\n     @classmethod\n-    def from_schema(\n+    def from_schema(  # type: ignore\n         cls,\n",
        "source_code_with_indent": "    <DED>@classmethod\n    def from_schema(\n        cls,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED>@classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/features/embedding.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/features/embedding.py",
    "file_hunks_size": 11,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "transformers4rec/torch/features/embedding.py:286:4 Inconsistent override [14]: `transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.from_schema` overrides method defined in `EmbeddingFeatures` inconsistently. Could not find parameter `pre` in overriding signature.",
    "message": " `transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.from_schema` overrides method defined in `EmbeddingFeatures` inconsistently. Could not find parameter `pre` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 286,
    "warning_line": "    def from_schema(",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "    @classmethod\n    def from_schema(\n        cls,\n",
        "source_code_len": 51,
        "target_code": "    @classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_len": 67,
        "diff_format": "@@ -285,3 +289,3 @@\n     @classmethod\n-    def from_schema(\n+    def from_schema(  # type: ignore\n         cls,\n",
        "source_code_with_indent": "    <DED>@classmethod\n    def from_schema(\n        cls,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED>@classmethod\n    def from_schema(  # type: ignore\n        cls,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/features/embedding.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/features/embedding.py",
    "file_hunks_size": 11,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/torch/features/embedding.py:363:20 Incompatible parameter type [6]: Expected `str` for 4th parameter `combiner` to call `TableConfig.__init__` but got `Optional[str]`.",
    "message": " Expected `str` for 4th parameter `combiner` to call `TableConfig.__init__` but got `Optional[str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 363,
    "warning_line": "                    combiner=combiner,"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/features/sequence.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/features/sequence.py",
    "file_hunks_size": 10,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/torch/features/sequence.py:136:8 Incompatible variable type [9]: continuous_tags is declared to have type `Union[None, List[typing.Any], merlin_standard_lib.schema.tag.Tag, str]` but is used as type `typing.Tuple[merlin_standard_lib.schema.tag.Tag]`.",
    "message": " continuous_tags is declared to have type `Union[None, List[typing.Any], merlin_standard_lib.schema.tag.Tag, str]` but is used as type `typing.Tuple[merlin_standard_lib.schema.tag.Tag]`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 136,
    "warning_line": "        continuous_tags: Optional[Union[Tag, list, str]] = (Tag.CONTINUOUS,),"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/features/sequence.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/features/sequence.py",
    "file_hunks_size": 10,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/torch/features/sequence.py:137:8 Incompatible variable type [9]: categorical_tags is declared to have type `Union[None, List[typing.Any], merlin_standard_lib.schema.tag.Tag, str]` but is used as type `typing.Tuple[merlin_standard_lib.schema.tag.Tag]`.",
    "message": " categorical_tags is declared to have type `Union[None, List[typing.Any], merlin_standard_lib.schema.tag.Tag, str]` but is used as type `typing.Tuple[merlin_standard_lib.schema.tag.Tag]`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 137,
    "warning_line": "        categorical_tags: Optional[Union[Tag, list, str]] = (Tag.CATEGORICAL,),"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/features/sequence.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/features/sequence.py",
    "file_hunks_size": 10,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "transformers4rec/torch/features/sequence.py:213:8 Incompatible return type [7]: Expected `TabularSequenceFeatures` but got `TabularFeatures`.",
    "message": " Expected `TabularSequenceFeatures` but got `TabularFeatures`.",
    "rule_id": "Incompatible return type [7]",
    "warning_line_no": 213,
    "warning_line": "        return output",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "        \"\"\"\n        output = super().from_schema(\n            schema=schema,\n",
        "source_code_len": 77,
        "target_code": "        \"\"\"\n        output: TabularSequenceFeatures = super().from_schema(  # type: ignore\n            schema=schema,\n",
        "target_code_len": 118,
        "diff_format": "@@ -184,3 +190,3 @@\n         \"\"\"\n-        output = super().from_schema(\n+        output: TabularSequenceFeatures = super().from_schema(  # type: ignore\n             schema=schema,\n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "\n        output = super().from_schema(\n            schema=schema,\n",
        "target_code_with_indent": "\n        output: TabularSequenceFeatures = super().from_schema(  # type: ignore\n            schema=schema,\n"
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/features/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/features/tabular.py",
    "file_hunks_size": 7,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/torch/features/tabular.py:110:4 Inconsistent override [14]: `transformers4rec.torch.features.tabular.TabularFeatures.from_schema` overrides method defined in `transformers4rec.torch.tabular.tabular.TabularModule` inconsistently. Could not find parameter `tags` in overriding signature.",
    "message": " `transformers4rec.torch.features.tabular.TabularFeatures.from_schema` overrides method defined in `transformers4rec.torch.tabular.tabular.TabularModule` inconsistently. Could not find parameter `tags` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 110,
    "warning_line": "    def from_schema("
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/features/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/features/tabular.py",
    "file_hunks_size": 7,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/torch/features/tabular.py:113:8 Incompatible variable type [9]: continuous_tags is declared to have type `Union[None, List[typing.Any], merlin_standard_lib.schema.tag.Tag, str]` but is used as type `typing.Tuple[merlin_standard_lib.schema.tag.Tag]`.",
    "message": " continuous_tags is declared to have type `Union[None, List[typing.Any], merlin_standard_lib.schema.tag.Tag, str]` but is used as type `typing.Tuple[merlin_standard_lib.schema.tag.Tag]`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 113,
    "warning_line": "        continuous_tags: Optional[Union[Tag, list, str]] = (Tag.CONTINUOUS,),"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/features/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/features/tabular.py",
    "file_hunks_size": 7,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/torch/features/tabular.py:114:8 Incompatible variable type [9]: categorical_tags is declared to have type `Union[None, List[typing.Any], merlin_standard_lib.schema.tag.Tag, str]` but is used as type `typing.Tuple[merlin_standard_lib.schema.tag.Tag]`.",
    "message": " categorical_tags is declared to have type `Union[None, List[typing.Any], merlin_standard_lib.schema.tag.Tag, str]` but is used as type `typing.Tuple[merlin_standard_lib.schema.tag.Tag]`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 114,
    "warning_line": "        categorical_tags: Optional[Union[Tag, list, str]] = (Tag.CATEGORICAL,),"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/model/head.py",
    "min_patch_found": false,
    "full_warning_msg": "transformers4rec/torch/model/head.py:84:33 Incompatible parameter type [6]: Expected `typing.Iterable[Variable[_T1]]` for 1st positional only parameter to call `zip.__new__` but got `Union[List[PredictionTask], PredictionTask]`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/model/head.py'",
    "dd_fail": true
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/model/head.py",
    "min_patch_found": false,
    "full_warning_msg": "transformers4rec/torch/model/head.py:203:4 Inconsistent override [14]: `transformers4rec.torch.model.head.Head.compute_loss` overrides method defined in `LossMixin` inconsistently. Could not find parameter `inputs` in overriding signature.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/model/head.py'",
    "dd_fail": true
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/model/head.py",
    "min_patch_found": false,
    "full_warning_msg": "transformers4rec/torch/model/head.py:227:4 Inconsistent override [14]: `transformers4rec.torch.model.head.Head.calculate_metrics` overrides method defined in `MetricsMixin` inconsistently. Could not find parameter `inputs` in overriding signature.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/model/head.py'",
    "dd_fail": true
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/model/head.py",
    "min_patch_found": false,
    "full_warning_msg": "transformers4rec/torch/model/head.py:248:30 Incompatible variable type [9]: mode is declared to have type `str` but is used as type `None`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/model/head.py'",
    "dd_fail": true
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/model/model.py",
    "min_patch_found": false,
    "full_warning_msg": "transformers4rec/torch/model/model.py:95:36 Incompatible parameter type [6]: Expected `str` for 2nd positional only parameter to call `getattr` but got `Optional[str]`.",
    "exception": "[Errno 2] No such file or directory: '/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/model/model.py'",
    "dd_fail": true
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/model/prediction_task.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/model/prediction_task.py",
    "file_hunks_size": 10,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/torch/model/prediction_task.py:194:22 Call error [29]: `PredictionTask` is not a function.",
    "message": " `PredictionTask` is not a function.",
    "rule_id": "Call error [29]",
    "warning_line_no": 194,
    "warning_line": "        predictions = self(inputs, training=training)"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/model/prediction_task.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/model/prediction_task.py",
    "file_hunks_size": 10,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/torch/model/prediction_task.py:204:4 Inconsistent override [14]: `transformers4rec.torch.model.prediction_task.PredictionTask.calculate_metrics` overrides method defined in `MetricsMixin` inconsistently. Could not find parameter `inputs` in overriding signature.",
    "message": " `transformers4rec.torch.model.prediction_task.PredictionTask.calculate_metrics` overrides method defined in `MetricsMixin` inconsistently. Could not find parameter `inputs` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 204,
    "warning_line": "    def calculate_metrics("
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/model/prediction_task.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/model/prediction_task.py",
    "file_hunks_size": 10,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/torch/model/prediction_task.py:217:26 Call error [29]: `PredictionTask` is not a function.",
    "message": " `PredictionTask` is not a function.",
    "rule_id": "Call error [29]",
    "warning_line_no": 217,
    "warning_line": "            predictions = self(predictions)"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/tabular/base.py",
    "file_hunks_size": 21,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "transformers4rec/torch/tabular/tabular.py:160:8 Incompatible attribute type [8]: Attribute `pre` declared in class `TabularModule` has type `Union[List[TabularTransformation], List[str], TabularTransformation, str]` but is used as type `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]`.",
    "message": " Attribute `pre` declared in class `TabularModule` has type `Union[List[TabularTransformation], List[str], TabularTransformation, str]` but is used as type `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]`.",
    "rule_id": "Incompatible attribute type [8]",
    "warning_line_no": 160,
    "warning_line": "        self.pre = pre",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "        self.input_size = None\n        self.pre = pre\n        self.post = post\n        self.aggregation = aggregation\n        self.schema = schema\n\n",
        "source_code_len": 148,
        "target_code": "        self.input_size = None\n        self.pre = pre  # type: ignore\n        self.post = post  # type: ignore\n        self.aggregation = aggregation  # type: ignore\n\n",
        "target_code_len": 167,
        "diff_format": "@@ -159,6 +158,5 @@\n         self.input_size = None\n-        self.pre = pre\n-        self.post = post\n-        self.aggregation = aggregation\n-        self.schema = schema\n+        self.pre = pre  # type: ignore\n+        self.post = post  # type: ignore\n+        self.aggregation = aggregation  # type: ignore\n \n",
        "source_code_with_indent": "        self.input_size = None\n        self.pre = pre\n        self.post = post\n        self.aggregation = aggregation\n        self.schema = schema\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        self.input_size = None\n        self.pre = pre  # type: ignore\n        self.post = post  # type: ignore\n        self.aggregation = aggregation  # type: ignore\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/tabular/base.py",
    "file_hunks_size": 21,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "transformers4rec/torch/tabular/tabular.py:161:8 Incompatible attribute type [8]: Attribute `post` declared in class `TabularModule` has type `Union[List[TabularTransformation], List[str], TabularTransformation, str]` but is used as type `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]`.",
    "message": " Attribute `post` declared in class `TabularModule` has type `Union[List[TabularTransformation], List[str], TabularTransformation, str]` but is used as type `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]`.",
    "rule_id": "Incompatible attribute type [8]",
    "warning_line_no": 161,
    "warning_line": "        self.post = post",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "        self.input_size = None\n        self.pre = pre\n        self.post = post\n        self.aggregation = aggregation\n        self.schema = schema\n\n",
        "source_code_len": 148,
        "target_code": "        self.input_size = None\n        self.pre = pre  # type: ignore\n        self.post = post  # type: ignore\n        self.aggregation = aggregation  # type: ignore\n\n",
        "target_code_len": 167,
        "diff_format": "@@ -159,6 +158,5 @@\n         self.input_size = None\n-        self.pre = pre\n-        self.post = post\n-        self.aggregation = aggregation\n-        self.schema = schema\n+        self.pre = pre  # type: ignore\n+        self.post = post  # type: ignore\n+        self.aggregation = aggregation  # type: ignore\n \n",
        "source_code_with_indent": "        self.input_size = None\n        self.pre = pre\n        self.post = post\n        self.aggregation = aggregation\n        self.schema = schema\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        self.input_size = None\n        self.pre = pre  # type: ignore\n        self.post = post  # type: ignore\n        self.aggregation = aggregation  # type: ignore\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/tabular/base.py",
    "file_hunks_size": 21,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "transformers4rec/torch/tabular/tabular.py:211:8 Incompatible variable type [9]: pre is declared to have type `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]` but is used as type `Union[List[Union[List[TabularTransformation], List[str], TabularTransformation, str]], FilterFeatures]`.",
    "message": " pre is declared to have type `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]` but is used as type `Union[List[Union[List[TabularTransformation], List[str], TabularTransformation, str]], FilterFeatures]`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 211,
    "warning_line": "        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "        \"\"\"\n        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)\n\n",
        "source_code_len": 96,
        "target_code": "        \"\"\"\n        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)  # type: ignore\n\n",
        "target_code_len": 112,
        "diff_format": "@@ -210,3 +208,3 @@\n         \"\"\"\n-        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)\n+        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)  # type: ignore\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "\n        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)\n\n",
        "target_code_with_indent": "\n        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)  # type: ignore\n\n"
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/tabular/base.py",
    "file_hunks_size": 21,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/torch/tabular/tabular.py:290:20 Incompatible parameter type [6]: Expected `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]` for 2nd parameter `transformations` to call `TabularModule._maybe_apply_transformations` but got `Union[None, SequentialTabularTransformations, TabularAggregation, str]`.",
    "message": " Expected `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]` for 2nd parameter `transformations` to call `TabularModule._maybe_apply_transformations` but got `Union[None, SequentialTabularTransformations, TabularAggregation, str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 290,
    "warning_line": "            inputs, transformations=transformations or self.pre",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\nTabularTransformationType = Union[\n    str, TabularTransformation, List[str], List[TabularTransformation]\n]\nTabularAggregationType = Union[str, TabularAggregation]\n",
        "source_code_len": 165,
        "target_code": "\nTabularTransformationType = Union[str, TabularTransformation]\nTabularTransformationsType = Union[TabularTransformationType, List[TabularTransformationType]]\nTabularAggregationType = Union[str, TabularAggregation]\n",
        "target_code_len": 214,
        "diff_format": "@@ -107,5 +107,4 @@\n \n-TabularTransformationType = Union[\n-    str, TabularTransformation, List[str], List[TabularTransformation]\n-]\n+TabularTransformationType = Union[str, TabularTransformation]\n+TabularTransformationsType = Union[TabularTransformationType, List[TabularTransformationType]]\n TabularAggregationType = Union[str, TabularAggregation]\n",
        "source_code_with_indent": "\n<DED><DED>TabularTransformationType = Union[\n    str, TabularTransformation, List[str], List[TabularTransformation]\n]\nTabularAggregationType = Union[str, TabularAggregation]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED><DED>TabularTransformationType = Union[str, TabularTransformation]\nTabularTransformationsType = Union[TabularTransformationType, List[TabularTransformationType]]\nTabularAggregationType = Union[str, TabularAggregation]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    def __init__(self, *transformation: TabularTransformationType):\n        if len(transformation) == 1 and isinstance(transformation, list):\n",
        "source_code_len": 143,
        "target_code": "\n    def __init__(self, *transformation: TabularTransformationsType):\n        if len(transformation) == 1 and isinstance(transformation, list):\n",
        "target_code_len": 144,
        "diff_format": "@@ -122,3 +121,3 @@\n \n-    def __init__(self, *transformation: TabularTransformationType):\n+    def __init__(self, *transformation: TabularTransformationsType):\n         if len(transformation) == 1 and isinstance(transformation, list):\n",
        "source_code_with_indent": "\n    def __init__(self, *transformation: TabularTransformationType):\n        <IND>if len(transformation) == 1 and isinstance(transformation, list):\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    def __init__(self, *transformation: TabularTransformationsType):\n        <IND>if len(transformation) == 1 and isinstance(transformation, list):\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "        \"\"\"\n        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)\n\n",
        "source_code_len": 96,
        "target_code": "        \"\"\"\n        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)  # type: ignore\n\n",
        "target_code_len": 112,
        "diff_format": "@@ -210,3 +208,3 @@\n         \"\"\"\n-        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)\n+        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)  # type: ignore\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "\n        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)\n\n",
        "target_code_with_indent": "\n        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)  # type: ignore\n\n"
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    @pre.setter\n    def pre(self, value: Union[str, TabularTransformation, List[str], List[TabularTransformation]]):\n        if value:\n            self._pre = SequentialTabularTransformations(value)\n        else:\n",
        "source_code_len": 213,
        "target_code": "    @pre.setter\n    def pre(self, value: Optional[TabularTransformationsType]):\n        if value:\n            self._pre: Optional[\n                SequentialTabularTransformations\n            ] = SequentialTabularTransformations(value)\n        else:\n",
        "target_code_len": 250,
        "diff_format": "@@ -225,5 +223,7 @@\n     @pre.setter\n-    def pre(self, value: Union[str, TabularTransformation, List[str], List[TabularTransformation]]):\n+    def pre(self, value: Optional[TabularTransformationsType]):\n         if value:\n-            self._pre = SequentialTabularTransformations(value)\n+            self._pre: Optional[\n+                SequentialTabularTransformations\n+            ] = SequentialTabularTransformations(value)\n         else:\n",
        "source_code_with_indent": "    <DED>@pre.setter\n    def pre(self, value: Union[str, TabularTransformation, List[str], List[TabularTransformation]]):\n        <IND>if value:\n            <IND>self._pre = SequentialTabularTransformations(value)\n        <DED>else:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED>@pre.setter\n    def pre(self, value: Optional[TabularTransformationsType]):\n        <IND>if value:\n            <IND>self._pre: Optional[\n                SequentialTabularTransformations\n            ] = SequentialTabularTransformations(value)\n        <DED>else:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    @post.setter\n    def post(\n        self, value: Union[str, TabularTransformation, List[str], List[TabularTransformation]]\n    ):\n        if value:\n            self._post = SequentialTabularTransformations(value)\n        else:\n",
        "source_code_len": 230,
        "target_code": "    @post.setter\n    def post(self, value: Optional[TabularTransformationsType]):\n        if value:\n            self._post: Optional[\n                SequentialTabularTransformations\n            ] = SequentialTabularTransformations(value)\n        else:\n",
        "target_code_len": 253,
        "diff_format": "@@ -242,7 +242,7 @@\n     @post.setter\n-    def post(\n-        self, value: Union[str, TabularTransformation, List[str], List[TabularTransformation]]\n-    ):\n+    def post(self, value: Optional[TabularTransformationsType]):\n         if value:\n-            self._post = SequentialTabularTransformations(value)\n+            self._post: Optional[\n+                SequentialTabularTransformations\n+            ] = SequentialTabularTransformations(value)\n         else:\n",
        "source_code_with_indent": "    <DED>@post.setter\n    def post(\n        self, value: Union[str, TabularTransformation, List[str], List[TabularTransformation]]\n    ):\n        <IND>if value:\n            <IND>self._post = SequentialTabularTransformations(value)\n        <DED>else:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED>@post.setter\n    def post(self, value: Optional[TabularTransformationsType]):\n        <IND>if value:\n            <IND>self._post: Optional[\n                SequentialTabularTransformations\n            ] = SequentialTabularTransformations(value)\n        <DED>else:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    def pre_forward(\n        self, inputs: TabularData, transformations: Optional[TabularAggregationType] = None\n    ) -> TabularData:\n",
        "source_code_len": 135,
        "target_code": "    def pre_forward(\n        self, inputs: TabularData, transformations: Optional[TabularTransformationsType] = None\n    ) -> TabularData:\n",
        "target_code_len": 139,
        "diff_format": "@@ -274,3 +274,3 @@\n     def pre_forward(\n-        self, inputs: TabularData, transformations: Optional[TabularAggregationType] = None\n+        self, inputs: TabularData, transformations: Optional[TabularTransformationsType] = None\n     ) -> TabularData:\n",
        "source_code_with_indent": "    <DED><DED>def pre_forward(\n        self, inputs: TabularData, transformations: Optional[TabularAggregationType] = None\n    ) -> TabularData:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED><DED>def pre_forward(\n        self, inputs: TabularData, transformations: Optional[TabularTransformationsType] = None\n    ) -> TabularData:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        inputs: TabularData,\n        transformations: Optional[TabularTransformationType] = None,\n    ) -> TabularData:\n",
        "source_code_len": 120,
        "target_code": "        inputs: TabularData,\n        transformations: Optional[\n            Union[TabularTransformationsType, SequentialTabularTransformations]\n        ] = None,\n    ) -> TabularData:\n",
        "target_code_len": 184,
        "diff_format": "@@ -388,3 +390,5 @@\n         inputs: TabularData,\n-        transformations: Optional[TabularTransformationType] = None,\n+        transformations: Optional[\n+            Union[TabularTransformationsType, SequentialTabularTransformations]\n+        ] = None,\n     ) -> TabularData:\n",
        "source_code_with_indent": "        inputs: TabularData,\n        transformations: Optional[TabularTransformationType] = None,\n    ) -> TabularData:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        inputs: TabularData,\n        transformations: Optional[\n            Union[TabularTransformationsType, SequentialTabularTransformations]\n        ] = None,\n    ) -> TabularData:\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/tabular/base.py",
    "file_hunks_size": 21,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/torch/tabular/tabular.py:300:8 Incompatible variable type [9]: merge_with is declared to have type `Union[List[TabularModule], TabularModule]` but is used as type `None`.",
    "message": " merge_with is declared to have type `Union[List[TabularModule], TabularModule]` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 300,
    "warning_line": "        merge_with: Union[\"TabularModule\", List[\"TabularModule\"]] = None,"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/tabular/base.py",
    "file_hunks_size": 21,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/torch/tabular/tabular.py:333:21 Incompatible parameter type [6]: Expected `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]` for 2nd parameter `transformations` to call `TabularModule._maybe_apply_transformations` but got `Union[None, List[TabularTransformation], List[str], SequentialTabularTransformations, TabularTransformation, str]`.",
    "message": " Expected `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]` for 2nd parameter `transformations` to call `TabularModule._maybe_apply_transformations` but got `Union[None, List[TabularTransformation], List[str], SequentialTabularTransformations, TabularTransformation, str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 333,
    "warning_line": "            outputs, transformations=transformations or self.post",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\nTabularTransformationType = Union[\n    str, TabularTransformation, List[str], List[TabularTransformation]\n]\nTabularAggregationType = Union[str, TabularAggregation]\n",
        "source_code_len": 165,
        "target_code": "\nTabularTransformationType = Union[str, TabularTransformation]\nTabularTransformationsType = Union[TabularTransformationType, List[TabularTransformationType]]\nTabularAggregationType = Union[str, TabularAggregation]\n",
        "target_code_len": 214,
        "diff_format": "@@ -107,5 +107,4 @@\n \n-TabularTransformationType = Union[\n-    str, TabularTransformation, List[str], List[TabularTransformation]\n-]\n+TabularTransformationType = Union[str, TabularTransformation]\n+TabularTransformationsType = Union[TabularTransformationType, List[TabularTransformationType]]\n TabularAggregationType = Union[str, TabularAggregation]\n",
        "source_code_with_indent": "\n<DED><DED>TabularTransformationType = Union[\n    str, TabularTransformation, List[str], List[TabularTransformation]\n]\nTabularAggregationType = Union[str, TabularAggregation]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED><DED>TabularTransformationType = Union[str, TabularTransformation]\nTabularTransformationsType = Union[TabularTransformationType, List[TabularTransformationType]]\nTabularAggregationType = Union[str, TabularAggregation]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    def __init__(self, *transformation: TabularTransformationType):\n        if len(transformation) == 1 and isinstance(transformation, list):\n",
        "source_code_len": 143,
        "target_code": "\n    def __init__(self, *transformation: TabularTransformationsType):\n        if len(transformation) == 1 and isinstance(transformation, list):\n",
        "target_code_len": 144,
        "diff_format": "@@ -122,3 +121,3 @@\n \n-    def __init__(self, *transformation: TabularTransformationType):\n+    def __init__(self, *transformation: TabularTransformationsType):\n         if len(transformation) == 1 and isinstance(transformation, list):\n",
        "source_code_with_indent": "\n    def __init__(self, *transformation: TabularTransformationType):\n        <IND>if len(transformation) == 1 and isinstance(transformation, list):\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    def __init__(self, *transformation: TabularTransformationsType):\n        <IND>if len(transformation) == 1 and isinstance(transformation, list):\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "        \"\"\"\n        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)\n\n",
        "source_code_len": 96,
        "target_code": "        \"\"\"\n        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)  # type: ignore\n\n",
        "target_code_len": 112,
        "diff_format": "@@ -210,3 +208,3 @@\n         \"\"\"\n-        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)\n+        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)  # type: ignore\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "\n        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)\n\n",
        "target_code_with_indent": "\n        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)  # type: ignore\n\n"
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    @pre.setter\n    def pre(self, value: Union[str, TabularTransformation, List[str], List[TabularTransformation]]):\n        if value:\n            self._pre = SequentialTabularTransformations(value)\n        else:\n",
        "source_code_len": 213,
        "target_code": "    @pre.setter\n    def pre(self, value: Optional[TabularTransformationsType]):\n        if value:\n            self._pre: Optional[\n                SequentialTabularTransformations\n            ] = SequentialTabularTransformations(value)\n        else:\n",
        "target_code_len": 250,
        "diff_format": "@@ -225,5 +223,7 @@\n     @pre.setter\n-    def pre(self, value: Union[str, TabularTransformation, List[str], List[TabularTransformation]]):\n+    def pre(self, value: Optional[TabularTransformationsType]):\n         if value:\n-            self._pre = SequentialTabularTransformations(value)\n+            self._pre: Optional[\n+                SequentialTabularTransformations\n+            ] = SequentialTabularTransformations(value)\n         else:\n",
        "source_code_with_indent": "    <DED>@pre.setter\n    def pre(self, value: Union[str, TabularTransformation, List[str], List[TabularTransformation]]):\n        <IND>if value:\n            <IND>self._pre = SequentialTabularTransformations(value)\n        <DED>else:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED>@pre.setter\n    def pre(self, value: Optional[TabularTransformationsType]):\n        <IND>if value:\n            <IND>self._pre: Optional[\n                SequentialTabularTransformations\n            ] = SequentialTabularTransformations(value)\n        <DED>else:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    @post.setter\n    def post(\n        self, value: Union[str, TabularTransformation, List[str], List[TabularTransformation]]\n    ):\n        if value:\n            self._post = SequentialTabularTransformations(value)\n        else:\n",
        "source_code_len": 230,
        "target_code": "    @post.setter\n    def post(self, value: Optional[TabularTransformationsType]):\n        if value:\n            self._post: Optional[\n                SequentialTabularTransformations\n            ] = SequentialTabularTransformations(value)\n        else:\n",
        "target_code_len": 253,
        "diff_format": "@@ -242,7 +242,7 @@\n     @post.setter\n-    def post(\n-        self, value: Union[str, TabularTransformation, List[str], List[TabularTransformation]]\n-    ):\n+    def post(self, value: Optional[TabularTransformationsType]):\n         if value:\n-            self._post = SequentialTabularTransformations(value)\n+            self._post: Optional[\n+                SequentialTabularTransformations\n+            ] = SequentialTabularTransformations(value)\n         else:\n",
        "source_code_with_indent": "    <DED>@post.setter\n    def post(\n        self, value: Union[str, TabularTransformation, List[str], List[TabularTransformation]]\n    ):\n        <IND>if value:\n            <IND>self._post = SequentialTabularTransformations(value)\n        <DED>else:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED>@post.setter\n    def post(self, value: Optional[TabularTransformationsType]):\n        <IND>if value:\n            <IND>self._post: Optional[\n                SequentialTabularTransformations\n            ] = SequentialTabularTransformations(value)\n        <DED>else:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    def pre_forward(\n        self, inputs: TabularData, transformations: Optional[TabularAggregationType] = None\n    ) -> TabularData:\n",
        "source_code_len": 135,
        "target_code": "    def pre_forward(\n        self, inputs: TabularData, transformations: Optional[TabularTransformationsType] = None\n    ) -> TabularData:\n",
        "target_code_len": 139,
        "diff_format": "@@ -274,3 +274,3 @@\n     def pre_forward(\n-        self, inputs: TabularData, transformations: Optional[TabularAggregationType] = None\n+        self, inputs: TabularData, transformations: Optional[TabularTransformationsType] = None\n     ) -> TabularData:\n",
        "source_code_with_indent": "    <DED><DED>def pre_forward(\n        self, inputs: TabularData, transformations: Optional[TabularAggregationType] = None\n    ) -> TabularData:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED><DED>def pre_forward(\n        self, inputs: TabularData, transformations: Optional[TabularTransformationsType] = None\n    ) -> TabularData:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        inputs: TabularData,\n        transformations: Optional[TabularTransformationType] = None,\n    ) -> TabularData:\n",
        "source_code_len": 120,
        "target_code": "        inputs: TabularData,\n        transformations: Optional[\n            Union[TabularTransformationsType, SequentialTabularTransformations]\n        ] = None,\n    ) -> TabularData:\n",
        "target_code_len": 184,
        "diff_format": "@@ -388,3 +390,5 @@\n         inputs: TabularData,\n-        transformations: Optional[TabularTransformationType] = None,\n+        transformations: Optional[\n+            Union[TabularTransformationsType, SequentialTabularTransformations]\n+        ] = None,\n     ) -> TabularData:\n",
        "source_code_with_indent": "        inputs: TabularData,\n        transformations: Optional[TabularTransformationType] = None,\n    ) -> TabularData:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        inputs: TabularData,\n        transformations: Optional[\n            Union[TabularTransformationsType, SequentialTabularTransformations]\n        ] = None,\n    ) -> TabularData:\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/tabular/base.py",
    "file_hunks_size": 21,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/torch/tabular/tabular.py:349:8 Incompatible variable type [9]: merge_with is declared to have type `Union[List[TabularModule], TabularModule]` but is used as type `None`.",
    "message": " merge_with is declared to have type `Union[List[TabularModule], TabularModule]` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 349,
    "warning_line": "        merge_with: Union[\"TabularModule\", List[\"TabularModule\"]] = None,"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/tabular/base.py",
    "file_hunks_size": 21,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/torch/tabular/tabular.py:374:42 Incompatible parameter type [6]: Expected `Union[None, TabularAggregation, str]` for 2nd parameter `transformations` to call `TabularModule.pre_forward` but got `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]`.",
    "message": " Expected `Union[None, TabularAggregation, str]` for 2nd parameter `transformations` to call `TabularModule.pre_forward` but got `Union[None, List[TabularTransformation], List[str], TabularTransformation, str]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 374,
    "warning_line": "        inputs = self.pre_forward(inputs, transformations=pre)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\nTabularTransformationType = Union[\n    str, TabularTransformation, List[str], List[TabularTransformation]\n]\nTabularAggregationType = Union[str, TabularAggregation]\n",
        "source_code_len": 165,
        "target_code": "\nTabularTransformationType = Union[str, TabularTransformation]\nTabularTransformationsType = Union[TabularTransformationType, List[TabularTransformationType]]\nTabularAggregationType = Union[str, TabularAggregation]\n",
        "target_code_len": 214,
        "diff_format": "@@ -107,5 +107,4 @@\n \n-TabularTransformationType = Union[\n-    str, TabularTransformation, List[str], List[TabularTransformation]\n-]\n+TabularTransformationType = Union[str, TabularTransformation]\n+TabularTransformationsType = Union[TabularTransformationType, List[TabularTransformationType]]\n TabularAggregationType = Union[str, TabularAggregation]\n",
        "source_code_with_indent": "\n<DED><DED>TabularTransformationType = Union[\n    str, TabularTransformation, List[str], List[TabularTransformation]\n]\nTabularAggregationType = Union[str, TabularAggregation]\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED><DED>TabularTransformationType = Union[str, TabularTransformation]\nTabularTransformationsType = Union[TabularTransformationType, List[TabularTransformationType]]\nTabularAggregationType = Union[str, TabularAggregation]\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    def __init__(self, *transformation: TabularTransformationType):\n        if len(transformation) == 1 and isinstance(transformation, list):\n",
        "source_code_len": 143,
        "target_code": "\n    def __init__(self, *transformation: TabularTransformationsType):\n        if len(transformation) == 1 and isinstance(transformation, list):\n",
        "target_code_len": 144,
        "diff_format": "@@ -122,3 +121,3 @@\n \n-    def __init__(self, *transformation: TabularTransformationType):\n+    def __init__(self, *transformation: TabularTransformationsType):\n         if len(transformation) == 1 and isinstance(transformation, list):\n",
        "source_code_with_indent": "\n    def __init__(self, *transformation: TabularTransformationType):\n        <IND>if len(transformation) == 1 and isinstance(transformation, list):\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    def __init__(self, *transformation: TabularTransformationsType):\n        <IND>if len(transformation) == 1 and isinstance(transformation, list):\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "        \"\"\"\n        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)\n\n",
        "source_code_len": 96,
        "target_code": "        \"\"\"\n        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)  # type: ignore\n\n",
        "target_code_len": 112,
        "diff_format": "@@ -210,3 +208,3 @@\n         \"\"\"\n-        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)\n+        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)  # type: ignore\n \n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "\n        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)\n\n",
        "target_code_with_indent": "\n        pre = [FilterFeatures(features), pre] if pre else FilterFeatures(features)  # type: ignore\n\n"
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    @pre.setter\n    def pre(self, value: Union[str, TabularTransformation, List[str], List[TabularTransformation]]):\n        if value:\n            self._pre = SequentialTabularTransformations(value)\n        else:\n",
        "source_code_len": 213,
        "target_code": "    @pre.setter\n    def pre(self, value: Optional[TabularTransformationsType]):\n        if value:\n            self._pre: Optional[\n                SequentialTabularTransformations\n            ] = SequentialTabularTransformations(value)\n        else:\n",
        "target_code_len": 250,
        "diff_format": "@@ -225,5 +223,7 @@\n     @pre.setter\n-    def pre(self, value: Union[str, TabularTransformation, List[str], List[TabularTransformation]]):\n+    def pre(self, value: Optional[TabularTransformationsType]):\n         if value:\n-            self._pre = SequentialTabularTransformations(value)\n+            self._pre: Optional[\n+                SequentialTabularTransformations\n+            ] = SequentialTabularTransformations(value)\n         else:\n",
        "source_code_with_indent": "    <DED>@pre.setter\n    def pre(self, value: Union[str, TabularTransformation, List[str], List[TabularTransformation]]):\n        <IND>if value:\n            <IND>self._pre = SequentialTabularTransformations(value)\n        <DED>else:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED>@pre.setter\n    def pre(self, value: Optional[TabularTransformationsType]):\n        <IND>if value:\n            <IND>self._pre: Optional[\n                SequentialTabularTransformations\n            ] = SequentialTabularTransformations(value)\n        <DED>else:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    @post.setter\n    def post(\n        self, value: Union[str, TabularTransformation, List[str], List[TabularTransformation]]\n    ):\n        if value:\n            self._post = SequentialTabularTransformations(value)\n        else:\n",
        "source_code_len": 230,
        "target_code": "    @post.setter\n    def post(self, value: Optional[TabularTransformationsType]):\n        if value:\n            self._post: Optional[\n                SequentialTabularTransformations\n            ] = SequentialTabularTransformations(value)\n        else:\n",
        "target_code_len": 253,
        "diff_format": "@@ -242,7 +242,7 @@\n     @post.setter\n-    def post(\n-        self, value: Union[str, TabularTransformation, List[str], List[TabularTransformation]]\n-    ):\n+    def post(self, value: Optional[TabularTransformationsType]):\n         if value:\n-            self._post = SequentialTabularTransformations(value)\n+            self._post: Optional[\n+                SequentialTabularTransformations\n+            ] = SequentialTabularTransformations(value)\n         else:\n",
        "source_code_with_indent": "    <DED>@post.setter\n    def post(\n        self, value: Union[str, TabularTransformation, List[str], List[TabularTransformation]]\n    ):\n        <IND>if value:\n            <IND>self._post = SequentialTabularTransformations(value)\n        <DED>else:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED>@post.setter\n    def post(self, value: Optional[TabularTransformationsType]):\n        <IND>if value:\n            <IND>self._post: Optional[\n                SequentialTabularTransformations\n            ] = SequentialTabularTransformations(value)\n        <DED>else:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    def pre_forward(\n        self, inputs: TabularData, transformations: Optional[TabularAggregationType] = None\n    ) -> TabularData:\n",
        "source_code_len": 135,
        "target_code": "    def pre_forward(\n        self, inputs: TabularData, transformations: Optional[TabularTransformationsType] = None\n    ) -> TabularData:\n",
        "target_code_len": 139,
        "diff_format": "@@ -274,3 +274,3 @@\n     def pre_forward(\n-        self, inputs: TabularData, transformations: Optional[TabularAggregationType] = None\n+        self, inputs: TabularData, transformations: Optional[TabularTransformationsType] = None\n     ) -> TabularData:\n",
        "source_code_with_indent": "    <DED><DED>def pre_forward(\n        self, inputs: TabularData, transformations: Optional[TabularAggregationType] = None\n    ) -> TabularData:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    <DED><DED>def pre_forward(\n        self, inputs: TabularData, transformations: Optional[TabularTransformationsType] = None\n    ) -> TabularData:\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        inputs: TabularData,\n        transformations: Optional[TabularTransformationType] = None,\n    ) -> TabularData:\n",
        "source_code_len": 120,
        "target_code": "        inputs: TabularData,\n        transformations: Optional[\n            Union[TabularTransformationsType, SequentialTabularTransformations]\n        ] = None,\n    ) -> TabularData:\n",
        "target_code_len": 184,
        "diff_format": "@@ -388,3 +390,5 @@\n         inputs: TabularData,\n-        transformations: Optional[TabularTransformationType] = None,\n+        transformations: Optional[\n+            Union[TabularTransformationsType, SequentialTabularTransformations]\n+        ] = None,\n     ) -> TabularData:\n",
        "source_code_with_indent": "        inputs: TabularData,\n        transformations: Optional[TabularTransformationType] = None,\n    ) -> TabularData:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        inputs: TabularData,\n        transformations: Optional[\n            Union[TabularTransformationsType, SequentialTabularTransformations]\n        ] = None,\n    ) -> TabularData:\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/tabular/base.py",
    "file_hunks_size": 21,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "transformers4rec/torch/tabular/tabular.py:557:12 Incompatible variable type [9]: Unable to unpack `Union[Dict[str, typing.Any], TabularModule]`, expected a tuple.",
    "message": " Unable to unpack `Union[Dict[str, typing.Any], TabularModule]`, expected a tuple.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 557,
    "warning_line": "            modules_to_merge = reduce(lambda a, b: dict(a, **b), modules_to_merge)"
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/tabular/base.py",
    "file_hunks_size": 21,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "transformers4rec/torch/tabular/tabular.py:573:4 Inconsistent override [14]: `transformers4rec.torch.tabular.tabular.MergeTabular.forward` overrides method defined in `TabularModule` inconsistently. Could not find parameter `x` in overriding signature.",
    "message": " `transformers4rec.torch.tabular.tabular.MergeTabular.forward` overrides method defined in `TabularModule` inconsistently. Could not find parameter `x` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 573,
    "warning_line": "    def forward(self, inputs: TabularData, **kwargs) -> TabularData:",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "\n    def forward(self, inputs: TabularData, **kwargs) -> TabularData:\n        assert isinstance(inputs, dict), \"Inputs needs to be a dict\"\n",
        "source_code_len": 139,
        "target_code": "\n    def forward(self, inputs: TabularData, training=True, **kwargs) -> TabularData:  # type: ignore\n        assert isinstance(inputs, dict), \"Inputs needs to be a dict\"\n",
        "target_code_len": 170,
        "diff_format": "@@ -572,3 +583,3 @@\n \n-    def forward(self, inputs: TabularData, **kwargs) -> TabularData:\n+    def forward(self, inputs: TabularData, training=True, **kwargs) -> TabularData:  # type: ignore\n         assert isinstance(inputs, dict), \"Inputs needs to be a dict\"\n",
        "source_code_with_indent": "\n    <DED>def forward(self, inputs: TabularData, **kwargs) -> TabularData:\n        <IND>assert isinstance(inputs, dict), \"Inputs needs to be a dict\"\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>def forward(self, inputs: TabularData, training=True, **kwargs) -> TabularData:  # type: ignore\n        <IND>assert isinstance(inputs, dict), \"Inputs needs to be a dict\"\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/tabular/base.py",
    "file_hunks_size": 21,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "transformers4rec/torch/tabular/tabular.py:573:4 Inconsistent override [14]: `transformers4rec.torch.tabular.tabular.MergeTabular.forward` overrides method defined in `TabularModule` inconsistently. Could not find parameter `Variable(unknown)` in overriding signature.",
    "message": " `transformers4rec.torch.tabular.tabular.MergeTabular.forward` overrides method defined in `TabularModule` inconsistently. Could not find parameter `Variable(unknown)` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 573,
    "warning_line": "    def forward(self, inputs: TabularData, **kwargs) -> TabularData:",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "\n    def forward(self, inputs: TabularData, **kwargs) -> TabularData:\n        assert isinstance(inputs, dict), \"Inputs needs to be a dict\"\n",
        "source_code_len": 139,
        "target_code": "\n    def forward(self, inputs: TabularData, training=True, **kwargs) -> TabularData:  # type: ignore\n        assert isinstance(inputs, dict), \"Inputs needs to be a dict\"\n",
        "target_code_len": 170,
        "diff_format": "@@ -572,3 +583,3 @@\n \n-    def forward(self, inputs: TabularData, **kwargs) -> TabularData:\n+    def forward(self, inputs: TabularData, training=True, **kwargs) -> TabularData:  # type: ignore\n         assert isinstance(inputs, dict), \"Inputs needs to be a dict\"\n",
        "source_code_with_indent": "\n    <DED>def forward(self, inputs: TabularData, **kwargs) -> TabularData:\n        <IND>assert isinstance(inputs, dict), \"Inputs needs to be a dict\"\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>def forward(self, inputs: TabularData, training=True, **kwargs) -> TabularData:  # type: ignore\n        <IND>assert isinstance(inputs, dict), \"Inputs needs to be a dict\"\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/tabular/base.py",
    "file_hunks_size": 21,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "transformers4rec/torch/tabular/tabular.py:612:4 Inconsistent override [14]: `transformers4rec.torch.tabular.tabular.AsTabular.forward` overrides method defined in `TabularModule` inconsistently. Could not find parameter `x` in overriding signature.",
    "message": " `transformers4rec.torch.tabular.tabular.AsTabular.forward` overrides method defined in `TabularModule` inconsistently. Could not find parameter `x` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 612,
    "warning_line": "    def forward(self, inputs: torch.Tensor, **kwargs) -> TabularData:",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "\n    def forward(self, inputs: torch.Tensor, **kwargs) -> TabularData:\n        return {self.output_name: inputs}\n",
        "source_code_len": 113,
        "target_code": "\n    def forward(self, inputs: torch.Tensor, **kwargs) -> TabularData:  # type: ignore\n        return {self.output_name: inputs}\n",
        "target_code_len": 129,
        "diff_format": "@@ -611,3 +622,3 @@\n \n-    def forward(self, inputs: torch.Tensor, **kwargs) -> TabularData:\n+    def forward(self, inputs: torch.Tensor, **kwargs) -> TabularData:  # type: ignore\n         return {self.output_name: inputs}\n",
        "source_code_with_indent": "\n    <DED>def forward(self, inputs: torch.Tensor, **kwargs) -> TabularData:\n        <IND>return {self.output_name: inputs}\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>def forward(self, inputs: torch.Tensor, **kwargs) -> TabularData:  # type: ignore\n        <IND>return {self.output_name: inputs}\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "NVIDIA-Merlin/Transformers4Rec",
    "commit": "538fc54bb8f2e3dc79224e497bebee15b00e4ab7",
    "filename": "transformers4rec/torch/tabular/tabular.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/NVIDIA-Merlin-Transformers4Rec/transformers4rec/torch/tabular/base.py",
    "file_hunks_size": 21,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "transformers4rec/torch/tabular/tabular.py:612:4 Inconsistent override [14]: `transformers4rec.torch.tabular.tabular.AsTabular.forward` overrides method defined in `TabularModule` inconsistently. Could not find parameter `Variable(unknown)` in overriding signature.",
    "message": " `transformers4rec.torch.tabular.tabular.AsTabular.forward` overrides method defined in `TabularModule` inconsistently. Could not find parameter `Variable(unknown)` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 612,
    "warning_line": "    def forward(self, inputs: torch.Tensor, **kwargs) -> TabularData:",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "\n    def forward(self, inputs: torch.Tensor, **kwargs) -> TabularData:\n        return {self.output_name: inputs}\n",
        "source_code_len": 113,
        "target_code": "\n    def forward(self, inputs: torch.Tensor, **kwargs) -> TabularData:  # type: ignore\n        return {self.output_name: inputs}\n",
        "target_code_len": 129,
        "diff_format": "@@ -611,3 +622,3 @@\n \n-    def forward(self, inputs: torch.Tensor, **kwargs) -> TabularData:\n+    def forward(self, inputs: torch.Tensor, **kwargs) -> TabularData:  # type: ignore\n         return {self.output_name: inputs}\n",
        "source_code_with_indent": "\n    <DED>def forward(self, inputs: torch.Tensor, **kwargs) -> TabularData:\n        <IND>return {self.output_name: inputs}\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>def forward(self, inputs: torch.Tensor, **kwargs) -> TabularData:  # type: ignore\n        <IND>return {self.output_name: inputs}\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  }
]