[
  {
    "project": "PyTorchLightning/pytorch-lightning",
    "commit": "9a14f04322c93de45f5903476c8d64e1634880b7",
    "filename": "pytorch_lightning/loops/batch/training_batch_loop.py",
    "min_patch_found": false,
    "full_warning_msg": "pytorch_lightning/loops/batch/training_batch_loop.py:227:77 Incompatible parameter type [6]: Expected `pytorch_lightning.trainer.trainer.Trainer` for 1st positional only parameter to call `_process_training_step_output` but got `Optional[pytorch_lightning.trainer.trainer.Trainer]`.",
    "exception": "PatchSet should only have 1 Patch, but it has 0",
    "dd_fail": true
  },
  {
    "project": "PyTorchLightning/pytorch-lightning",
    "commit": "9a14f04322c93de45f5903476c8d64e1634880b7",
    "filename": "pytorch_lightning/loops/optimizer/optimizer_loop.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/PyTorchLightning-pytorch-lightning/pytorch_lightning/loops/optimizer/optimizer_loop.py",
    "file_hunks_size": 15,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "pytorch_lightning/loops/optimizer/optimizer_loop.py:69:4 Inconsistent override [14]: `pytorch_lightning.loops.optimizer.optimizer_loop.OptimizerLoop.on_run_start` overrides method defined in `pytorch_lightning.loops.base.Loop` inconsistently. Could not find parameter `Variable(typing.Any)` in overriding signature.",
    "message": " `pytorch_lightning.loops.optimizer.optimizer_loop.OptimizerLoop.on_run_start` overrides method defined in `pytorch_lightning.loops.base.Loop` inconsistently. Could not find parameter `Variable(typing.Any)` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 69,
    "warning_line": "    def on_run_start(self, batch: Any, hiddens: Any, optimizers: List[Optimizer], batch_idx: int) -> None:"
  },
  {
    "project": "PyTorchLightning/pytorch-lightning",
    "commit": "9a14f04322c93de45f5903476c8d64e1634880b7",
    "filename": "pytorch_lightning/loops/optimizer/optimizer_loop.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/PyTorchLightning-pytorch-lightning/pytorch_lightning/loops/optimizer/optimizer_loop.py",
    "file_hunks_size": 15,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "pytorch_lightning/loops/optimizer/optimizer_loop.py:69:4 Inconsistent override [14]: `pytorch_lightning.loops.optimizer.optimizer_loop.OptimizerLoop.on_run_start` overrides method defined in `pytorch_lightning.loops.base.Loop` inconsistently. Could not find parameter `Keywords(typing.Any)` in overriding signature.",
    "message": " `pytorch_lightning.loops.optimizer.optimizer_loop.OptimizerLoop.on_run_start` overrides method defined in `pytorch_lightning.loops.base.Loop` inconsistently. Could not find parameter `Keywords(typing.Any)` in overriding signature.",
    "rule_id": "Inconsistent override [14]",
    "warning_line_no": 69,
    "warning_line": "    def on_run_start(self, batch: Any, hiddens: Any, optimizers: List[Optimizer], batch_idx: int) -> None:"
  },
  {
    "project": "PyTorchLightning/pytorch-lightning",
    "commit": "9a14f04322c93de45f5903476c8d64e1634880b7",
    "filename": "pytorch_lightning/loops/optimizer/optimizer_loop.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/PyTorchLightning-pytorch-lightning/pytorch_lightning/loops/optimizer/optimizer_loop.py",
    "file_hunks_size": 15,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "pytorch_lightning/loops/optimizer/optimizer_loop.py:76:12 Incompatible parameter type [6]: Expected `int` for 1st positional only parameter to call `OptimizerLoop._run_optimization` but got `Optional[int]`.",
    "message": " Expected `int` for 1st positional only parameter to call `OptimizerLoop._run_optimization` but got `Optional[int]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 76,
    "warning_line": "            self._batch_idx,",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        self._skip_backward: bool = False\n        self._batch_idx: Optional[int] = None\n        self._optimizers: Optional[List[Optimizer]] = None\n        self._hiddens: Optional[Any] = None\n",
        "source_code_len": 191,
        "target_code": "        self._skip_backward: bool = False\n        self._batch_idx: int = 0\n        self._optimizers: List[Optimizer] = []\n        self._hiddens: Optional[Any] = None\n",
        "target_code_len": 166,
        "diff_format": "@@ -51,4 +51,4 @@\n         self._skip_backward: bool = False\n-        self._batch_idx: Optional[int] = None\n-        self._optimizers: Optional[List[Optimizer]] = None\n+        self._batch_idx: int = 0\n+        self._optimizers: List[Optimizer] = []\n         self._hiddens: Optional[Any] = None\n",
        "source_code_with_indent": "        self._skip_backward: bool = False\n        self._batch_idx: Optional[int] = None\n        self._optimizers: Optional[List[Optimizer]] = None\n        self._hiddens: Optional[Any] = None\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        self._skip_backward: bool = False\n        self._batch_idx: int = 0\n        self._optimizers: List[Optimizer] = []\n        self._hiddens: Optional[Any] = None\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "PyTorchLightning/pytorch-lightning",
    "commit": "9a14f04322c93de45f5903476c8d64e1634880b7",
    "filename": "pytorch_lightning/loops/optimizer/optimizer_loop.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/PyTorchLightning-pytorch-lightning/pytorch_lightning/loops/optimizer/optimizer_loop.py",
    "file_hunks_size": 15,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "pytorch_lightning/loops/optimizer/optimizer_loop.py:135:37 Incompatible parameter type [6]: Expected `int` for 1st positional only parameter to call `OptimizerLoop._run_optimization_start` but got `Optional[int]`.",
    "message": " Expected `int` for 1st positional only parameter to call `OptimizerLoop._run_optimization_start` but got `Optional[int]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 135,
    "warning_line": "        self._run_optimization_start(opt_idx, optimizer)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        self,\n        batch_idx: int,\n        split_batch: Any,\n        opt_idx: Optional[int] = None,\n        optimizer: Optional[torch.optim.Optimizer] = None,\n    ) -> Optional[ClosureResult]:\n",
        "source_code_len": 196,
        "target_code": "        self,\n        split_batch: Any,\n        batch_idx: int,\n        optimizer: torch.optim.Optimizer,\n        opt_idx: int,\n    ) -> Optional[ClosureResult]:\n",
        "target_code_len": 162,
        "diff_format": "@@ -120,6 +122,6 @@\n         self,\n+        split_batch: Any,\n         batch_idx: int,\n-        split_batch: Any,\n-        opt_idx: Optional[int] = None,\n-        optimizer: Optional[torch.optim.Optimizer] = None,\n+        optimizer: torch.optim.Optimizer,\n+        opt_idx: int,\n     ) -> Optional[ClosureResult]:\n",
        "source_code_with_indent": "        self,\n        batch_idx: int,\n        split_batch: Any,\n        opt_idx: Optional[int] = None,\n        optimizer: Optional[torch.optim.Optimizer] = None,\n    ) -> Optional[ClosureResult]:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        self,\n        split_batch: Any,\n        batch_idx: int,\n        optimizer: torch.optim.Optimizer,\n        opt_idx: int,\n    ) -> Optional[ClosureResult]:\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "PyTorchLightning/pytorch-lightning",
    "commit": "9a14f04322c93de45f5903476c8d64e1634880b7",
    "filename": "pytorch_lightning/loops/optimizer/optimizer_loop.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/PyTorchLightning-pytorch-lightning/pytorch_lightning/loops/optimizer/optimizer_loop.py",
    "file_hunks_size": 15,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "pytorch_lightning/loops/optimizer/optimizer_loop.py:137:61 Incompatible parameter type [6]: Expected `int` for 3rd positional only parameter to call `OptimizerLoop._make_closure` but got `Optional[int]`.",
    "message": " Expected `int` for 3rd positional only parameter to call `OptimizerLoop._make_closure` but got `Optional[int]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 137,
    "warning_line": "        closure = self._make_closure(split_batch, batch_idx, opt_idx, optimizer, self._hiddens)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        self,\n        batch_idx: int,\n        split_batch: Any,\n        opt_idx: Optional[int] = None,\n        optimizer: Optional[torch.optim.Optimizer] = None,\n    ) -> Optional[ClosureResult]:\n",
        "source_code_len": 196,
        "target_code": "        self,\n        split_batch: Any,\n        batch_idx: int,\n        optimizer: torch.optim.Optimizer,\n        opt_idx: int,\n    ) -> Optional[ClosureResult]:\n",
        "target_code_len": 162,
        "diff_format": "@@ -120,6 +122,6 @@\n         self,\n+        split_batch: Any,\n         batch_idx: int,\n-        split_batch: Any,\n-        opt_idx: Optional[int] = None,\n-        optimizer: Optional[torch.optim.Optimizer] = None,\n+        optimizer: torch.optim.Optimizer,\n+        opt_idx: int,\n     ) -> Optional[ClosureResult]:\n",
        "source_code_with_indent": "        self,\n        batch_idx: int,\n        split_batch: Any,\n        opt_idx: Optional[int] = None,\n        optimizer: Optional[torch.optim.Optimizer] = None,\n    ) -> Optional[ClosureResult]:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        self,\n        split_batch: Any,\n        batch_idx: int,\n        optimizer: torch.optim.Optimizer,\n        opt_idx: int,\n    ) -> Optional[ClosureResult]:\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "PyTorchLightning/pytorch-lightning",
    "commit": "9a14f04322c93de45f5903476c8d64e1634880b7",
    "filename": "pytorch_lightning/loops/optimizer/optimizer_loop.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/PyTorchLightning-pytorch-lightning/pytorch_lightning/loops/optimizer/optimizer_loop.py",
    "file_hunks_size": 15,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "pytorch_lightning/loops/optimizer/optimizer_loop.py:146:47 Incompatible parameter type [6]: Expected `pytorch_lightning.trainer.trainer.Trainer` for 1st positional only parameter to call `_block_parallel_sync_behavior` but got `Optional[pytorch_lightning.trainer.trainer.Trainer]`.",
    "message": " Expected `pytorch_lightning.trainer.trainer.Trainer` for 1st positional only parameter to call `_block_parallel_sync_behavior` but got `Optional[pytorch_lightning.trainer.trainer.Trainer]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 146,
    "warning_line": "            with _block_parallel_sync_behavior(self.trainer, block=True):"
  },
  {
    "project": "PyTorchLightning/pytorch-lightning",
    "commit": "9a14f04322c93de45f5903476c8d64e1634880b7",
    "filename": "pytorch_lightning/loops/optimizer/optimizer_loop.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/PyTorchLightning-pytorch-lightning/pytorch_lightning/loops/optimizer/optimizer_loop.py",
    "file_hunks_size": 15,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "pytorch_lightning/loops/optimizer/optimizer_loop.py:154:44 Incompatible parameter type [6]: Expected `int` for 2nd positional only parameter to call `OptimizerLoop._optimizer_step` but got `Optional[int]`.",
    "message": " Expected `int` for 2nd positional only parameter to call `OptimizerLoop._optimizer_step` but got `Optional[int]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 154,
    "warning_line": "            self._optimizer_step(optimizer, opt_idx, batch_idx, closure)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        self,\n        batch_idx: int,\n        split_batch: Any,\n        opt_idx: Optional[int] = None,\n        optimizer: Optional[torch.optim.Optimizer] = None,\n    ) -> Optional[ClosureResult]:\n",
        "source_code_len": 196,
        "target_code": "        self,\n        split_batch: Any,\n        batch_idx: int,\n        optimizer: torch.optim.Optimizer,\n        opt_idx: int,\n    ) -> Optional[ClosureResult]:\n",
        "target_code_len": 162,
        "diff_format": "@@ -120,6 +122,6 @@\n         self,\n+        split_batch: Any,\n         batch_idx: int,\n-        split_batch: Any,\n-        opt_idx: Optional[int] = None,\n-        optimizer: Optional[torch.optim.Optimizer] = None,\n+        optimizer: torch.optim.Optimizer,\n+        opt_idx: int,\n     ) -> Optional[ClosureResult]:\n",
        "source_code_with_indent": "        self,\n        batch_idx: int,\n        split_batch: Any,\n        opt_idx: Optional[int] = None,\n        optimizer: Optional[torch.optim.Optimizer] = None,\n    ) -> Optional[ClosureResult]:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        self,\n        split_batch: Any,\n        batch_idx: int,\n        optimizer: torch.optim.Optimizer,\n        opt_idx: int,\n    ) -> Optional[ClosureResult]:\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "PyTorchLightning/pytorch-lightning",
    "commit": "9a14f04322c93de45f5903476c8d64e1634880b7",
    "filename": "pytorch_lightning/loops/optimizer/optimizer_loop.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/PyTorchLightning-pytorch-lightning/pytorch_lightning/loops/optimizer/optimizer_loop.py",
    "file_hunks_size": 15,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "pytorch_lightning/loops/optimizer/optimizer_loop.py:165:35 Incompatible parameter type [6]: Expected `int` for 1st positional only parameter to call `OptimizerLoop._run_optimization_end` but got `Optional[int]`.",
    "message": " Expected `int` for 1st positional only parameter to call `OptimizerLoop._run_optimization_end` but got `Optional[int]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 165,
    "warning_line": "        self._run_optimization_end(opt_idx)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        self,\n        batch_idx: int,\n        split_batch: Any,\n        opt_idx: Optional[int] = None,\n        optimizer: Optional[torch.optim.Optimizer] = None,\n    ) -> Optional[ClosureResult]:\n",
        "source_code_len": 196,
        "target_code": "        self,\n        split_batch: Any,\n        batch_idx: int,\n        optimizer: torch.optim.Optimizer,\n        opt_idx: int,\n    ) -> Optional[ClosureResult]:\n",
        "target_code_len": 162,
        "diff_format": "@@ -120,6 +122,6 @@\n         self,\n+        split_batch: Any,\n         batch_idx: int,\n-        split_batch: Any,\n-        opt_idx: Optional[int] = None,\n-        optimizer: Optional[torch.optim.Optimizer] = None,\n+        optimizer: torch.optim.Optimizer,\n+        opt_idx: int,\n     ) -> Optional[ClosureResult]:\n",
        "source_code_with_indent": "        self,\n        batch_idx: int,\n        split_batch: Any,\n        opt_idx: Optional[int] = None,\n        optimizer: Optional[torch.optim.Optimizer] = None,\n    ) -> Optional[ClosureResult]:\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        self,\n        split_batch: Any,\n        batch_idx: int,\n        optimizer: torch.optim.Optimizer,\n        opt_idx: int,\n    ) -> Optional[ClosureResult]:\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "PyTorchLightning/pytorch-lightning",
    "commit": "9a14f04322c93de45f5903476c8d64e1634880b7",
    "filename": "pytorch_lightning/loops/optimizer/optimizer_loop.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/PyTorchLightning-pytorch-lightning/pytorch_lightning/loops/optimizer/optimizer_loop.py",
    "file_hunks_size": 15,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "pytorch_lightning/loops/optimizer/optimizer_loop.py:193:8 Incompatible return type [7]: Expected `typing.Callable[[], Dict[typing.Any, typing.Any]]` but got `partial[Optional[pytorch_lightning.utilities.parsing.AttributeDict]]`.",
    "message": " Expected `typing.Callable[[], Dict[typing.Any, typing.Any]]` but got `partial[Optional[pytorch_lightning.utilities.parsing.AttributeDict]]`.",
    "rule_id": "Incompatible return type [7]",
    "warning_line_no": 193,
    "warning_line": "        return partial(self._training_step, split_batch, batch_idx, opt_idx, hiddens)"
  },
  {
    "project": "PyTorchLightning/pytorch-lightning",
    "commit": "9a14f04322c93de45f5903476c8d64e1634880b7",
    "filename": "pytorch_lightning/loops/optimizer/optimizer_loop.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/PyTorchLightning-pytorch-lightning/pytorch_lightning/loops/optimizer/optimizer_loop.py",
    "file_hunks_size": 15,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "pytorch_lightning/loops/optimizer/optimizer_loop.py:349:77 Incompatible parameter type [6]: Expected `pytorch_lightning.trainer.trainer.Trainer` for 1st positional only parameter to call `_process_training_step_output` but got `Optional[pytorch_lightning.trainer.trainer.Trainer]`.",
    "message": " Expected `pytorch_lightning.trainer.trainer.Trainer` for 1st positional only parameter to call `_process_training_step_output` but got `Optional[pytorch_lightning.trainer.trainer.Trainer]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 349,
    "warning_line": "            result_collection, self._hiddens = _process_training_step_output(self.trainer, training_step_output)"
  }
]