[
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/core/policies/policy.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/core/policies/policy.py",
    "file_hunks_size": 1,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/core/policies/policy.py:367:28 Unsupported operand [58]: `/` is not supported for operand types `Path` and `Optional[str]`.",
    "message": " `/` is not supported for operand types `Path` and `Optional[str]`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 367,
    "warning_line": "        file = Path(path) / self._metadata_filename()",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    @classmethod\n    def _metadata_filename(cls) -> Optional[Text]:\n        \"\"\"Returns the filename of the persisted policy metadata.\n",
        "source_code_len": 134,
        "target_code": "    @classmethod\n    def _metadata_filename(cls) -> Text:\n        \"\"\"Returns the filename of the persisted policy metadata.\n",
        "target_code_len": 124,
        "diff_format": "@@ -345,3 +345,3 @@\n     @classmethod\n-    def _metadata_filename(cls) -> Optional[Text]:\n+    def _metadata_filename(cls) -> Text:\n         \"\"\"Returns the filename of the persisted policy metadata.\n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "    <DED>@classmethod\n    def _metadata_filename(cls) -> Optional[Text]:\n        <IND>",
        "target_code_with_indent": "    <DED>@classmethod\n    def _metadata_filename(cls) -> Text:\n        <IND>"
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/core/policies/policy.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/core/policies/policy.py",
    "file_hunks_size": 1,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/core/policies/policy.py:382:37 Unsupported operand [58]: `/` is not supported for operand types `Path` and `Optional[str]`.",
    "message": " `/` is not supported for operand types `Path` and `Optional[str]`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 382,
    "warning_line": "        metadata_file = Path(path) / cls._metadata_filename()",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    @classmethod\n    def _metadata_filename(cls) -> Optional[Text]:\n        \"\"\"Returns the filename of the persisted policy metadata.\n",
        "source_code_len": 134,
        "target_code": "    @classmethod\n    def _metadata_filename(cls) -> Text:\n        \"\"\"Returns the filename of the persisted policy metadata.\n",
        "target_code_len": 124,
        "diff_format": "@@ -345,3 +345,3 @@\n     @classmethod\n-    def _metadata_filename(cls) -> Optional[Text]:\n+    def _metadata_filename(cls) -> Text:\n         \"\"\"Returns the filename of the persisted policy metadata.\n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "    <DED>@classmethod\n    def _metadata_filename(cls) -> Optional[Text]:\n        <IND>",
        "target_code_with_indent": "    <DED>@classmethod\n    def _metadata_filename(cls) -> Text:\n        <IND>"
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/core/policies/rule_policy.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/core/policies/rule_policy.py",
    "file_hunks_size": 3,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/core/policies/rule_policy.py:945:50 Unsupported operand [58]: `+` is not supported for operand types `str` and `Optional[str]`.",
    "message": " `+` is not supported for operand types `str` and `Optional[str]`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 945,
    "warning_line": "            return active_loop_name, LOOP_RULES + active_loop_name",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        active_loop_name = tracker.active_loop_name\n        active_loop_rejected = tracker.active_loop.get(LOOP_REJECTED)\n        should_predict_loop = (\n            active_loop_name\n            and not active_loop_rejected\n            and tracker.latest_action.get(ACTION_NAME) != active_loop_name\n",
        "source_code_len": 299,
        "target_code": "        active_loop_name = tracker.active_loop_name\n        if active_loop_name is None:\n            return None, None\n\n        active_loop_rejected = tracker.active_loop.get(LOOP_REJECTED)\n        should_predict_loop = (\n            not active_loop_rejected\n            and tracker.latest_action.get(ACTION_NAME) != active_loop_name\n",
        "target_code_len": 334,
        "diff_format": "@@ -930,6 +931,8 @@\n         active_loop_name = tracker.active_loop_name\n+        if active_loop_name is None:\n+            return None, None\n+\n         active_loop_rejected = tracker.active_loop.get(LOOP_REJECTED)\n         should_predict_loop = (\n-            active_loop_name\n-            and not active_loop_rejected\n+            not active_loop_rejected\n             and tracker.latest_action.get(ACTION_NAME) != active_loop_name\n",
        "source_code_with_indent": "        <IND>active_loop_name = tracker.active_loop_name\n        active_loop_rejected = tracker.active_loop.get(LOOP_REJECTED)\n        should_predict_loop = (\n            active_loop_name\n            and not active_loop_rejected\n            and tracker.latest_action.get(ACTION_NAME) != active_loop_name\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        <IND>active_loop_name = tracker.active_loop_name\n        if active_loop_name is None:\n            <IND>return None, None\n\n        <DED>active_loop_rejected = tracker.active_loop.get(LOOP_REJECTED)\n        should_predict_loop = (\n            not active_loop_rejected\n            and tracker.latest_action.get(ACTION_NAME) != active_loop_name\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/model.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/model.py",
    "file_hunks_size": 1,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": true,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/model.py:389:49 Unsupported operand [58]: `not in` is not supported for right operand type `Optional[List[str]]`.",
    "message": " `not in` is not supported for right operand type `Optional[List[str]]`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 389,
    "warning_line": "    keys = include_keys or list(filter(lambda k: k not in exclude_keys, config.keys()))",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n    keys = include_keys or list(filter(lambda k: k not in exclude_keys, config.keys()))\n\n",
        "source_code_len": 90,
        "target_code": "\n    exclude_keys = exclude_keys or []\n    keys = include_keys or [k for k in config.keys() if k not in exclude_keys]\n\n",
        "target_code_len": 119,
        "diff_format": "@@ -388,3 +388,4 @@\n \n-    keys = include_keys or list(filter(lambda k: k not in exclude_keys, config.keys()))\n+    exclude_keys = exclude_keys or []\n+    keys = include_keys or [k for k in config.keys() if k not in exclude_keys]\n \n",
        "source_code_with_indent": "\n    <DED>keys = include_keys or list(filter(lambda k: k not in exclude_keys, config.keys()))\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n    <DED>exclude_keys = exclude_keys or []\n    keys = include_keys or [k for k in config.keys() if k not in exclude_keys]\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/nlu/classifiers/diet_classifier.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/nlu/classifiers/diet_classifier.py",
    "file_hunks_size": 12,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": true,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/nlu/classifiers/diet_classifier.py:1014:8 Incompatible variable type [9]: model_dir is declared to have type `str` but is used as type `Path`.",
    "message": " model_dir is declared to have type `str` but is used as type `Path`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 1014,
    "warning_line": "        model_dir = Path(model_dir)",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n        model_dir = Path(model_dir)\n        tf_model_file = model_dir / f\"{file_name}.tf_model\"\n\n",
        "source_code_len": 98,
        "target_code": "\n        model_dir_path = Path(model_dir)\n        tf_model_file = model_dir_path / f\"{file_name}.tf_model\"\n\n",
        "target_code_len": 108,
        "diff_format": "@@ -1013,4 +1014,4 @@\n \n-        model_dir = Path(model_dir)\n-        tf_model_file = model_dir / f\"{file_name}.tf_model\"\n+        model_dir_path = Path(model_dir)\n+        tf_model_file = model_dir_path / f\"{file_name}.tf_model\"\n \n",
        "source_code_with_indent": "\n        <DED>model_dir = Path(model_dir)\n        tf_model_file = model_dir / f\"{file_name}.tf_model\"\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n        <DED>model_dir_path = Path(model_dir)\n        tf_model_file = model_dir_path / f\"{file_name}.tf_model\"\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/nlu/classifiers/diet_classifier.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/nlu/classifiers/diet_classifier.py",
    "file_hunks_size": 12,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": true,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/nlu/classifiers/diet_classifier.py:1015:24 Unsupported operand [58]: `/` is not supported for operand types `str` and `str`.",
    "message": " `/` is not supported for operand types `str` and `str`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 1015,
    "warning_line": "        tf_model_file = model_dir / f\"{file_name}.tf_model\"",
    "min_patch": [
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n        model_dir = Path(model_dir)\n        tf_model_file = model_dir / f\"{file_name}.tf_model\"\n\n",
        "source_code_len": 98,
        "target_code": "\n        model_dir_path = Path(model_dir)\n        tf_model_file = model_dir_path / f\"{file_name}.tf_model\"\n\n",
        "target_code_len": 108,
        "diff_format": "@@ -1013,4 +1014,4 @@\n \n-        model_dir = Path(model_dir)\n-        tf_model_file = model_dir / f\"{file_name}.tf_model\"\n+        model_dir_path = Path(model_dir)\n+        tf_model_file = model_dir_path / f\"{file_name}.tf_model\"\n \n",
        "source_code_with_indent": "\n        <DED>model_dir = Path(model_dir)\n        tf_model_file = model_dir / f\"{file_name}.tf_model\"\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n        <DED>model_dir_path = Path(model_dir)\n        tf_model_file = model_dir_path / f\"{file_name}.tf_model\"\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/nlu/classifiers/diet_classifier.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/nlu/classifiers/diet_classifier.py",
    "file_hunks_size": 12,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/nlu/classifiers/diet_classifier.py:1020:49 Unsupported operand [58]: `/` is not supported for operand types `str` and `str`.",
    "message": " `/` is not supported for operand types `str` and `str`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 1020,
    "warning_line": "            shutil.move(self.tmp_checkpoint_dir, model_dir / \"checkpoints\")",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n        model_dir = Path(model_dir)\n        tf_model_file = model_dir / f\"{file_name}.tf_model\"\n\n",
        "source_code_len": 98,
        "target_code": "\n        model_dir_path = Path(model_dir)\n        tf_model_file = model_dir_path / f\"{file_name}.tf_model\"\n\n",
        "target_code_len": 108,
        "diff_format": "@@ -1013,4 +1014,4 @@\n \n-        model_dir = Path(model_dir)\n-        tf_model_file = model_dir / f\"{file_name}.tf_model\"\n+        model_dir_path = Path(model_dir)\n+        tf_model_file = model_dir_path / f\"{file_name}.tf_model\"\n \n",
        "source_code_with_indent": "\n        <DED>model_dir = Path(model_dir)\n        tf_model_file = model_dir / f\"{file_name}.tf_model\"\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n        <DED>model_dir_path = Path(model_dir)\n        tf_model_file = model_dir_path / f\"{file_name}.tf_model\"\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        if self.component_config[CHECKPOINT_MODEL]:\n            shutil.move(self.tmp_checkpoint_dir, model_dir / \"checkpoints\")\n        self.model.save(str(tf_model_file))\n",
        "source_code_len": 172,
        "target_code": "        if self.component_config[CHECKPOINT_MODEL]:\n            shutil.move(self.tmp_checkpoint_dir, model_dir_path / \"checkpoints\")\n        self.model.save(str(tf_model_file))\n",
        "target_code_len": 177,
        "diff_format": "@@ -1019,3 +1020,3 @@\n         if self.component_config[CHECKPOINT_MODEL]:\n-            shutil.move(self.tmp_checkpoint_dir, model_dir / \"checkpoints\")\n+            shutil.move(self.tmp_checkpoint_dir, model_dir_path / \"checkpoints\")\n         self.model.save(str(tf_model_file))\n",
        "source_code_with_indent": "        if self.component_config[CHECKPOINT_MODEL]:\n            <IND>shutil.move(self.tmp_checkpoint_dir, model_dir / \"checkpoints\")\n        <DED>self.model.save(str(tf_model_file))\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        if self.component_config[CHECKPOINT_MODEL]:\n            <IND>shutil.move(self.tmp_checkpoint_dir, model_dir_path / \"checkpoints\")\n        <DED>self.model.save(str(tf_model_file))\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/nlu/classifiers/diet_classifier.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/nlu/classifiers/diet_classifier.py",
    "file_hunks_size": 12,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/nlu/classifiers/diet_classifier.py:1024:12 Unsupported operand [58]: `/` is not supported for operand types `str` and `str`.",
    "message": " `/` is not supported for operand types `str` and `str`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 1024,
    "warning_line": "            model_dir / f\"{file_name}.data_example.pkl\", self._data_example",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n        model_dir = Path(model_dir)\n        tf_model_file = model_dir / f\"{file_name}.tf_model\"\n\n",
        "source_code_len": 98,
        "target_code": "\n        model_dir_path = Path(model_dir)\n        tf_model_file = model_dir_path / f\"{file_name}.tf_model\"\n\n",
        "target_code_len": 108,
        "diff_format": "@@ -1013,4 +1014,4 @@\n \n-        model_dir = Path(model_dir)\n-        tf_model_file = model_dir / f\"{file_name}.tf_model\"\n+        model_dir_path = Path(model_dir)\n+        tf_model_file = model_dir_path / f\"{file_name}.tf_model\"\n \n",
        "source_code_with_indent": "\n        <DED>model_dir = Path(model_dir)\n        tf_model_file = model_dir / f\"{file_name}.tf_model\"\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n        <DED>model_dir_path = Path(model_dir)\n        tf_model_file = model_dir_path / f\"{file_name}.tf_model\"\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        io_utils.pickle_dump(\n            model_dir / f\"{file_name}.data_example.pkl\", self._data_example\n        )\n        io_utils.pickle_dump(\n            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\",\n            self._sparse_feature_sizes,\n",
        "source_code_len": 251,
        "target_code": "        io_utils.pickle_dump(\n            model_dir_path / f\"{file_name}.data_example.pkl\", self._data_example\n        )\n        io_utils.pickle_dump(\n            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\",\n            self._sparse_feature_sizes,\n",
        "target_code_len": 261,
        "diff_format": "@@ -1023,6 +1024,6 @@\n         io_utils.pickle_dump(\n-            model_dir / f\"{file_name}.data_example.pkl\", self._data_example\n+            model_dir_path / f\"{file_name}.data_example.pkl\", self._data_example\n         )\n         io_utils.pickle_dump(\n-            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\",\n+            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\",\n             self._sparse_feature_sizes,\n",
        "source_code_with_indent": "        io_utils.pickle_dump(\n            model_dir / f\"{file_name}.data_example.pkl\", self._data_example\n        )\n        io_utils.pickle_dump(\n            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\",\n            self._sparse_feature_sizes,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        io_utils.pickle_dump(\n            model_dir_path / f\"{file_name}.data_example.pkl\", self._data_example\n        )\n        io_utils.pickle_dump(\n            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\",\n            self._sparse_feature_sizes,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/nlu/classifiers/diet_classifier.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/nlu/classifiers/diet_classifier.py",
    "file_hunks_size": 12,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/nlu/classifiers/diet_classifier.py:1027:12 Unsupported operand [58]: `/` is not supported for operand types `str` and `str`.",
    "message": " `/` is not supported for operand types `str` and `str`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 1027,
    "warning_line": "            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\",",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n        model_dir = Path(model_dir)\n        tf_model_file = model_dir / f\"{file_name}.tf_model\"\n\n",
        "source_code_len": 98,
        "target_code": "\n        model_dir_path = Path(model_dir)\n        tf_model_file = model_dir_path / f\"{file_name}.tf_model\"\n\n",
        "target_code_len": 108,
        "diff_format": "@@ -1013,4 +1014,4 @@\n \n-        model_dir = Path(model_dir)\n-        tf_model_file = model_dir / f\"{file_name}.tf_model\"\n+        model_dir_path = Path(model_dir)\n+        tf_model_file = model_dir_path / f\"{file_name}.tf_model\"\n \n",
        "source_code_with_indent": "\n        <DED>model_dir = Path(model_dir)\n        tf_model_file = model_dir / f\"{file_name}.tf_model\"\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n        <DED>model_dir_path = Path(model_dir)\n        tf_model_file = model_dir_path / f\"{file_name}.tf_model\"\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        io_utils.pickle_dump(\n            model_dir / f\"{file_name}.data_example.pkl\", self._data_example\n        )\n        io_utils.pickle_dump(\n            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\",\n            self._sparse_feature_sizes,\n",
        "source_code_len": 251,
        "target_code": "        io_utils.pickle_dump(\n            model_dir_path / f\"{file_name}.data_example.pkl\", self._data_example\n        )\n        io_utils.pickle_dump(\n            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\",\n            self._sparse_feature_sizes,\n",
        "target_code_len": 261,
        "diff_format": "@@ -1023,6 +1024,6 @@\n         io_utils.pickle_dump(\n-            model_dir / f\"{file_name}.data_example.pkl\", self._data_example\n+            model_dir_path / f\"{file_name}.data_example.pkl\", self._data_example\n         )\n         io_utils.pickle_dump(\n-            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\",\n+            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\",\n             self._sparse_feature_sizes,\n",
        "source_code_with_indent": "        io_utils.pickle_dump(\n            model_dir / f\"{file_name}.data_example.pkl\", self._data_example\n        )\n        io_utils.pickle_dump(\n            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\",\n            self._sparse_feature_sizes,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        io_utils.pickle_dump(\n            model_dir_path / f\"{file_name}.data_example.pkl\", self._data_example\n        )\n        io_utils.pickle_dump(\n            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\",\n            self._sparse_feature_sizes,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/nlu/classifiers/diet_classifier.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/nlu/classifiers/diet_classifier.py",
    "file_hunks_size": 12,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/nlu/classifiers/diet_classifier.py:1031:12 Unsupported operand [58]: `/` is not supported for operand types `str` and `str`.",
    "message": " `/` is not supported for operand types `str` and `str`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 1031,
    "warning_line": "            model_dir / f\"{file_name}.label_data.pkl\", dict(self._label_data.data)"
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/nlu/classifiers/diet_classifier.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/nlu/classifiers/diet_classifier.py",
    "file_hunks_size": 12,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/nlu/classifiers/diet_classifier.py:1034:12 Unsupported operand [58]: `/` is not supported for operand types `str` and `str`.",
    "message": " `/` is not supported for operand types `str` and `str`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 1034,
    "warning_line": "            model_dir / f\"{file_name}.index_label_id_mapping.json\",",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n        model_dir = Path(model_dir)\n        tf_model_file = model_dir / f\"{file_name}.tf_model\"\n\n",
        "source_code_len": 98,
        "target_code": "\n        model_dir_path = Path(model_dir)\n        tf_model_file = model_dir_path / f\"{file_name}.tf_model\"\n\n",
        "target_code_len": 108,
        "diff_format": "@@ -1013,4 +1014,4 @@\n \n-        model_dir = Path(model_dir)\n-        tf_model_file = model_dir / f\"{file_name}.tf_model\"\n+        model_dir_path = Path(model_dir)\n+        tf_model_file = model_dir_path / f\"{file_name}.tf_model\"\n \n",
        "source_code_with_indent": "\n        <DED>model_dir = Path(model_dir)\n        tf_model_file = model_dir / f\"{file_name}.tf_model\"\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n        <DED>model_dir_path = Path(model_dir)\n        tf_model_file = model_dir_path / f\"{file_name}.tf_model\"\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        io_utils.pickle_dump(\n            model_dir / f\"{file_name}.label_data.pkl\", dict(self._label_data.data)\n        )\n        io_utils.json_pickle(\n            model_dir / f\"{file_name}.index_label_id_mapping.json\",\n            self.index_label_id_mapping,\n",
        "source_code_len": 262,
        "target_code": "        io_utils.pickle_dump(\n            model_dir_path / f\"{file_name}.label_data.pkl\", dict(self._label_data.data)\n        )\n        io_utils.json_pickle(\n            model_dir_path / f\"{file_name}.index_label_id_mapping.json\",\n            self.index_label_id_mapping,\n",
        "target_code_len": 272,
        "diff_format": "@@ -1030,6 +1031,6 @@\n         io_utils.pickle_dump(\n-            model_dir / f\"{file_name}.label_data.pkl\", dict(self._label_data.data)\n+            model_dir_path / f\"{file_name}.label_data.pkl\", dict(self._label_data.data)\n         )\n         io_utils.json_pickle(\n-            model_dir / f\"{file_name}.index_label_id_mapping.json\",\n+            model_dir_path / f\"{file_name}.index_label_id_mapping.json\",\n             self.index_label_id_mapping,\n",
        "source_code_with_indent": "        io_utils.pickle_dump(\n            model_dir / f\"{file_name}.label_data.pkl\", dict(self._label_data.data)\n        )\n        io_utils.json_pickle(\n            model_dir / f\"{file_name}.index_label_id_mapping.json\",\n            self.index_label_id_mapping,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        io_utils.pickle_dump(\n            model_dir_path / f\"{file_name}.label_data.pkl\", dict(self._label_data.data)\n        )\n        io_utils.json_pickle(\n            model_dir_path / f\"{file_name}.index_label_id_mapping.json\",\n            self.index_label_id_mapping,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/nlu/classifiers/diet_classifier.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/nlu/classifiers/diet_classifier.py",
    "file_hunks_size": 12,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/nlu/classifiers/diet_classifier.py:1044:12 Unsupported operand [58]: `/` is not supported for operand types `str` and `str`.",
    "message": " `/` is not supported for operand types `str` and `str`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 1044,
    "warning_line": "            model_dir / f\"{file_name}.entity_tag_specs.json\", entity_tag_specs",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\n        model_dir = Path(model_dir)\n        tf_model_file = model_dir / f\"{file_name}.tf_model\"\n\n",
        "source_code_len": 98,
        "target_code": "\n        model_dir_path = Path(model_dir)\n        tf_model_file = model_dir_path / f\"{file_name}.tf_model\"\n\n",
        "target_code_len": 108,
        "diff_format": "@@ -1013,4 +1014,4 @@\n \n-        model_dir = Path(model_dir)\n-        tf_model_file = model_dir / f\"{file_name}.tf_model\"\n+        model_dir_path = Path(model_dir)\n+        tf_model_file = model_dir_path / f\"{file_name}.tf_model\"\n \n",
        "source_code_with_indent": "\n        <DED>model_dir = Path(model_dir)\n        tf_model_file = model_dir / f\"{file_name}.tf_model\"\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n        <DED>model_dir_path = Path(model_dir)\n        tf_model_file = model_dir_path / f\"{file_name}.tf_model\"\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": true,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        rasa.shared.utils.io.dump_obj_as_json_to_file(\n            model_dir / f\"{file_name}.entity_tag_specs.json\", entity_tag_specs\n        )\n",
        "source_code_len": 144,
        "target_code": "        rasa.shared.utils.io.dump_obj_as_json_to_file(\n            model_dir_path / f\"{file_name}.entity_tag_specs.json\", entity_tag_specs\n        )\n",
        "target_code_len": 149,
        "diff_format": "@@ -1043,3 +1044,3 @@\n         rasa.shared.utils.io.dump_obj_as_json_to_file(\n-            model_dir / f\"{file_name}.entity_tag_specs.json\", entity_tag_specs\n+            model_dir_path / f\"{file_name}.entity_tag_specs.json\", entity_tag_specs\n         )\n",
        "source_code_with_indent": "        rasa.shared.utils.io.dump_obj_as_json_to_file(\n            model_dir / f\"{file_name}.entity_tag_specs.json\", entity_tag_specs\n        )\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        rasa.shared.utils.io.dump_obj_as_json_to_file(\n            model_dir_path / f\"{file_name}.entity_tag_specs.json\", entity_tag_specs\n        )\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/nlu/classifiers/diet_classifier.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/nlu/classifiers/diet_classifier.py",
    "file_hunks_size": 12,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/nlu/classifiers/diet_classifier.py:1052:4 Inconsistent override [15]: `rasa.nlu.classifiers.diet_classifier.DIETClassifier.load` overrides method defined in `Component` inconsistently. Returned type `unknown` is not a subtype of the overridden return `Component`.",
    "message": " `rasa.nlu.classifiers.diet_classifier.DIETClassifier.load` overrides method defined in `Component` inconsistently. Returned type `unknown` is not a subtype of the overridden return `Component`.",
    "rule_id": "Inconsistent override [15]",
    "warning_line_no": 1052,
    "warning_line": "    def load("
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/nlu/classifiers/diet_classifier.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/nlu/classifiers/diet_classifier.py",
    "file_hunks_size": 12,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/nlu/classifiers/diet_classifier.py:1115:8 Incompatible variable type [9]: model_dir is declared to have type `str` but is used as type `Path`.",
    "message": " model_dir is declared to have type `str` but is used as type `Path`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 1115,
    "warning_line": "        model_dir = Path(model_dir)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ]:\n        file_name = meta.get(\"file\")\n\n        model_dir = Path(model_dir)\n\n        data_example = io_utils.pickle_load(model_dir / f\"{file_name}.data_example.pkl\")\n        label_data = io_utils.pickle_load(model_dir / f\"{file_name}.label_data.pkl\")\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "source_code_len": 704,
        "target_code": "    ]:\n        file_name = meta[\"file\"]\n\n        model_dir_path = Path(model_dir)\n\n        data_example = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.data_example.pkl\"\n        )\n        label_data = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.label_data.pkl\"\n        )\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir_path / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir_path / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "target_code_len": 774,
        "diff_format": "@@ -1112,17 +1111,21 @@\n     ]:\n-        file_name = meta.get(\"file\")\n-\n-        model_dir = Path(model_dir)\n-\n-        data_example = io_utils.pickle_load(model_dir / f\"{file_name}.data_example.pkl\")\n-        label_data = io_utils.pickle_load(model_dir / f\"{file_name}.label_data.pkl\")\n+        file_name = meta[\"file\"]\n+\n+        model_dir_path = Path(model_dir)\n+\n+        data_example = io_utils.pickle_load(\n+            model_dir_path / f\"{file_name}.data_example.pkl\"\n+        )\n+        label_data = io_utils.pickle_load(\n+            model_dir_path / f\"{file_name}.label_data.pkl\"\n+        )\n         label_data = RasaModelData(data=label_data)\n         sparse_feature_sizes = io_utils.pickle_load(\n-            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\"\n+            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\"\n         )\n         index_label_id_mapping = io_utils.json_unpickle(\n-            model_dir / f\"{file_name}.index_label_id_mapping.json\"\n+            model_dir_path / f\"{file_name}.index_label_id_mapping.json\"\n         )\n         entity_tag_specs = rasa.shared.utils.io.read_json_file(\n-            model_dir / f\"{file_name}.entity_tag_specs.json\"\n+            model_dir_path / f\"{file_name}.entity_tag_specs.json\"\n         )\n",
        "source_code_with_indent": "    ]:\n        <IND>file_name = meta.get(\"file\")\n\n        model_dir = Path(model_dir)\n\n        data_example = io_utils.pickle_load(model_dir / f\"{file_name}.data_example.pkl\")\n        label_data = io_utils.pickle_load(model_dir / f\"{file_name}.label_data.pkl\")\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ]:\n        <IND>file_name = meta[\"file\"]\n\n        model_dir_path = Path(model_dir)\n\n        data_example = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.data_example.pkl\"\n        )\n        label_data = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.label_data.pkl\"\n        )\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir_path / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir_path / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/nlu/classifiers/diet_classifier.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/nlu/classifiers/diet_classifier.py",
    "file_hunks_size": 12,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/nlu/classifiers/diet_classifier.py:1117:44 Unsupported operand [58]: `/` is not supported for operand types `str` and `str`.",
    "message": " `/` is not supported for operand types `str` and `str`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 1117,
    "warning_line": "        data_example = io_utils.pickle_load(model_dir / f\"{file_name}.data_example.pkl\")",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ]:\n        file_name = meta.get(\"file\")\n\n        model_dir = Path(model_dir)\n\n        data_example = io_utils.pickle_load(model_dir / f\"{file_name}.data_example.pkl\")\n        label_data = io_utils.pickle_load(model_dir / f\"{file_name}.label_data.pkl\")\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "source_code_len": 704,
        "target_code": "    ]:\n        file_name = meta[\"file\"]\n\n        model_dir_path = Path(model_dir)\n\n        data_example = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.data_example.pkl\"\n        )\n        label_data = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.label_data.pkl\"\n        )\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir_path / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir_path / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "target_code_len": 774,
        "diff_format": "@@ -1112,17 +1111,21 @@\n     ]:\n-        file_name = meta.get(\"file\")\n-\n-        model_dir = Path(model_dir)\n-\n-        data_example = io_utils.pickle_load(model_dir / f\"{file_name}.data_example.pkl\")\n-        label_data = io_utils.pickle_load(model_dir / f\"{file_name}.label_data.pkl\")\n+        file_name = meta[\"file\"]\n+\n+        model_dir_path = Path(model_dir)\n+\n+        data_example = io_utils.pickle_load(\n+            model_dir_path / f\"{file_name}.data_example.pkl\"\n+        )\n+        label_data = io_utils.pickle_load(\n+            model_dir_path / f\"{file_name}.label_data.pkl\"\n+        )\n         label_data = RasaModelData(data=label_data)\n         sparse_feature_sizes = io_utils.pickle_load(\n-            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\"\n+            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\"\n         )\n         index_label_id_mapping = io_utils.json_unpickle(\n-            model_dir / f\"{file_name}.index_label_id_mapping.json\"\n+            model_dir_path / f\"{file_name}.index_label_id_mapping.json\"\n         )\n         entity_tag_specs = rasa.shared.utils.io.read_json_file(\n-            model_dir / f\"{file_name}.entity_tag_specs.json\"\n+            model_dir_path / f\"{file_name}.entity_tag_specs.json\"\n         )\n",
        "source_code_with_indent": "    ]:\n        <IND>file_name = meta.get(\"file\")\n\n        model_dir = Path(model_dir)\n\n        data_example = io_utils.pickle_load(model_dir / f\"{file_name}.data_example.pkl\")\n        label_data = io_utils.pickle_load(model_dir / f\"{file_name}.label_data.pkl\")\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ]:\n        <IND>file_name = meta[\"file\"]\n\n        model_dir_path = Path(model_dir)\n\n        data_example = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.data_example.pkl\"\n        )\n        label_data = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.label_data.pkl\"\n        )\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir_path / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir_path / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/nlu/classifiers/diet_classifier.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/nlu/classifiers/diet_classifier.py",
    "file_hunks_size": 12,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/nlu/classifiers/diet_classifier.py:1118:42 Unsupported operand [58]: `/` is not supported for operand types `str` and `str`.",
    "message": " `/` is not supported for operand types `str` and `str`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 1118,
    "warning_line": "        label_data = io_utils.pickle_load(model_dir / f\"{file_name}.label_data.pkl\")",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ]:\n        file_name = meta.get(\"file\")\n\n        model_dir = Path(model_dir)\n\n        data_example = io_utils.pickle_load(model_dir / f\"{file_name}.data_example.pkl\")\n        label_data = io_utils.pickle_load(model_dir / f\"{file_name}.label_data.pkl\")\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "source_code_len": 704,
        "target_code": "    ]:\n        file_name = meta[\"file\"]\n\n        model_dir_path = Path(model_dir)\n\n        data_example = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.data_example.pkl\"\n        )\n        label_data = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.label_data.pkl\"\n        )\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir_path / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir_path / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "target_code_len": 774,
        "diff_format": "@@ -1112,17 +1111,21 @@\n     ]:\n-        file_name = meta.get(\"file\")\n-\n-        model_dir = Path(model_dir)\n-\n-        data_example = io_utils.pickle_load(model_dir / f\"{file_name}.data_example.pkl\")\n-        label_data = io_utils.pickle_load(model_dir / f\"{file_name}.label_data.pkl\")\n+        file_name = meta[\"file\"]\n+\n+        model_dir_path = Path(model_dir)\n+\n+        data_example = io_utils.pickle_load(\n+            model_dir_path / f\"{file_name}.data_example.pkl\"\n+        )\n+        label_data = io_utils.pickle_load(\n+            model_dir_path / f\"{file_name}.label_data.pkl\"\n+        )\n         label_data = RasaModelData(data=label_data)\n         sparse_feature_sizes = io_utils.pickle_load(\n-            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\"\n+            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\"\n         )\n         index_label_id_mapping = io_utils.json_unpickle(\n-            model_dir / f\"{file_name}.index_label_id_mapping.json\"\n+            model_dir_path / f\"{file_name}.index_label_id_mapping.json\"\n         )\n         entity_tag_specs = rasa.shared.utils.io.read_json_file(\n-            model_dir / f\"{file_name}.entity_tag_specs.json\"\n+            model_dir_path / f\"{file_name}.entity_tag_specs.json\"\n         )\n",
        "source_code_with_indent": "    ]:\n        <IND>file_name = meta.get(\"file\")\n\n        model_dir = Path(model_dir)\n\n        data_example = io_utils.pickle_load(model_dir / f\"{file_name}.data_example.pkl\")\n        label_data = io_utils.pickle_load(model_dir / f\"{file_name}.label_data.pkl\")\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ]:\n        <IND>file_name = meta[\"file\"]\n\n        model_dir_path = Path(model_dir)\n\n        data_example = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.data_example.pkl\"\n        )\n        label_data = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.label_data.pkl\"\n        )\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir_path / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir_path / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/nlu/classifiers/diet_classifier.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/nlu/classifiers/diet_classifier.py",
    "file_hunks_size": 12,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/nlu/classifiers/diet_classifier.py:1121:12 Unsupported operand [58]: `/` is not supported for operand types `str` and `str`.",
    "message": " `/` is not supported for operand types `str` and `str`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 1121,
    "warning_line": "            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\"",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ]:\n        file_name = meta.get(\"file\")\n\n        model_dir = Path(model_dir)\n\n        data_example = io_utils.pickle_load(model_dir / f\"{file_name}.data_example.pkl\")\n        label_data = io_utils.pickle_load(model_dir / f\"{file_name}.label_data.pkl\")\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "source_code_len": 704,
        "target_code": "    ]:\n        file_name = meta[\"file\"]\n\n        model_dir_path = Path(model_dir)\n\n        data_example = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.data_example.pkl\"\n        )\n        label_data = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.label_data.pkl\"\n        )\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir_path / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir_path / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "target_code_len": 774,
        "diff_format": "@@ -1112,17 +1111,21 @@\n     ]:\n-        file_name = meta.get(\"file\")\n-\n-        model_dir = Path(model_dir)\n-\n-        data_example = io_utils.pickle_load(model_dir / f\"{file_name}.data_example.pkl\")\n-        label_data = io_utils.pickle_load(model_dir / f\"{file_name}.label_data.pkl\")\n+        file_name = meta[\"file\"]\n+\n+        model_dir_path = Path(model_dir)\n+\n+        data_example = io_utils.pickle_load(\n+            model_dir_path / f\"{file_name}.data_example.pkl\"\n+        )\n+        label_data = io_utils.pickle_load(\n+            model_dir_path / f\"{file_name}.label_data.pkl\"\n+        )\n         label_data = RasaModelData(data=label_data)\n         sparse_feature_sizes = io_utils.pickle_load(\n-            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\"\n+            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\"\n         )\n         index_label_id_mapping = io_utils.json_unpickle(\n-            model_dir / f\"{file_name}.index_label_id_mapping.json\"\n+            model_dir_path / f\"{file_name}.index_label_id_mapping.json\"\n         )\n         entity_tag_specs = rasa.shared.utils.io.read_json_file(\n-            model_dir / f\"{file_name}.entity_tag_specs.json\"\n+            model_dir_path / f\"{file_name}.entity_tag_specs.json\"\n         )\n",
        "source_code_with_indent": "    ]:\n        <IND>file_name = meta.get(\"file\")\n\n        model_dir = Path(model_dir)\n\n        data_example = io_utils.pickle_load(model_dir / f\"{file_name}.data_example.pkl\")\n        label_data = io_utils.pickle_load(model_dir / f\"{file_name}.label_data.pkl\")\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ]:\n        <IND>file_name = meta[\"file\"]\n\n        model_dir_path = Path(model_dir)\n\n        data_example = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.data_example.pkl\"\n        )\n        label_data = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.label_data.pkl\"\n        )\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir_path / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir_path / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/nlu/classifiers/diet_classifier.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/nlu/classifiers/diet_classifier.py",
    "file_hunks_size": 12,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/nlu/classifiers/diet_classifier.py:1124:12 Unsupported operand [58]: `/` is not supported for operand types `str` and `str`.",
    "message": " `/` is not supported for operand types `str` and `str`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 1124,
    "warning_line": "            model_dir / f\"{file_name}.index_label_id_mapping.json\"",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ]:\n        file_name = meta.get(\"file\")\n\n        model_dir = Path(model_dir)\n\n        data_example = io_utils.pickle_load(model_dir / f\"{file_name}.data_example.pkl\")\n        label_data = io_utils.pickle_load(model_dir / f\"{file_name}.label_data.pkl\")\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "source_code_len": 704,
        "target_code": "    ]:\n        file_name = meta[\"file\"]\n\n        model_dir_path = Path(model_dir)\n\n        data_example = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.data_example.pkl\"\n        )\n        label_data = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.label_data.pkl\"\n        )\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir_path / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir_path / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "target_code_len": 774,
        "diff_format": "@@ -1112,17 +1111,21 @@\n     ]:\n-        file_name = meta.get(\"file\")\n-\n-        model_dir = Path(model_dir)\n-\n-        data_example = io_utils.pickle_load(model_dir / f\"{file_name}.data_example.pkl\")\n-        label_data = io_utils.pickle_load(model_dir / f\"{file_name}.label_data.pkl\")\n+        file_name = meta[\"file\"]\n+\n+        model_dir_path = Path(model_dir)\n+\n+        data_example = io_utils.pickle_load(\n+            model_dir_path / f\"{file_name}.data_example.pkl\"\n+        )\n+        label_data = io_utils.pickle_load(\n+            model_dir_path / f\"{file_name}.label_data.pkl\"\n+        )\n         label_data = RasaModelData(data=label_data)\n         sparse_feature_sizes = io_utils.pickle_load(\n-            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\"\n+            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\"\n         )\n         index_label_id_mapping = io_utils.json_unpickle(\n-            model_dir / f\"{file_name}.index_label_id_mapping.json\"\n+            model_dir_path / f\"{file_name}.index_label_id_mapping.json\"\n         )\n         entity_tag_specs = rasa.shared.utils.io.read_json_file(\n-            model_dir / f\"{file_name}.entity_tag_specs.json\"\n+            model_dir_path / f\"{file_name}.entity_tag_specs.json\"\n         )\n",
        "source_code_with_indent": "    ]:\n        <IND>file_name = meta.get(\"file\")\n\n        model_dir = Path(model_dir)\n\n        data_example = io_utils.pickle_load(model_dir / f\"{file_name}.data_example.pkl\")\n        label_data = io_utils.pickle_load(model_dir / f\"{file_name}.label_data.pkl\")\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ]:\n        <IND>file_name = meta[\"file\"]\n\n        model_dir_path = Path(model_dir)\n\n        data_example = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.data_example.pkl\"\n        )\n        label_data = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.label_data.pkl\"\n        )\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir_path / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir_path / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/nlu/classifiers/diet_classifier.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/nlu/classifiers/diet_classifier.py",
    "file_hunks_size": 12,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/nlu/classifiers/diet_classifier.py:1127:12 Unsupported operand [58]: `/` is not supported for operand types `str` and `str`.",
    "message": " `/` is not supported for operand types `str` and `str`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 1127,
    "warning_line": "            model_dir / f\"{file_name}.entity_tag_specs.json\"",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ]:\n        file_name = meta.get(\"file\")\n\n        model_dir = Path(model_dir)\n\n        data_example = io_utils.pickle_load(model_dir / f\"{file_name}.data_example.pkl\")\n        label_data = io_utils.pickle_load(model_dir / f\"{file_name}.label_data.pkl\")\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "source_code_len": 704,
        "target_code": "    ]:\n        file_name = meta[\"file\"]\n\n        model_dir_path = Path(model_dir)\n\n        data_example = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.data_example.pkl\"\n        )\n        label_data = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.label_data.pkl\"\n        )\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir_path / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir_path / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "target_code_len": 774,
        "diff_format": "@@ -1112,17 +1111,21 @@\n     ]:\n-        file_name = meta.get(\"file\")\n-\n-        model_dir = Path(model_dir)\n-\n-        data_example = io_utils.pickle_load(model_dir / f\"{file_name}.data_example.pkl\")\n-        label_data = io_utils.pickle_load(model_dir / f\"{file_name}.label_data.pkl\")\n+        file_name = meta[\"file\"]\n+\n+        model_dir_path = Path(model_dir)\n+\n+        data_example = io_utils.pickle_load(\n+            model_dir_path / f\"{file_name}.data_example.pkl\"\n+        )\n+        label_data = io_utils.pickle_load(\n+            model_dir_path / f\"{file_name}.label_data.pkl\"\n+        )\n         label_data = RasaModelData(data=label_data)\n         sparse_feature_sizes = io_utils.pickle_load(\n-            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\"\n+            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\"\n         )\n         index_label_id_mapping = io_utils.json_unpickle(\n-            model_dir / f\"{file_name}.index_label_id_mapping.json\"\n+            model_dir_path / f\"{file_name}.index_label_id_mapping.json\"\n         )\n         entity_tag_specs = rasa.shared.utils.io.read_json_file(\n-            model_dir / f\"{file_name}.entity_tag_specs.json\"\n+            model_dir_path / f\"{file_name}.entity_tag_specs.json\"\n         )\n",
        "source_code_with_indent": "    ]:\n        <IND>file_name = meta.get(\"file\")\n\n        model_dir = Path(model_dir)\n\n        data_example = io_utils.pickle_load(model_dir / f\"{file_name}.data_example.pkl\")\n        label_data = io_utils.pickle_load(model_dir / f\"{file_name}.label_data.pkl\")\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ]:\n        <IND>file_name = meta[\"file\"]\n\n        model_dir_path = Path(model_dir)\n\n        data_example = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.data_example.pkl\"\n        )\n        label_data = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.label_data.pkl\"\n        )\n        label_data = RasaModelData(data=label_data)\n        sparse_feature_sizes = io_utils.pickle_load(\n            model_dir_path / f\"{file_name}.sparse_feature_sizes.pkl\"\n        )\n        index_label_id_mapping = io_utils.json_unpickle(\n            model_dir_path / f\"{file_name}.index_label_id_mapping.json\"\n        )\n        entity_tag_specs = rasa.shared.utils.io.read_json_file(\n            model_dir_path / f\"{file_name}.entity_tag_specs.json\"\n        )\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/nlu/featurizers/sparse_featurizer/count_vectors_featurizer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/nlu/featurizers/sparse_featurizer/count_vectors_featurizer.py",
    "file_hunks_size": 4,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/nlu/featurizers/sparse_featurizer/count_vectors_featurizer.py:282:37 Unsupported operand [58]: `in` is not supported for right operand type `Optional[Dict[str, int]]`.",
    "message": " `in` is not supported for right operand type `Optional[Dict[str, int]]`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 282,
    "warning_line": "            if vocabulary_exists and self.OOV_token in self._get_attribute_vocabulary(",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ) -> List[Text]:\n        \"\"\"Replace OOV words with OOV token\"\"\"\n\n        if self.OOV_token and self.analyzer == \"word\":\n            vocabulary_exists = self._check_attribute_vocabulary(attribute)\n            if vocabulary_exists and self.OOV_token in self._get_attribute_vocabulary(\n                attribute\n            ):\n                # CountVectorizer is trained, process for prediction\n                tokens = [\n                    t\n                    if t in self._get_attribute_vocabulary_tokens(attribute)\n                    else self.OOV_token\n                    for t in tokens\n",
        "source_code_len": 599,
        "target_code": "    ) -> List[Text]:\n        \"\"\"Replace OOV words with OOV token.\"\"\"\n        if self.OOV_token and self.analyzer == \"word\":\n            attribute_vocab = self._get_attribute_vocabulary(attribute)\n            if attribute_vocab is not None and self.OOV_token in attribute_vocab:\n                # CountVectorizer is trained, process for prediction\n                attribute_vocabulary_tokens = set(attribute_vocab.keys())\n                tokens = [\n                    t if t in attribute_vocabulary_tokens else self.OOV_token\n                    for t in tokens\n",
        "target_code_len": 562,
        "diff_format": "@@ -277,14 +260,10 @@\n     ) -> List[Text]:\n-        \"\"\"Replace OOV words with OOV token\"\"\"\n-\n+        \"\"\"Replace OOV words with OOV token.\"\"\"\n         if self.OOV_token and self.analyzer == \"word\":\n-            vocabulary_exists = self._check_attribute_vocabulary(attribute)\n-            if vocabulary_exists and self.OOV_token in self._get_attribute_vocabulary(\n-                attribute\n-            ):\n+            attribute_vocab = self._get_attribute_vocabulary(attribute)\n+            if attribute_vocab is not None and self.OOV_token in attribute_vocab:\n                 # CountVectorizer is trained, process for prediction\n+                attribute_vocabulary_tokens = set(attribute_vocab.keys())\n                 tokens = [\n-                    t\n-                    if t in self._get_attribute_vocabulary_tokens(attribute)\n-                    else self.OOV_token\n+                    t if t in attribute_vocabulary_tokens else self.OOV_token\n                     for t in tokens\n",
        "source_code_with_indent": "    ) -> List[Text]:\n        <IND>\"\"\"Replace OOV words with OOV token\"\"\"\n\n        if self.OOV_token and self.analyzer == \"word\":\n            <IND>vocabulary_exists = self._check_attribute_vocabulary(attribute)\n            if vocabulary_exists and self.OOV_token in self._get_attribute_vocabulary(\n                attribute\n            ):\n                # CountVectorizer is trained, process for prediction\n                <IND>tokens = [\n                    t\n                    if t in self._get_attribute_vocabulary_tokens(attribute)\n                    else self.OOV_token\n                    for t in tokens\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ) -> List[Text]:\n        <IND>\"\"\"Replace OOV words with OOV token.\"\"\"\n        if self.OOV_token and self.analyzer == \"word\":\n            <IND>attribute_vocab = self._get_attribute_vocabulary(attribute)\n            if attribute_vocab is not None and self.OOV_token in attribute_vocab:\n                # CountVectorizer is trained, process for prediction\n                <IND>attribute_vocabulary_tokens = set(attribute_vocab.keys())\n                tokens = [\n                    t if t in attribute_vocabulary_tokens else self.OOV_token\n                    for t in tokens\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/nlu/featurizers/sparse_featurizer/count_vectors_featurizer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/nlu/featurizers/sparse_featurizer/count_vectors_featurizer.py",
    "file_hunks_size": 4,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/nlu/featurizers/sparse_featurizer/count_vectors_featurizer.py:288:23 Unsupported operand [58]: `in` is not supported for right operand type `Optional[List[str]]`.",
    "message": " `in` is not supported for right operand type `Optional[List[str]]`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 288,
    "warning_line": "                    if t in self._get_attribute_vocabulary_tokens(attribute)",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "    ) -> List[Text]:\n        \"\"\"Replace OOV words with OOV token\"\"\"\n\n        if self.OOV_token and self.analyzer == \"word\":\n            vocabulary_exists = self._check_attribute_vocabulary(attribute)\n            if vocabulary_exists and self.OOV_token in self._get_attribute_vocabulary(\n                attribute\n            ):\n                # CountVectorizer is trained, process for prediction\n                tokens = [\n                    t\n                    if t in self._get_attribute_vocabulary_tokens(attribute)\n                    else self.OOV_token\n                    for t in tokens\n",
        "source_code_len": 599,
        "target_code": "    ) -> List[Text]:\n        \"\"\"Replace OOV words with OOV token.\"\"\"\n        if self.OOV_token and self.analyzer == \"word\":\n            attribute_vocab = self._get_attribute_vocabulary(attribute)\n            if attribute_vocab is not None and self.OOV_token in attribute_vocab:\n                # CountVectorizer is trained, process for prediction\n                attribute_vocabulary_tokens = set(attribute_vocab.keys())\n                tokens = [\n                    t if t in attribute_vocabulary_tokens else self.OOV_token\n                    for t in tokens\n",
        "target_code_len": 562,
        "diff_format": "@@ -277,14 +260,10 @@\n     ) -> List[Text]:\n-        \"\"\"Replace OOV words with OOV token\"\"\"\n-\n+        \"\"\"Replace OOV words with OOV token.\"\"\"\n         if self.OOV_token and self.analyzer == \"word\":\n-            vocabulary_exists = self._check_attribute_vocabulary(attribute)\n-            if vocabulary_exists and self.OOV_token in self._get_attribute_vocabulary(\n-                attribute\n-            ):\n+            attribute_vocab = self._get_attribute_vocabulary(attribute)\n+            if attribute_vocab is not None and self.OOV_token in attribute_vocab:\n                 # CountVectorizer is trained, process for prediction\n+                attribute_vocabulary_tokens = set(attribute_vocab.keys())\n                 tokens = [\n-                    t\n-                    if t in self._get_attribute_vocabulary_tokens(attribute)\n-                    else self.OOV_token\n+                    t if t in attribute_vocabulary_tokens else self.OOV_token\n                     for t in tokens\n",
        "source_code_with_indent": "    ) -> List[Text]:\n        <IND>\"\"\"Replace OOV words with OOV token\"\"\"\n\n        if self.OOV_token and self.analyzer == \"word\":\n            <IND>vocabulary_exists = self._check_attribute_vocabulary(attribute)\n            if vocabulary_exists and self.OOV_token in self._get_attribute_vocabulary(\n                attribute\n            ):\n                # CountVectorizer is trained, process for prediction\n                <IND>tokens = [\n                    t\n                    if t in self._get_attribute_vocabulary_tokens(attribute)\n                    else self.OOV_token\n                    for t in tokens\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "    ) -> List[Text]:\n        <IND>\"\"\"Replace OOV words with OOV token.\"\"\"\n        if self.OOV_token and self.analyzer == \"word\":\n            <IND>attribute_vocab = self._get_attribute_vocabulary(attribute)\n            if attribute_vocab is not None and self.OOV_token in attribute_vocab:\n                # CountVectorizer is trained, process for prediction\n                <IND>attribute_vocabulary_tokens = set(attribute_vocab.keys())\n                tokens = [\n                    t if t in attribute_vocabulary_tokens else self.OOV_token\n                    for t in tokens\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/shared/core/generator.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/shared/core/generator.py",
    "file_hunks_size": 1,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/shared/core/generator.py:646:65 Unsupported operand [58]: `+` is not supported for operand types `str` and `Optional[str]`.",
    "message": " `+` is not supported for operand types `str` and `Optional[str]`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 646,
    "warning_line": "                        new_sender = tracker.sender_id + \" > \" + step.block_name",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "                if tracker.sender_id:\n                    if step.block_name not in tracker.sender_id.split(\" > \"):\n                        new_sender = tracker.sender_id + \" > \" + step.block_name\n",
        "source_code_len": 197,
        "target_code": "                if tracker.sender_id:\n                    if (\n                        step.block_name\n                        and step.block_name not in tracker.sender_id.split(\" > \")\n                    ):\n                        new_sender = tracker.sender_id + \" > \" + step.block_name\n",
        "target_code_len": 289,
        "diff_format": "@@ -644,3 +644,6 @@\n                 if tracker.sender_id:\n-                    if step.block_name not in tracker.sender_id.split(\" > \"):\n+                    if (\n+                        step.block_name\n+                        and step.block_name not in tracker.sender_id.split(\" > \")\n+                    ):\n                         new_sender = tracker.sender_id + \" > \" + step.block_name\n",
        "source_code_with_indent": "                <IND>if tracker.sender_id:\n                    <IND>if step.block_name not in tracker.sender_id.split(\" > \"):\n                        <IND>new_sender = tracker.sender_id + \" > \" + step.block_name\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "                <IND>if tracker.sender_id:\n                    <IND>if (\n                        step.block_name\n                        and step.block_name not in tracker.sender_id.split(\" > \")\n                    ):\n                        <IND>new_sender = tracker.sender_id + \" > \" + step.block_name\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/utils/endpoints.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/utils/endpoints.py",
    "file_hunks_size": 2,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/utils/endpoints.py:76:8 Incompatible variable type [9]: url is declared to have type `str` but is used as type `None`.",
    "message": " url is declared to have type `str` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 76,
    "warning_line": "        url: Text = None,"
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/utils/endpoints.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/utils/endpoints.py",
    "file_hunks_size": 2,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/utils/endpoints.py:77:8 Incompatible variable type [9]: params is declared to have type `Dict[str, typing.Any]` but is used as type `None`.",
    "message": " params is declared to have type `Dict[str, typing.Any]` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 77,
    "warning_line": "        params: Dict[Text, Any] = None,"
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/utils/endpoints.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/utils/endpoints.py",
    "file_hunks_size": 2,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/utils/endpoints.py:78:8 Incompatible variable type [9]: headers is declared to have type `Dict[str, typing.Any]` but is used as type `None`.",
    "message": " headers is declared to have type `Dict[str, typing.Any]` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 78,
    "warning_line": "        headers: Dict[Text, Any] = None,"
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/utils/endpoints.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/utils/endpoints.py",
    "file_hunks_size": 2,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/utils/endpoints.py:79:8 Incompatible variable type [9]: basic_auth is declared to have type `Dict[str, str]` but is used as type `None`.",
    "message": " basic_auth is declared to have type `Dict[str, str]` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 79,
    "warning_line": "        basic_auth: Dict[Text, Text] = None,"
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/utils/tensorflow/transformer.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/utils/tensorflow/transformer.py",
    "file_hunks_size": 4,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/utils/tensorflow/transformer.py:140:53 Unsupported operand [58]: `-` is not supported for operand types `Optional[int]` and `int`.",
    "message": " `-` is not supported for operand types `Optional[int]` and `int`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 140,
    "warning_line": "            pad_right = tf.tile(pad_right, (1, 1, 1, self.relative_length - 1, 1))",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        use_value_relative_position: bool = False,\n        max_relative_position: Optional[int] = None,\n        heads_share_relative_embedding: bool = False,\n",
        "source_code_len": 158,
        "target_code": "        use_value_relative_position: bool = False,\n        max_relative_position: int = 5,\n        heads_share_relative_embedding: bool = False,\n",
        "target_code_len": 145,
        "diff_format": "@@ -40,3 +40,3 @@\n         use_value_relative_position: bool = False,\n-        max_relative_position: Optional[int] = None,\n+        max_relative_position: int = 5,\n         heads_share_relative_embedding: bool = False,\n",
        "source_code_with_indent": "        use_value_relative_position: bool = False,\n        max_relative_position: Optional[int] = None,\n        heads_share_relative_embedding: bool = False,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        use_value_relative_position: bool = False,\n        max_relative_position: int = 5,\n        heads_share_relative_embedding: bool = False,\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        use_value_relative_position: bool = False,\n        max_relative_position: Optional[int] = None,\n        heads_share_relative_embedding: bool = False,\n",
        "source_code_len": 158,
        "target_code": "        use_value_relative_position: bool = False,\n        max_relative_position: int = 5,\n        heads_share_relative_embedding: bool = False,\n",
        "target_code_len": 145,
        "diff_format": "@@ -416,3 +415,3 @@\n         use_value_relative_position: bool = False,\n-        max_relative_position: Optional[int] = None,\n+        max_relative_position: int = 5,\n         heads_share_relative_embedding: bool = False,\n",
        "source_code_with_indent": "        use_value_relative_position: bool = False,\n        max_relative_position: Optional[int] = None,\n        heads_share_relative_embedding: bool = False,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        use_value_relative_position: bool = False,\n        max_relative_position: int = 5,\n        heads_share_relative_embedding: bool = False,\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "        use_value_relative_position: bool = False,\n        max_relative_position: Optional[int] = None,\n        heads_share_relative_embedding: bool = False,\n",
        "source_code_len": 158,
        "target_code": "        use_value_relative_position: bool = False,\n        max_relative_position: int = 5,\n        heads_share_relative_embedding: bool = False,\n",
        "target_code_len": 145,
        "diff_format": "@@ -523,3 +522,3 @@\n         use_value_relative_position: bool = False,\n-        max_relative_position: Optional[int] = None,\n+        max_relative_position: int = 5,\n         heads_share_relative_embedding: bool = False,\n",
        "source_code_with_indent": "        use_value_relative_position: bool = False,\n        max_relative_position: Optional[int] = None,\n        heads_share_relative_embedding: bool = False,\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "        use_value_relative_position: bool = False,\n        max_relative_position: int = 5,\n        heads_share_relative_embedding: bool = False,\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/utils/train_utils.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/utils/train_utils.py",
    "file_hunks_size": 1,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/utils/train_utils.py:64:11 Unsupported operand [58]: `<` is not supported for operand types `int` and `Optional[int]`.",
    "message": " `<` is not supported for operand types `int` and `Optional[int]`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 64,
    "warning_line": "    if 0 < ranking_length < len(new_values):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef normalize(values: np.ndarray, ranking_length: Optional[int] = 0) -> np.ndarray:\n    \"\"\"Normalizes an array of positive numbers over the top `ranking_length` values.\n",
        "source_code_len": 170,
        "target_code": "\ndef normalize(values: np.ndarray, ranking_length: int = 0) -> np.ndarray:\n    \"\"\"Normalizes an array of positive numbers over the top `ranking_length` values.\n",
        "target_code_len": 160,
        "diff_format": "@@ -57,3 +57,3 @@\n \n-def normalize(values: np.ndarray, ranking_length: Optional[int] = 0) -> np.ndarray:\n+def normalize(values: np.ndarray, ranking_length: int = 0) -> np.ndarray:\n     \"\"\"Normalizes an array of positive numbers over the top `ranking_length` values.\n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "\n<DED>def normalize(values: np.ndarray, ranking_length: Optional[int] = 0) -> np.ndarray:\n    <IND>",
        "target_code_with_indent": "\n<DED>def normalize(values: np.ndarray, ranking_length: int = 0) -> np.ndarray:\n    <IND>"
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/utils/train_utils.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/utils/train_utils.py",
    "file_hunks_size": 1,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/utils/train_utils.py:64:11 Unsupported operand [58]: `<` is not supported for operand types `Optional[int]` and `int`.",
    "message": " `<` is not supported for operand types `Optional[int]` and `int`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 64,
    "warning_line": "    if 0 < ranking_length < len(new_values):",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef normalize(values: np.ndarray, ranking_length: Optional[int] = 0) -> np.ndarray:\n    \"\"\"Normalizes an array of positive numbers over the top `ranking_length` values.\n",
        "source_code_len": 170,
        "target_code": "\ndef normalize(values: np.ndarray, ranking_length: int = 0) -> np.ndarray:\n    \"\"\"Normalizes an array of positive numbers over the top `ranking_length` values.\n",
        "target_code_len": 160,
        "diff_format": "@@ -57,3 +57,3 @@\n \n-def normalize(values: np.ndarray, ranking_length: Optional[int] = 0) -> np.ndarray:\n+def normalize(values: np.ndarray, ranking_length: int = 0) -> np.ndarray:\n     \"\"\"Normalizes an array of positive numbers over the top `ranking_length` values.\n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "\n<DED>def normalize(values: np.ndarray, ranking_length: Optional[int] = 0) -> np.ndarray:\n    <IND>",
        "target_code_with_indent": "\n<DED>def normalize(values: np.ndarray, ranking_length: int = 0) -> np.ndarray:\n    <IND>"
      }
    ]
  },
  {
    "project": "RasaHQ/rasa",
    "commit": "f78a6a17d5146248500630a2397ee099a24e0f5c",
    "filename": "rasa/utils/train_utils.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/RasaHQ-rasa/rasa/utils/train_utils.py",
    "file_hunks_size": 1,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "rasa/utils/train_utils.py:66:39 Unsupported operand [58]: `-` is not supported for operand types `Optional[int]` and `int`.",
    "message": " `-` is not supported for operand types `Optional[int]` and `int`.",
    "rule_id": "Unsupported operand [58]",
    "warning_line_no": 66,
    "warning_line": "        new_values[new_values < ranked[ranking_length - 1]] = 0",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": false,
        "source_code": "\ndef normalize(values: np.ndarray, ranking_length: Optional[int] = 0) -> np.ndarray:\n    \"\"\"Normalizes an array of positive numbers over the top `ranking_length` values.\n",
        "source_code_len": 170,
        "target_code": "\ndef normalize(values: np.ndarray, ranking_length: int = 0) -> np.ndarray:\n    \"\"\"Normalizes an array of positive numbers over the top `ranking_length` values.\n",
        "target_code_len": 160,
        "diff_format": "@@ -57,3 +57,3 @@\n \n-def normalize(values: np.ndarray, ranking_length: Optional[int] = 0) -> np.ndarray:\n+def normalize(values: np.ndarray, ranking_length: int = 0) -> np.ndarray:\n     \"\"\"Normalizes an array of positive numbers over the top `ranking_length` values.\n",
        "source_code_with_indent_exact_match": false,
        "target_code_with_indent_exact_match": false,
        "source_code_with_indent": "\n<DED>def normalize(values: np.ndarray, ranking_length: Optional[int] = 0) -> np.ndarray:\n    <IND>",
        "target_code_with_indent": "\n<DED>def normalize(values: np.ndarray, ranking_length: int = 0) -> np.ndarray:\n    <IND>"
      }
    ]
  }
]