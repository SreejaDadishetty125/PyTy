[
  {
    "project": "quantumblacklabs/causalnex",
    "commit": "e73a638f788d879bb1efc9d5733370e60ae3cb00",
    "filename": "causalnex/structure/data_generators.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/quantumblacklabs-causalnex/causalnex/structure/data_generators/core.py",
    "file_hunks_size": 14,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": true,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "causalnex/structure/data_generators.py:140:4 Incompatible variable type [9]: seed is declared to have type `int` but is used as type `None`.",
    "message": " seed is declared to have type `int` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 140,
    "warning_line": "    seed: int = None,",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "\ndef generate_continuous_data(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"gaussian\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> np.ndarray:\n    \"\"\"\n    Simulate samples from SEM with specified type of noise.\n    The order of the columns on the returned array is the one provided by `sm.nodes`\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n            'exponential', 'gumbel'.\n        noise_scale: The standard deviation of the noise.\n        intercept: Whether to use an intercept for each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution isn't gaussian/normal/student-t/exponential/gumbel\n    \"\"\"\n    df = sem_generator(\n        graph=sm,\n        default_type=\"continuous\",\n        n_samples=n_samples,\n        distributions={\"continuous\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n    return df[list(sm.nodes())].values\n\n\ndef generate_binary_data(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> np.ndarray:\n    \"\"\"\n    Simulate samples from SEM with specified type of noise.\n    The order of the columns on the returned array is the one provided by `sm.nodes`\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            'logit' (default).\n        noise_scale: The standard deviation of the noise. The binary and\n            categorical features are created using a latent variable approach.\n            The noise standard deviation determines how much weight the \"mean\"\n            estimate has on the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution isn't 'probit', 'normal', 'logit'\n    \"\"\"\n    df = sem_generator(\n        graph=sm,\n        default_type=\"binary\",\n        n_samples=n_samples,\n        distributions={\"binary\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n    return df[list(sm.nodes())].values\n\n\ndef generate_continuous_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"gaussian\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    \"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n            'exponential', 'gumbel'.\n        noise_scale: The standard deviation of the noise.\n        intercept: Whether to use an intercept for each feature.\n        seed: Random state\n    Returns:\n        Dataframe with the node names as column names\n    Raises:\n        ValueError: if distribution is not 'gaussian', 'normal', 'student-t',\n            'exponential', 'gumbel'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"continuous\",\n        n_samples=n_samples,\n        distributions={\"continuous\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\ndef generate_binary_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    \"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            'logit' (default).\n        noise_scale: The standard deviation of the noise. The binary and\n            categorical features are created using a latent variable approach.\n            The noise standard deviation determines how much weight the \"mean\"\n            estimate has on the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution is not 'probit', 'normal', 'logit'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"binary\",\n        n_samples=n_samples,\n        distributions={\"binary\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\ndef generate_categorical_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    n_categories: int = 3,\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    \"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            \"logit\"/\"gumbel\" (alias). Logit is default.\n        n_categories: Number of categories per variable/node.\n        noise_scale: The standard deviation of the noise. The categorical features\n            are created using a latent variable approach. The noise standard\n            deviation determines how much weight the \"mean\" estimate has on\n            the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples, d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution is not 'probit', 'normal', 'logit', 'gumbel'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"categorical:{}\".format(n_categories),\n        n_samples=n_samples,\n        distributions={\"categorical\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\ndef sem_generator(\n",
        "source_code_len": 6990,
        "target_code": "\ndef sem_generator(\n",
        "target_code_len": 20,
        "diff_format": "@@ -133,197 +133,2 @@\n \n-def generate_continuous_data(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"gaussian\",\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> np.ndarray:\n-    \"\"\"\n-    Simulate samples from SEM with specified type of noise.\n-    The order of the columns on the returned array is the one provided by `sm.nodes`\n-\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n-            'exponential', 'gumbel'.\n-        noise_scale: The standard deviation of the noise.\n-        intercept: Whether to use an intercept for each feature.\n-        seed: Random state\n-    Returns:\n-        x_mat: [n_samples,d_nodes] sample matrix\n-    Raises:\n-        ValueError: if distribution isn't gaussian/normal/student-t/exponential/gumbel\n-    \"\"\"\n-    df = sem_generator(\n-        graph=sm,\n-        default_type=\"continuous\",\n-        n_samples=n_samples,\n-        distributions={\"continuous\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-    return df[list(sm.nodes())].values\n-\n-\n-def generate_binary_data(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"logit\",\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> np.ndarray:\n-    \"\"\"\n-    Simulate samples from SEM with specified type of noise.\n-    The order of the columns on the returned array is the one provided by `sm.nodes`\n-\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'probit'/'normal' (alias),\n-            'logit' (default).\n-        noise_scale: The standard deviation of the noise. The binary and\n-            categorical features are created using a latent variable approach.\n-            The noise standard deviation determines how much weight the \"mean\"\n-            estimate has on the feature value.\n-        intercept: Whether to use an intercept for the latent variable of each feature.\n-        seed: Random state\n-    Returns:\n-        x_mat: [n_samples,d_nodes] sample matrix\n-    Raises:\n-        ValueError: if distribution isn't 'probit', 'normal', 'logit'\n-    \"\"\"\n-    df = sem_generator(\n-        graph=sm,\n-        default_type=\"binary\",\n-        n_samples=n_samples,\n-        distributions={\"binary\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-    return df[list(sm.nodes())].values\n-\n-\n-def generate_continuous_dataframe(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"gaussian\",\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> pd.DataFrame:\n-    \"\"\"\n-    Generates a dataframe with samples from SEM with specified type of noise.\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n-            'exponential', 'gumbel'.\n-        noise_scale: The standard deviation of the noise.\n-        intercept: Whether to use an intercept for each feature.\n-        seed: Random state\n-    Returns:\n-        Dataframe with the node names as column names\n-    Raises:\n-        ValueError: if distribution is not 'gaussian', 'normal', 'student-t',\n-            'exponential', 'gumbel'\n-    \"\"\"\n-    return sem_generator(\n-        graph=sm,\n-        default_type=\"continuous\",\n-        n_samples=n_samples,\n-        distributions={\"continuous\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-\n-\n-def generate_binary_dataframe(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"logit\",\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> pd.DataFrame:\n-    \"\"\"\n-    Generates a dataframe with samples from SEM with specified type of noise.\n-\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'probit'/'normal' (alias),\n-            'logit' (default).\n-        noise_scale: The standard deviation of the noise. The binary and\n-            categorical features are created using a latent variable approach.\n-            The noise standard deviation determines how much weight the \"mean\"\n-            estimate has on the feature value.\n-        intercept: Whether to use an intercept for the latent variable of each feature.\n-        seed: Random state\n-    Returns:\n-        x_mat: [n_samples,d_nodes] sample matrix\n-    Raises:\n-        ValueError: if distribution is not 'probit', 'normal', 'logit'\n-    \"\"\"\n-    return sem_generator(\n-        graph=sm,\n-        default_type=\"binary\",\n-        n_samples=n_samples,\n-        distributions={\"binary\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-\n-\n-def generate_categorical_dataframe(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"logit\",\n-    n_categories: int = 3,\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> pd.DataFrame:\n-    \"\"\"\n-    Generates a dataframe with samples from SEM with specified type of noise.\n-\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'probit'/'normal' (alias),\n-            \"logit\"/\"gumbel\" (alias). Logit is default.\n-        n_categories: Number of categories per variable/node.\n-        noise_scale: The standard deviation of the noise. The categorical features\n-            are created using a latent variable approach. The noise standard\n-            deviation determines how much weight the \"mean\" estimate has on\n-            the feature value.\n-        intercept: Whether to use an intercept for the latent variable of each feature.\n-        seed: Random state\n-    Returns:\n-        x_mat: [n_samples, d_nodes] sample matrix\n-    Raises:\n-        ValueError: if distribution is not 'probit', 'normal', 'logit', 'gumbel'\n-    \"\"\"\n-    return sem_generator(\n-        graph=sm,\n-        default_type=\"categorical:{}\".format(n_categories),\n-        n_samples=n_samples,\n-        distributions={\"categorical\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-\n-\n def sem_generator(\n",
        "source_code_with_indent": "\n<DED>def generate_continuous_data(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"gaussian\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> np.ndarray:\n    <IND>\"\"\"\n    Simulate samples from SEM with specified type of noise.\n    The order of the columns on the returned array is the one provided by `sm.nodes`\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n            'exponential', 'gumbel'.\n        noise_scale: The standard deviation of the noise.\n        intercept: Whether to use an intercept for each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution isn't gaussian/normal/student-t/exponential/gumbel\n    \"\"\"\n    df = sem_generator(\n        graph=sm,\n        default_type=\"continuous\",\n        n_samples=n_samples,\n        distributions={\"continuous\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n    return df[list(sm.nodes())].values\n\n\n<DED>def generate_binary_data(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> np.ndarray:\n    <IND>\"\"\"\n    Simulate samples from SEM with specified type of noise.\n    The order of the columns on the returned array is the one provided by `sm.nodes`\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            'logit' (default).\n        noise_scale: The standard deviation of the noise. The binary and\n            categorical features are created using a latent variable approach.\n            The noise standard deviation determines how much weight the \"mean\"\n            estimate has on the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution isn't 'probit', 'normal', 'logit'\n    \"\"\"\n    df = sem_generator(\n        graph=sm,\n        default_type=\"binary\",\n        n_samples=n_samples,\n        distributions={\"binary\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n    return df[list(sm.nodes())].values\n\n\n<DED>def generate_continuous_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"gaussian\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    <IND>\"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n            'exponential', 'gumbel'.\n        noise_scale: The standard deviation of the noise.\n        intercept: Whether to use an intercept for each feature.\n        seed: Random state\n    Returns:\n        Dataframe with the node names as column names\n    Raises:\n        ValueError: if distribution is not 'gaussian', 'normal', 'student-t',\n            'exponential', 'gumbel'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"continuous\",\n        n_samples=n_samples,\n        distributions={\"continuous\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\n<DED>def generate_binary_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    <IND>\"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            'logit' (default).\n        noise_scale: The standard deviation of the noise. The binary and\n            categorical features are created using a latent variable approach.\n            The noise standard deviation determines how much weight the \"mean\"\n            estimate has on the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution is not 'probit', 'normal', 'logit'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"binary\",\n        n_samples=n_samples,\n        distributions={\"binary\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\n<DED>def generate_categorical_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    n_categories: int = 3,\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    <IND>\"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            \"logit\"/\"gumbel\" (alias). Logit is default.\n        n_categories: Number of categories per variable/node.\n        noise_scale: The standard deviation of the noise. The categorical features\n            are created using a latent variable approach. The noise standard\n            deviation determines how much weight the \"mean\" estimate has on\n            the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples, d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution is not 'probit', 'normal', 'logit', 'gumbel'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"categorical:{}\".format(n_categories),\n        n_samples=n_samples,\n        distributions={\"categorical\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\n<DED>def sem_generator(\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def sem_generator(\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "quantumblacklabs/causalnex",
    "commit": "e73a638f788d879bb1efc9d5733370e60ae3cb00",
    "filename": "causalnex/structure/data_generators.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/quantumblacklabs-causalnex/causalnex/structure/data_generators/core.py",
    "file_hunks_size": 14,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": true,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "causalnex/structure/data_generators.py:178:4 Incompatible variable type [9]: seed is declared to have type `int` but is used as type `None`.",
    "message": " seed is declared to have type `int` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 178,
    "warning_line": "    seed: int = None,",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "\ndef generate_continuous_data(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"gaussian\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> np.ndarray:\n    \"\"\"\n    Simulate samples from SEM with specified type of noise.\n    The order of the columns on the returned array is the one provided by `sm.nodes`\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n            'exponential', 'gumbel'.\n        noise_scale: The standard deviation of the noise.\n        intercept: Whether to use an intercept for each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution isn't gaussian/normal/student-t/exponential/gumbel\n    \"\"\"\n    df = sem_generator(\n        graph=sm,\n        default_type=\"continuous\",\n        n_samples=n_samples,\n        distributions={\"continuous\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n    return df[list(sm.nodes())].values\n\n\ndef generate_binary_data(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> np.ndarray:\n    \"\"\"\n    Simulate samples from SEM with specified type of noise.\n    The order of the columns on the returned array is the one provided by `sm.nodes`\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            'logit' (default).\n        noise_scale: The standard deviation of the noise. The binary and\n            categorical features are created using a latent variable approach.\n            The noise standard deviation determines how much weight the \"mean\"\n            estimate has on the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution isn't 'probit', 'normal', 'logit'\n    \"\"\"\n    df = sem_generator(\n        graph=sm,\n        default_type=\"binary\",\n        n_samples=n_samples,\n        distributions={\"binary\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n    return df[list(sm.nodes())].values\n\n\ndef generate_continuous_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"gaussian\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    \"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n            'exponential', 'gumbel'.\n        noise_scale: The standard deviation of the noise.\n        intercept: Whether to use an intercept for each feature.\n        seed: Random state\n    Returns:\n        Dataframe with the node names as column names\n    Raises:\n        ValueError: if distribution is not 'gaussian', 'normal', 'student-t',\n            'exponential', 'gumbel'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"continuous\",\n        n_samples=n_samples,\n        distributions={\"continuous\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\ndef generate_binary_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    \"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            'logit' (default).\n        noise_scale: The standard deviation of the noise. The binary and\n            categorical features are created using a latent variable approach.\n            The noise standard deviation determines how much weight the \"mean\"\n            estimate has on the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution is not 'probit', 'normal', 'logit'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"binary\",\n        n_samples=n_samples,\n        distributions={\"binary\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\ndef generate_categorical_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    n_categories: int = 3,\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    \"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            \"logit\"/\"gumbel\" (alias). Logit is default.\n        n_categories: Number of categories per variable/node.\n        noise_scale: The standard deviation of the noise. The categorical features\n            are created using a latent variable approach. The noise standard\n            deviation determines how much weight the \"mean\" estimate has on\n            the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples, d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution is not 'probit', 'normal', 'logit', 'gumbel'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"categorical:{}\".format(n_categories),\n        n_samples=n_samples,\n        distributions={\"categorical\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\ndef sem_generator(\n",
        "source_code_len": 6990,
        "target_code": "\ndef sem_generator(\n",
        "target_code_len": 20,
        "diff_format": "@@ -133,197 +133,2 @@\n \n-def generate_continuous_data(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"gaussian\",\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> np.ndarray:\n-    \"\"\"\n-    Simulate samples from SEM with specified type of noise.\n-    The order of the columns on the returned array is the one provided by `sm.nodes`\n-\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n-            'exponential', 'gumbel'.\n-        noise_scale: The standard deviation of the noise.\n-        intercept: Whether to use an intercept for each feature.\n-        seed: Random state\n-    Returns:\n-        x_mat: [n_samples,d_nodes] sample matrix\n-    Raises:\n-        ValueError: if distribution isn't gaussian/normal/student-t/exponential/gumbel\n-    \"\"\"\n-    df = sem_generator(\n-        graph=sm,\n-        default_type=\"continuous\",\n-        n_samples=n_samples,\n-        distributions={\"continuous\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-    return df[list(sm.nodes())].values\n-\n-\n-def generate_binary_data(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"logit\",\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> np.ndarray:\n-    \"\"\"\n-    Simulate samples from SEM with specified type of noise.\n-    The order of the columns on the returned array is the one provided by `sm.nodes`\n-\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'probit'/'normal' (alias),\n-            'logit' (default).\n-        noise_scale: The standard deviation of the noise. The binary and\n-            categorical features are created using a latent variable approach.\n-            The noise standard deviation determines how much weight the \"mean\"\n-            estimate has on the feature value.\n-        intercept: Whether to use an intercept for the latent variable of each feature.\n-        seed: Random state\n-    Returns:\n-        x_mat: [n_samples,d_nodes] sample matrix\n-    Raises:\n-        ValueError: if distribution isn't 'probit', 'normal', 'logit'\n-    \"\"\"\n-    df = sem_generator(\n-        graph=sm,\n-        default_type=\"binary\",\n-        n_samples=n_samples,\n-        distributions={\"binary\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-    return df[list(sm.nodes())].values\n-\n-\n-def generate_continuous_dataframe(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"gaussian\",\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> pd.DataFrame:\n-    \"\"\"\n-    Generates a dataframe with samples from SEM with specified type of noise.\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n-            'exponential', 'gumbel'.\n-        noise_scale: The standard deviation of the noise.\n-        intercept: Whether to use an intercept for each feature.\n-        seed: Random state\n-    Returns:\n-        Dataframe with the node names as column names\n-    Raises:\n-        ValueError: if distribution is not 'gaussian', 'normal', 'student-t',\n-            'exponential', 'gumbel'\n-    \"\"\"\n-    return sem_generator(\n-        graph=sm,\n-        default_type=\"continuous\",\n-        n_samples=n_samples,\n-        distributions={\"continuous\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-\n-\n-def generate_binary_dataframe(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"logit\",\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> pd.DataFrame:\n-    \"\"\"\n-    Generates a dataframe with samples from SEM with specified type of noise.\n-\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'probit'/'normal' (alias),\n-            'logit' (default).\n-        noise_scale: The standard deviation of the noise. The binary and\n-            categorical features are created using a latent variable approach.\n-            The noise standard deviation determines how much weight the \"mean\"\n-            estimate has on the feature value.\n-        intercept: Whether to use an intercept for the latent variable of each feature.\n-        seed: Random state\n-    Returns:\n-        x_mat: [n_samples,d_nodes] sample matrix\n-    Raises:\n-        ValueError: if distribution is not 'probit', 'normal', 'logit'\n-    \"\"\"\n-    return sem_generator(\n-        graph=sm,\n-        default_type=\"binary\",\n-        n_samples=n_samples,\n-        distributions={\"binary\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-\n-\n-def generate_categorical_dataframe(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"logit\",\n-    n_categories: int = 3,\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> pd.DataFrame:\n-    \"\"\"\n-    Generates a dataframe with samples from SEM with specified type of noise.\n-\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'probit'/'normal' (alias),\n-            \"logit\"/\"gumbel\" (alias). Logit is default.\n-        n_categories: Number of categories per variable/node.\n-        noise_scale: The standard deviation of the noise. The categorical features\n-            are created using a latent variable approach. The noise standard\n-            deviation determines how much weight the \"mean\" estimate has on\n-            the feature value.\n-        intercept: Whether to use an intercept for the latent variable of each feature.\n-        seed: Random state\n-    Returns:\n-        x_mat: [n_samples, d_nodes] sample matrix\n-    Raises:\n-        ValueError: if distribution is not 'probit', 'normal', 'logit', 'gumbel'\n-    \"\"\"\n-    return sem_generator(\n-        graph=sm,\n-        default_type=\"categorical:{}\".format(n_categories),\n-        n_samples=n_samples,\n-        distributions={\"categorical\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-\n-\n def sem_generator(\n",
        "source_code_with_indent": "\n<DED>def generate_continuous_data(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"gaussian\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> np.ndarray:\n    <IND>\"\"\"\n    Simulate samples from SEM with specified type of noise.\n    The order of the columns on the returned array is the one provided by `sm.nodes`\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n            'exponential', 'gumbel'.\n        noise_scale: The standard deviation of the noise.\n        intercept: Whether to use an intercept for each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution isn't gaussian/normal/student-t/exponential/gumbel\n    \"\"\"\n    df = sem_generator(\n        graph=sm,\n        default_type=\"continuous\",\n        n_samples=n_samples,\n        distributions={\"continuous\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n    return df[list(sm.nodes())].values\n\n\n<DED>def generate_binary_data(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> np.ndarray:\n    <IND>\"\"\"\n    Simulate samples from SEM with specified type of noise.\n    The order of the columns on the returned array is the one provided by `sm.nodes`\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            'logit' (default).\n        noise_scale: The standard deviation of the noise. The binary and\n            categorical features are created using a latent variable approach.\n            The noise standard deviation determines how much weight the \"mean\"\n            estimate has on the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution isn't 'probit', 'normal', 'logit'\n    \"\"\"\n    df = sem_generator(\n        graph=sm,\n        default_type=\"binary\",\n        n_samples=n_samples,\n        distributions={\"binary\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n    return df[list(sm.nodes())].values\n\n\n<DED>def generate_continuous_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"gaussian\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    <IND>\"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n            'exponential', 'gumbel'.\n        noise_scale: The standard deviation of the noise.\n        intercept: Whether to use an intercept for each feature.\n        seed: Random state\n    Returns:\n        Dataframe with the node names as column names\n    Raises:\n        ValueError: if distribution is not 'gaussian', 'normal', 'student-t',\n            'exponential', 'gumbel'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"continuous\",\n        n_samples=n_samples,\n        distributions={\"continuous\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\n<DED>def generate_binary_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    <IND>\"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            'logit' (default).\n        noise_scale: The standard deviation of the noise. The binary and\n            categorical features are created using a latent variable approach.\n            The noise standard deviation determines how much weight the \"mean\"\n            estimate has on the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution is not 'probit', 'normal', 'logit'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"binary\",\n        n_samples=n_samples,\n        distributions={\"binary\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\n<DED>def generate_categorical_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    n_categories: int = 3,\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    <IND>\"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            \"logit\"/\"gumbel\" (alias). Logit is default.\n        n_categories: Number of categories per variable/node.\n        noise_scale: The standard deviation of the noise. The categorical features\n            are created using a latent variable approach. The noise standard\n            deviation determines how much weight the \"mean\" estimate has on\n            the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples, d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution is not 'probit', 'normal', 'logit', 'gumbel'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"categorical:{}\".format(n_categories),\n        n_samples=n_samples,\n        distributions={\"categorical\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\n<DED>def sem_generator(\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def sem_generator(\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "quantumblacklabs/causalnex",
    "commit": "e73a638f788d879bb1efc9d5733370e60ae3cb00",
    "filename": "causalnex/structure/data_generators.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/quantumblacklabs-causalnex/causalnex/structure/data_generators/core.py",
    "file_hunks_size": 14,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": true,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "causalnex/structure/data_generators.py:219:4 Incompatible variable type [9]: seed is declared to have type `int` but is used as type `None`.",
    "message": " seed is declared to have type `int` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 219,
    "warning_line": "    seed: int = None,",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "\ndef generate_continuous_data(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"gaussian\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> np.ndarray:\n    \"\"\"\n    Simulate samples from SEM with specified type of noise.\n    The order of the columns on the returned array is the one provided by `sm.nodes`\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n            'exponential', 'gumbel'.\n        noise_scale: The standard deviation of the noise.\n        intercept: Whether to use an intercept for each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution isn't gaussian/normal/student-t/exponential/gumbel\n    \"\"\"\n    df = sem_generator(\n        graph=sm,\n        default_type=\"continuous\",\n        n_samples=n_samples,\n        distributions={\"continuous\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n    return df[list(sm.nodes())].values\n\n\ndef generate_binary_data(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> np.ndarray:\n    \"\"\"\n    Simulate samples from SEM with specified type of noise.\n    The order of the columns on the returned array is the one provided by `sm.nodes`\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            'logit' (default).\n        noise_scale: The standard deviation of the noise. The binary and\n            categorical features are created using a latent variable approach.\n            The noise standard deviation determines how much weight the \"mean\"\n            estimate has on the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution isn't 'probit', 'normal', 'logit'\n    \"\"\"\n    df = sem_generator(\n        graph=sm,\n        default_type=\"binary\",\n        n_samples=n_samples,\n        distributions={\"binary\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n    return df[list(sm.nodes())].values\n\n\ndef generate_continuous_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"gaussian\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    \"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n            'exponential', 'gumbel'.\n        noise_scale: The standard deviation of the noise.\n        intercept: Whether to use an intercept for each feature.\n        seed: Random state\n    Returns:\n        Dataframe with the node names as column names\n    Raises:\n        ValueError: if distribution is not 'gaussian', 'normal', 'student-t',\n            'exponential', 'gumbel'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"continuous\",\n        n_samples=n_samples,\n        distributions={\"continuous\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\ndef generate_binary_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    \"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            'logit' (default).\n        noise_scale: The standard deviation of the noise. The binary and\n            categorical features are created using a latent variable approach.\n            The noise standard deviation determines how much weight the \"mean\"\n            estimate has on the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution is not 'probit', 'normal', 'logit'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"binary\",\n        n_samples=n_samples,\n        distributions={\"binary\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\ndef generate_categorical_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    n_categories: int = 3,\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    \"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            \"logit\"/\"gumbel\" (alias). Logit is default.\n        n_categories: Number of categories per variable/node.\n        noise_scale: The standard deviation of the noise. The categorical features\n            are created using a latent variable approach. The noise standard\n            deviation determines how much weight the \"mean\" estimate has on\n            the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples, d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution is not 'probit', 'normal', 'logit', 'gumbel'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"categorical:{}\".format(n_categories),\n        n_samples=n_samples,\n        distributions={\"categorical\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\ndef sem_generator(\n",
        "source_code_len": 6990,
        "target_code": "\ndef sem_generator(\n",
        "target_code_len": 20,
        "diff_format": "@@ -133,197 +133,2 @@\n \n-def generate_continuous_data(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"gaussian\",\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> np.ndarray:\n-    \"\"\"\n-    Simulate samples from SEM with specified type of noise.\n-    The order of the columns on the returned array is the one provided by `sm.nodes`\n-\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n-            'exponential', 'gumbel'.\n-        noise_scale: The standard deviation of the noise.\n-        intercept: Whether to use an intercept for each feature.\n-        seed: Random state\n-    Returns:\n-        x_mat: [n_samples,d_nodes] sample matrix\n-    Raises:\n-        ValueError: if distribution isn't gaussian/normal/student-t/exponential/gumbel\n-    \"\"\"\n-    df = sem_generator(\n-        graph=sm,\n-        default_type=\"continuous\",\n-        n_samples=n_samples,\n-        distributions={\"continuous\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-    return df[list(sm.nodes())].values\n-\n-\n-def generate_binary_data(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"logit\",\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> np.ndarray:\n-    \"\"\"\n-    Simulate samples from SEM with specified type of noise.\n-    The order of the columns on the returned array is the one provided by `sm.nodes`\n-\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'probit'/'normal' (alias),\n-            'logit' (default).\n-        noise_scale: The standard deviation of the noise. The binary and\n-            categorical features are created using a latent variable approach.\n-            The noise standard deviation determines how much weight the \"mean\"\n-            estimate has on the feature value.\n-        intercept: Whether to use an intercept for the latent variable of each feature.\n-        seed: Random state\n-    Returns:\n-        x_mat: [n_samples,d_nodes] sample matrix\n-    Raises:\n-        ValueError: if distribution isn't 'probit', 'normal', 'logit'\n-    \"\"\"\n-    df = sem_generator(\n-        graph=sm,\n-        default_type=\"binary\",\n-        n_samples=n_samples,\n-        distributions={\"binary\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-    return df[list(sm.nodes())].values\n-\n-\n-def generate_continuous_dataframe(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"gaussian\",\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> pd.DataFrame:\n-    \"\"\"\n-    Generates a dataframe with samples from SEM with specified type of noise.\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n-            'exponential', 'gumbel'.\n-        noise_scale: The standard deviation of the noise.\n-        intercept: Whether to use an intercept for each feature.\n-        seed: Random state\n-    Returns:\n-        Dataframe with the node names as column names\n-    Raises:\n-        ValueError: if distribution is not 'gaussian', 'normal', 'student-t',\n-            'exponential', 'gumbel'\n-    \"\"\"\n-    return sem_generator(\n-        graph=sm,\n-        default_type=\"continuous\",\n-        n_samples=n_samples,\n-        distributions={\"continuous\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-\n-\n-def generate_binary_dataframe(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"logit\",\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> pd.DataFrame:\n-    \"\"\"\n-    Generates a dataframe with samples from SEM with specified type of noise.\n-\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'probit'/'normal' (alias),\n-            'logit' (default).\n-        noise_scale: The standard deviation of the noise. The binary and\n-            categorical features are created using a latent variable approach.\n-            The noise standard deviation determines how much weight the \"mean\"\n-            estimate has on the feature value.\n-        intercept: Whether to use an intercept for the latent variable of each feature.\n-        seed: Random state\n-    Returns:\n-        x_mat: [n_samples,d_nodes] sample matrix\n-    Raises:\n-        ValueError: if distribution is not 'probit', 'normal', 'logit'\n-    \"\"\"\n-    return sem_generator(\n-        graph=sm,\n-        default_type=\"binary\",\n-        n_samples=n_samples,\n-        distributions={\"binary\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-\n-\n-def generate_categorical_dataframe(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"logit\",\n-    n_categories: int = 3,\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> pd.DataFrame:\n-    \"\"\"\n-    Generates a dataframe with samples from SEM with specified type of noise.\n-\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'probit'/'normal' (alias),\n-            \"logit\"/\"gumbel\" (alias). Logit is default.\n-        n_categories: Number of categories per variable/node.\n-        noise_scale: The standard deviation of the noise. The categorical features\n-            are created using a latent variable approach. The noise standard\n-            deviation determines how much weight the \"mean\" estimate has on\n-            the feature value.\n-        intercept: Whether to use an intercept for the latent variable of each feature.\n-        seed: Random state\n-    Returns:\n-        x_mat: [n_samples, d_nodes] sample matrix\n-    Raises:\n-        ValueError: if distribution is not 'probit', 'normal', 'logit', 'gumbel'\n-    \"\"\"\n-    return sem_generator(\n-        graph=sm,\n-        default_type=\"categorical:{}\".format(n_categories),\n-        n_samples=n_samples,\n-        distributions={\"categorical\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-\n-\n def sem_generator(\n",
        "source_code_with_indent": "\n<DED>def generate_continuous_data(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"gaussian\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> np.ndarray:\n    <IND>\"\"\"\n    Simulate samples from SEM with specified type of noise.\n    The order of the columns on the returned array is the one provided by `sm.nodes`\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n            'exponential', 'gumbel'.\n        noise_scale: The standard deviation of the noise.\n        intercept: Whether to use an intercept for each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution isn't gaussian/normal/student-t/exponential/gumbel\n    \"\"\"\n    df = sem_generator(\n        graph=sm,\n        default_type=\"continuous\",\n        n_samples=n_samples,\n        distributions={\"continuous\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n    return df[list(sm.nodes())].values\n\n\n<DED>def generate_binary_data(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> np.ndarray:\n    <IND>\"\"\"\n    Simulate samples from SEM with specified type of noise.\n    The order of the columns on the returned array is the one provided by `sm.nodes`\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            'logit' (default).\n        noise_scale: The standard deviation of the noise. The binary and\n            categorical features are created using a latent variable approach.\n            The noise standard deviation determines how much weight the \"mean\"\n            estimate has on the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution isn't 'probit', 'normal', 'logit'\n    \"\"\"\n    df = sem_generator(\n        graph=sm,\n        default_type=\"binary\",\n        n_samples=n_samples,\n        distributions={\"binary\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n    return df[list(sm.nodes())].values\n\n\n<DED>def generate_continuous_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"gaussian\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    <IND>\"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n            'exponential', 'gumbel'.\n        noise_scale: The standard deviation of the noise.\n        intercept: Whether to use an intercept for each feature.\n        seed: Random state\n    Returns:\n        Dataframe with the node names as column names\n    Raises:\n        ValueError: if distribution is not 'gaussian', 'normal', 'student-t',\n            'exponential', 'gumbel'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"continuous\",\n        n_samples=n_samples,\n        distributions={\"continuous\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\n<DED>def generate_binary_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    <IND>\"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            'logit' (default).\n        noise_scale: The standard deviation of the noise. The binary and\n            categorical features are created using a latent variable approach.\n            The noise standard deviation determines how much weight the \"mean\"\n            estimate has on the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution is not 'probit', 'normal', 'logit'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"binary\",\n        n_samples=n_samples,\n        distributions={\"binary\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\n<DED>def generate_categorical_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    n_categories: int = 3,\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    <IND>\"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            \"logit\"/\"gumbel\" (alias). Logit is default.\n        n_categories: Number of categories per variable/node.\n        noise_scale: The standard deviation of the noise. The categorical features\n            are created using a latent variable approach. The noise standard\n            deviation determines how much weight the \"mean\" estimate has on\n            the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples, d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution is not 'probit', 'normal', 'logit', 'gumbel'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"categorical:{}\".format(n_categories),\n        n_samples=n_samples,\n        distributions={\"categorical\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\n<DED>def sem_generator(\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def sem_generator(\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "quantumblacklabs/causalnex",
    "commit": "e73a638f788d879bb1efc9d5733370e60ae3cb00",
    "filename": "causalnex/structure/data_generators.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/quantumblacklabs-causalnex/causalnex/structure/data_generators/core.py",
    "file_hunks_size": 14,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": true,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "causalnex/structure/data_generators.py:255:4 Incompatible variable type [9]: seed is declared to have type `int` but is used as type `None`.",
    "message": " seed is declared to have type `int` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 255,
    "warning_line": "    seed: int = None,",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "\ndef generate_continuous_data(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"gaussian\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> np.ndarray:\n    \"\"\"\n    Simulate samples from SEM with specified type of noise.\n    The order of the columns on the returned array is the one provided by `sm.nodes`\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n            'exponential', 'gumbel'.\n        noise_scale: The standard deviation of the noise.\n        intercept: Whether to use an intercept for each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution isn't gaussian/normal/student-t/exponential/gumbel\n    \"\"\"\n    df = sem_generator(\n        graph=sm,\n        default_type=\"continuous\",\n        n_samples=n_samples,\n        distributions={\"continuous\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n    return df[list(sm.nodes())].values\n\n\ndef generate_binary_data(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> np.ndarray:\n    \"\"\"\n    Simulate samples from SEM with specified type of noise.\n    The order of the columns on the returned array is the one provided by `sm.nodes`\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            'logit' (default).\n        noise_scale: The standard deviation of the noise. The binary and\n            categorical features are created using a latent variable approach.\n            The noise standard deviation determines how much weight the \"mean\"\n            estimate has on the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution isn't 'probit', 'normal', 'logit'\n    \"\"\"\n    df = sem_generator(\n        graph=sm,\n        default_type=\"binary\",\n        n_samples=n_samples,\n        distributions={\"binary\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n    return df[list(sm.nodes())].values\n\n\ndef generate_continuous_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"gaussian\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    \"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n            'exponential', 'gumbel'.\n        noise_scale: The standard deviation of the noise.\n        intercept: Whether to use an intercept for each feature.\n        seed: Random state\n    Returns:\n        Dataframe with the node names as column names\n    Raises:\n        ValueError: if distribution is not 'gaussian', 'normal', 'student-t',\n            'exponential', 'gumbel'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"continuous\",\n        n_samples=n_samples,\n        distributions={\"continuous\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\ndef generate_binary_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    \"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            'logit' (default).\n        noise_scale: The standard deviation of the noise. The binary and\n            categorical features are created using a latent variable approach.\n            The noise standard deviation determines how much weight the \"mean\"\n            estimate has on the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution is not 'probit', 'normal', 'logit'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"binary\",\n        n_samples=n_samples,\n        distributions={\"binary\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\ndef generate_categorical_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    n_categories: int = 3,\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    \"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            \"logit\"/\"gumbel\" (alias). Logit is default.\n        n_categories: Number of categories per variable/node.\n        noise_scale: The standard deviation of the noise. The categorical features\n            are created using a latent variable approach. The noise standard\n            deviation determines how much weight the \"mean\" estimate has on\n            the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples, d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution is not 'probit', 'normal', 'logit', 'gumbel'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"categorical:{}\".format(n_categories),\n        n_samples=n_samples,\n        distributions={\"categorical\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\ndef sem_generator(\n",
        "source_code_len": 6990,
        "target_code": "\ndef sem_generator(\n",
        "target_code_len": 20,
        "diff_format": "@@ -133,197 +133,2 @@\n \n-def generate_continuous_data(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"gaussian\",\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> np.ndarray:\n-    \"\"\"\n-    Simulate samples from SEM with specified type of noise.\n-    The order of the columns on the returned array is the one provided by `sm.nodes`\n-\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n-            'exponential', 'gumbel'.\n-        noise_scale: The standard deviation of the noise.\n-        intercept: Whether to use an intercept for each feature.\n-        seed: Random state\n-    Returns:\n-        x_mat: [n_samples,d_nodes] sample matrix\n-    Raises:\n-        ValueError: if distribution isn't gaussian/normal/student-t/exponential/gumbel\n-    \"\"\"\n-    df = sem_generator(\n-        graph=sm,\n-        default_type=\"continuous\",\n-        n_samples=n_samples,\n-        distributions={\"continuous\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-    return df[list(sm.nodes())].values\n-\n-\n-def generate_binary_data(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"logit\",\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> np.ndarray:\n-    \"\"\"\n-    Simulate samples from SEM with specified type of noise.\n-    The order of the columns on the returned array is the one provided by `sm.nodes`\n-\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'probit'/'normal' (alias),\n-            'logit' (default).\n-        noise_scale: The standard deviation of the noise. The binary and\n-            categorical features are created using a latent variable approach.\n-            The noise standard deviation determines how much weight the \"mean\"\n-            estimate has on the feature value.\n-        intercept: Whether to use an intercept for the latent variable of each feature.\n-        seed: Random state\n-    Returns:\n-        x_mat: [n_samples,d_nodes] sample matrix\n-    Raises:\n-        ValueError: if distribution isn't 'probit', 'normal', 'logit'\n-    \"\"\"\n-    df = sem_generator(\n-        graph=sm,\n-        default_type=\"binary\",\n-        n_samples=n_samples,\n-        distributions={\"binary\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-    return df[list(sm.nodes())].values\n-\n-\n-def generate_continuous_dataframe(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"gaussian\",\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> pd.DataFrame:\n-    \"\"\"\n-    Generates a dataframe with samples from SEM with specified type of noise.\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n-            'exponential', 'gumbel'.\n-        noise_scale: The standard deviation of the noise.\n-        intercept: Whether to use an intercept for each feature.\n-        seed: Random state\n-    Returns:\n-        Dataframe with the node names as column names\n-    Raises:\n-        ValueError: if distribution is not 'gaussian', 'normal', 'student-t',\n-            'exponential', 'gumbel'\n-    \"\"\"\n-    return sem_generator(\n-        graph=sm,\n-        default_type=\"continuous\",\n-        n_samples=n_samples,\n-        distributions={\"continuous\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-\n-\n-def generate_binary_dataframe(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"logit\",\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> pd.DataFrame:\n-    \"\"\"\n-    Generates a dataframe with samples from SEM with specified type of noise.\n-\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'probit'/'normal' (alias),\n-            'logit' (default).\n-        noise_scale: The standard deviation of the noise. The binary and\n-            categorical features are created using a latent variable approach.\n-            The noise standard deviation determines how much weight the \"mean\"\n-            estimate has on the feature value.\n-        intercept: Whether to use an intercept for the latent variable of each feature.\n-        seed: Random state\n-    Returns:\n-        x_mat: [n_samples,d_nodes] sample matrix\n-    Raises:\n-        ValueError: if distribution is not 'probit', 'normal', 'logit'\n-    \"\"\"\n-    return sem_generator(\n-        graph=sm,\n-        default_type=\"binary\",\n-        n_samples=n_samples,\n-        distributions={\"binary\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-\n-\n-def generate_categorical_dataframe(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"logit\",\n-    n_categories: int = 3,\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> pd.DataFrame:\n-    \"\"\"\n-    Generates a dataframe with samples from SEM with specified type of noise.\n-\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'probit'/'normal' (alias),\n-            \"logit\"/\"gumbel\" (alias). Logit is default.\n-        n_categories: Number of categories per variable/node.\n-        noise_scale: The standard deviation of the noise. The categorical features\n-            are created using a latent variable approach. The noise standard\n-            deviation determines how much weight the \"mean\" estimate has on\n-            the feature value.\n-        intercept: Whether to use an intercept for the latent variable of each feature.\n-        seed: Random state\n-    Returns:\n-        x_mat: [n_samples, d_nodes] sample matrix\n-    Raises:\n-        ValueError: if distribution is not 'probit', 'normal', 'logit', 'gumbel'\n-    \"\"\"\n-    return sem_generator(\n-        graph=sm,\n-        default_type=\"categorical:{}\".format(n_categories),\n-        n_samples=n_samples,\n-        distributions={\"categorical\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-\n-\n def sem_generator(\n",
        "source_code_with_indent": "\n<DED>def generate_continuous_data(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"gaussian\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> np.ndarray:\n    <IND>\"\"\"\n    Simulate samples from SEM with specified type of noise.\n    The order of the columns on the returned array is the one provided by `sm.nodes`\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n            'exponential', 'gumbel'.\n        noise_scale: The standard deviation of the noise.\n        intercept: Whether to use an intercept for each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution isn't gaussian/normal/student-t/exponential/gumbel\n    \"\"\"\n    df = sem_generator(\n        graph=sm,\n        default_type=\"continuous\",\n        n_samples=n_samples,\n        distributions={\"continuous\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n    return df[list(sm.nodes())].values\n\n\n<DED>def generate_binary_data(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> np.ndarray:\n    <IND>\"\"\"\n    Simulate samples from SEM with specified type of noise.\n    The order of the columns on the returned array is the one provided by `sm.nodes`\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            'logit' (default).\n        noise_scale: The standard deviation of the noise. The binary and\n            categorical features are created using a latent variable approach.\n            The noise standard deviation determines how much weight the \"mean\"\n            estimate has on the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution isn't 'probit', 'normal', 'logit'\n    \"\"\"\n    df = sem_generator(\n        graph=sm,\n        default_type=\"binary\",\n        n_samples=n_samples,\n        distributions={\"binary\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n    return df[list(sm.nodes())].values\n\n\n<DED>def generate_continuous_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"gaussian\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    <IND>\"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n            'exponential', 'gumbel'.\n        noise_scale: The standard deviation of the noise.\n        intercept: Whether to use an intercept for each feature.\n        seed: Random state\n    Returns:\n        Dataframe with the node names as column names\n    Raises:\n        ValueError: if distribution is not 'gaussian', 'normal', 'student-t',\n            'exponential', 'gumbel'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"continuous\",\n        n_samples=n_samples,\n        distributions={\"continuous\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\n<DED>def generate_binary_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    <IND>\"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            'logit' (default).\n        noise_scale: The standard deviation of the noise. The binary and\n            categorical features are created using a latent variable approach.\n            The noise standard deviation determines how much weight the \"mean\"\n            estimate has on the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution is not 'probit', 'normal', 'logit'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"binary\",\n        n_samples=n_samples,\n        distributions={\"binary\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\n<DED>def generate_categorical_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    n_categories: int = 3,\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    <IND>\"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            \"logit\"/\"gumbel\" (alias). Logit is default.\n        n_categories: Number of categories per variable/node.\n        noise_scale: The standard deviation of the noise. The categorical features\n            are created using a latent variable approach. The noise standard\n            deviation determines how much weight the \"mean\" estimate has on\n            the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples, d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution is not 'probit', 'normal', 'logit', 'gumbel'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"categorical:{}\".format(n_categories),\n        n_samples=n_samples,\n        distributions={\"categorical\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\n<DED>def sem_generator(\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def sem_generator(\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "quantumblacklabs/causalnex",
    "commit": "e73a638f788d879bb1efc9d5733370e60ae3cb00",
    "filename": "causalnex/structure/data_generators.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/quantumblacklabs-causalnex/causalnex/structure/data_generators/core.py",
    "file_hunks_size": 14,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": true,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "causalnex/structure/data_generators.py:295:4 Incompatible variable type [9]: seed is declared to have type `int` but is used as type `None`.",
    "message": " seed is declared to have type `int` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 295,
    "warning_line": "    seed: int = None,",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "\ndef generate_continuous_data(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"gaussian\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> np.ndarray:\n    \"\"\"\n    Simulate samples from SEM with specified type of noise.\n    The order of the columns on the returned array is the one provided by `sm.nodes`\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n            'exponential', 'gumbel'.\n        noise_scale: The standard deviation of the noise.\n        intercept: Whether to use an intercept for each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution isn't gaussian/normal/student-t/exponential/gumbel\n    \"\"\"\n    df = sem_generator(\n        graph=sm,\n        default_type=\"continuous\",\n        n_samples=n_samples,\n        distributions={\"continuous\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n    return df[list(sm.nodes())].values\n\n\ndef generate_binary_data(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> np.ndarray:\n    \"\"\"\n    Simulate samples from SEM with specified type of noise.\n    The order of the columns on the returned array is the one provided by `sm.nodes`\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            'logit' (default).\n        noise_scale: The standard deviation of the noise. The binary and\n            categorical features are created using a latent variable approach.\n            The noise standard deviation determines how much weight the \"mean\"\n            estimate has on the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution isn't 'probit', 'normal', 'logit'\n    \"\"\"\n    df = sem_generator(\n        graph=sm,\n        default_type=\"binary\",\n        n_samples=n_samples,\n        distributions={\"binary\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n    return df[list(sm.nodes())].values\n\n\ndef generate_continuous_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"gaussian\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    \"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n            'exponential', 'gumbel'.\n        noise_scale: The standard deviation of the noise.\n        intercept: Whether to use an intercept for each feature.\n        seed: Random state\n    Returns:\n        Dataframe with the node names as column names\n    Raises:\n        ValueError: if distribution is not 'gaussian', 'normal', 'student-t',\n            'exponential', 'gumbel'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"continuous\",\n        n_samples=n_samples,\n        distributions={\"continuous\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\ndef generate_binary_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    \"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            'logit' (default).\n        noise_scale: The standard deviation of the noise. The binary and\n            categorical features are created using a latent variable approach.\n            The noise standard deviation determines how much weight the \"mean\"\n            estimate has on the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution is not 'probit', 'normal', 'logit'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"binary\",\n        n_samples=n_samples,\n        distributions={\"binary\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\ndef generate_categorical_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    n_categories: int = 3,\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    \"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            \"logit\"/\"gumbel\" (alias). Logit is default.\n        n_categories: Number of categories per variable/node.\n        noise_scale: The standard deviation of the noise. The categorical features\n            are created using a latent variable approach. The noise standard\n            deviation determines how much weight the \"mean\" estimate has on\n            the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples, d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution is not 'probit', 'normal', 'logit', 'gumbel'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"categorical:{}\".format(n_categories),\n        n_samples=n_samples,\n        distributions={\"categorical\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\ndef sem_generator(\n",
        "source_code_len": 6990,
        "target_code": "\ndef sem_generator(\n",
        "target_code_len": 20,
        "diff_format": "@@ -133,197 +133,2 @@\n \n-def generate_continuous_data(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"gaussian\",\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> np.ndarray:\n-    \"\"\"\n-    Simulate samples from SEM with specified type of noise.\n-    The order of the columns on the returned array is the one provided by `sm.nodes`\n-\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n-            'exponential', 'gumbel'.\n-        noise_scale: The standard deviation of the noise.\n-        intercept: Whether to use an intercept for each feature.\n-        seed: Random state\n-    Returns:\n-        x_mat: [n_samples,d_nodes] sample matrix\n-    Raises:\n-        ValueError: if distribution isn't gaussian/normal/student-t/exponential/gumbel\n-    \"\"\"\n-    df = sem_generator(\n-        graph=sm,\n-        default_type=\"continuous\",\n-        n_samples=n_samples,\n-        distributions={\"continuous\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-    return df[list(sm.nodes())].values\n-\n-\n-def generate_binary_data(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"logit\",\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> np.ndarray:\n-    \"\"\"\n-    Simulate samples from SEM with specified type of noise.\n-    The order of the columns on the returned array is the one provided by `sm.nodes`\n-\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'probit'/'normal' (alias),\n-            'logit' (default).\n-        noise_scale: The standard deviation of the noise. The binary and\n-            categorical features are created using a latent variable approach.\n-            The noise standard deviation determines how much weight the \"mean\"\n-            estimate has on the feature value.\n-        intercept: Whether to use an intercept for the latent variable of each feature.\n-        seed: Random state\n-    Returns:\n-        x_mat: [n_samples,d_nodes] sample matrix\n-    Raises:\n-        ValueError: if distribution isn't 'probit', 'normal', 'logit'\n-    \"\"\"\n-    df = sem_generator(\n-        graph=sm,\n-        default_type=\"binary\",\n-        n_samples=n_samples,\n-        distributions={\"binary\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-    return df[list(sm.nodes())].values\n-\n-\n-def generate_continuous_dataframe(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"gaussian\",\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> pd.DataFrame:\n-    \"\"\"\n-    Generates a dataframe with samples from SEM with specified type of noise.\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n-            'exponential', 'gumbel'.\n-        noise_scale: The standard deviation of the noise.\n-        intercept: Whether to use an intercept for each feature.\n-        seed: Random state\n-    Returns:\n-        Dataframe with the node names as column names\n-    Raises:\n-        ValueError: if distribution is not 'gaussian', 'normal', 'student-t',\n-            'exponential', 'gumbel'\n-    \"\"\"\n-    return sem_generator(\n-        graph=sm,\n-        default_type=\"continuous\",\n-        n_samples=n_samples,\n-        distributions={\"continuous\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-\n-\n-def generate_binary_dataframe(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"logit\",\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> pd.DataFrame:\n-    \"\"\"\n-    Generates a dataframe with samples from SEM with specified type of noise.\n-\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'probit'/'normal' (alias),\n-            'logit' (default).\n-        noise_scale: The standard deviation of the noise. The binary and\n-            categorical features are created using a latent variable approach.\n-            The noise standard deviation determines how much weight the \"mean\"\n-            estimate has on the feature value.\n-        intercept: Whether to use an intercept for the latent variable of each feature.\n-        seed: Random state\n-    Returns:\n-        x_mat: [n_samples,d_nodes] sample matrix\n-    Raises:\n-        ValueError: if distribution is not 'probit', 'normal', 'logit'\n-    \"\"\"\n-    return sem_generator(\n-        graph=sm,\n-        default_type=\"binary\",\n-        n_samples=n_samples,\n-        distributions={\"binary\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-\n-\n-def generate_categorical_dataframe(\n-    sm: nx.DiGraph,\n-    n_samples: int,\n-    distribution: str = \"logit\",\n-    n_categories: int = 3,\n-    noise_scale: float = 1.0,\n-    intercept: bool = False,\n-    seed: int = None,\n-) -> pd.DataFrame:\n-    \"\"\"\n-    Generates a dataframe with samples from SEM with specified type of noise.\n-\n-    Args:\n-        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n-        n_samples: The number of rows/observations to sample.\n-        distribution: The type of distribution to use for the noise\n-            of a variable. Options: 'probit'/'normal' (alias),\n-            \"logit\"/\"gumbel\" (alias). Logit is default.\n-        n_categories: Number of categories per variable/node.\n-        noise_scale: The standard deviation of the noise. The categorical features\n-            are created using a latent variable approach. The noise standard\n-            deviation determines how much weight the \"mean\" estimate has on\n-            the feature value.\n-        intercept: Whether to use an intercept for the latent variable of each feature.\n-        seed: Random state\n-    Returns:\n-        x_mat: [n_samples, d_nodes] sample matrix\n-    Raises:\n-        ValueError: if distribution is not 'probit', 'normal', 'logit', 'gumbel'\n-    \"\"\"\n-    return sem_generator(\n-        graph=sm,\n-        default_type=\"categorical:{}\".format(n_categories),\n-        n_samples=n_samples,\n-        distributions={\"categorical\": distribution},\n-        noise_std=noise_scale,\n-        intercept=intercept,\n-        seed=seed,\n-    )\n-\n-\n def sem_generator(\n",
        "source_code_with_indent": "\n<DED>def generate_continuous_data(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"gaussian\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> np.ndarray:\n    <IND>\"\"\"\n    Simulate samples from SEM with specified type of noise.\n    The order of the columns on the returned array is the one provided by `sm.nodes`\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n            'exponential', 'gumbel'.\n        noise_scale: The standard deviation of the noise.\n        intercept: Whether to use an intercept for each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution isn't gaussian/normal/student-t/exponential/gumbel\n    \"\"\"\n    df = sem_generator(\n        graph=sm,\n        default_type=\"continuous\",\n        n_samples=n_samples,\n        distributions={\"continuous\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n    return df[list(sm.nodes())].values\n\n\n<DED>def generate_binary_data(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> np.ndarray:\n    <IND>\"\"\"\n    Simulate samples from SEM with specified type of noise.\n    The order of the columns on the returned array is the one provided by `sm.nodes`\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            'logit' (default).\n        noise_scale: The standard deviation of the noise. The binary and\n            categorical features are created using a latent variable approach.\n            The noise standard deviation determines how much weight the \"mean\"\n            estimate has on the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution isn't 'probit', 'normal', 'logit'\n    \"\"\"\n    df = sem_generator(\n        graph=sm,\n        default_type=\"binary\",\n        n_samples=n_samples,\n        distributions={\"binary\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n    return df[list(sm.nodes())].values\n\n\n<DED>def generate_continuous_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"gaussian\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    <IND>\"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'gaussian'/'normal' (alias), 'student-t',\n            'exponential', 'gumbel'.\n        noise_scale: The standard deviation of the noise.\n        intercept: Whether to use an intercept for each feature.\n        seed: Random state\n    Returns:\n        Dataframe with the node names as column names\n    Raises:\n        ValueError: if distribution is not 'gaussian', 'normal', 'student-t',\n            'exponential', 'gumbel'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"continuous\",\n        n_samples=n_samples,\n        distributions={\"continuous\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\n<DED>def generate_binary_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    <IND>\"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            'logit' (default).\n        noise_scale: The standard deviation of the noise. The binary and\n            categorical features are created using a latent variable approach.\n            The noise standard deviation determines how much weight the \"mean\"\n            estimate has on the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples,d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution is not 'probit', 'normal', 'logit'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"binary\",\n        n_samples=n_samples,\n        distributions={\"binary\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\n<DED>def generate_categorical_dataframe(\n    sm: nx.DiGraph,\n    n_samples: int,\n    distribution: str = \"logit\",\n    n_categories: int = 3,\n    noise_scale: float = 1.0,\n    intercept: bool = False,\n    seed: int = None,\n) -> pd.DataFrame:\n    <IND>\"\"\"\n    Generates a dataframe with samples from SEM with specified type of noise.\n\n    Args:\n        sm: A DAG in form of a networkx or StructureModel. Does not require weights.\n        n_samples: The number of rows/observations to sample.\n        distribution: The type of distribution to use for the noise\n            of a variable. Options: 'probit'/'normal' (alias),\n            \"logit\"/\"gumbel\" (alias). Logit is default.\n        n_categories: Number of categories per variable/node.\n        noise_scale: The standard deviation of the noise. The categorical features\n            are created using a latent variable approach. The noise standard\n            deviation determines how much weight the \"mean\" estimate has on\n            the feature value.\n        intercept: Whether to use an intercept for the latent variable of each feature.\n        seed: Random state\n    Returns:\n        x_mat: [n_samples, d_nodes] sample matrix\n    Raises:\n        ValueError: if distribution is not 'probit', 'normal', 'logit', 'gumbel'\n    \"\"\"\n    return sem_generator(\n        graph=sm,\n        default_type=\"categorical:{}\".format(n_categories),\n        n_samples=n_samples,\n        distributions={\"categorical\": distribution},\n        noise_std=noise_scale,\n        intercept=intercept,\n        seed=seed,\n    )\n\n\n<DED>def sem_generator(\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n<DED>def sem_generator(\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "quantumblacklabs/causalnex",
    "commit": "e73a638f788d879bb1efc9d5733370e60ae3cb00",
    "filename": "causalnex/structure/data_generators.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/quantumblacklabs-causalnex/causalnex/structure/data_generators/core.py",
    "file_hunks_size": 14,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "causalnex/structure/data_generators.py:335:4 Incompatible variable type [9]: distributions is declared to have type `Dict[str, str]` but is used as type `None`.",
    "message": " distributions is declared to have type `Dict[str, str]` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 335,
    "warning_line": "    distributions: Dict[str, str] = None,"
  },
  {
    "project": "quantumblacklabs/causalnex",
    "commit": "e73a638f788d879bb1efc9d5733370e60ae3cb00",
    "filename": "causalnex/structure/data_generators.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/quantumblacklabs-causalnex/causalnex/structure/data_generators/core.py",
    "file_hunks_size": 14,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "causalnex/structure/data_generators.py:337:4 Incompatible variable type [9]: seed is declared to have type `int` but is used as type `None`.",
    "message": " seed is declared to have type `int` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 337,
    "warning_line": "    seed: int = None,"
  },
  {
    "project": "quantumblacklabs/causalnex",
    "commit": "e73a638f788d879bb1efc9d5733370e60ae3cb00",
    "filename": "causalnex/structure/data_generators.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/quantumblacklabs-causalnex/causalnex/structure/data_generators/core.py",
    "file_hunks_size": 14,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "causalnex/structure/data_generators.py:463:15 Incompatible parameter type [6]: Expected `typing.Sized` for 1st positional only parameter to call `len` but got `typing.Union[List[int], int]`.",
    "message": " Expected `typing.Sized` for 1st positional only parameter to call `len` but got `typing.Union[List[int], int]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 463,
    "warning_line": "        if len(parents_idx) <= root_node_len:"
  },
  {
    "project": "quantumblacklabs/causalnex",
    "commit": "e73a638f788d879bb1efc9d5733370e60ae3cb00",
    "filename": "causalnex/structure/data_generators.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/quantumblacklabs-causalnex/causalnex/structure/data_generators/core.py",
    "file_hunks_size": 14,
    "min_patch_found": false,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "causalnex/structure/data_generators.py:589:8 Incompatible parameter type [6]: Expected `Tuple[int]` for 4th parameter `size` to call `_handle_distribution_sampling` but got `Tuple[typing.Any, typing.Any]`.",
    "message": " Expected `Tuple[int]` for 4th parameter `size` to call `_handle_distribution_sampling` but got `Tuple[typing.Any, typing.Any]`.",
    "rule_id": "Incompatible parameter type [6]",
    "warning_line_no": 589,
    "warning_line": "        size=(n_samples, n_cardinality),"
  }
]