[
  {
    "project": "microsoft/msticpy",
    "commit": "d425c771a19d67f333caba7c607f3fd53a8e070b",
    "filename": "msticpy/sectools/process_tree_utils.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/microsoft-msticpy/msticpy/sectools/process_tree_utils.py",
    "file_hunks_size": 5,
    "min_patch_found": true,
    "single_hunk": false,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": false,
    "full_warning_msg": "msticpy/sectools/process_tree_utils.py:131:4 Incompatible variable type [9]: schema is declared to have type `ProcSchema` but is used as type `None`.",
    "message": " schema is declared to have type `ProcSchema` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 131,
    "warning_line": "    schema: ProcSchema = None,",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": true,
        "has_suppression": false,
        "source_code": "__author__ = \"Ian Hellen\"\n\n\nclass ProcessTreeSchemaException(MsticpyException):\n    \"\"\"Custom exception for Process Tree schema.\"\"\"\n\n\n@attr.s(auto_attribs=True)\nclass ProcSchema:\n    \"\"\"Property name lookup for Process event schema.\"\"\"\n\n    process_name: str\n    process_id: str\n    parent_id: str\n    logon_id: str\n    cmd_line: str\n    user_name: str\n    path_separator: str\n    time_stamp: str = \"TimeGenerated\"\n    parent_name: Optional[str] = None\n    target_logon_id: Optional[str] = None\n    user_id: Optional[str] = None\n\n    @property\n    def column_map(self) -> Dict[str, str]:\n        \"\"\"Return a dictionary that maps fields to schema names.\"\"\"\n        return {key: str(val) for key, val in attr.asdict(self).items()}\n\n    @property\n    def columns(self) -> Iterable[str]:\n        \"\"\"Return an interable of target column names.\"\"\"\n        return [str(val) for val in attr.asdict(self).values() if val]\n\n    @property\n    def event_type_col(self) -> str:\n        \"\"\"\n        Return the column name containing the event identifier.\n\n        Returns\n        -------\n        str\n            The name of the event ID column.\n\n        Raises\n        ------\n        ProcessTreeSchemaException\n            If the schema is not known.\n\n        \"\"\"\n        if self.process_name == \"NewProcessName\":\n            return \"EventID\"\n        if self.process_name == \"exe\":\n            return \"EventType\"\n        raise ProcessTreeSchemaException(\"Unknown schema.\")\n\n    @property\n    def event_filter(self) -> Any:\n        \"\"\"\n        Return the event type/ID to process for the current schema.\n\n        Returns\n        -------\n        Any\n            The value of the event ID to process.\n\n        Raises\n        ------\n        ProcessTreeSchemaException\n            If the schema is not known.\n\n        \"\"\"\n        if self.process_name == \"NewProcessName\":\n            return 4688\n        if self.process_name == \"exe\":\n            return \"SYSCALL_EXECVE\"\n        raise ProcessTreeSchemaException(\"Unknown schema.\")\n\n\nWIN_EVENT_SCH = ProcSchema(\n    time_stamp=\"TimeGenerated\",\n    process_name=\"NewProcessName\",\n    process_id=\"NewProcessId\",\n    parent_name=\"ParentProcessName\",\n    parent_id=\"ProcessId\",\n    logon_id=\"SubjectLogonId\",\n    target_logon_id=\"TargetLogonId\",\n    cmd_line=\"CommandLine\",\n    user_name=\"SubjectUserName\",\n    path_separator=\"\\\\\",\n    user_id=\"SubjectUserSid\",\n)\n\nLX_EVENT_SCH = ProcSchema(\n    time_stamp=\"TimeGenerated\",\n    process_name=\"exe\",\n    process_id=\"pid\",\n    parent_name=None,\n    parent_id=\"ppid\",\n    logon_id=\"ses\",\n    target_logon_id=None,\n    cmd_line=\"cmdline\",\n    user_name=\"acct\",\n    path_separator=\"/\",\n    user_id=\"uid\",\n)\n\nLX_INT_TYPES = [\"argc\", \"egid\", \"euid\", \"gid\", \"auid\", \"ppid\", \"pid\", \"ses\", \"uid\"]\n\n\nTS_FMT_STRING = \"%Y-%m-%d %H:%M:%S.%f\"\n\n\ndef build_process_tree(\n    procs: pd.DataFrame,\n    schema: ProcSchema = None,\n    show_progress: bool = False,\n    debug: bool = False,\n) -> pd.DataFrame:\n    \"\"\"\n    Build process trees from the process events.\n\n    Parameters\n    ----------\n    procs : pd.DataFrame\n        Process events (Windows 4688 or Linux Auditd)\n    schema : ProcSchema, optional\n        The column schema to use, by default None\n        If None, then the schema is inferred\n    show_progress : bool\n        Shows the progress of the process (helpful for\n        very large data sets)\n    debug : bool\n        If True produces extra debugging output,\n        by default False\n\n    Returns\n    -------\n    pd.DataFrame\n        Process tree dataframe.\n\n    \"\"\"\n    # If schema is none, infer schema from columns\n    if not schema:\n        schema = infer_schema(procs)\n\n    data_len = len(procs)\n    section_len = int(data_len / 4)\n    progress_ui = Progress(completed_len=data_len * 2, visible=show_progress)\n\n    # Clean data\n    procs_cln = _clean_proc_data(procs, schema)\n    progress_ui.update_progress(delta=section_len)\n\n    # Merge parent-child\n    merged_procs = _merge_parent_by_time(procs_cln, schema)\n    if debug:\n        _check_merge_status(procs_cln, merged_procs, schema)\n    progress_ui.update_progress(delta=section_len)\n\n    # extract inferred parents\n    merged_procs_par = _extract_inferred_parents(merged_procs, schema)\n    if debug:\n        _check_inferred_parents(merged_procs, merged_procs_par)\n    progress_ui.update_progress(delta=section_len)\n\n    # create parent-child keys\n    merged_procs_keys = _assign_proc_keys(merged_procs_par, schema)\n    if debug:\n        _check_proc_keys(merged_procs_keys, schema)\n    progress_ui.update_progress(delta=section_len)\n\n    # Build process paths\n    proc_tree = _build_proc_tree(merged_procs_keys, progress_ui)\n\n    if show_progress:\n        print(get_summary_info(proc_tree))\n    return proc_tree\n\n\ndef infer_schema(data: Union[pd.DataFrame, pd.Series]) -> ProcSchema:\n    \"\"\"\n    Infer the correct schema to use for this data set.\n\n    Parameters\n    ----------\n    data : Union[pd.DataFrame, pd.Series]\n        Data set to test\n\n    Returns\n    -------\n    ProcSchema\n        The schema most closely matching the data set.\n\n    \"\"\"\n    src_cols = data.columns if isinstance(data, pd.DataFrame) else data.index\n    lx_match = set(src_cols) & set(LX_EVENT_SCH.columns)\n    win_match = set(src_cols) & set(WIN_EVENT_SCH.columns)\n    return LX_EVENT_SCH if len(lx_match) > len(win_match) else WIN_EVENT_SCH\n\n\ndef _clean_proc_data(procs: pd.DataFrame, schema: ProcSchema) -> pd.DataFrame:\n    \"\"\"Return cleaned process data.\"\"\"\n    procs_cln = (\n        procs.drop_duplicates().sort_values(schema.time_stamp, ascending=True).copy()\n    )\n\n    # Filter out any non-process events\n    event_type_filter = procs_cln[schema.event_type_col] == schema.event_filter\n    procs_cln = procs_cln[event_type_filter]\n\n    # Change Linux int cols to force int then to string types\n    type_chng_int_dict = {col: \"int\" for col in LX_INT_TYPES if col in procs.columns}\n    if type_chng_int_dict:\n        procs_cln = procs_cln.astype(type_chng_int_dict)\n        type_chng_str_dict = {\n            col: \"str\" for col in LX_INT_TYPES if col in procs.columns\n        }\n        procs_cln = procs_cln.astype(type_chng_str_dict)\n    if \"EventID\" not in procs_cln.columns and \"EventType\" in procs_cln.columns:\n        procs_cln = procs_cln.rename(columns={\"EventType\": \"EventID\"})\n\n    procs_cln[\"EffectiveLogonId\"] = procs_cln[schema.logon_id]\n    # Create effective logon Id for Windows, if the TargetLogonId is not 0x0\n    if schema.target_logon_id:\n        has_tgt_logonid = (procs_cln[schema.target_logon_id] != \"0x0\") & (\n            procs_cln[schema.target_logon_id].notna()\n        )\n        procs_cln.loc[has_tgt_logonid, \"EffectiveLogonId\"] = procs_cln[\n            schema.target_logon_id\n        ]\n    procs_cln[\"new_process_lc\"] = procs_cln[schema.process_name].str.lower()\n    if schema.parent_name:\n        no_pproc = procs_cln[schema.parent_name] == \"\"\n        procs_cln.loc[no_pproc, schema.parent_name] = \"unknown\"\n        procs_cln[\"parent_proc_lc\"] = procs_cln[schema.parent_name].str.lower()\n    procs_cln[\"source_index\"] = procs_cln.index\n    return procs_cln\n\n\ndef _merge_parent_by_time(procs: pd.DataFrame, schema: ProcSchema) -> pd.DataFrame:\n    \"\"\"Merge procs with parents using merge_asof.\"\"\"\n    parent_procs = (\n        procs[\n            [\n                schema.process_id,\n                \"EffectiveLogonId\",\n                \"new_process_lc\",\n                \"source_index\",\n                schema.parent_id,\n                schema.time_stamp,\n                schema.process_name,\n            ]\n        ]\n        .assign(TimeGenerated_orig_par=procs[schema.time_stamp])\n        .sort_values(schema.time_stamp, ascending=True)\n    )\n    # if we have a parent name (Windows) - use that as part of the\n    # match\n    if schema.parent_name:\n        par_join_cols = [schema.process_id, \"new_process_lc\"]\n        child_join_cols = [schema.parent_id, \"parent_proc_lc\"]\n    else:\n        par_join_cols = [schema.process_id]\n        child_join_cols = [schema.parent_id]\n    # merge_asof merges on the \"by\" fields and then the closest time\n    # match in the time_stamp field. The default is to look backwards\n    # for a match on the right of the join (parent) that is a time earlier\n    # than the corresponding row on the left.\n    return pd.merge_asof(\n        left=procs.sort_values(schema.time_stamp, ascending=True),\n        right=parent_procs,\n        on=schema.time_stamp,\n        left_by=child_join_cols,\n        right_by=par_join_cols,\n        suffixes=(\"\", \"_par\"),\n    )\n\n\ndef _extract_inferred_parents(\n    merged_procs: pd.DataFrame, schema: ProcSchema\n) -> pd.DataFrame:\n    \"\"\"Find any inferred parents and creates rows for them.\"\"\"\n    tz_aware = merged_procs.iloc[0][schema.time_stamp].tz\n    time_zero = pd.Timestamp(0) if tz_aware is None else pd.Timestamp(0, tz=0)\n\n    # Fill in missing values for root processes\n    root_procs_crit = merged_procs[\"source_index_par\"].isna()\n    merged_procs.loc[root_procs_crit, \"NewProcessId_par\"] = merged_procs[\n        schema.parent_id\n    ]\n    if schema.parent_name:\n        merged_procs.loc[root_procs_crit, \"new_process_lc_par\"] = merged_procs[\n            \"parent_proc_lc\"\n        ]\n    else:\n        merged_procs.loc[root_procs_crit, \"new_process_lc_par\"] = \"unknown\"\n        merged_procs.loc[root_procs_crit, f\"{schema.process_name}_par\"] = \"unknown\"\n        # If the schema doesn't have a ParentProcessName/parent_proc_lc - copy this value\n        # from the merged data for ALL processes\n        merged_procs[\"ParentProcessName\"] = merged_procs[f\"{schema.process_name}_par\"]\n        merged_procs[\"parent_proc_lc\"] = merged_procs[\"new_process_lc_par\"]\n    merged_procs.loc[root_procs_crit, \"EffectiveLogonId_par\"] = merged_procs[\n        schema.logon_id\n    ]\n    merged_procs.loc[root_procs_crit, \"TimeGenerated_orig_par\"] = time_zero\n\n    # Extract synthentic rows for the parents of root processes\n    inferred_parents = (\n        merged_procs[root_procs_crit][\n            [\n                \"TenantId\",\n                \"EventID\",\n                \"Computer\",\n                schema.parent_id,\n                \"EffectiveLogonId_par\",\n                \"ParentProcessName\",\n                \"parent_proc_lc\",\n            ]\n        ]\n        .rename(\n            columns={\n                schema.parent_id: schema.process_id,\n                \"ParentProcessName\": schema.process_name,\n                \"parent_proc_lc\": \"new_process_lc\",\n                \"EffectiveLogonId_par\": schema.logon_id,\n            }\n        )\n        .assign(TimeGenerated=time_zero, EffectiveLogonId=merged_procs[schema.logon_id])\n        .drop_duplicates()\n    )\n\n    return pd.concat(\n        [merged_procs, inferred_parents], ignore_index=True, axis=0, sort=False\n    )\n\n\ndef _assign_proc_keys(\n    merged_procs_par: pd.DataFrame, schema: ProcSchema\n) -> pd.DataFrame:\n    \"\"\"Create process and parent keys for unambiguous par-child relation.\"\"\"\n    # Create Process Key\n    merged_procs_par[\"proc_key\"] = (\n        merged_procs_par[\"new_process_lc\"]\n        + merged_procs_par[schema.process_id].astype(str)\n        + merged_procs_par[schema.time_stamp]\n        .dt.round(\"10us\")\n        .dt.strftime(TS_FMT_STRING)\n    )\n    # Create Parent Key\n    merged_procs_par[\"parent_key\"] = (\n        merged_procs_par[\"parent_proc_lc\"]\n        + merged_procs_par[schema.parent_id].astype(str)\n        + merged_procs_par[\"TimeGenerated_orig_par\"]\n        .dt.round(\"10us\")\n        .dt.strftime(TS_FMT_STRING)\n    )\n    proc_tree = merged_procs_par.copy()\n    # Create labels based on node type\n    ppids = proc_tree[[\"parent_key\"]].set_index(\"parent_key\")\n    proc_tree = proc_tree.assign(IsRoot=False, IsLeaf=False, IsBranch=False)\n\n    is_root = proc_tree[\"parent_key\"].isna()\n    has_child = proc_tree[\"proc_key\"].isin(ppids.index)\n    proc_tree.loc[is_root, \"IsRoot\"] = True\n    proc_tree.loc[~has_child, \"IsLeaf\"] = True\n    proc_tree.loc[~is_root & has_child, \"IsBranch\"] = True\n\n    # Save the current numeric index as \"source_index\" converting to string\n    proc_tree[\"source_index\"] = proc_tree.index.astype(str)\n    # Set the index of the output frame to be the proc_key\n    proc_tree = proc_tree.set_index(\"proc_key\")\n\n    first_unique = proc_tree.index.duplicated()\n    proc_tree = proc_tree[~first_unique]\n    return proc_tree\n\n\ndef _build_proc_tree(input_tree, progress: Progress, max_depth=-1):\n    \"\"\"Build process tree paths.\"\"\"\n    # set default path == current process ID\n    input_tree[\"path\"] = input_tree[\"source_index\"]\n\n    cur_level = input_tree[input_tree[\"IsRoot\"]]\n    remaining_procs = input_tree[~input_tree[\"IsRoot\"]]\n\n    cur_level_num = 0\n    progress.update_progress(delta=len(cur_level))\n    while True:\n        sel_crit = remaining_procs[\"parent_key\"].isin(cur_level.index)\n        next_level = remaining_procs[sel_crit].copy()\n        remaining_procs = remaining_procs[~sel_crit]\n\n        if next_level.empty:\n            progress.update_progress(new_total=progress.max)\n            break\n        if max_depth != -1 and cur_level_num >= max_depth:\n            print(f\"max path depth reached: {cur_level_num}\")\n            print(\n                f\"processed {progress.value} of {progress.max} for specified depth of {max_depth}\"\n            )\n            progress.update_progress(new_total=progress.max)\n            break\n\n        # merge next level with current level\n        tmp_df = next_level.merge(\n            cur_level[[\"source_index\", \"path\"]],\n            how=\"inner\",\n            left_on=\"parent_key\",\n            right_index=True,\n        )\n\n        # Build the path of these processes\n        # = parent_path + child source_index\n        next_level.loc[tmp_df.index, \"path\"] = (\n            tmp_df[\"path_y\"] + \"/\" + tmp_df[\"source_index_x\"]\n        )\n        input_tree.loc[next_level.index, \"path\"] = next_level[\"path\"]\n        input_tree.loc[tmp_df.index, \"parent_index\"] = tmp_df[\"source_index_y\"]\n\n        cur_level = next_level\n        cur_level_num += 1\n        progress.update_progress(delta=len(cur_level))\n\n    return input_tree\n\n",
        "source_code_len": 14069,
        "target_code": "__author__ = \"Ian Hellen\"\n\n",
        "target_code_len": 27,
        "diff_format": "@@ -17,425 +14,2 @@\n __author__ = \"Ian Hellen\"\n-\n-\n-class ProcessTreeSchemaException(MsticpyException):\n-    \"\"\"Custom exception for Process Tree schema.\"\"\"\n-\n-\n-@attr.s(auto_attribs=True)\n-class ProcSchema:\n-    \"\"\"Property name lookup for Process event schema.\"\"\"\n-\n-    process_name: str\n-    process_id: str\n-    parent_id: str\n-    logon_id: str\n-    cmd_line: str\n-    user_name: str\n-    path_separator: str\n-    time_stamp: str = \"TimeGenerated\"\n-    parent_name: Optional[str] = None\n-    target_logon_id: Optional[str] = None\n-    user_id: Optional[str] = None\n-\n-    @property\n-    def column_map(self) -> Dict[str, str]:\n-        \"\"\"Return a dictionary that maps fields to schema names.\"\"\"\n-        return {key: str(val) for key, val in attr.asdict(self).items()}\n-\n-    @property\n-    def columns(self) -> Iterable[str]:\n-        \"\"\"Return an interable of target column names.\"\"\"\n-        return [str(val) for val in attr.asdict(self).values() if val]\n-\n-    @property\n-    def event_type_col(self) -> str:\n-        \"\"\"\n-        Return the column name containing the event identifier.\n-\n-        Returns\n-        -------\n-        str\n-            The name of the event ID column.\n-\n-        Raises\n-        ------\n-        ProcessTreeSchemaException\n-            If the schema is not known.\n-\n-        \"\"\"\n-        if self.process_name == \"NewProcessName\":\n-            return \"EventID\"\n-        if self.process_name == \"exe\":\n-            return \"EventType\"\n-        raise ProcessTreeSchemaException(\"Unknown schema.\")\n-\n-    @property\n-    def event_filter(self) -> Any:\n-        \"\"\"\n-        Return the event type/ID to process for the current schema.\n-\n-        Returns\n-        -------\n-        Any\n-            The value of the event ID to process.\n-\n-        Raises\n-        ------\n-        ProcessTreeSchemaException\n-            If the schema is not known.\n-\n-        \"\"\"\n-        if self.process_name == \"NewProcessName\":\n-            return 4688\n-        if self.process_name == \"exe\":\n-            return \"SYSCALL_EXECVE\"\n-        raise ProcessTreeSchemaException(\"Unknown schema.\")\n-\n-\n-WIN_EVENT_SCH = ProcSchema(\n-    time_stamp=\"TimeGenerated\",\n-    process_name=\"NewProcessName\",\n-    process_id=\"NewProcessId\",\n-    parent_name=\"ParentProcessName\",\n-    parent_id=\"ProcessId\",\n-    logon_id=\"SubjectLogonId\",\n-    target_logon_id=\"TargetLogonId\",\n-    cmd_line=\"CommandLine\",\n-    user_name=\"SubjectUserName\",\n-    path_separator=\"\\\\\",\n-    user_id=\"SubjectUserSid\",\n-)\n-\n-LX_EVENT_SCH = ProcSchema(\n-    time_stamp=\"TimeGenerated\",\n-    process_name=\"exe\",\n-    process_id=\"pid\",\n-    parent_name=None,\n-    parent_id=\"ppid\",\n-    logon_id=\"ses\",\n-    target_logon_id=None,\n-    cmd_line=\"cmdline\",\n-    user_name=\"acct\",\n-    path_separator=\"/\",\n-    user_id=\"uid\",\n-)\n-\n-LX_INT_TYPES = [\"argc\", \"egid\", \"euid\", \"gid\", \"auid\", \"ppid\", \"pid\", \"ses\", \"uid\"]\n-\n-\n-TS_FMT_STRING = \"%Y-%m-%d %H:%M:%S.%f\"\n-\n-\n-def build_process_tree(\n-    procs: pd.DataFrame,\n-    schema: ProcSchema = None,\n-    show_progress: bool = False,\n-    debug: bool = False,\n-) -> pd.DataFrame:\n-    \"\"\"\n-    Build process trees from the process events.\n-\n-    Parameters\n-    ----------\n-    procs : pd.DataFrame\n-        Process events (Windows 4688 or Linux Auditd)\n-    schema : ProcSchema, optional\n-        The column schema to use, by default None\n-        If None, then the schema is inferred\n-    show_progress : bool\n-        Shows the progress of the process (helpful for\n-        very large data sets)\n-    debug : bool\n-        If True produces extra debugging output,\n-        by default False\n-\n-    Returns\n-    -------\n-    pd.DataFrame\n-        Process tree dataframe.\n-\n-    \"\"\"\n-    # If schema is none, infer schema from columns\n-    if not schema:\n-        schema = infer_schema(procs)\n-\n-    data_len = len(procs)\n-    section_len = int(data_len / 4)\n-    progress_ui = Progress(completed_len=data_len * 2, visible=show_progress)\n-\n-    # Clean data\n-    procs_cln = _clean_proc_data(procs, schema)\n-    progress_ui.update_progress(delta=section_len)\n-\n-    # Merge parent-child\n-    merged_procs = _merge_parent_by_time(procs_cln, schema)\n-    if debug:\n-        _check_merge_status(procs_cln, merged_procs, schema)\n-    progress_ui.update_progress(delta=section_len)\n-\n-    # extract inferred parents\n-    merged_procs_par = _extract_inferred_parents(merged_procs, schema)\n-    if debug:\n-        _check_inferred_parents(merged_procs, merged_procs_par)\n-    progress_ui.update_progress(delta=section_len)\n-\n-    # create parent-child keys\n-    merged_procs_keys = _assign_proc_keys(merged_procs_par, schema)\n-    if debug:\n-        _check_proc_keys(merged_procs_keys, schema)\n-    progress_ui.update_progress(delta=section_len)\n-\n-    # Build process paths\n-    proc_tree = _build_proc_tree(merged_procs_keys, progress_ui)\n-\n-    if show_progress:\n-        print(get_summary_info(proc_tree))\n-    return proc_tree\n-\n-\n-def infer_schema(data: Union[pd.DataFrame, pd.Series]) -> ProcSchema:\n-    \"\"\"\n-    Infer the correct schema to use for this data set.\n-\n-    Parameters\n-    ----------\n-    data : Union[pd.DataFrame, pd.Series]\n-        Data set to test\n-\n-    Returns\n-    -------\n-    ProcSchema\n-        The schema most closely matching the data set.\n-\n-    \"\"\"\n-    src_cols = data.columns if isinstance(data, pd.DataFrame) else data.index\n-    lx_match = set(src_cols) & set(LX_EVENT_SCH.columns)\n-    win_match = set(src_cols) & set(WIN_EVENT_SCH.columns)\n-    return LX_EVENT_SCH if len(lx_match) > len(win_match) else WIN_EVENT_SCH\n-\n-\n-def _clean_proc_data(procs: pd.DataFrame, schema: ProcSchema) -> pd.DataFrame:\n-    \"\"\"Return cleaned process data.\"\"\"\n-    procs_cln = (\n-        procs.drop_duplicates().sort_values(schema.time_stamp, ascending=True).copy()\n-    )\n-\n-    # Filter out any non-process events\n-    event_type_filter = procs_cln[schema.event_type_col] == schema.event_filter\n-    procs_cln = procs_cln[event_type_filter]\n-\n-    # Change Linux int cols to force int then to string types\n-    type_chng_int_dict = {col: \"int\" for col in LX_INT_TYPES if col in procs.columns}\n-    if type_chng_int_dict:\n-        procs_cln = procs_cln.astype(type_chng_int_dict)\n-        type_chng_str_dict = {\n-            col: \"str\" for col in LX_INT_TYPES if col in procs.columns\n-        }\n-        procs_cln = procs_cln.astype(type_chng_str_dict)\n-    if \"EventID\" not in procs_cln.columns and \"EventType\" in procs_cln.columns:\n-        procs_cln = procs_cln.rename(columns={\"EventType\": \"EventID\"})\n-\n-    procs_cln[\"EffectiveLogonId\"] = procs_cln[schema.logon_id]\n-    # Create effective logon Id for Windows, if the TargetLogonId is not 0x0\n-    if schema.target_logon_id:\n-        has_tgt_logonid = (procs_cln[schema.target_logon_id] != \"0x0\") & (\n-            procs_cln[schema.target_logon_id].notna()\n-        )\n-        procs_cln.loc[has_tgt_logonid, \"EffectiveLogonId\"] = procs_cln[\n-            schema.target_logon_id\n-        ]\n-    procs_cln[\"new_process_lc\"] = procs_cln[schema.process_name].str.lower()\n-    if schema.parent_name:\n-        no_pproc = procs_cln[schema.parent_name] == \"\"\n-        procs_cln.loc[no_pproc, schema.parent_name] = \"unknown\"\n-        procs_cln[\"parent_proc_lc\"] = procs_cln[schema.parent_name].str.lower()\n-    procs_cln[\"source_index\"] = procs_cln.index\n-    return procs_cln\n-\n-\n-def _merge_parent_by_time(procs: pd.DataFrame, schema: ProcSchema) -> pd.DataFrame:\n-    \"\"\"Merge procs with parents using merge_asof.\"\"\"\n-    parent_procs = (\n-        procs[\n-            [\n-                schema.process_id,\n-                \"EffectiveLogonId\",\n-                \"new_process_lc\",\n-                \"source_index\",\n-                schema.parent_id,\n-                schema.time_stamp,\n-                schema.process_name,\n-            ]\n-        ]\n-        .assign(TimeGenerated_orig_par=procs[schema.time_stamp])\n-        .sort_values(schema.time_stamp, ascending=True)\n-    )\n-    # if we have a parent name (Windows) - use that as part of the\n-    # match\n-    if schema.parent_name:\n-        par_join_cols = [schema.process_id, \"new_process_lc\"]\n-        child_join_cols = [schema.parent_id, \"parent_proc_lc\"]\n-    else:\n-        par_join_cols = [schema.process_id]\n-        child_join_cols = [schema.parent_id]\n-    # merge_asof merges on the \"by\" fields and then the closest time\n-    # match in the time_stamp field. The default is to look backwards\n-    # for a match on the right of the join (parent) that is a time earlier\n-    # than the corresponding row on the left.\n-    return pd.merge_asof(\n-        left=procs.sort_values(schema.time_stamp, ascending=True),\n-        right=parent_procs,\n-        on=schema.time_stamp,\n-        left_by=child_join_cols,\n-        right_by=par_join_cols,\n-        suffixes=(\"\", \"_par\"),\n-    )\n-\n-\n-def _extract_inferred_parents(\n-    merged_procs: pd.DataFrame, schema: ProcSchema\n-) -> pd.DataFrame:\n-    \"\"\"Find any inferred parents and creates rows for them.\"\"\"\n-    tz_aware = merged_procs.iloc[0][schema.time_stamp].tz\n-    time_zero = pd.Timestamp(0) if tz_aware is None else pd.Timestamp(0, tz=0)\n-\n-    # Fill in missing values for root processes\n-    root_procs_crit = merged_procs[\"source_index_par\"].isna()\n-    merged_procs.loc[root_procs_crit, \"NewProcessId_par\"] = merged_procs[\n-        schema.parent_id\n-    ]\n-    if schema.parent_name:\n-        merged_procs.loc[root_procs_crit, \"new_process_lc_par\"] = merged_procs[\n-            \"parent_proc_lc\"\n-        ]\n-    else:\n-        merged_procs.loc[root_procs_crit, \"new_process_lc_par\"] = \"unknown\"\n-        merged_procs.loc[root_procs_crit, f\"{schema.process_name}_par\"] = \"unknown\"\n-        # If the schema doesn't have a ParentProcessName/parent_proc_lc - copy this value\n-        # from the merged data for ALL processes\n-        merged_procs[\"ParentProcessName\"] = merged_procs[f\"{schema.process_name}_par\"]\n-        merged_procs[\"parent_proc_lc\"] = merged_procs[\"new_process_lc_par\"]\n-    merged_procs.loc[root_procs_crit, \"EffectiveLogonId_par\"] = merged_procs[\n-        schema.logon_id\n-    ]\n-    merged_procs.loc[root_procs_crit, \"TimeGenerated_orig_par\"] = time_zero\n-\n-    # Extract synthentic rows for the parents of root processes\n-    inferred_parents = (\n-        merged_procs[root_procs_crit][\n-            [\n-                \"TenantId\",\n-                \"EventID\",\n-                \"Computer\",\n-                schema.parent_id,\n-                \"EffectiveLogonId_par\",\n-                \"ParentProcessName\",\n-                \"parent_proc_lc\",\n-            ]\n-        ]\n-        .rename(\n-            columns={\n-                schema.parent_id: schema.process_id,\n-                \"ParentProcessName\": schema.process_name,\n-                \"parent_proc_lc\": \"new_process_lc\",\n-                \"EffectiveLogonId_par\": schema.logon_id,\n-            }\n-        )\n-        .assign(TimeGenerated=time_zero, EffectiveLogonId=merged_procs[schema.logon_id])\n-        .drop_duplicates()\n-    )\n-\n-    return pd.concat(\n-        [merged_procs, inferred_parents], ignore_index=True, axis=0, sort=False\n-    )\n-\n-\n-def _assign_proc_keys(\n-    merged_procs_par: pd.DataFrame, schema: ProcSchema\n-) -> pd.DataFrame:\n-    \"\"\"Create process and parent keys for unambiguous par-child relation.\"\"\"\n-    # Create Process Key\n-    merged_procs_par[\"proc_key\"] = (\n-        merged_procs_par[\"new_process_lc\"]\n-        + merged_procs_par[schema.process_id].astype(str)\n-        + merged_procs_par[schema.time_stamp]\n-        .dt.round(\"10us\")\n-        .dt.strftime(TS_FMT_STRING)\n-    )\n-    # Create Parent Key\n-    merged_procs_par[\"parent_key\"] = (\n-        merged_procs_par[\"parent_proc_lc\"]\n-        + merged_procs_par[schema.parent_id].astype(str)\n-        + merged_procs_par[\"TimeGenerated_orig_par\"]\n-        .dt.round(\"10us\")\n-        .dt.strftime(TS_FMT_STRING)\n-    )\n-    proc_tree = merged_procs_par.copy()\n-    # Create labels based on node type\n-    ppids = proc_tree[[\"parent_key\"]].set_index(\"parent_key\")\n-    proc_tree = proc_tree.assign(IsRoot=False, IsLeaf=False, IsBranch=False)\n-\n-    is_root = proc_tree[\"parent_key\"].isna()\n-    has_child = proc_tree[\"proc_key\"].isin(ppids.index)\n-    proc_tree.loc[is_root, \"IsRoot\"] = True\n-    proc_tree.loc[~has_child, \"IsLeaf\"] = True\n-    proc_tree.loc[~is_root & has_child, \"IsBranch\"] = True\n-\n-    # Save the current numeric index as \"source_index\" converting to string\n-    proc_tree[\"source_index\"] = proc_tree.index.astype(str)\n-    # Set the index of the output frame to be the proc_key\n-    proc_tree = proc_tree.set_index(\"proc_key\")\n-\n-    first_unique = proc_tree.index.duplicated()\n-    proc_tree = proc_tree[~first_unique]\n-    return proc_tree\n-\n-\n-def _build_proc_tree(input_tree, progress: Progress, max_depth=-1):\n-    \"\"\"Build process tree paths.\"\"\"\n-    # set default path == current process ID\n-    input_tree[\"path\"] = input_tree[\"source_index\"]\n-\n-    cur_level = input_tree[input_tree[\"IsRoot\"]]\n-    remaining_procs = input_tree[~input_tree[\"IsRoot\"]]\n-\n-    cur_level_num = 0\n-    progress.update_progress(delta=len(cur_level))\n-    while True:\n-        sel_crit = remaining_procs[\"parent_key\"].isin(cur_level.index)\n-        next_level = remaining_procs[sel_crit].copy()\n-        remaining_procs = remaining_procs[~sel_crit]\n-\n-        if next_level.empty:\n-            progress.update_progress(new_total=progress.max)\n-            break\n-        if max_depth != -1 and cur_level_num >= max_depth:\n-            print(f\"max path depth reached: {cur_level_num}\")\n-            print(\n-                f\"processed {progress.value} of {progress.max} for specified depth of {max_depth}\"\n-            )\n-            progress.update_progress(new_total=progress.max)\n-            break\n-\n-        # merge next level with current level\n-        tmp_df = next_level.merge(\n-            cur_level[[\"source_index\", \"path\"]],\n-            how=\"inner\",\n-            left_on=\"parent_key\",\n-            right_index=True,\n-        )\n-\n-        # Build the path of these processes\n-        # = parent_path + child source_index\n-        next_level.loc[tmp_df.index, \"path\"] = (\n-            tmp_df[\"path_y\"] + \"/\" + tmp_df[\"source_index_x\"]\n-        )\n-        input_tree.loc[next_level.index, \"path\"] = next_level[\"path\"]\n-        input_tree.loc[tmp_df.index, \"parent_index\"] = tmp_df[\"source_index_y\"]\n-\n-        cur_level = next_level\n-        cur_level_num += 1\n-        progress.update_progress(delta=len(cur_level))\n-\n-    return input_tree\n \n",
        "source_code_with_indent": "__author__ = \"Ian Hellen\"\n\n\nclass ProcessTreeSchemaException(MsticpyException):\n    <IND>\"\"\"Custom exception for Process Tree schema.\"\"\"\n\n\n<DED>@attr.s(auto_attribs=True)\nclass ProcSchema:\n    <IND>\"\"\"Property name lookup for Process event schema.\"\"\"\n\n    process_name: str\n    process_id: str\n    parent_id: str\n    logon_id: str\n    cmd_line: str\n    user_name: str\n    path_separator: str\n    time_stamp: str = \"TimeGenerated\"\n    parent_name: Optional[str] = None\n    target_logon_id: Optional[str] = None\n    user_id: Optional[str] = None\n\n    @property\n    def column_map(self) -> Dict[str, str]:\n        <IND>\"\"\"Return a dictionary that maps fields to schema names.\"\"\"\n        return {key: str(val) for key, val in attr.asdict(self).items()}\n\n    <DED>@property\n    def columns(self) -> Iterable[str]:\n        <IND>\"\"\"Return an interable of target column names.\"\"\"\n        return [str(val) for val in attr.asdict(self).values() if val]\n\n    <DED>@property\n    def event_type_col(self) -> str:\n        <IND>\"\"\"\n        Return the column name containing the event identifier.\n\n        Returns\n        -------\n        str\n            The name of the event ID column.\n\n        Raises\n        ------\n        ProcessTreeSchemaException\n            If the schema is not known.\n\n        \"\"\"\n        if self.process_name == \"NewProcessName\":\n            <IND>return \"EventID\"\n        <DED>if self.process_name == \"exe\":\n            <IND>return \"EventType\"\n        <DED>raise ProcessTreeSchemaException(\"Unknown schema.\")\n\n    <DED>@property\n    def event_filter(self) -> Any:\n        <IND>\"\"\"\n        Return the event type/ID to process for the current schema.\n\n        Returns\n        -------\n        Any\n            The value of the event ID to process.\n\n        Raises\n        ------\n        ProcessTreeSchemaException\n            If the schema is not known.\n\n        \"\"\"\n        if self.process_name == \"NewProcessName\":\n            <IND>return 4688\n        <DED>if self.process_name == \"exe\":\n            <IND>return \"SYSCALL_EXECVE\"\n        <DED>raise ProcessTreeSchemaException(\"Unknown schema.\")\n\n\n<DED><DED>WIN_EVENT_SCH = ProcSchema(\n    time_stamp=\"TimeGenerated\",\n    process_name=\"NewProcessName\",\n    process_id=\"NewProcessId\",\n    parent_name=\"ParentProcessName\",\n    parent_id=\"ProcessId\",\n    logon_id=\"SubjectLogonId\",\n    target_logon_id=\"TargetLogonId\",\n    cmd_line=\"CommandLine\",\n    user_name=\"SubjectUserName\",\n    path_separator=\"\\\\\",\n    user_id=\"SubjectUserSid\",\n)\n\nLX_EVENT_SCH = ProcSchema(\n    time_stamp=\"TimeGenerated\",\n    process_name=\"exe\",\n    process_id=\"pid\",\n    parent_name=None,\n    parent_id=\"ppid\",\n    logon_id=\"ses\",\n    target_logon_id=None,\n    cmd_line=\"cmdline\",\n    user_name=\"acct\",\n    path_separator=\"/\",\n    user_id=\"uid\",\n)\n\nLX_INT_TYPES = [\"argc\", \"egid\", \"euid\", \"gid\", \"auid\", \"ppid\", \"pid\", \"ses\", \"uid\"]\n\n\nTS_FMT_STRING = \"%Y-%m-%d %H:%M:%S.%f\"\n\n\ndef build_process_tree(\n    procs: pd.DataFrame,\n    schema: ProcSchema = None,\n    show_progress: bool = False,\n    debug: bool = False,\n) -> pd.DataFrame:\n    <IND>\"\"\"\n    Build process trees from the process events.\n\n    Parameters\n    ----------\n    procs : pd.DataFrame\n        Process events (Windows 4688 or Linux Auditd)\n    schema : ProcSchema, optional\n        The column schema to use, by default None\n        If None, then the schema is inferred\n    show_progress : bool\n        Shows the progress of the process (helpful for\n        very large data sets)\n    debug : bool\n        If True produces extra debugging output,\n        by default False\n\n    Returns\n    -------\n    pd.DataFrame\n        Process tree dataframe.\n\n    \"\"\"\n    # If schema is none, infer schema from columns\n    if not schema:\n        <IND>schema = infer_schema(procs)\n\n    <DED>data_len = len(procs)\n    section_len = int(data_len / 4)\n    progress_ui = Progress(completed_len=data_len * 2, visible=show_progress)\n\n    # Clean data\n    procs_cln = _clean_proc_data(procs, schema)\n    progress_ui.update_progress(delta=section_len)\n\n    # Merge parent-child\n    merged_procs = _merge_parent_by_time(procs_cln, schema)\n    if debug:\n        <IND>_check_merge_status(procs_cln, merged_procs, schema)\n    <DED>progress_ui.update_progress(delta=section_len)\n\n    # extract inferred parents\n    merged_procs_par = _extract_inferred_parents(merged_procs, schema)\n    if debug:\n        <IND>_check_inferred_parents(merged_procs, merged_procs_par)\n    <DED>progress_ui.update_progress(delta=section_len)\n\n    # create parent-child keys\n    merged_procs_keys = _assign_proc_keys(merged_procs_par, schema)\n    if debug:\n        <IND>_check_proc_keys(merged_procs_keys, schema)\n    <DED>progress_ui.update_progress(delta=section_len)\n\n    # Build process paths\n    proc_tree = _build_proc_tree(merged_procs_keys, progress_ui)\n\n    if show_progress:\n        <IND>print(get_summary_info(proc_tree))\n    <DED>return proc_tree\n\n\n<DED>def infer_schema(data: Union[pd.DataFrame, pd.Series]) -> ProcSchema:\n    <IND>\"\"\"\n    Infer the correct schema to use for this data set.\n\n    Parameters\n    ----------\n    data : Union[pd.DataFrame, pd.Series]\n        Data set to test\n\n    Returns\n    -------\n    ProcSchema\n        The schema most closely matching the data set.\n\n    \"\"\"\n    src_cols = data.columns if isinstance(data, pd.DataFrame) else data.index\n    lx_match = set(src_cols) & set(LX_EVENT_SCH.columns)\n    win_match = set(src_cols) & set(WIN_EVENT_SCH.columns)\n    return LX_EVENT_SCH if len(lx_match) > len(win_match) else WIN_EVENT_SCH\n\n\n<DED>def _clean_proc_data(procs: pd.DataFrame, schema: ProcSchema) -> pd.DataFrame:\n    <IND>\"\"\"Return cleaned process data.\"\"\"\n    procs_cln = (\n        procs.drop_duplicates().sort_values(schema.time_stamp, ascending=True).copy()\n    )\n\n    # Filter out any non-process events\n    event_type_filter = procs_cln[schema.event_type_col] == schema.event_filter\n    procs_cln = procs_cln[event_type_filter]\n\n    # Change Linux int cols to force int then to string types\n    type_chng_int_dict = {col: \"int\" for col in LX_INT_TYPES if col in procs.columns}\n    if type_chng_int_dict:\n        <IND>procs_cln = procs_cln.astype(type_chng_int_dict)\n        type_chng_str_dict = {\n            col: \"str\" for col in LX_INT_TYPES if col in procs.columns\n        }\n        procs_cln = procs_cln.astype(type_chng_str_dict)\n    <DED>if \"EventID\" not in procs_cln.columns and \"EventType\" in procs_cln.columns:\n        <IND>procs_cln = procs_cln.rename(columns={\"EventType\": \"EventID\"})\n\n    <DED>procs_cln[\"EffectiveLogonId\"] = procs_cln[schema.logon_id]\n    # Create effective logon Id for Windows, if the TargetLogonId is not 0x0\n    if schema.target_logon_id:\n        <IND>has_tgt_logonid = (procs_cln[schema.target_logon_id] != \"0x0\") & (\n            procs_cln[schema.target_logon_id].notna()\n        )\n        procs_cln.loc[has_tgt_logonid, \"EffectiveLogonId\"] = procs_cln[\n            schema.target_logon_id\n        ]\n    <DED>procs_cln[\"new_process_lc\"] = procs_cln[schema.process_name].str.lower()\n    if schema.parent_name:\n        <IND>no_pproc = procs_cln[schema.parent_name] == \"\"\n        procs_cln.loc[no_pproc, schema.parent_name] = \"unknown\"\n        procs_cln[\"parent_proc_lc\"] = procs_cln[schema.parent_name].str.lower()\n    <DED>procs_cln[\"source_index\"] = procs_cln.index\n    return procs_cln\n\n\n<DED>def _merge_parent_by_time(procs: pd.DataFrame, schema: ProcSchema) -> pd.DataFrame:\n    <IND>\"\"\"Merge procs with parents using merge_asof.\"\"\"\n    parent_procs = (\n        procs[\n            [\n                schema.process_id,\n                \"EffectiveLogonId\",\n                \"new_process_lc\",\n                \"source_index\",\n                schema.parent_id,\n                schema.time_stamp,\n                schema.process_name,\n            ]\n        ]\n        .assign(TimeGenerated_orig_par=procs[schema.time_stamp])\n        .sort_values(schema.time_stamp, ascending=True)\n    )\n    # if we have a parent name (Windows) - use that as part of the\n    # match\n    if schema.parent_name:\n        <IND>par_join_cols = [schema.process_id, \"new_process_lc\"]\n        child_join_cols = [schema.parent_id, \"parent_proc_lc\"]\n    <DED>else:\n        <IND>par_join_cols = [schema.process_id]\n        child_join_cols = [schema.parent_id]\n    # merge_asof merges on the \"by\" fields and then the closest time\n    # match in the time_stamp field. The default is to look backwards\n    # for a match on the right of the join (parent) that is a time earlier\n    # than the corresponding row on the left.\n    <DED>return pd.merge_asof(\n        left=procs.sort_values(schema.time_stamp, ascending=True),\n        right=parent_procs,\n        on=schema.time_stamp,\n        left_by=child_join_cols,\n        right_by=par_join_cols,\n        suffixes=(\"\", \"_par\"),\n    )\n\n\n<DED>def _extract_inferred_parents(\n    merged_procs: pd.DataFrame, schema: ProcSchema\n) -> pd.DataFrame:\n    <IND>\"\"\"Find any inferred parents and creates rows for them.\"\"\"\n    tz_aware = merged_procs.iloc[0][schema.time_stamp].tz\n    time_zero = pd.Timestamp(0) if tz_aware is None else pd.Timestamp(0, tz=0)\n\n    # Fill in missing values for root processes\n    root_procs_crit = merged_procs[\"source_index_par\"].isna()\n    merged_procs.loc[root_procs_crit, \"NewProcessId_par\"] = merged_procs[\n        schema.parent_id\n    ]\n    if schema.parent_name:\n        <IND>merged_procs.loc[root_procs_crit, \"new_process_lc_par\"] = merged_procs[\n            \"parent_proc_lc\"\n        ]\n    <DED>else:\n        <IND>merged_procs.loc[root_procs_crit, \"new_process_lc_par\"] = \"unknown\"\n        merged_procs.loc[root_procs_crit, f\"{schema.process_name}_par\"] = \"unknown\"\n        # If the schema doesn't have a ParentProcessName/parent_proc_lc - copy this value\n        # from the merged data for ALL processes\n        merged_procs[\"ParentProcessName\"] = merged_procs[f\"{schema.process_name}_par\"]\n        merged_procs[\"parent_proc_lc\"] = merged_procs[\"new_process_lc_par\"]\n    <DED>merged_procs.loc[root_procs_crit, \"EffectiveLogonId_par\"] = merged_procs[\n        schema.logon_id\n    ]\n    merged_procs.loc[root_procs_crit, \"TimeGenerated_orig_par\"] = time_zero\n\n    # Extract synthentic rows for the parents of root processes\n    inferred_parents = (\n        merged_procs[root_procs_crit][\n            [\n                \"TenantId\",\n                \"EventID\",\n                \"Computer\",\n                schema.parent_id,\n                \"EffectiveLogonId_par\",\n                \"ParentProcessName\",\n                \"parent_proc_lc\",\n            ]\n        ]\n        .rename(\n            columns={\n                schema.parent_id: schema.process_id,\n                \"ParentProcessName\": schema.process_name,\n                \"parent_proc_lc\": \"new_process_lc\",\n                \"EffectiveLogonId_par\": schema.logon_id,\n            }\n        )\n        .assign(TimeGenerated=time_zero, EffectiveLogonId=merged_procs[schema.logon_id])\n        .drop_duplicates()\n    )\n\n    return pd.concat(\n        [merged_procs, inferred_parents], ignore_index=True, axis=0, sort=False\n    )\n\n\n<DED>def _assign_proc_keys(\n    merged_procs_par: pd.DataFrame, schema: ProcSchema\n) -> pd.DataFrame:\n    <IND>\"\"\"Create process and parent keys for unambiguous par-child relation.\"\"\"\n    # Create Process Key\n    merged_procs_par[\"proc_key\"] = (\n        merged_procs_par[\"new_process_lc\"]\n        + merged_procs_par[schema.process_id].astype(str)\n        + merged_procs_par[schema.time_stamp]\n        .dt.round(\"10us\")\n        .dt.strftime(TS_FMT_STRING)\n    )\n    # Create Parent Key\n    merged_procs_par[\"parent_key\"] = (\n        merged_procs_par[\"parent_proc_lc\"]\n        + merged_procs_par[schema.parent_id].astype(str)\n        + merged_procs_par[\"TimeGenerated_orig_par\"]\n        .dt.round(\"10us\")\n        .dt.strftime(TS_FMT_STRING)\n    )\n    proc_tree = merged_procs_par.copy()\n    # Create labels based on node type\n    ppids = proc_tree[[\"parent_key\"]].set_index(\"parent_key\")\n    proc_tree = proc_tree.assign(IsRoot=False, IsLeaf=False, IsBranch=False)\n\n    is_root = proc_tree[\"parent_key\"].isna()\n    has_child = proc_tree[\"proc_key\"].isin(ppids.index)\n    proc_tree.loc[is_root, \"IsRoot\"] = True\n    proc_tree.loc[~has_child, \"IsLeaf\"] = True\n    proc_tree.loc[~is_root & has_child, \"IsBranch\"] = True\n\n    # Save the current numeric index as \"source_index\" converting to string\n    proc_tree[\"source_index\"] = proc_tree.index.astype(str)\n    # Set the index of the output frame to be the proc_key\n    proc_tree = proc_tree.set_index(\"proc_key\")\n\n    first_unique = proc_tree.index.duplicated()\n    proc_tree = proc_tree[~first_unique]\n    return proc_tree\n\n\n<DED>def _build_proc_tree(input_tree, progress: Progress, max_depth=-1):\n    <IND>\"\"\"Build process tree paths.\"\"\"\n    # set default path == current process ID\n    input_tree[\"path\"] = input_tree[\"source_index\"]\n\n    cur_level = input_tree[input_tree[\"IsRoot\"]]\n    remaining_procs = input_tree[~input_tree[\"IsRoot\"]]\n\n    cur_level_num = 0\n    progress.update_progress(delta=len(cur_level))\n    while True:\n        <IND>sel_crit = remaining_procs[\"parent_key\"].isin(cur_level.index)\n        next_level = remaining_procs[sel_crit].copy()\n        remaining_procs = remaining_procs[~sel_crit]\n\n        if next_level.empty:\n            <IND>progress.update_progress(new_total=progress.max)\n            break\n        <DED>if max_depth != -1 and cur_level_num >= max_depth:\n            <IND>print(f\"max path depth reached: {cur_level_num}\")\n            print(\n                f\"processed {progress.value} of {progress.max} for specified depth of {max_depth}\"\n            )\n            progress.update_progress(new_total=progress.max)\n            break\n\n        # merge next level with current level\n        <DED>tmp_df = next_level.merge(\n            cur_level[[\"source_index\", \"path\"]],\n            how=\"inner\",\n            left_on=\"parent_key\",\n            right_index=True,\n        )\n\n        # Build the path of these processes\n        # = parent_path + child source_index\n        next_level.loc[tmp_df.index, \"path\"] = (\n            tmp_df[\"path_y\"] + \"/\" + tmp_df[\"source_index_x\"]\n        )\n        input_tree.loc[next_level.index, \"path\"] = next_level[\"path\"]\n        input_tree.loc[tmp_df.index, \"parent_index\"] = tmp_df[\"source_index_y\"]\n\n        cur_level = next_level\n        cur_level_num += 1\n        progress.update_progress(delta=len(cur_level))\n\n    <DED>return input_tree\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "__author__ = \"Ian Hellen\"\n\n",
        "target_code_with_indent_exact_match": true
      },
      {
        "hunk_fit_TFix": false,
        "inside_window": false,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "\ndef build_process_key(source_proc: pd.Series, schema: ProcSchema = None) -> str:\n    \"\"\"\n    Return a process key from a process event.\n\n    Parameters\n    ----------\n    source_proc : pd.Series, optional\n        Source process\n    schema : ProcSchema, optional\n        The data schema to use, by default None\n        - if None the schema will be inferred\n\n    Returns\n    -------\n    str\n        Process key of the process\n\n    \"\"\"\n    if schema is None:\n        schema = infer_schema(source_proc)\n    proc_path = source_proc[schema.process_name].lower()\n    pid = source_proc[schema.process_id]\n    tstamp = pd.to_datetime(source_proc[schema.time_stamp]).strftime(TS_FMT_STRING)\n    return f\"{proc_path}{pid}{tstamp}\"\n\n",
        "source_code_len": 722,
        "target_code": "\n# def build_process_key(  # type: ignore  # noqa: F821\n#     source_proc: pd.Series,\n#     schema: \"ProcSchema\"\n# ) -> str:\n#     \"\"\"\n#     Return a process key from a process event.\n\n#     Parameters\n#     ----------\n#     source_proc : pd.Series, optional\n#         Source process\n#     schema : ProcSchema, optional\n#         The data schema to use, by default None\n#         - if None the schema will be inferred\n\n#     Returns\n#     -------\n#     str\n#         Process key of the process\n\n#     \"\"\"\n#     if schema is None:\n#         schema = infer_schema(source_proc)\n#     proc_path = source_proc[schema.process_name].lower()\n#     pid = source_proc[schema.process_id]\n#     tstamp = pd.to_datetime(source_proc[schema.time_stamp]).strftime(TS_FMT_STRING)\n#     return f\"{proc_path}{pid}{tstamp}\"\n\n",
        "target_code_len": 805,
        "diff_format": "@@ -462,26 +36,29 @@\n \n-def build_process_key(source_proc: pd.Series, schema: ProcSchema = None) -> str:\n-    \"\"\"\n-    Return a process key from a process event.\n-\n-    Parameters\n-    ----------\n-    source_proc : pd.Series, optional\n-        Source process\n-    schema : ProcSchema, optional\n-        The data schema to use, by default None\n-        - if None the schema will be inferred\n-\n-    Returns\n-    -------\n-    str\n-        Process key of the process\n-\n-    \"\"\"\n-    if schema is None:\n-        schema = infer_schema(source_proc)\n-    proc_path = source_proc[schema.process_name].lower()\n-    pid = source_proc[schema.process_id]\n-    tstamp = pd.to_datetime(source_proc[schema.time_stamp]).strftime(TS_FMT_STRING)\n-    return f\"{proc_path}{pid}{tstamp}\"\n+# def build_process_key(  # type: ignore  # noqa: F821\n+#     source_proc: pd.Series,\n+#     schema: \"ProcSchema\"\n+# ) -> str:\n+#     \"\"\"\n+#     Return a process key from a process event.\n+\n+#     Parameters\n+#     ----------\n+#     source_proc : pd.Series, optional\n+#         Source process\n+#     schema : ProcSchema, optional\n+#         The data schema to use, by default None\n+#         - if None the schema will be inferred\n+\n+#     Returns\n+#     -------\n+#     str\n+#         Process key of the process\n+\n+#     \"\"\"\n+#     if schema is None:\n+#         schema = infer_schema(source_proc)\n+#     proc_path = source_proc[schema.process_name].lower()\n+#     pid = source_proc[schema.process_id]\n+#     tstamp = pd.to_datetime(source_proc[schema.time_stamp]).strftime(TS_FMT_STRING)\n+#     return f\"{proc_path}{pid}{tstamp}\"\n \n",
        "source_code_with_indent": "\n<DED>def build_process_key(source_proc: pd.Series, schema: ProcSchema = None) -> str:\n    <IND>\"\"\"\n    Return a process key from a process event.\n\n    Parameters\n    ----------\n    source_proc : pd.Series, optional\n        Source process\n    schema : ProcSchema, optional\n        The data schema to use, by default None\n        - if None the schema will be inferred\n\n    Returns\n    -------\n    str\n        Process key of the process\n\n    \"\"\"\n    if schema is None:\n        <IND>schema = infer_schema(source_proc)\n    <DED>proc_path = source_proc[schema.process_name].lower()\n    pid = source_proc[schema.process_id]\n    tstamp = pd.to_datetime(source_proc[schema.time_stamp]).strftime(TS_FMT_STRING)\n    return f\"{proc_path}{pid}{tstamp}\"\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n# def build_process_key(  # type: ignore  # noqa: F821\n#     source_proc: pd.Series,\n#     schema: \"ProcSchema\"\n# ) -> str:\n#     \"\"\"\n#     Return a process key from a process event.\n\n#     Parameters\n#     ----------\n#     source_proc : pd.Series, optional\n#         Source process\n#     schema : ProcSchema, optional\n#         The data schema to use, by default None\n#         - if None the schema will be inferred\n\n#     Returns\n#     -------\n#     str\n#         Process key of the process\n\n#     \"\"\"\n#     if schema is None:\n#         schema = infer_schema(source_proc)\n#     proc_path = source_proc[schema.process_name].lower()\n#     pid = source_proc[schema.process_id]\n#     tstamp = pd.to_datetime(source_proc[schema.time_stamp]).strftime(TS_FMT_STRING)\n#     return f\"{proc_path}{pid}{tstamp}\"\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  },
  {
    "project": "microsoft/msticpy",
    "commit": "d425c771a19d67f333caba7c607f3fd53a8e070b",
    "filename": "msticpy/sectools/process_tree_utils.py",
    "filename_after_commit": "/home/chowyi/TypeAnnotation_Study/GitHub/microsoft-msticpy/msticpy/sectools/process_tree_utils.py",
    "file_hunks_size": 5,
    "min_patch_found": true,
    "single_hunk": true,
    "fit_TFix": false,
    "delete_only_patch": false,
    "has_suppression_all_hunks": true,
    "full_warning_msg": "msticpy/sectools/process_tree_utils.py:463:46 Incompatible variable type [9]: schema is declared to have type `ProcSchema` but is used as type `None`.",
    "message": " schema is declared to have type `ProcSchema` but is used as type `None`.",
    "rule_id": "Incompatible variable type [9]",
    "warning_line_no": 463,
    "warning_line": "def build_process_key(source_proc: pd.Series, schema: ProcSchema = None) -> str:",
    "min_patch": [
      {
        "hunk_fit_TFix": false,
        "inside_window": true,
        "delete_only": false,
        "has_suppression": true,
        "source_code": "\ndef build_process_key(source_proc: pd.Series, schema: ProcSchema = None) -> str:\n    \"\"\"\n    Return a process key from a process event.\n\n    Parameters\n    ----------\n    source_proc : pd.Series, optional\n        Source process\n    schema : ProcSchema, optional\n        The data schema to use, by default None\n        - if None the schema will be inferred\n\n    Returns\n    -------\n    str\n        Process key of the process\n\n    \"\"\"\n    if schema is None:\n        schema = infer_schema(source_proc)\n    proc_path = source_proc[schema.process_name].lower()\n    pid = source_proc[schema.process_id]\n    tstamp = pd.to_datetime(source_proc[schema.time_stamp]).strftime(TS_FMT_STRING)\n    return f\"{proc_path}{pid}{tstamp}\"\n\n",
        "source_code_len": 722,
        "target_code": "\n# def build_process_key(  # type: ignore  # noqa: F821\n#     source_proc: pd.Series,\n#     schema: \"ProcSchema\"\n# ) -> str:\n#     \"\"\"\n#     Return a process key from a process event.\n\n#     Parameters\n#     ----------\n#     source_proc : pd.Series, optional\n#         Source process\n#     schema : ProcSchema, optional\n#         The data schema to use, by default None\n#         - if None the schema will be inferred\n\n#     Returns\n#     -------\n#     str\n#         Process key of the process\n\n#     \"\"\"\n#     if schema is None:\n#         schema = infer_schema(source_proc)\n#     proc_path = source_proc[schema.process_name].lower()\n#     pid = source_proc[schema.process_id]\n#     tstamp = pd.to_datetime(source_proc[schema.time_stamp]).strftime(TS_FMT_STRING)\n#     return f\"{proc_path}{pid}{tstamp}\"\n\n",
        "target_code_len": 805,
        "diff_format": "@@ -462,26 +36,29 @@\n \n-def build_process_key(source_proc: pd.Series, schema: ProcSchema = None) -> str:\n-    \"\"\"\n-    Return a process key from a process event.\n-\n-    Parameters\n-    ----------\n-    source_proc : pd.Series, optional\n-        Source process\n-    schema : ProcSchema, optional\n-        The data schema to use, by default None\n-        - if None the schema will be inferred\n-\n-    Returns\n-    -------\n-    str\n-        Process key of the process\n-\n-    \"\"\"\n-    if schema is None:\n-        schema = infer_schema(source_proc)\n-    proc_path = source_proc[schema.process_name].lower()\n-    pid = source_proc[schema.process_id]\n-    tstamp = pd.to_datetime(source_proc[schema.time_stamp]).strftime(TS_FMT_STRING)\n-    return f\"{proc_path}{pid}{tstamp}\"\n+# def build_process_key(  # type: ignore  # noqa: F821\n+#     source_proc: pd.Series,\n+#     schema: \"ProcSchema\"\n+# ) -> str:\n+#     \"\"\"\n+#     Return a process key from a process event.\n+\n+#     Parameters\n+#     ----------\n+#     source_proc : pd.Series, optional\n+#         Source process\n+#     schema : ProcSchema, optional\n+#         The data schema to use, by default None\n+#         - if None the schema will be inferred\n+\n+#     Returns\n+#     -------\n+#     str\n+#         Process key of the process\n+\n+#     \"\"\"\n+#     if schema is None:\n+#         schema = infer_schema(source_proc)\n+#     proc_path = source_proc[schema.process_name].lower()\n+#     pid = source_proc[schema.process_id]\n+#     tstamp = pd.to_datetime(source_proc[schema.time_stamp]).strftime(TS_FMT_STRING)\n+#     return f\"{proc_path}{pid}{tstamp}\"\n \n",
        "source_code_with_indent": "\n<DED>def build_process_key(source_proc: pd.Series, schema: ProcSchema = None) -> str:\n    <IND>\"\"\"\n    Return a process key from a process event.\n\n    Parameters\n    ----------\n    source_proc : pd.Series, optional\n        Source process\n    schema : ProcSchema, optional\n        The data schema to use, by default None\n        - if None the schema will be inferred\n\n    Returns\n    -------\n    str\n        Process key of the process\n\n    \"\"\"\n    if schema is None:\n        <IND>schema = infer_schema(source_proc)\n    <DED>proc_path = source_proc[schema.process_name].lower()\n    pid = source_proc[schema.process_id]\n    tstamp = pd.to_datetime(source_proc[schema.time_stamp]).strftime(TS_FMT_STRING)\n    return f\"{proc_path}{pid}{tstamp}\"\n\n",
        "source_code_with_indent_exact_match": true,
        "target_code_with_indent": "\n# def build_process_key(  # type: ignore  # noqa: F821\n#     source_proc: pd.Series,\n#     schema: \"ProcSchema\"\n# ) -> str:\n#     \"\"\"\n#     Return a process key from a process event.\n\n#     Parameters\n#     ----------\n#     source_proc : pd.Series, optional\n#         Source process\n#     schema : ProcSchema, optional\n#         The data schema to use, by default None\n#         - if None the schema will be inferred\n\n#     Returns\n#     -------\n#     str\n#         Process key of the process\n\n#     \"\"\"\n#     if schema is None:\n#         schema = infer_schema(source_proc)\n#     proc_path = source_proc[schema.process_name].lower()\n#     pid = source_proc[schema.process_id]\n#     tstamp = pd.to_datetime(source_proc[schema.time_stamp]).strftime(TS_FMT_STRING)\n#     return f\"{proc_path}{pid}{tstamp}\"\n\n",
        "target_code_with_indent_exact_match": true
      }
    ]
  }
]